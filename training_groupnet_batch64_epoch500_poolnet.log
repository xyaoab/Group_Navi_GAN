[INFO: train.py:  132]: Initializing train dataset
[INFO: train.py:  134]: Initializing val dataset
[INFO: train.py:  148]: There are 21.03125 iterations per epoch
[INFO: train.py:  151]: There are 10515 iterations
[INFO: train.py:  154]: There are 500 epochs
[INFO: train.py:  193]: Here is the late-attention generator:
[INFO: train.py:  194]: LateAttentionFullGenerator(
  (intention_encoder): Encoder(
    (encoder): LSTM(16, 32)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
  )
  (force_encoder): Encoder(
    (encoder): LSTM(16, 32)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
  )
  (intention_decoder): Decoder(
    (decoder): LSTM(16, 32)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
    (hidden2pos): Linear(in_features=32, out_features=2, bias=True)
  )
  (force_decoder): Decoder(
    (decoder): LSTM(16, 32)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
    (hidden2pos): Linear(in_features=32, out_features=2, bias=True)
  )
  (pool_net): PoolHiddenNet(
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
    (mlp_pre_pool): Sequential(
      (0): Linear(in_features=48, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=32, bias=True)
      (3): ReLU()
    )
  )
  (force_mlp_decoder_context): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=32, bias=True)
    (3): ReLU()
  )
  (intention_mlp_decoder_context): Sequential(
    (0): Linear(in_features=32, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=30, bias=True)
    (3): ReLU()
  )
  (attention_mlp): Linear(in_features=64, out_features=2, bias=True)
)
[INFO: train.py:  210]: Here is the discriminator:
[INFO: train.py:  211]: TrajectoryDiscriminator(
  (encoder): Encoder(
    (encoder): LSTM(16, 64)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
  )
  (real_classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=1, bias=True)
    (3): ReLU()
  )
)
[INFO: train.py:  233]: Restoring from checkpoint ./models/groupnet_zara1_batch64_epoch500_poolnet_with_model.pt
[INFO: train.py:  282]: Starting epoch 252
[INFO: train.py:  283]: Epoch resist loss: tensor([ 0.])
[INFO: train.py:  572]: resist loss: tensor([ 21.8454], device='cuda:0')
[INFO: train.py:  313]: g step took 9.458553552627563
[INFO: train.py:  330]: Checking stats on val ...

[INFO: train.py:  133]: Initializing train dataset
[INFO: train.py:  135]: Initializing val dataset
[INFO: train.py:  149]: There are 21.03125 iterations per epoch
[INFO: train.py:  152]: There are 10515 iterations
[INFO: train.py:  155]: There are 500 epochs
[INFO: train.py:  194]: Here is the late-attention generator:
[INFO: train.py:  195]: LateAttentionFullGenerator(
  (intention_encoder): Encoder(
    (encoder): LSTM(16, 32)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
  )
  (force_encoder): Encoder(
    (encoder): LSTM(16, 32)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
  )
  (intention_decoder): Decoder(
    (decoder): LSTM(16, 32)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
    (hidden2pos): Linear(in_features=32, out_features=2, bias=True)
  )
  (force_decoder): Decoder(
    (decoder): LSTM(16, 32)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
    (hidden2pos): Linear(in_features=32, out_features=2, bias=True)
  )
  (pool_net): PoolHiddenNet(
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
    (mlp_pre_pool): Sequential(
      (0): Linear(in_features=48, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=32, bias=True)
      (3): ReLU()
    )
  )
  (force_mlp_decoder_context): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=32, bias=True)
    (3): ReLU()
  )
  (intention_mlp_decoder_context): Sequential(
    (0): Linear(in_features=32, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=30, bias=True)
    (3): ReLU()
  )
  (attention_mlp): Linear(in_features=64, out_features=2, bias=True)
)
[INFO: train.py:  211]: Here is the discriminator:
[INFO: train.py:  212]: TrajectoryDiscriminator(
  (encoder): Encoder(
    (encoder): LSTM(16, 64)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
  )
  (real_classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=1, bias=True)
    (3): ReLU()
  )
)
[INFO: train.py:  234]: Restoring from checkpoint ./models/trackedgroup_headingloss_zara1_batch64_epoch500_poolnet_with_model.pt
[INFO: train.py:  283]: Starting epoch 246
[INFO: train.py:  284]: Epoch resist loss: tensor([ 0.])
[INFO: train.py:  593]: resist loss: tensor([ 36.8567], device='cuda:0')
[INFO: train.py:  314]: g step took 3.827376365661621
[INFO: train.py:  331]: Checking stats on val ...
[INFO: train.py:  335]: Checking stats on train ...
[INFO: train.py:  342]:   [val] ade: 0.516
[INFO: train.py:  342]:   [val] ade_l: 1.136
[INFO: train.py:  342]:   [val] ade_nl: 0.945
[INFO: train.py:  342]:   [val] d_loss: 1.402
[INFO: train.py:  342]:   [val] fde: 1.272
[INFO: train.py:  342]:   [val] fde_l: 2.801
[INFO: train.py:  342]:   [val] fde_nl: 2.331
[INFO: train.py:  342]:   [val] g_l2_loss_abs: 0.342
[INFO: train.py:  342]:   [val] g_l2_loss_rel: 0.342
[INFO: train.py:  342]:   [val] resist_count: 2796.000
[INFO: train.py:  342]:   [val] resist_loss: 0.181
[INFO: train.py:  345]:   [train] ade: 0.480
[INFO: train.py:  345]:   [train] ade_l: 1.025
[INFO: train.py:  345]:   [train] ade_nl: 0.902
[INFO: train.py:  345]:   [train] d_loss: 1.404
[INFO: train.py:  345]:   [train] fde: 1.163
[INFO: train.py:  345]:   [train] fde_l: 2.485
[INFO: train.py:  345]:   [train] fde_nl: 2.187
[INFO: train.py:  345]:   [train] g_l2_loss_abs: 0.272
[INFO: train.py:  345]:   [train] g_l2_loss_rel: 0.272
[INFO: train.py:  345]:   [train] resist_count: 3122.000
[INFO: train.py:  345]:   [train] resist_loss: 0.135
[INFO: train.py:  372]: Saving checkpoint to ./models/trackedgroup_headingloss_zara1_batch64_epoch500_poolnet_with_model.pt
[INFO: train.py:  374]: Done.
[INFO: train.py:  380]: Saving checkpoint to ./models/trackedgroup_headingloss_zara1_batch64_epoch500_poolnet_no_model.pt
[INFO: train.py:  391]: Done.
[INFO: train.py:  593]: resist loss: tensor([ 33.8574], device='cuda:0')
[INFO: train.py:  314]: g step took 3.1035144329071045
[INFO: train.py:  320]: Interation 10510 took 15.706286191940308
[INFO: train.py:  593]: resist loss: tensor([ 42.5693], device='cuda:0')
[INFO: train.py:  314]: g step took 3.1479737758636475
[INFO: train.py:  320]: Interation 10511 took 3.148452043533325
[INFO: train.py:  593]: resist loss: tensor([ 24.8905], device='cuda:0')
[INFO: train.py:  314]: g step took 2.309511184692383
[INFO: train.py:  320]: Interation 10512 took 2.3147733211517334
[INFO: train.py:  593]: resist loss: tensor([ 26.9932], device='cuda:0')
[INFO: train.py:  314]: g step took 1.8680641651153564
[INFO: train.py:  320]: Interation 10513 took 1.8686912059783936

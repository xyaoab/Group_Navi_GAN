[INFO: train.py:  133]: Initializing train dataset
[INFO: train.py:  135]: Initializing val dataset
[INFO: train.py:  149]: There are 21.03125 iterations per epoch
[INFO: train.py:  152]: There are 10515 iterations
[INFO: train.py:  155]: There are 500 epochs
[INFO: train.py:  194]: Here is the late-attention generator:
[INFO: train.py:  195]: LateAttentionFullGenerator(
  (intention_encoder): Encoder(
    (encoder): LSTM(16, 32)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
  )
  (force_encoder): Encoder(
    (encoder): LSTM(16, 32)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
  )
  (intention_decoder): Decoder(
    (decoder): LSTM(16, 32)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
    (hidden2pos): Linear(in_features=32, out_features=2, bias=True)
  )
  (force_decoder): Decoder(
    (decoder): LSTM(16, 32)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
    (hidden2pos): Linear(in_features=32, out_features=2, bias=True)
  )
  (pool_net): PoolHiddenNet(
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
    (mlp_pre_pool): Sequential(
      (0): Linear(in_features=48, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=32, bias=True)
      (3): ReLU()
    )
  )
  (force_mlp_decoder_context): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=32, bias=True)
    (3): ReLU()
  )
  (intention_mlp_decoder_context): Sequential(
    (0): Linear(in_features=32, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=30, bias=True)
    (3): ReLU()
  )
  (attention_mlp): Linear(in_features=64, out_features=2, bias=True)
)
[INFO: train.py:  211]: Here is the discriminator:
[INFO: train.py:  212]: TrajectoryDiscriminator(
  (encoder): Encoder(
    (encoder): LSTM(16, 64)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
  )
  (real_classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=1, bias=True)
    (3): ReLU()
  )
)
[INFO: train.py:  234]: Restoring from checkpoint ./models/svmgroup_zara1_batch64_epoch500_poolnet_with_model.pt
[INFO: train.py:  283]: Starting epoch 247
[INFO: train.py:  284]: Epoch resist loss: tensor([ 0.])
[INFO: train.py:  581]: resist loss: tensor([ 48.5367], device='cuda:0')
[INFO: train.py:  314]: g step took 1.7525510787963867
[INFO: train.py:  331]: Checking stats on val ...
[INFO: train.py:  335]: Checking stats on train ...
[INFO: train.py:  342]:   [val] ade: 0.497
[INFO: train.py:  342]:   [val] ade_l: 1.094
[INFO: train.py:  342]:   [val] ade_nl: 0.911
[INFO: train.py:  342]:   [val] d_loss: 1.386
[INFO: train.py:  342]:   [val] fde: 1.155
[INFO: train.py:  342]:   [val] fde_l: 2.543
[INFO: train.py:  342]:   [val] fde_nl: 2.116
[INFO: train.py:  342]:   [val] g_l2_loss_abs: 0.378
[INFO: train.py:  342]:   [val] g_l2_loss_rel: 0.378
[INFO: train.py:  342]:   [val] resist_count: 4934.000
[INFO: train.py:  342]:   [val] resist_loss: 0.249
[INFO: train.py:  345]:   [train] ade: 0.450
[INFO: train.py:  345]:   [train] ade_l: 0.944
[INFO: train.py:  345]:   [train] ade_nl: 0.861
[INFO: train.py:  345]:   [train] d_loss: 1.386
[INFO: train.py:  345]:   [train] fde: 1.010
[INFO: train.py:  345]:   [train] fde_l: 2.118
[INFO: train.py:  345]:   [train] fde_nl: 1.931
[INFO: train.py:  345]:   [train] g_l2_loss_abs: 0.259
[INFO: train.py:  345]:   [train] g_l2_loss_rel: 0.259
[INFO: train.py:  345]:   [train] resist_count: 6158.000
[INFO: train.py:  345]:   [train] resist_loss: 0.241
[INFO: train.py:  372]: Saving checkpoint to ./models/svmgroup_zara1_batch64_epoch500_poolnet_with_model.pt
[INFO: train.py:  374]: Done.
[INFO: train.py:  380]: Saving checkpoint to ./models/svmgroup_zara1_batch64_epoch500_poolnet_no_model.pt
[INFO: train.py:  391]: Done.
[INFO: train.py:  581]: resist loss: tensor([ 22.2255], device='cuda:0')
[INFO: train.py:  314]: g step took 1.4870681762695312
[INFO: train.py:  320]: Interation 10510 took 9.231777906417847
[INFO: train.py:  581]: resist loss: tensor([ 33.5612], device='cuda:0')
[INFO: train.py:  314]: g step took 1.7184903621673584
[INFO: train.py:  320]: Interation 10511 took 1.7190897464752197
[INFO: train.py:  581]: resist loss: tensor([ 27.3572], device='cuda:0')
[INFO: train.py:  314]: g step took 1.7867281436920166
[INFO: train.py:  320]: Interation 10512 took 1.787426233291626
[INFO: train.py:  581]: resist loss: tensor([ 27.7966], device='cuda:0')
[INFO: train.py:  314]: g step took 1.7694370746612549
[INFO: train.py:  320]: Interation 10513 took 1.7700016498565674

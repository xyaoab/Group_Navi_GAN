cude available True
[INFO: train.py:  131]: Initializing train dataset
[INFO: train.py:  133]: Initializing val dataset
[INFO: train.py:  147]: There are 21.03125 iterations per epoch
[INFO: train.py:  150]: There are 10515 iterations
[INFO: train.py:  153]: There are 500 epochs
[INFO: train.py:  190]: Here is the late-attention generator:
[INFO: train.py:  191]: LateAttentionFullGenerator(
  (intention_encoder): Encoder(
    (encoder): LSTM(16, 32)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
  )
  (force_encoder): Encoder(
    (encoder): LSTM(16, 32)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
  )
  (intention_decoder): Decoder(
    (decoder): LSTM(16, 32)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
    (hidden2pos): Linear(in_features=32, out_features=2, bias=True)
  )
  (force_decoder): Decoder(
    (decoder): LSTM(16, 32)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
    (hidden2pos): Linear(in_features=32, out_features=2, bias=True)
  )
  (pool_net): SocialPooling(
    (mlp_pool): Sequential(
      (0): Linear(in_features=2048, out_features=32, bias=True)
      (1): ReLU()
    )
  )
  (force_mlp_decoder_context): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=32, bias=True)
    (3): ReLU()
  )
  (intention_mlp_decoder_context): Sequential(
    (0): Linear(in_features=32, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=30, bias=True)
    (3): ReLU()
  )
  (attention_mlp): Linear(in_features=64, out_features=2, bias=True)
)
[INFO: train.py:  207]: Here is the discriminator:
[INFO: train.py:  208]: TrajectoryDiscriminator(
  (encoder): Encoder(
    (encoder): LSTM(16, 64)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
  )
  (real_classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=1, bias=True)
    (3): ReLU()
  )
)
[INFO: train.py:  230]: Restoring from checkpoint ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  279]: Starting epoch 195
[INFO: train.py:  280]: Epoch resist loss: tensor([ 0.])
[INFO: train.py:  558]: resist loss: tensor([ 0.7736], device='cuda:0')
[INFO: train.py:  310]: g step took 1.1898305416107178
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 492, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 492, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 561, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 561, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 622, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 622, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 669, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 669, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 496, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 496, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 530, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 530, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 579, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 579, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 605, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 605, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 489, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 489, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 490, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 490, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 645, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 645, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 183, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 183, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 713, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 713, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 892, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 892, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 731, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 731, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 1016, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 1016, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 680, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 680, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 629, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 629, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 707, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 707, 2])
[INFO: train.py:  338]:   [val] ade: 0.633
[INFO: train.py:  338]:   [val] ade_l: 1.393
[INFO: train.py:  338]:   [val] ade_nl: 1.159
[INFO: train.py:  338]:   [val] d_loss: 1.406
[INFO: train.py:  338]:   [val] fde: 1.292
[INFO: train.py:  338]:   [val] fde_l: 2.844
[INFO: train.py:  338]:   [val] fde_nl: 2.367
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.463
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.463
[INFO: train.py:  338]:   [val] resist_count: 2721.000
[INFO: train.py:  338]:   [val] resist_loss: 0.330
[INFO: train.py:  341]:   [train] ade: 0.638
[INFO: train.py:  341]:   [train] ade_l: 1.374
[INFO: train.py:  341]:   [train] ade_nl: 1.190
[INFO: train.py:  341]:   [train] d_loss: 1.414
[INFO: train.py:  341]:   [train] fde: 1.223
[INFO: train.py:  341]:   [train] fde_l: 2.634
[INFO: train.py:  341]:   [train] fde_nl: 2.282
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.419
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.419
[INFO: train.py:  341]:   [train] resist_count: 2834.000
[INFO: train.py:  341]:   [train] resist_loss: 0.184
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.5892], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3022286891937256
[INFO: train.py:  316]: Interation 8310 took 7.242315053939819
[INFO: train.py:  558]: resist loss: tensor([ 9.9424], device='cuda:0')
[INFO: train.py:  310]: g step took 1.431509017944336
[INFO: train.py:  316]: Interation 8311 took 1.4363820552825928
[INFO: train.py:  558]: resist loss: tensor([ 1.4013], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3191769123077393
[INFO: train.py:  316]: Interation 8312 took 1.3195490837097168
[INFO: train.py:  558]: resist loss: tensor([ 2.0486], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3992509841918945
[INFO: train.py:  316]: Interation 8313 took 1.3996262550354004
[INFO: train.py:  558]: resist loss: tensor([ 11.4285], device='cuda:0')
[INFO: train.py:  310]: g step took 1.304497241973877
[INFO: train.py:  316]: Interation 8314 took 1.3282179832458496
[INFO: train.py:  558]: resist loss: tensor([ 12.7780], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5641047954559326
[INFO: train.py:  316]: Interation 8315 took 1.5644574165344238
[INFO: train.py:  558]: resist loss: tensor([ 9.9145], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4756219387054443
[INFO: train.py:  316]: Interation 8316 took 1.4760468006134033
[INFO: train.py:  558]: resist loss: tensor([ 0.7153], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4052200317382812
[INFO: train.py:  316]: Interation 8317 took 1.4055898189544678
[INFO: train.py:  558]: resist loss: tensor([ 1.4803], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5595970153808594
[INFO: train.py:  316]: Interation 8318 took 1.5777192115783691
[INFO: train.py:  558]: resist loss: tensor([ 9.5446], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8157260417938232
[INFO: train.py:  316]: Interation 8319 took 1.8195724487304688
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 499, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 499, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 571, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 571, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 497, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 497, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 657, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 657, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 605, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 605, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 558, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 558, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 527, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 527, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 539, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 539, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 537, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 537, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 622, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 622, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 616, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 616, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 133, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 133, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 918, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 918, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 684, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 684, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 726, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 726, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 732, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 732, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 718, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 718, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 805, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 805, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 936, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 936, 2])
[INFO: train.py:  338]:   [val] ade: 0.599
[INFO: train.py:  338]:   [val] ade_l: 1.320
[INFO: train.py:  338]:   [val] ade_nl: 1.098
[INFO: train.py:  338]:   [val] d_loss: 1.411
[INFO: train.py:  338]:   [val] fde: 1.254
[INFO: train.py:  338]:   [val] fde_l: 2.760
[INFO: train.py:  338]:   [val] fde_nl: 2.297
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.422
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.422
[INFO: train.py:  338]:   [val] resist_count: 3036.000
[INFO: train.py:  338]:   [val] resist_loss: 0.328
[INFO: train.py:  341]:   [train] ade: 0.597
[INFO: train.py:  341]:   [train] ade_l: 1.230
[INFO: train.py:  341]:   [train] ade_nl: 1.161
[INFO: train.py:  341]:   [train] d_loss: 1.398
[INFO: train.py:  341]:   [train] fde: 1.174
[INFO: train.py:  341]:   [train] fde_l: 2.418
[INFO: train.py:  341]:   [train] fde_nl: 2.282
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.365
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.365
[INFO: train.py:  341]:   [train] resist_count: 2981.000
[INFO: train.py:  341]:   [train] resist_loss: 0.169
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 6.9231], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3769562244415283
[INFO: train.py:  316]: Interation 8320 took 10.554892778396606
[INFO: train.py:  558]: resist loss: tensor([ 0.9408], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8604156970977783
[INFO: train.py:  316]: Interation 8321 took 1.860766887664795
[INFO: train.py:  558]: resist loss: tensor([ 2.6905], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9398181438446045
[INFO: train.py:  316]: Interation 8322 took 1.9401359558105469
[INFO: train.py:  558]: resist loss: tensor([ 0.5813], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1541452407836914
[INFO: train.py:  316]: Interation 8323 took 2.1545093059539795
[INFO: train.py:  558]: resist loss: tensor([ 0.9308], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2787365913391113
[INFO: train.py:  316]: Interation 8324 took 2.279167413711548
[INFO: train.py:  558]: resist loss: tensor([ 2.1942], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4768271446228027
[INFO: train.py:  316]: Interation 8325 took 1.4771900177001953
[INFO: train.py:  558]: resist loss: tensor([ 6.8328], device='cuda:0')
[INFO: train.py:  310]: g step took 1.931180477142334
[INFO: train.py:  316]: Interation 8326 took 1.935269832611084
[INFO: train.py:  558]: resist loss: tensor([ 2.1637], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7772290706634521
[INFO: train.py:  316]: Interation 8327 took 1.7809622287750244
[INFO: train.py:  558]: resist loss: tensor([ 10.8125], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9662132263183594
[INFO: train.py:  316]: Interation 8328 took 1.9700384140014648
[INFO: train.py:  558]: resist loss: tensor([ 5.4482], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7986860275268555
[INFO: train.py:  316]: Interation 8329 took 1.8030719757080078
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 635, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 635, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 576, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 576, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 458, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 458, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 590, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 590, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 599, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 599, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 601, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 601, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 508, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 508, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 534, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 534, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 553, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 553, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 537, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 537, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 598, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 598, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 172, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 172, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 769, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 769, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 884, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 884, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 874, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 874, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 658, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 658, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 797, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 797, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 822, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 822, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 780, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 780, 2])
[INFO: train.py:  338]:   [val] ade: 0.642
[INFO: train.py:  338]:   [val] ade_l: 1.414
[INFO: train.py:  338]:   [val] ade_nl: 1.177
[INFO: train.py:  338]:   [val] d_loss: 1.406
[INFO: train.py:  338]:   [val] fde: 1.334
[INFO: train.py:  338]:   [val] fde_l: 2.937
[INFO: train.py:  338]:   [val] fde_nl: 2.444
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.458
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.458
[INFO: train.py:  338]:   [val] resist_count: 3218.000
[INFO: train.py:  338]:   [val] resist_loss: 0.349
[INFO: train.py:  341]:   [train] ade: 0.641
[INFO: train.py:  341]:   [train] ade_l: 1.403
[INFO: train.py:  341]:   [train] ade_nl: 1.180
[INFO: train.py:  341]:   [train] d_loss: 1.406
[INFO: train.py:  341]:   [train] fde: 1.257
[INFO: train.py:  341]:   [train] fde_l: 2.752
[INFO: train.py:  341]:   [train] fde_nl: 2.315
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.410
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.410
[INFO: train.py:  341]:   [train] resist_count: 3409.000
[INFO: train.py:  341]:   [train] resist_loss: 0.189
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 1.2501], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0398898124694824
[INFO: train.py:  316]: Interation 8330 took 10.199506521224976
[INFO: train.py:  558]: resist loss: tensor([ 5.0383], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9883949756622314
[INFO: train.py:  316]: Interation 8331 took 1.991774559020996
[INFO: train.py:  558]: resist loss: tensor([ 0.6206], device='cuda:0')
[INFO: train.py:  310]: g step took 1.734459638595581
[INFO: train.py:  316]: Interation 8332 took 1.7385573387145996
[INFO: train.py:  558]: resist loss: tensor([ 0.8659], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9133844375610352
[INFO: train.py:  316]: Interation 8333 took 1.9171693325042725
[INFO: train.py:  558]: resist loss: tensor([ 2.0925], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7897841930389404
[INFO: train.py:  316]: Interation 8334 took 1.793463945388794
[INFO: train.py:  558]: resist loss: tensor([ 6.8799], device='cuda:0')
[INFO: train.py:  310]: g step took 1.980659008026123
[INFO: train.py:  316]: Interation 8335 took 1.984464406967163
[INFO: train.py:  558]: resist loss: tensor([ 6.6914], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2560958862304688
[INFO: train.py:  316]: Interation 8336 took 2.2598464488983154
[INFO: train.py:  558]: resist loss: tensor([ 0.8192], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9024477005004883
[INFO: train.py:  316]: Interation 8337 took 1.9062285423278809
[INFO: train.py:  558]: resist loss: tensor([ 1.1968], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2855899333953857
[INFO: train.py:  316]: Interation 8338 took 2.289301872253418
[INFO: train.py:  558]: resist loss: tensor([ 0.4812], device='cuda:0')
[INFO: train.py:  310]: g step took 2.508641242980957
[INFO: train.py:  316]: Interation 8339 took 2.512514352798462
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 505, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 505, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 585, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 585, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 564, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 564, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 594, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 594, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 643, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 643, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 505, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 505, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 622, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 622, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 474, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 474, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 592, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 592, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 597, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 597, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 513, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 513, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 167, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 167, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 746, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 746, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 874, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 874, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 684, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 684, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 693, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 693, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 796, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 796, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 736, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 736, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 809, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 809, 2])
[INFO: train.py:  338]:   [val] ade: 0.641
[INFO: train.py:  338]:   [val] ade_l: 1.412
[INFO: train.py:  338]:   [val] ade_nl: 1.175
[INFO: train.py:  338]:   [val] d_loss: 1.413
[INFO: train.py:  338]:   [val] fde: 1.359
[INFO: train.py:  338]:   [val] fde_l: 2.993
[INFO: train.py:  338]:   [val] fde_nl: 2.490
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.466
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.466
[INFO: train.py:  338]:   [val] resist_count: 3640.000
[INFO: train.py:  338]:   [val] resist_loss: 0.446
[INFO: train.py:  341]:   [train] ade: 0.631
[INFO: train.py:  341]:   [train] ade_l: 1.311
[INFO: train.py:  341]:   [train] ade_nl: 1.217
[INFO: train.py:  341]:   [train] d_loss: 1.408
[INFO: train.py:  341]:   [train] fde: 1.265
[INFO: train.py:  341]:   [train] fde_l: 2.628
[INFO: train.py:  341]:   [train] fde_nl: 2.440
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.401
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.401
[INFO: train.py:  341]:   [train] resist_count: 3362.000
[INFO: train.py:  341]:   [train] resist_loss: 0.201
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 7.0222], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3297841548919678
[INFO: train.py:  316]: Interation 8340 took 10.72517466545105
[INFO: train.py:  558]: resist loss: tensor([ 12.0064], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7510805130004883
[INFO: train.py:  316]: Interation 8341 took 1.7549026012420654
[INFO: train.py:  558]: resist loss: tensor([ 1.2466], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5801441669464111
[INFO: train.py:  316]: Interation 8342 took 1.583937644958496
[INFO: train.py:  558]: resist loss: tensor([ 3.6257], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9753148555755615
[INFO: train.py:  316]: Interation 8343 took 1.9790852069854736
[INFO: train.py:  558]: resist loss: tensor([ 2.7306], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0199503898620605
[INFO: train.py:  316]: Interation 8344 took 2.0237128734588623
[INFO: train.py:  558]: resist loss: tensor([ 3.8339], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6943809986114502
[INFO: train.py:  316]: Interation 8345 took 1.698063850402832
[INFO: train.py:  558]: resist loss: tensor([ 10.1737], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3461127281188965
[INFO: train.py:  316]: Interation 8346 took 2.349868059158325
[INFO: train.py:  558]: resist loss: tensor([ 15.6599], device='cuda:0')
[INFO: train.py:  310]: g step took 2.28810977935791
[INFO: train.py:  316]: Interation 8347 took 2.2921128273010254
[INFO: train.py:  558]: resist loss: tensor([ 1.3407], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0847692489624023
[INFO: train.py:  316]: Interation 8348 took 2.0888583660125732
[INFO: train.py:  558]: resist loss: tensor([ 7.1524], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9703166484832764
[INFO: train.py:  316]: Interation 8349 took 1.9740090370178223
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 586, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 586, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 535, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 535, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 553, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 553, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 561, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 561, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 488, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 488, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 488, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 488, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 652, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 652, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 544, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 544, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 613, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 613, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 610, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 610, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 562, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 562, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 169, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 169, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 573, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 573, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 882, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 882, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 817, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 817, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 756, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 756, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 949, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 949, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 740, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 740, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 645, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 645, 2])
[INFO: train.py:  338]:   [val] ade: 0.648
[INFO: train.py:  338]:   [val] ade_l: 1.427
[INFO: train.py:  338]:   [val] ade_nl: 1.188
[INFO: train.py:  338]:   [val] d_loss: 1.407
[INFO: train.py:  338]:   [val] fde: 1.233
[INFO: train.py:  338]:   [val] fde_l: 2.716
[INFO: train.py:  338]:   [val] fde_nl: 2.260
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.461
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.461
[INFO: train.py:  338]:   [val] resist_count: 3121.000
[INFO: train.py:  338]:   [val] resist_loss: 0.372
[INFO: train.py:  341]:   [train] ade: 0.678
[INFO: train.py:  341]:   [train] ade_l: 1.442
[INFO: train.py:  341]:   [train] ade_nl: 1.279
[INFO: train.py:  341]:   [train] d_loss: 1.397
[INFO: train.py:  341]:   [train] fde: 1.212
[INFO: train.py:  341]:   [train] fde_l: 2.579
[INFO: train.py:  341]:   [train] fde_nl: 2.287
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.445
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.445
[INFO: train.py:  341]:   [train] resist_count: 2715.000
[INFO: train.py:  341]:   [train] resist_loss: 0.172
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 11.9033], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9973070621490479
[INFO: train.py:  316]: Interation 8350 took 10.316421508789062
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 9.7917], device='cuda:0')
[INFO: train.py:  310]: g step took 0.17774033546447754
[INFO: train.py:  316]: Interation 8351 took 0.1814584732055664
[INFO: train.py:  279]: Starting epoch 196
[INFO: train.py:  280]: Epoch resist loss: tensor([ 202.8632])
[INFO: train.py:  558]: resist loss: tensor([ 6.8189], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2832093238830566
[INFO: train.py:  316]: Interation 8352 took 2.6514532566070557
[INFO: train.py:  558]: resist loss: tensor([ 3.8963], device='cuda:0')
[INFO: train.py:  310]: g step took 2.038417100906372
[INFO: train.py:  316]: Interation 8353 took 2.0388193130493164
[INFO: train.py:  558]: resist loss: tensor([ 11.4038], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1239089965820312
[INFO: train.py:  316]: Interation 8354 took 2.1242518424987793
[INFO: train.py:  558]: resist loss: tensor([ 5.2031], device='cuda:0')
[INFO: train.py:  310]: g step took 2.096118211746216
[INFO: train.py:  316]: Interation 8355 took 2.0964300632476807
[INFO: train.py:  558]: resist loss: tensor([ 2.6283], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7669949531555176
[INFO: train.py:  316]: Interation 8356 took 1.7673773765563965
[INFO: train.py:  558]: resist loss: tensor([ 1.0102], device='cuda:0')
[INFO: train.py:  310]: g step took 1.95414400100708
[INFO: train.py:  316]: Interation 8357 took 1.954519510269165
[INFO: train.py:  558]: resist loss: tensor([ 6.7011], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9209189414978027
[INFO: train.py:  316]: Interation 8358 took 1.924952507019043
[INFO: train.py:  558]: resist loss: tensor([ 2.3761], device='cuda:0')
[INFO: train.py:  310]: g step took 1.778862714767456
[INFO: train.py:  316]: Interation 8359 took 1.7791869640350342
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 451, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 451, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 598, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 598, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 504, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 504, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 602, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 602, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 482, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 482, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 605, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 605, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 589, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 589, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 528, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 528, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 626, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 626, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 693, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 693, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 571, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 571, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 112, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 112, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 806, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 806, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 695, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 695, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 646, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 646, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 839, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 839, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 730, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 730, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 996, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 996, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 761, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 761, 2])
[INFO: train.py:  338]:   [val] ade: 0.609
[INFO: train.py:  338]:   [val] ade_l: 1.340
[INFO: train.py:  338]:   [val] ade_nl: 1.115
[INFO: train.py:  338]:   [val] d_loss: 1.411
[INFO: train.py:  338]:   [val] fde: 1.198
[INFO: train.py:  338]:   [val] fde_l: 2.638
[INFO: train.py:  338]:   [val] fde_nl: 2.195
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.424
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.424
[INFO: train.py:  338]:   [val] resist_count: 3168.000
[INFO: train.py:  338]:   [val] resist_loss: 0.395
[INFO: train.py:  341]:   [train] ade: 0.609
[INFO: train.py:  341]:   [train] ade_l: 1.283
[INFO: train.py:  341]:   [train] ade_nl: 1.159
[INFO: train.py:  341]:   [train] d_loss: 1.411
[INFO: train.py:  341]:   [train] fde: 1.141
[INFO: train.py:  341]:   [train] fde_l: 2.405
[INFO: train.py:  341]:   [train] fde_nl: 2.172
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.394
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.394
[INFO: train.py:  341]:   [train] resist_count: 3008.000
[INFO: train.py:  341]:   [train] resist_loss: 0.214
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 6.0758], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9418394565582275
[INFO: train.py:  316]: Interation 8360 took 10.343977928161621
[INFO: train.py:  558]: resist loss: tensor([ 3.8144], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9187381267547607
[INFO: train.py:  316]: Interation 8361 took 1.919067621231079
[INFO: train.py:  558]: resist loss: tensor([ 12.0870], device='cuda:0')
[INFO: train.py:  310]: g step took 2.411144495010376
[INFO: train.py:  316]: Interation 8362 took 2.411454439163208
[INFO: train.py:  558]: resist loss: tensor([ 0.7700], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2482244968414307
[INFO: train.py:  316]: Interation 8363 took 2.248589515686035
[INFO: train.py:  558]: resist loss: tensor([ 1.1870], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1428232192993164
[INFO: train.py:  316]: Interation 8364 took 2.1432676315307617
[INFO: train.py:  558]: resist loss: tensor([ 0.6348], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9386911392211914
[INFO: train.py:  316]: Interation 8365 took 1.9390437602996826
[INFO: train.py:  558]: resist loss: tensor([ 0.3753], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7986149787902832
[INFO: train.py:  316]: Interation 8366 took 1.8029539585113525
[INFO: train.py:  558]: resist loss: tensor([ 3.6460], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7509472370147705
[INFO: train.py:  316]: Interation 8367 took 1.7512693405151367
[INFO: train.py:  558]: resist loss: tensor([ 14.4589], device='cuda:0')
[INFO: train.py:  310]: g step took 2.210078716278076
[INFO: train.py:  316]: Interation 8368 took 2.2141664028167725
[INFO: train.py:  558]: resist loss: tensor([ 18.8203], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1112220287323
[INFO: train.py:  316]: Interation 8369 took 2.115353584289551
[INFO: train.py:  327]: Checking stats on val ...
Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7fc4e2955518>>
Traceback (most recent call last):
  File "/data/xinjiey/Group_Navi_GAN/env/lib/python3.5/site-packages/torch/utils/data/dataloader.py", line 349, in __del__
    self._shutdown_workers()
  File "/data/xinjiey/Group_Navi_GAN/env/lib/python3.5/site-packages/torch/utils/data/dataloader.py", line 328, in _shutdown_workers
    self.worker_result_queue.get()
  File "/usr/lib/python3.5/multiprocessing/queues.py", line 345, in get
    return ForkingPickler.loads(res)
  File "/data/xinjiey/Group_Navi_GAN/env/lib/python3.5/site-packages/torch/multiprocessing/reductions.py", line 70, in rebuild_storage_fd
    fd = df.detach()
  File "/usr/lib/python3.5/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/usr/lib/python3.5/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 494, in Client
    deliver_challenge(c, authkey)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 722, in deliver_challenge
    response = connection.recv_bytes(256)        # reject large message
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
ConnectionResetError: [Errno 104] Connection reset by peer
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 605, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 605, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 535, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 535, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 496, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 496, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 534, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 534, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 520, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 520, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 528, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 528, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 644, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 644, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 617, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 617, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 491, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 491, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 661, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 661, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 631, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 631, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 99, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 99, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 840, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 840, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 793, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 793, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 788, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 788, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 587, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 587, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 611, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 611, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 769, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 769, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 732, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 732, 2])
[INFO: train.py:  338]:   [val] ade: 0.602
[INFO: train.py:  338]:   [val] ade_l: 1.326
[INFO: train.py:  338]:   [val] ade_nl: 1.104
[INFO: train.py:  338]:   [val] d_loss: 1.411
[INFO: train.py:  338]:   [val] fde: 1.250
[INFO: train.py:  338]:   [val] fde_l: 2.753
[INFO: train.py:  338]:   [val] fde_nl: 2.290
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.439
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.439
[INFO: train.py:  338]:   [val] resist_count: 2776.000
[INFO: train.py:  338]:   [val] resist_loss: 0.325
[INFO: train.py:  341]:   [train] ade: 0.605
[INFO: train.py:  341]:   [train] ade_l: 1.293
[INFO: train.py:  341]:   [train] ade_nl: 1.135
[INFO: train.py:  341]:   [train] d_loss: 1.410
[INFO: train.py:  341]:   [train] fde: 1.196
[INFO: train.py:  341]:   [train] fde_l: 2.559
[INFO: train.py:  341]:   [train] fde_nl: 2.247
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.384
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.384
[INFO: train.py:  341]:   [train] resist_count: 2715.000
[INFO: train.py:  341]:   [train] resist_loss: 0.177
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 9.5128], device='cuda:0')
[INFO: train.py:  310]: g step took 1.844346046447754
[INFO: train.py:  316]: Interation 8370 took 10.404578447341919
[INFO: train.py:  558]: resist loss: tensor([ 1.7438], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7225663661956787
[INFO: train.py:  316]: Interation 8371 took 1.7264628410339355
[INFO: train.py:  558]: resist loss: tensor([ 7.8468], device='cuda:0')
[INFO: train.py:  310]: g step took 2.189220666885376
[INFO: train.py:  316]: Interation 8372 took 2.193127393722534
[INFO: train.py:  558]: resist loss: tensor([ 1.1182], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0730183124542236
[INFO: train.py:  316]: Interation 8373 took 2.0768837928771973
[INFO: train.py:  558]: resist loss: tensor([ 0.8545], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6121957302093506
[INFO: train.py:  316]: Interation 8374 took 1.6161038875579834
[INFO: train.py:  558]: resist loss: tensor([ 4.6101], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8777296543121338
[INFO: train.py:  316]: Interation 8375 took 1.881582498550415
[INFO: train.py:  558]: resist loss: tensor([ 3.9296], device='cuda:0')
[INFO: train.py:  310]: g step took 1.815354824066162
[INFO: train.py:  316]: Interation 8376 took 1.8195669651031494
[INFO: train.py:  558]: resist loss: tensor([ 7.6292], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1174046993255615
[INFO: train.py:  316]: Interation 8377 took 2.121279001235962
[INFO: train.py:  558]: resist loss: tensor([ 10.3932], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9378845691680908
[INFO: train.py:  316]: Interation 8378 took 1.9419565200805664
[INFO: train.py:  558]: resist loss: tensor([ 4.2610], device='cuda:0')
[INFO: train.py:  310]: g step took 2.131826400756836
[INFO: train.py:  316]: Interation 8379 took 2.135711193084717
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 591, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 591, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 519, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 519, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 444, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 444, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 633, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 633, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 653, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 653, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 565, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 565, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 560, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 560, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 496, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 496, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 636, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 636, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 547, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 547, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 570, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 570, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 147, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 147, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 729, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 729, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 796, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 796, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 757, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 757, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 732, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 732, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 753, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 753, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 673, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 673, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 689, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 689, 2])
[INFO: train.py:  338]:   [val] ade: 0.653
[INFO: train.py:  338]:   [val] ade_l: 1.438
[INFO: train.py:  338]:   [val] ade_nl: 1.197
[INFO: train.py:  338]:   [val] d_loss: 1.410
[INFO: train.py:  338]:   [val] fde: 1.394
[INFO: train.py:  338]:   [val] fde_l: 3.069
[INFO: train.py:  338]:   [val] fde_nl: 2.554
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.526
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.526
[INFO: train.py:  338]:   [val] resist_count: 2795.000
[INFO: train.py:  338]:   [val] resist_loss: 0.249
[INFO: train.py:  341]:   [train] ade: 0.650
[INFO: train.py:  341]:   [train] ade_l: 1.408
[INFO: train.py:  341]:   [train] ade_nl: 1.206
[INFO: train.py:  341]:   [train] d_loss: 1.397
[INFO: train.py:  341]:   [train] fde: 1.332
[INFO: train.py:  341]:   [train] fde_l: 2.887
[INFO: train.py:  341]:   [train] fde_nl: 2.472
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.462
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.462
[INFO: train.py:  341]:   [train] resist_count: 2767.000
[INFO: train.py:  341]:   [train] resist_loss: 0.163
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 6.5871], device='cuda:0')
[INFO: train.py:  310]: g step took 2.174602746963501
[INFO: train.py:  316]: Interation 8380 took 10.719650506973267
[INFO: train.py:  558]: resist loss: tensor([ 0.4236], device='cuda:0')
[INFO: train.py:  310]: g step took 1.912658929824829
[INFO: train.py:  316]: Interation 8381 took 1.9160044193267822
[INFO: train.py:  558]: resist loss: tensor([ 3.7327], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7325024604797363
[INFO: train.py:  316]: Interation 8382 took 1.7361938953399658
[INFO: train.py:  558]: resist loss: tensor([ 0.8163], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6174213886260986
[INFO: train.py:  316]: Interation 8383 took 1.6211178302764893
[INFO: train.py:  558]: resist loss: tensor([ 4.5189], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8033909797668457
[INFO: train.py:  316]: Interation 8384 took 1.8075051307678223
[INFO: train.py:  558]: resist loss: tensor([ 7.4980], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7331693172454834
[INFO: train.py:  316]: Interation 8385 took 1.7368667125701904
[INFO: train.py:  558]: resist loss: tensor([ 12.8900], device='cuda:0')
[INFO: train.py:  310]: g step took 1.84442138671875
[INFO: train.py:  316]: Interation 8386 took 1.8482449054718018
[INFO: train.py:  558]: resist loss: tensor([ 3.4863], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0999836921691895
[INFO: train.py:  316]: Interation 8387 took 2.103875160217285
[INFO: train.py:  558]: resist loss: tensor([ 4.8547], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6518337726593018
[INFO: train.py:  316]: Interation 8388 took 1.6556813716888428
[INFO: train.py:  558]: resist loss: tensor([ 4.6244], device='cuda:0')
[INFO: train.py:  310]: g step took 1.497103214263916
[INFO: train.py:  316]: Interation 8389 took 1.5009334087371826
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 512, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 512, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 601, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 601, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 689, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 689, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 503, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 503, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 568, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 568, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 475, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 475, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 565, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 565, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 622, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 622, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 553, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 553, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 590, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 590, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 535, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 535, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 148, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 148, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 864, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 864, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 838, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 838, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 657, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 657, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 708, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 708, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 778, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 778, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 659, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 659, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 852, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 852, 2])
[INFO: train.py:  338]:   [val] ade: 0.693
[INFO: train.py:  338]:   [val] ade_l: 1.526
[INFO: train.py:  338]:   [val] ade_nl: 1.270
[INFO: train.py:  338]:   [val] d_loss: 1.413
[INFO: train.py:  338]:   [val] fde: 1.402
[INFO: train.py:  338]:   [val] fde_l: 3.087
[INFO: train.py:  338]:   [val] fde_nl: 2.568
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.539
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.539
[INFO: train.py:  338]:   [val] resist_count: 2861.000
[INFO: train.py:  338]:   [val] resist_loss: 0.247
[INFO: train.py:  341]:   [train] ade: 0.670
[INFO: train.py:  341]:   [train] ade_l: 1.374
[INFO: train.py:  341]:   [train] ade_nl: 1.307
[INFO: train.py:  341]:   [train] d_loss: 1.418
[INFO: train.py:  341]:   [train] fde: 1.272
[INFO: train.py:  341]:   [train] fde_l: 2.610
[INFO: train.py:  341]:   [train] fde_nl: 2.483
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.447
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.447
[INFO: train.py:  341]:   [train] resist_count: 2672.000
[INFO: train.py:  341]:   [train] resist_loss: 0.169
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.7192], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7673845291137695
[INFO: train.py:  316]: Interation 8390 took 10.445184707641602
[INFO: train.py:  558]: resist loss: tensor([ 0.3484], device='cuda:0')
[INFO: train.py:  310]: g step took 2.112560510635376
[INFO: train.py:  316]: Interation 8391 took 2.1162359714508057
[INFO: train.py:  558]: resist loss: tensor([ 10.3594], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1325035095214844
[INFO: train.py:  316]: Interation 8392 took 2.136373281478882
[INFO: train.py:  558]: resist loss: tensor([ 0.9271], device='cuda:0')
[INFO: train.py:  310]: g step took 1.935811996459961
[INFO: train.py:  316]: Interation 8393 took 1.9395816326141357
[INFO: train.py:  558]: resist loss: tensor([ 0.1026], device='cuda:0')
[INFO: train.py:  310]: g step took 0.21947097778320312
[INFO: train.py:  316]: Interation 8394 took 0.223250150680542
[INFO: train.py:  279]: Starting epoch 197
[INFO: train.py:  280]: Epoch resist loss: tensor([ 215.6952])
[INFO: train.py:  558]: resist loss: tensor([ 6.3055], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8638668060302734
[INFO: train.py:  316]: Interation 8395 took 2.198674440383911
[INFO: train.py:  558]: resist loss: tensor([ 3.0496], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0533928871154785
[INFO: train.py:  316]: Interation 8396 took 2.0609264373779297
[INFO: train.py:  558]: resist loss: tensor([ 9.9214], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7830510139465332
[INFO: train.py:  316]: Interation 8397 took 1.7834434509277344
[INFO: train.py:  558]: resist loss: tensor([ 2.7478], device='cuda:0')
[INFO: train.py:  310]: g step took 2.076730251312256
[INFO: train.py:  316]: Interation 8398 took 2.0880889892578125
[INFO: train.py:  558]: resist loss: tensor([ 8.6809], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6091742515563965
[INFO: train.py:  316]: Interation 8399 took 1.6095101833343506
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 534, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 534, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 568, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 568, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 627, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 627, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 607, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 607, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 636, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 636, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 537, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 537, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 442, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 442, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 634, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 634, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 487, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 487, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 589, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 589, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 588, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 588, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 112, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 112, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 818, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 818, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 715, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 715, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 677, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 677, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 938, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 938, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 850, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 850, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 740, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 740, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 710, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 710, 2])
[INFO: train.py:  338]:   [val] ade: 0.640
[INFO: train.py:  338]:   [val] ade_l: 1.409
[INFO: train.py:  338]:   [val] ade_nl: 1.173
[INFO: train.py:  338]:   [val] d_loss: 1.408
[INFO: train.py:  338]:   [val] fde: 1.330
[INFO: train.py:  338]:   [val] fde_l: 2.928
[INFO: train.py:  338]:   [val] fde_nl: 2.437
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.471
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.471
[INFO: train.py:  338]:   [val] resist_count: 2876.000
[INFO: train.py:  338]:   [val] resist_loss: 0.305
[INFO: train.py:  341]:   [train] ade: 0.639
[INFO: train.py:  341]:   [train] ade_l: 1.336
[INFO: train.py:  341]:   [train] ade_nl: 1.226
[INFO: train.py:  341]:   [train] d_loss: 1.401
[INFO: train.py:  341]:   [train] fde: 1.239
[INFO: train.py:  341]:   [train] fde_l: 2.589
[INFO: train.py:  341]:   [train] fde_nl: 2.376
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.417
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.417
[INFO: train.py:  341]:   [train] resist_count: 3018.000
[INFO: train.py:  341]:   [train] resist_loss: 0.186
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.2808], device='cuda:0')
[INFO: train.py:  310]: g step took 2.150317668914795
[INFO: train.py:  316]: Interation 8400 took 10.642553806304932
[INFO: train.py:  558]: resist loss: tensor([ 11.1007], device='cuda:0')
[INFO: train.py:  310]: g step took 1.993807077407837
[INFO: train.py:  316]: Interation 8401 took 1.9942190647125244
[INFO: train.py:  558]: resist loss: tensor([ 0.4476], device='cuda:0')
[INFO: train.py:  310]: g step took 2.196171522140503
[INFO: train.py:  316]: Interation 8402 took 2.199747085571289
[INFO: train.py:  558]: resist loss: tensor([ 12.1141], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1825270652770996
[INFO: train.py:  316]: Interation 8403 took 2.206545352935791
[INFO: train.py:  558]: resist loss: tensor([ 0.6371], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1322860717773438
[INFO: train.py:  316]: Interation 8404 took 2.132647752761841
[INFO: train.py:  558]: resist loss: tensor([ 9.6487], device='cuda:0')
[INFO: train.py:  310]: g step took 1.65730881690979
[INFO: train.py:  316]: Interation 8405 took 1.6576356887817383
[INFO: train.py:  558]: resist loss: tensor([ 1.5901], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9015259742736816
[INFO: train.py:  316]: Interation 8406 took 1.9018518924713135
[INFO: train.py:  558]: resist loss: tensor([ 6.5701], device='cuda:0')
[INFO: train.py:  310]: g step took 1.816667079925537
[INFO: train.py:  316]: Interation 8407 took 1.8169891834259033
[INFO: train.py:  558]: resist loss: tensor([ 1.5455], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8614609241485596
[INFO: train.py:  316]: Interation 8408 took 1.8654792308807373
[INFO: train.py:  558]: resist loss: tensor([ 2.8066], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7926127910614014
[INFO: train.py:  316]: Interation 8409 took 1.7929601669311523
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 615, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 615, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 546, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 546, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 544, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 544, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 511, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 511, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 597, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 597, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 457, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 457, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 673, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 673, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 592, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 592, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 654, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 654, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 486, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 486, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 544, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 544, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 142, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 142, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 678, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 678, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 897, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 897, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 823, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 823, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 760, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 760, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 934, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 934, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 786, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 786, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 989, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 989, 2])
[INFO: train.py:  338]:   [val] ade: 0.598
[INFO: train.py:  338]:   [val] ade_l: 1.317
[INFO: train.py:  338]:   [val] ade_nl: 1.096
[INFO: train.py:  338]:   [val] d_loss: 1.414
[INFO: train.py:  338]:   [val] fde: 1.212
[INFO: train.py:  338]:   [val] fde_l: 2.669
[INFO: train.py:  338]:   [val] fde_nl: 2.221
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.413
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.413
[INFO: train.py:  338]:   [val] resist_count: 3093.000
[INFO: train.py:  338]:   [val] resist_loss: 0.324
[INFO: train.py:  341]:   [train] ade: 0.594
[INFO: train.py:  341]:   [train] ade_l: 1.251
[INFO: train.py:  341]:   [train] ade_nl: 1.132
[INFO: train.py:  341]:   [train] d_loss: 1.410
[INFO: train.py:  341]:   [train] fde: 1.129
[INFO: train.py:  341]:   [train] fde_l: 2.377
[INFO: train.py:  341]:   [train] fde_nl: 2.151
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.357
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.357
[INFO: train.py:  341]:   [train] resist_count: 3811.000
[INFO: train.py:  341]:   [train] resist_loss: 0.207
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.9387], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7378787994384766
[INFO: train.py:  316]: Interation 8410 took 10.715883255004883
[INFO: train.py:  558]: resist loss: tensor([ 12.6414], device='cuda:0')
[INFO: train.py:  310]: g step took 1.920872449874878
[INFO: train.py:  316]: Interation 8411 took 1.9247922897338867
[INFO: train.py:  558]: resist loss: tensor([ 3.0473], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7423031330108643
[INFO: train.py:  316]: Interation 8412 took 1.74617338180542
[INFO: train.py:  558]: resist loss: tensor([ 0.6862], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0310616493225098
[INFO: train.py:  316]: Interation 8413 took 2.0350043773651123
[INFO: train.py:  558]: resist loss: tensor([ 7.2431], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2790584564208984
[INFO: train.py:  316]: Interation 8414 took 2.2829174995422363
[INFO: train.py:  558]: resist loss: tensor([ 6.9576], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7803897857666016
[INFO: train.py:  316]: Interation 8415 took 1.7840003967285156
[INFO: train.py:  558]: resist loss: tensor([ 1.9962], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6441893577575684
[INFO: train.py:  316]: Interation 8416 took 1.6479694843292236
[INFO: train.py:  558]: resist loss: tensor([ 4.1544], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5799400806427002
[INFO: train.py:  316]: Interation 8417 took 1.583691120147705
[INFO: train.py:  558]: resist loss: tensor([ 7.1890], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1759212017059326
[INFO: train.py:  316]: Interation 8418 took 2.1797406673431396
[INFO: train.py:  558]: resist loss: tensor([ 1.3185], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9422805309295654
[INFO: train.py:  316]: Interation 8419 took 1.946136236190796
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 654, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 654, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 663, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 663, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 466, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 466, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 688, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 688, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 479, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 479, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 469, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 469, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 604, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 604, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 469, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 469, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 544, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 544, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 590, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 590, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 541, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 541, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 194, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 194, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 653, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 653, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 954, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 954, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 960, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 960, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 820, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 820, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 858, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 858, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 733, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 733, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 910, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 910, 2])
[INFO: train.py:  338]:   [val] ade: 0.663
[INFO: train.py:  338]:   [val] ade_l: 1.459
[INFO: train.py:  338]:   [val] ade_nl: 1.214
[INFO: train.py:  338]:   [val] d_loss: 1.405
[INFO: train.py:  338]:   [val] fde: 1.235
[INFO: train.py:  338]:   [val] fde_l: 2.718
[INFO: train.py:  338]:   [val] fde_nl: 2.262
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.455
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.455
[INFO: train.py:  338]:   [val] resist_count: 2909.000
[INFO: train.py:  338]:   [val] resist_loss: 0.318
[INFO: train.py:  341]:   [train] ade: 0.677
[INFO: train.py:  341]:   [train] ade_l: 1.459
[INFO: train.py:  341]:   [train] ade_nl: 1.262
[INFO: train.py:  341]:   [train] d_loss: 1.397
[INFO: train.py:  341]:   [train] fde: 1.189
[INFO: train.py:  341]:   [train] fde_l: 2.564
[INFO: train.py:  341]:   [train] fde_nl: 2.218
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.430
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.430
[INFO: train.py:  341]:   [train] resist_count: 3319.000
[INFO: train.py:  341]:   [train] resist_loss: 0.190
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 17.6682], device='cuda:0')
[INFO: train.py:  310]: g step took 2.419313430786133
[INFO: train.py:  316]: Interation 8420 took 11.421948671340942
[INFO: train.py:  558]: resist loss: tensor([ 12.5676], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3715546131134033
[INFO: train.py:  316]: Interation 8421 took 2.3755600452423096
[INFO: train.py:  558]: resist loss: tensor([ 0.7626], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6865887641906738
[INFO: train.py:  316]: Interation 8422 took 1.6904776096343994
[INFO: train.py:  558]: resist loss: tensor([ 11.6241], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9326164722442627
[INFO: train.py:  316]: Interation 8423 took 1.9361252784729004
[INFO: train.py:  558]: resist loss: tensor([ 1.2395], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1020686626434326
[INFO: train.py:  316]: Interation 8424 took 2.1064610481262207
[INFO: train.py:  558]: resist loss: tensor([ 2.3725], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7325587272644043
[INFO: train.py:  316]: Interation 8425 took 1.736393690109253
[INFO: train.py:  558]: resist loss: tensor([ 12.3371], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3227477073669434
[INFO: train.py:  316]: Interation 8426 took 2.3266496658325195
[INFO: train.py:  558]: resist loss: tensor([ 13.1528], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9283580780029297
[INFO: train.py:  316]: Interation 8427 took 1.93186616897583
[INFO: train.py:  558]: resist loss: tensor([ 2.2175], device='cuda:0')
[INFO: train.py:  310]: g step took 2.070214033126831
[INFO: train.py:  316]: Interation 8428 took 2.0739622116088867
[INFO: train.py:  558]: resist loss: tensor([ 6.6723], device='cuda:0')
[INFO: train.py:  310]: g step took 2.206343173980713
[INFO: train.py:  316]: Interation 8429 took 2.210059404373169
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 664, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 664, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 570, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 570, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 530, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 530, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 602, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 602, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 477, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 477, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 393, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 393, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 610, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 610, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 528, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 528, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 732, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 732, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 500, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 500, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 609, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 609, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 146, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 146, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 838, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 838, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 805, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 805, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 650, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 650, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 688, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 688, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 710, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 710, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 892, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 892, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 749, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 749, 2])
[INFO: train.py:  338]:   [val] ade: 0.623
[INFO: train.py:  338]:   [val] ade_l: 1.372
[INFO: train.py:  338]:   [val] ade_nl: 1.142
[INFO: train.py:  338]:   [val] d_loss: 1.408
[INFO: train.py:  338]:   [val] fde: 1.261
[INFO: train.py:  338]:   [val] fde_l: 2.777
[INFO: train.py:  338]:   [val] fde_nl: 2.311
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.440
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.440
[INFO: train.py:  338]:   [val] resist_count: 2774.000
[INFO: train.py:  338]:   [val] resist_loss: 0.296
[INFO: train.py:  341]:   [train] ade: 0.647
[INFO: train.py:  341]:   [train] ade_l: 1.391
[INFO: train.py:  341]:   [train] ade_nl: 1.211
[INFO: train.py:  341]:   [train] d_loss: 1.411
[INFO: train.py:  341]:   [train] fde: 1.254
[INFO: train.py:  341]:   [train] fde_l: 2.694
[INFO: train.py:  341]:   [train] fde_nl: 2.346
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.429
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.429
[INFO: train.py:  341]:   [train] resist_count: 2841.000
[INFO: train.py:  341]:   [train] resist_loss: 0.175
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.6995], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7871716022491455
[INFO: train.py:  316]: Interation 8430 took 10.552869319915771
[INFO: train.py:  558]: resist loss: tensor([ 4.3324], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9869272708892822
[INFO: train.py:  316]: Interation 8431 took 1.9908578395843506
[INFO: train.py:  558]: resist loss: tensor([ 1.1394], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9762561321258545
[INFO: train.py:  316]: Interation 8432 took 1.9801008701324463
[INFO: train.py:  558]: resist loss: tensor([ 0.5952], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9981255531311035
[INFO: train.py:  316]: Interation 8433 took 2.0019452571868896
[INFO: train.py:  558]: resist loss: tensor([ 0.7112], device='cuda:0')
[INFO: train.py:  310]: g step took 1.408186435699463
[INFO: train.py:  316]: Interation 8434 took 1.4121487140655518
[INFO: train.py:  558]: resist loss: tensor([ 0.4642], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4019134044647217
[INFO: train.py:  316]: Interation 8435 took 1.4063711166381836
[INFO: train.py:  558]: resist loss: tensor([ 5.7948], device='cuda:0')
[INFO: train.py:  310]: g step took 1.662243127822876
[INFO: train.py:  316]: Interation 8436 took 1.666177749633789
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 2.4039], device='cuda:0')
[INFO: train.py:  310]: g step took 0.18523430824279785
[INFO: train.py:  316]: Interation 8437 took 0.18899083137512207
[INFO: train.py:  279]: Starting epoch 198
[INFO: train.py:  280]: Epoch resist loss: tensor([ 223.9935])
[INFO: train.py:  558]: resist loss: tensor([ 4.0945], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6103060245513916
[INFO: train.py:  316]: Interation 8438 took 1.9639256000518799
[INFO: train.py:  558]: resist loss: tensor([ 1.1118], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9763586521148682
[INFO: train.py:  316]: Interation 8439 took 1.9913861751556396
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 547, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 547, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 468, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 468, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 579, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 579, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 583, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 583, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 440, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 440, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 533, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 533, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 512, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 512, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 675, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 675, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 554, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 554, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 527, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 527, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 802, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 802, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 141, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 141, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 951, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 951, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 745, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 745, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 786, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 786, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 851, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 851, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 773, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 773, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 874, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 874, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 931, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 931, 2])
[INFO: train.py:  338]:   [val] ade: 0.628
[INFO: train.py:  338]:   [val] ade_l: 1.382
[INFO: train.py:  338]:   [val] ade_nl: 1.150
[INFO: train.py:  338]:   [val] d_loss: 1.402
[INFO: train.py:  338]:   [val] fde: 1.168
[INFO: train.py:  338]:   [val] fde_l: 2.572
[INFO: train.py:  338]:   [val] fde_nl: 2.140
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.435
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.435
[INFO: train.py:  338]:   [val] resist_count: 3060.000
[INFO: train.py:  338]:   [val] resist_loss: 0.358
[INFO: train.py:  341]:   [train] ade: 0.639
[INFO: train.py:  341]:   [train] ade_l: 1.343
[INFO: train.py:  341]:   [train] ade_nl: 1.218
[INFO: train.py:  341]:   [train] d_loss: 1.400
[INFO: train.py:  341]:   [train] fde: 1.107
[INFO: train.py:  341]:   [train] fde_l: 2.327
[INFO: train.py:  341]:   [train] fde_nl: 2.110
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.390
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.390
[INFO: train.py:  341]:   [train] resist_count: 4009.000
[INFO: train.py:  341]:   [train] resist_loss: 0.224
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.1185], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6293063163757324
[INFO: train.py:  316]: Interation 8440 took 10.473706483840942
[INFO: train.py:  558]: resist loss: tensor([ 18.5690], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0502560138702393
[INFO: train.py:  316]: Interation 8441 took 2.0505735874176025
[INFO: train.py:  558]: resist loss: tensor([ 5.9150], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2121381759643555
[INFO: train.py:  316]: Interation 8442 took 2.2158701419830322
[INFO: train.py:  558]: resist loss: tensor([ 12.5118], device='cuda:0')
[INFO: train.py:  310]: g step took 2.14750337600708
[INFO: train.py:  316]: Interation 8443 took 2.147794485092163
[INFO: train.py:  558]: resist loss: tensor([ 0.8648], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0659103393554688
[INFO: train.py:  316]: Interation 8444 took 2.0663342475891113
[INFO: train.py:  558]: resist loss: tensor([ 2.1932], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7215521335601807
[INFO: train.py:  316]: Interation 8445 took 1.7220115661621094
[INFO: train.py:  558]: resist loss: tensor([ 16.4849], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2953474521636963
[INFO: train.py:  316]: Interation 8446 took 2.3161802291870117
[INFO: train.py:  558]: resist loss: tensor([ 4.0722], device='cuda:0')
[INFO: train.py:  310]: g step took 2.082439422607422
[INFO: train.py:  316]: Interation 8447 took 2.089938163757324
[INFO: train.py:  558]: resist loss: tensor([ 9.1711], device='cuda:0')
[INFO: train.py:  310]: g step took 2.112577438354492
[INFO: train.py:  316]: Interation 8448 took 2.112933397293091
[INFO: train.py:  558]: resist loss: tensor([ 0.6099], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9860472679138184
[INFO: train.py:  316]: Interation 8449 took 1.9864463806152344
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 619, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 619, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 627, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 627, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 533, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 533, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 562, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 562, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 592, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 592, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 459, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 459, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 666, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 666, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 631, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 631, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 521, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 521, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 529, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 529, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 492, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 492, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 130, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 130, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 706, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 706, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 592, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 592, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 1087, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 1087, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 726, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 726, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 769, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 769, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 685, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 685, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 844, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 844, 2])
[INFO: train.py:  338]:   [val] ade: 0.639
[INFO: train.py:  338]:   [val] ade_l: 1.406
[INFO: train.py:  338]:   [val] ade_nl: 1.170
[INFO: train.py:  338]:   [val] d_loss: 1.404
[INFO: train.py:  338]:   [val] fde: 1.278
[INFO: train.py:  338]:   [val] fde_l: 2.815
[INFO: train.py:  338]:   [val] fde_nl: 2.342
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.466
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.466
[INFO: train.py:  338]:   [val] resist_count: 2659.000
[INFO: train.py:  338]:   [val] resist_loss: 0.277
[INFO: train.py:  341]:   [train] ade: 0.655
[INFO: train.py:  341]:   [train] ade_l: 1.411
[INFO: train.py:  341]:   [train] ade_nl: 1.224
[INFO: train.py:  341]:   [train] d_loss: 1.415
[INFO: train.py:  341]:   [train] fde: 1.235
[INFO: train.py:  341]:   [train] fde_l: 2.659
[INFO: train.py:  341]:   [train] fde_nl: 2.306
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.432
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.432
[INFO: train.py:  341]:   [train] resist_count: 2637.000
[INFO: train.py:  341]:   [train] resist_loss: 0.153
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.5494], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5415923595428467
[INFO: train.py:  316]: Interation 8450 took 10.257354497909546
[INFO: train.py:  558]: resist loss: tensor([ 12.1501], device='cuda:0')
[INFO: train.py:  310]: g step took 2.086409568786621
[INFO: train.py:  316]: Interation 8451 took 2.0867741107940674
[INFO: train.py:  558]: resist loss: tensor([ 1.2514], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8988947868347168
[INFO: train.py:  316]: Interation 8452 took 1.8993124961853027
[INFO: train.py:  558]: resist loss: tensor([ 9.4498], device='cuda:0')
[INFO: train.py:  310]: g step took 1.972369909286499
[INFO: train.py:  316]: Interation 8453 took 1.972762107849121
[INFO: train.py:  558]: resist loss: tensor([ 0.6245], device='cuda:0')
[INFO: train.py:  310]: g step took 1.451354742050171
[INFO: train.py:  316]: Interation 8454 took 1.4554195404052734
[INFO: train.py:  558]: resist loss: tensor([ 3.0556], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9747874736785889
[INFO: train.py:  316]: Interation 8455 took 1.9786696434020996
[INFO: train.py:  558]: resist loss: tensor([ 3.1697], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8617424964904785
[INFO: train.py:  316]: Interation 8456 took 1.8656785488128662
[INFO: train.py:  558]: resist loss: tensor([ 11.0512], device='cuda:0')
[INFO: train.py:  310]: g step took 2.076991558074951
[INFO: train.py:  316]: Interation 8457 took 2.0808603763580322
[INFO: train.py:  558]: resist loss: tensor([ 6.7259], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0129001140594482
[INFO: train.py:  316]: Interation 8458 took 2.016723155975342
[INFO: train.py:  558]: resist loss: tensor([ 6.8559], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0617616176605225
[INFO: train.py:  316]: Interation 8459 took 2.0657429695129395
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 615, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 615, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 573, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 573, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 422, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 422, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 573, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 573, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 485, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 485, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 555, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 555, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 601, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 601, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 613, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 613, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 588, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 588, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 615, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 615, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 630, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 630, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 91, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 91, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 700, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 700, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 886, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 886, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 769, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 769, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 736, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 736, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 781, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 781, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 1088, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 1088, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 718, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 718, 2])
[INFO: train.py:  338]:   [val] ade: 0.602
[INFO: train.py:  338]:   [val] ade_l: 1.325
[INFO: train.py:  338]:   [val] ade_nl: 1.103
[INFO: train.py:  338]:   [val] d_loss: 1.412
[INFO: train.py:  338]:   [val] fde: 1.273
[INFO: train.py:  338]:   [val] fde_l: 2.802
[INFO: train.py:  338]:   [val] fde_nl: 2.332
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.457
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.457
[INFO: train.py:  338]:   [val] resist_count: 2641.000
[INFO: train.py:  338]:   [val] resist_loss: 0.266
[INFO: train.py:  341]:   [train] ade: 0.616
[INFO: train.py:  341]:   [train] ade_l: 1.248
[INFO: train.py:  341]:   [train] ade_nl: 1.217
[INFO: train.py:  341]:   [train] d_loss: 1.391
[INFO: train.py:  341]:   [train] fde: 1.227
[INFO: train.py:  341]:   [train] fde_l: 2.485
[INFO: train.py:  341]:   [train] fde_nl: 2.423
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.410
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.410
[INFO: train.py:  341]:   [train] resist_count: 2791.000
[INFO: train.py:  341]:   [train] resist_loss: 0.136
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.6795], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9188156127929688
[INFO: train.py:  316]: Interation 8460 took 10.661540746688843
[INFO: train.py:  558]: resist loss: tensor([ 0.1315], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8169279098510742
[INFO: train.py:  316]: Interation 8461 took 1.820608377456665
[INFO: train.py:  558]: resist loss: tensor([ 1.3322], device='cuda:0')
[INFO: train.py:  310]: g step took 2.033376693725586
[INFO: train.py:  316]: Interation 8462 took 2.0373716354370117
[INFO: train.py:  558]: resist loss: tensor([ 9.1854], device='cuda:0')
[INFO: train.py:  310]: g step took 1.761171817779541
[INFO: train.py:  316]: Interation 8463 took 1.765655517578125
[INFO: train.py:  558]: resist loss: tensor([ 7.6100], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9357361793518066
[INFO: train.py:  316]: Interation 8464 took 1.9395968914031982
[INFO: train.py:  558]: resist loss: tensor([ 14.8069], device='cuda:0')
[INFO: train.py:  310]: g step took 2.033668041229248
[INFO: train.py:  316]: Interation 8465 took 2.0372090339660645
[INFO: train.py:  558]: resist loss: tensor([ 2.4365], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1019203662872314
[INFO: train.py:  316]: Interation 8466 took 2.105670690536499
[INFO: train.py:  558]: resist loss: tensor([ 9.6547], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7780256271362305
[INFO: train.py:  316]: Interation 8467 took 1.7819132804870605
[INFO: train.py:  558]: resist loss: tensor([ 7.6647], device='cuda:0')
[INFO: train.py:  310]: g step took 2.094604969024658
[INFO: train.py:  316]: Interation 8468 took 2.098439931869507
[INFO: train.py:  558]: resist loss: tensor([ 16.7212], device='cuda:0')
[INFO: train.py:  310]: g step took 2.417778968811035
[INFO: train.py:  316]: Interation 8469 took 2.420933723449707
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 592, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 592, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 578, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 578, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 523, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 523, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 529, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 529, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 487, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 487, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 653, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 653, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 602, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 602, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 574, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 574, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 531, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 531, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 578, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 578, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 608, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 608, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 106, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 106, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 730, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 730, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 905, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 905, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 724, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 724, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 783, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 783, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 594, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 594, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 639, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 639, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 974, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 974, 2])
[INFO: train.py:  338]:   [val] ade: 0.637
[INFO: train.py:  338]:   [val] ade_l: 1.402
[INFO: train.py:  338]:   [val] ade_nl: 1.166
[INFO: train.py:  338]:   [val] d_loss: 1.400
[INFO: train.py:  338]:   [val] fde: 1.383
[INFO: train.py:  338]:   [val] fde_l: 3.044
[INFO: train.py:  338]:   [val] fde_nl: 2.533
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.523
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.523
[INFO: train.py:  338]:   [val] resist_count: 2513.000
[INFO: train.py:  338]:   [val] resist_loss: 0.218
[INFO: train.py:  341]:   [train] ade: 0.653
[INFO: train.py:  341]:   [train] ade_l: 1.393
[INFO: train.py:  341]:   [train] ade_nl: 1.228
[INFO: train.py:  341]:   [train] d_loss: 1.407
[INFO: train.py:  341]:   [train] fde: 1.354
[INFO: train.py:  341]:   [train] fde_l: 2.890
[INFO: train.py:  341]:   [train] fde_nl: 2.547
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.464
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.464
[INFO: train.py:  341]:   [train] resist_count: 2602.000
[INFO: train.py:  341]:   [train] resist_loss: 0.131
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 1.1868], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9474997520446777
[INFO: train.py:  316]: Interation 8470 took 10.365722417831421
[INFO: train.py:  558]: resist loss: tensor([ 0.7325], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6144657135009766
[INFO: train.py:  316]: Interation 8471 took 1.6184298992156982
[INFO: train.py:  558]: resist loss: tensor([ 3.0339], device='cuda:0')
[INFO: train.py:  310]: g step took 1.503056287765503
[INFO: train.py:  316]: Interation 8472 took 1.5068514347076416
[INFO: train.py:  558]: resist loss: tensor([ 5.2530], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6978561878204346
[INFO: train.py:  316]: Interation 8473 took 1.7016198635101318
[INFO: train.py:  558]: resist loss: tensor([ 5.1628], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0190558433532715
[INFO: train.py:  316]: Interation 8474 took 2.0233285427093506
[INFO: train.py:  558]: resist loss: tensor([ 1.5312], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9689884185791016
[INFO: train.py:  316]: Interation 8475 took 1.972869873046875
[INFO: train.py:  558]: resist loss: tensor([ 1.8460], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0824315547943115
[INFO: train.py:  316]: Interation 8476 took 2.0865895748138428
[INFO: train.py:  558]: resist loss: tensor([ 4.7254], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8356099128723145
[INFO: train.py:  316]: Interation 8477 took 1.8396029472351074
[INFO: train.py:  558]: resist loss: tensor([ 1.2625], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8375468254089355
[INFO: train.py:  316]: Interation 8478 took 1.841186761856079
[INFO: train.py:  558]: resist loss: tensor([ 18.4371], device='cuda:0')
[INFO: train.py:  310]: g step took 2.447736978530884
[INFO: train.py:  316]: Interation 8479 took 2.451505661010742
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 615, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 615, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 573, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 573, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 571, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 571, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 633, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 633, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 586, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 586, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 467, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 467, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 583, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 583, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 600, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 600, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 505, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 505, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 572, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 572, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 545, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 545, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 111, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 111, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 700, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 700, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 888, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 888, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 917, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 917, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 786, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 786, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 863, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 863, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 767, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 767, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 870, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 870, 2])
[INFO: train.py:  338]:   [val] ade: 0.639
[INFO: train.py:  338]:   [val] ade_l: 1.406
[INFO: train.py:  338]:   [val] ade_nl: 1.170
[INFO: train.py:  338]:   [val] d_loss: 1.397
[INFO: train.py:  338]:   [val] fde: 1.365
[INFO: train.py:  338]:   [val] fde_l: 3.006
[INFO: train.py:  338]:   [val] fde_nl: 2.501
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.502
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.502
[INFO: train.py:  338]:   [val] resist_count: 2863.000
[INFO: train.py:  338]:   [val] resist_loss: 0.256
[INFO: train.py:  341]:   [train] ade: 0.640
[INFO: train.py:  341]:   [train] ade_l: 1.361
[INFO: train.py:  341]:   [train] ade_nl: 1.209
[INFO: train.py:  341]:   [train] d_loss: 1.397
[INFO: train.py:  341]:   [train] fde: 1.297
[INFO: train.py:  341]:   [train] fde_l: 2.757
[INFO: train.py:  341]:   [train] fde_nl: 2.449
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.439
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.439
[INFO: train.py:  341]:   [train] resist_count: 2710.000
[INFO: train.py:  341]:   [train] resist_loss: 0.144
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.], device='cuda:0')
[INFO: train.py:  310]: g step took 0.11312389373779297
[INFO: train.py:  316]: Interation 8480 took 8.7122163772583
[INFO: train.py:  279]: Starting epoch 199
[INFO: train.py:  280]: Epoch resist loss: tensor([ 243.9940])
[INFO: train.py:  558]: resist loss: tensor([ 11.5419], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2384872436523438
[INFO: train.py:  316]: Interation 8481 took 2.5963056087493896
[INFO: train.py:  558]: resist loss: tensor([ 9.8793], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5732636451721191
[INFO: train.py:  316]: Interation 8482 took 1.5981347560882568
[INFO: train.py:  558]: resist loss: tensor([ 3.6550], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7471013069152832
[INFO: train.py:  316]: Interation 8483 took 1.7474327087402344
[INFO: train.py:  558]: resist loss: tensor([ 0.5516], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6175851821899414
[INFO: train.py:  316]: Interation 8484 took 1.6179304122924805
[INFO: train.py:  558]: resist loss: tensor([ 1.1199], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0209262371063232
[INFO: train.py:  316]: Interation 8485 took 2.0212960243225098
[INFO: train.py:  558]: resist loss: tensor([ 3.6385], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7346367835998535
[INFO: train.py:  316]: Interation 8486 took 1.7349944114685059
[INFO: train.py:  558]: resist loss: tensor([ 0.8472], device='cuda:0')
[INFO: train.py:  310]: g step took 1.916930913925171
[INFO: train.py:  316]: Interation 8487 took 1.9172279834747314
[INFO: train.py:  558]: resist loss: tensor([ 14.0153], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9416327476501465
[INFO: train.py:  316]: Interation 8488 took 1.9419867992401123
[INFO: train.py:  558]: resist loss: tensor([ 2.1274], device='cuda:0')
[INFO: train.py:  310]: g step took 2.002321720123291
[INFO: train.py:  316]: Interation 8489 took 2.02032470703125
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 579, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 579, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 615, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 615, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 522, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 522, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 481, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 481, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 617, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 617, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 606, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 606, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 427, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 427, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 497, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 497, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 631, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 631, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 677, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 677, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 543, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 543, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 166, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 166, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 847, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 847, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 788, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 788, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 904, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 904, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 698, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 698, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 695, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 695, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 663, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 663, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 865, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 865, 2])
[INFO: train.py:  338]:   [val] ade: 0.611
[INFO: train.py:  338]:   [val] ade_l: 1.346
[INFO: train.py:  338]:   [val] ade_nl: 1.120
[INFO: train.py:  338]:   [val] d_loss: 1.412
[INFO: train.py:  338]:   [val] fde: 1.311
[INFO: train.py:  338]:   [val] fde_l: 2.885
[INFO: train.py:  338]:   [val] fde_nl: 2.401
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.463
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.463
[INFO: train.py:  338]:   [val] resist_count: 2995.000
[INFO: train.py:  338]:   [val] resist_loss: 0.354
[INFO: train.py:  341]:   [train] ade: 0.633
[INFO: train.py:  341]:   [train] ade_l: 1.369
[INFO: train.py:  341]:   [train] ade_nl: 1.178
[INFO: train.py:  341]:   [train] d_loss: 1.408
[INFO: train.py:  341]:   [train] fde: 1.293
[INFO: train.py:  341]:   [train] fde_l: 2.796
[INFO: train.py:  341]:   [train] fde_nl: 2.405
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.420
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.420
[INFO: train.py:  341]:   [train] resist_count: 3030.000
[INFO: train.py:  341]:   [train] resist_loss: 0.174
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 13.9837], device='cuda:0')
[INFO: train.py:  310]: g step took 2.548393726348877
[INFO: train.py:  316]: Interation 8490 took 11.36659836769104
[INFO: train.py:  558]: resist loss: tensor([ 12.0975], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4032864570617676
[INFO: train.py:  316]: Interation 8491 took 2.403651237487793
[INFO: train.py:  558]: resist loss: tensor([ 1.1613], device='cuda:0')
[INFO: train.py:  310]: g step took 2.402409076690674
[INFO: train.py:  316]: Interation 8492 took 2.402737855911255
[INFO: train.py:  558]: resist loss: tensor([ 2.2809], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1122896671295166
[INFO: train.py:  316]: Interation 8493 took 2.112635612487793
[INFO: train.py:  558]: resist loss: tensor([ 3.7482], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0448997020721436
[INFO: train.py:  316]: Interation 8494 took 2.045250415802002
[INFO: train.py:  558]: resist loss: tensor([ 8.8413], device='cuda:0')
[INFO: train.py:  310]: g step took 2.197256088256836
[INFO: train.py:  316]: Interation 8495 took 2.1977293491363525
[INFO: train.py:  558]: resist loss: tensor([ 5.0218], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4677841663360596
[INFO: train.py:  316]: Interation 8496 took 2.468134880065918
[INFO: train.py:  558]: resist loss: tensor([ 1.2335], device='cuda:0')
[INFO: train.py:  310]: g step took 2.415332794189453
[INFO: train.py:  316]: Interation 8497 took 2.4195730686187744
[INFO: train.py:  558]: resist loss: tensor([ 4.7450], device='cuda:0')
[INFO: train.py:  310]: g step took 2.350167989730835
[INFO: train.py:  316]: Interation 8498 took 2.356260061264038
[INFO: train.py:  558]: resist loss: tensor([ 7.1231], device='cuda:0')
[INFO: train.py:  310]: g step took 2.229600191116333
[INFO: train.py:  316]: Interation 8499 took 2.233527183532715
[INFO: train.py:  327]: Checking stats on val ...
Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7fc4e2956ba8>>
Traceback (most recent call last):
  File "/data/xinjiey/Group_Navi_GAN/env/lib/python3.5/site-packages/torch/utils/data/dataloader.py", line 349, in __del__
    self._shutdown_workers()
  File "/data/xinjiey/Group_Navi_GAN/env/lib/python3.5/site-packages/torch/utils/data/dataloader.py", line 328, in _shutdown_workers
    self.worker_result_queue.get()
  File "/usr/lib/python3.5/multiprocessing/queues.py", line 345, in get
    return ForkingPickler.loads(res)
  File "/data/xinjiey/Group_Navi_GAN/env/lib/python3.5/site-packages/torch/multiprocessing/reductions.py", line 70, in rebuild_storage_fd
    fd = df.detach()
  File "/usr/lib/python3.5/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/usr/lib/python3.5/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 494, in Client
    deliver_challenge(c, authkey)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 722, in deliver_challenge
    response = connection.recv_bytes(256)        # reject large message
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError: 
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 611, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 611, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 742, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 742, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 558, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 558, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 556, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 556, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 515, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 515, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 529, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 529, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 421, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 421, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 542, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 542, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 517, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 517, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 599, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 599, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 631, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 631, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 140, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 140, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 726, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 726, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 839, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 839, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 846, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 846, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 837, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 837, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 871, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 871, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 779, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 779, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 927, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 927, 2])
[INFO: train.py:  338]:   [val] ade: 0.614
[INFO: train.py:  338]:   [val] ade_l: 1.351
[INFO: train.py:  338]:   [val] ade_nl: 1.124
[INFO: train.py:  338]:   [val] d_loss: 1.418
[INFO: train.py:  338]:   [val] fde: 1.263
[INFO: train.py:  338]:   [val] fde_l: 2.781
[INFO: train.py:  338]:   [val] fde_nl: 2.314
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.429
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.429
[INFO: train.py:  338]:   [val] resist_count: 3223.000
[INFO: train.py:  338]:   [val] resist_loss: 0.380
[INFO: train.py:  341]:   [train] ade: 0.617
[INFO: train.py:  341]:   [train] ade_l: 1.294
[INFO: train.py:  341]:   [train] ade_nl: 1.179
[INFO: train.py:  341]:   [train] d_loss: 1.395
[INFO: train.py:  341]:   [train] fde: 1.195
[INFO: train.py:  341]:   [train] fde_l: 2.506
[INFO: train.py:  341]:   [train] fde_nl: 2.284
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.387
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.387
[INFO: train.py:  341]:   [train] resist_count: 3455.000
[INFO: train.py:  341]:   [train] resist_loss: 0.231
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 4.9977], device='cuda:0')
[INFO: train.py:  310]: g step took 2.510679244995117
[INFO: train.py:  316]: Interation 8500 took 11.256933450698853
[INFO: train.py:  558]: resist loss: tensor([ 13.7395], device='cuda:0')
[INFO: train.py:  310]: g step took 2.36696457862854
[INFO: train.py:  316]: Interation 8501 took 2.3708858489990234
[INFO: train.py:  558]: resist loss: tensor([ 26.0467], device='cuda:0')
[INFO: train.py:  310]: g step took 2.985189199447632
[INFO: train.py:  316]: Interation 8502 took 2.9888482093811035
[INFO: train.py:  558]: resist loss: tensor([ 4.4741], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4948694705963135
[INFO: train.py:  316]: Interation 8503 took 2.498887538909912
[INFO: train.py:  558]: resist loss: tensor([ 4.1500], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1152124404907227
[INFO: train.py:  316]: Interation 8504 took 2.1190946102142334
[INFO: train.py:  558]: resist loss: tensor([ 2.4175], device='cuda:0')
[INFO: train.py:  310]: g step took 2.6259260177612305
[INFO: train.py:  316]: Interation 8505 took 2.629826068878174
[INFO: train.py:  558]: resist loss: tensor([ 7.7580], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0968031883239746
[INFO: train.py:  316]: Interation 8506 took 2.100097894668579
[INFO: train.py:  558]: resist loss: tensor([ 3.9691], device='cuda:0')
[INFO: train.py:  310]: g step took 2.091698169708252
[INFO: train.py:  316]: Interation 8507 took 2.095620632171631
[INFO: train.py:  558]: resist loss: tensor([ 15.8401], device='cuda:0')
[INFO: train.py:  310]: g step took 2.293203115463257
[INFO: train.py:  316]: Interation 8508 took 2.2971506118774414
[INFO: train.py:  558]: resist loss: tensor([ 15.8332], device='cuda:0')
[INFO: train.py:  310]: g step took 1.760711431503296
[INFO: train.py:  316]: Interation 8509 took 1.7648136615753174
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 528, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 528, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 638, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 638, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 715, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 715, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 619, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 619, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 492, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 492, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 547, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 547, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 548, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 548, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 566, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 566, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 598, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 598, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 493, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 493, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 496, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 496, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 121, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 121, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 853, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 853, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 822, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 822, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 701, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 701, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 730, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 730, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 843, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 843, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 839, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 839, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 824, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 824, 2])
[INFO: train.py:  338]:   [val] ade: 0.608
[INFO: train.py:  338]:   [val] ade_l: 1.338
[INFO: train.py:  338]:   [val] ade_nl: 1.113
[INFO: train.py:  338]:   [val] d_loss: 1.404
[INFO: train.py:  338]:   [val] fde: 1.247
[INFO: train.py:  338]:   [val] fde_l: 2.746
[INFO: train.py:  338]:   [val] fde_nl: 2.285
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.433
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.433
[INFO: train.py:  338]:   [val] resist_count: 3076.000
[INFO: train.py:  338]:   [val] resist_loss: 0.317
[INFO: train.py:  341]:   [train] ade: 0.606
[INFO: train.py:  341]:   [train] ade_l: 1.265
[INFO: train.py:  341]:   [train] ade_nl: 1.163
[INFO: train.py:  341]:   [train] d_loss: 1.398
[INFO: train.py:  341]:   [train] fde: 1.178
[INFO: train.py:  341]:   [train] fde_l: 2.459
[INFO: train.py:  341]:   [train] fde_nl: 2.260
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.387
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.387
[INFO: train.py:  341]:   [train] resist_count: 3159.000
[INFO: train.py:  341]:   [train] resist_loss: 0.177
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.9804], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3552515506744385
[INFO: train.py:  316]: Interation 8510 took 11.905609130859375
[INFO: train.py:  558]: resist loss: tensor([ 9.8687], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0077576637268066
[INFO: train.py:  316]: Interation 8511 took 2.0116422176361084
[INFO: train.py:  558]: resist loss: tensor([ 7.5990], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3434805870056152
[INFO: train.py:  316]: Interation 8512 took 2.347259521484375
[INFO: train.py:  558]: resist loss: tensor([ 0.2008], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8444087505340576
[INFO: train.py:  316]: Interation 8513 took 1.848153829574585
[INFO: train.py:  558]: resist loss: tensor([ 13.1695], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9606106281280518
[INFO: train.py:  316]: Interation 8514 took 1.9641752243041992
[INFO: train.py:  558]: resist loss: tensor([ 6.5744], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9263803958892822
[INFO: train.py:  316]: Interation 8515 took 1.9300963878631592
[INFO: train.py:  558]: resist loss: tensor([ 9.1337], device='cuda:0')
[INFO: train.py:  310]: g step took 2.225458860397339
[INFO: train.py:  316]: Interation 8516 took 2.229144811630249
[INFO: train.py:  558]: resist loss: tensor([ 1.7274], device='cuda:0')
[INFO: train.py:  310]: g step took 1.75108003616333
[INFO: train.py:  316]: Interation 8517 took 1.7549026012420654
[INFO: train.py:  558]: resist loss: tensor([ 1.1135], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7900328636169434
[INFO: train.py:  316]: Interation 8518 took 1.7936761379241943
[INFO: train.py:  558]: resist loss: tensor([ 0.2129], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4886300563812256
[INFO: train.py:  316]: Interation 8519 took 1.4921610355377197
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 495, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 495, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 414, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 414, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 554, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 554, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 687, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 687, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 569, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 569, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 740, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 740, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 606, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 606, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 547, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 547, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 524, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 524, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 554, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 554, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 529, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 529, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 142, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 142, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 795, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 795, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 594, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 594, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 656, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 656, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 699, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 699, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 817, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 817, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 740, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 740, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 580, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 580, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 902, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 902, 2])
[INFO: train.py:  338]:   [val] ade: 0.644
[INFO: train.py:  338]:   [val] ade_l: 1.417
[INFO: train.py:  338]:   [val] ade_nl: 1.179
[INFO: train.py:  338]:   [val] d_loss: 1.400
[INFO: train.py:  338]:   [val] fde: 1.302
[INFO: train.py:  338]:   [val] fde_l: 2.867
[INFO: train.py:  338]:   [val] fde_nl: 2.386
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.464
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.464
[INFO: train.py:  338]:   [val] resist_count: 3076.000
[INFO: train.py:  338]:   [val] resist_loss: 0.325
[INFO: train.py:  341]:   [train] ade: 0.635
[INFO: train.py:  341]:   [train] ade_l: 1.303
[INFO: train.py:  341]:   [train] ade_nl: 1.239
[INFO: train.py:  341]:   [train] d_loss: 1.396
[INFO: train.py:  341]:   [train] fde: 1.212
[INFO: train.py:  341]:   [train] fde_l: 2.486
[INFO: train.py:  341]:   [train] fde_nl: 2.364
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.401
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.401
[INFO: train.py:  341]:   [train] resist_count: 2978.000
[INFO: train.py:  341]:   [train] resist_loss: 0.187
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 1.0353], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0251553058624268
[INFO: train.py:  316]: Interation 8520 took 10.892617464065552
[INFO: train.py:  558]: resist loss: tensor([ 2.1552], device='cuda:0')
[INFO: train.py:  310]: g step took 2.018064022064209
[INFO: train.py:  316]: Interation 8521 took 2.0217928886413574
[INFO: train.py:  558]: resist loss: tensor([ 7.4701], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9273080825805664
[INFO: train.py:  316]: Interation 8522 took 1.931114673614502
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 3.6344], device='cuda:0')
[INFO: train.py:  310]: g step took 0.11718869209289551
[INFO: train.py:  316]: Interation 8523 took 0.12093400955200195
[INFO: train.py:  279]: Starting epoch 200
[INFO: train.py:  280]: Epoch resist loss: tensor([ 270.1157])
[INFO: train.py:  558]: resist loss: tensor([ 6.8812], device='cuda:0')
[INFO: train.py:  310]: g step took 1.859262466430664
[INFO: train.py:  316]: Interation 8524 took 2.2239112854003906
[INFO: train.py:  558]: resist loss: tensor([ 5.1681], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8835461139678955
[INFO: train.py:  316]: Interation 8525 took 1.891232967376709
[INFO: train.py:  558]: resist loss: tensor([ 10.2161], device='cuda:0')
[INFO: train.py:  310]: g step took 2.10516095161438
[INFO: train.py:  316]: Interation 8526 took 2.1055431365966797
[INFO: train.py:  558]: resist loss: tensor([ 6.7450], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5470547676086426
[INFO: train.py:  316]: Interation 8527 took 1.554717779159546
[INFO: train.py:  558]: resist loss: tensor([ 5.6959], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0753166675567627
[INFO: train.py:  316]: Interation 8528 took 2.0756654739379883
[INFO: train.py:  558]: resist loss: tensor([ 0.8984], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4985466003417969
[INFO: train.py:  316]: Interation 8529 took 1.4989466667175293
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 538, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 538, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 570, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 570, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 529, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 529, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 641, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 641, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 512, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 512, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 460, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 460, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 630, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 630, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 546, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 546, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 650, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 650, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 671, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 671, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 491, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 491, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 123, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 123, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 907, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 907, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 737, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 737, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 840, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 840, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 731, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 731, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 937, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 937, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 749, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 749, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 806, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 806, 2])
[INFO: train.py:  338]:   [val] ade: 0.640
[INFO: train.py:  338]:   [val] ade_l: 1.409
[INFO: train.py:  338]:   [val] ade_nl: 1.173
[INFO: train.py:  338]:   [val] d_loss: 1.409
[INFO: train.py:  338]:   [val] fde: 1.288
[INFO: train.py:  338]:   [val] fde_l: 2.835
[INFO: train.py:  338]:   [val] fde_nl: 2.359
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.466
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.466
[INFO: train.py:  338]:   [val] resist_count: 3176.000
[INFO: train.py:  338]:   [val] resist_loss: 0.366
[INFO: train.py:  341]:   [train] ade: 0.665
[INFO: train.py:  341]:   [train] ade_l: 1.387
[INFO: train.py:  341]:   [train] ade_nl: 1.277
[INFO: train.py:  341]:   [train] d_loss: 1.402
[INFO: train.py:  341]:   [train] fde: 1.232
[INFO: train.py:  341]:   [train] fde_l: 2.570
[INFO: train.py:  341]:   [train] fde_nl: 2.367
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.438
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.438
[INFO: train.py:  341]:   [train] resist_count: 3473.000
[INFO: train.py:  341]:   [train] resist_loss: 0.214
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 11.1301], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1845617294311523
[INFO: train.py:  316]: Interation 8530 took 11.089059114456177
[INFO: train.py:  558]: resist loss: tensor([ 4.5859], device='cuda:0')
[INFO: train.py:  310]: g step took 2.02242374420166
[INFO: train.py:  316]: Interation 8531 took 2.0227556228637695
[INFO: train.py:  558]: resist loss: tensor([ 16.3689], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0769877433776855
[INFO: train.py:  316]: Interation 8532 took 2.087759256362915
[INFO: train.py:  558]: resist loss: tensor([ 0.3023], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0293385982513428
[INFO: train.py:  316]: Interation 8533 took 2.036536455154419
[INFO: train.py:  558]: resist loss: tensor([ 6.3927], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8611574172973633
[INFO: train.py:  316]: Interation 8534 took 1.861480712890625
[INFO: train.py:  558]: resist loss: tensor([ 4.2718], device='cuda:0')
[INFO: train.py:  310]: g step took 2.09086537361145
[INFO: train.py:  316]: Interation 8535 took 2.09806489944458
[INFO: train.py:  558]: resist loss: tensor([ 2.9696], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0948705673217773
[INFO: train.py:  316]: Interation 8536 took 2.095240354537964
[INFO: train.py:  558]: resist loss: tensor([ 8.1770], device='cuda:0')
[INFO: train.py:  310]: g step took 2.074155330657959
[INFO: train.py:  316]: Interation 8537 took 2.0745301246643066
[INFO: train.py:  558]: resist loss: tensor([ 0.8682], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5593218803405762
[INFO: train.py:  316]: Interation 8538 took 1.5632364749908447
[INFO: train.py:  558]: resist loss: tensor([ 0.5228], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8840878009796143
[INFO: train.py:  316]: Interation 8539 took 1.8844168186187744
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 518, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 518, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 511, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 511, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 472, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 472, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 480, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 480, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 669, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 669, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 537, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 537, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 574, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 574, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 561, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 561, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 621, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 621, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 610, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 610, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 619, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 619, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 189, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 189, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 856, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 856, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 794, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 794, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 665, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 665, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 694, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 694, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 824, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 824, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 748, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 748, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 742, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 742, 2])
[INFO: train.py:  338]:   [val] ade: 0.644
[INFO: train.py:  338]:   [val] ade_l: 1.418
[INFO: train.py:  338]:   [val] ade_nl: 1.180
[INFO: train.py:  338]:   [val] d_loss: 1.401
[INFO: train.py:  338]:   [val] fde: 1.363
[INFO: train.py:  338]:   [val] fde_l: 3.001
[INFO: train.py:  338]:   [val] fde_nl: 2.497
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.482
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.482
[INFO: train.py:  338]:   [val] resist_count: 3150.000
[INFO: train.py:  338]:   [val] resist_loss: 0.376
[INFO: train.py:  341]:   [train] ade: 0.642
[INFO: train.py:  341]:   [train] ade_l: 1.335
[INFO: train.py:  341]:   [train] ade_nl: 1.238
[INFO: train.py:  341]:   [train] d_loss: 1.399
[INFO: train.py:  341]:   [train] fde: 1.277
[INFO: train.py:  341]:   [train] fde_l: 2.654
[INFO: train.py:  341]:   [train] fde_nl: 2.461
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.435
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.435
[INFO: train.py:  341]:   [train] resist_count: 3192.000
[INFO: train.py:  341]:   [train] resist_loss: 0.208
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 17.0016], device='cuda:0')
[INFO: train.py:  310]: g step took 2.278829574584961
[INFO: train.py:  316]: Interation 8540 took 11.058343172073364
[INFO: train.py:  558]: resist loss: tensor([ 4.8521], device='cuda:0')
[INFO: train.py:  310]: g step took 1.782343864440918
[INFO: train.py:  316]: Interation 8541 took 1.7860534191131592
[INFO: train.py:  558]: resist loss: tensor([ 1.7019], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1510415077209473
[INFO: train.py:  316]: Interation 8542 took 2.1548514366149902
[INFO: train.py:  558]: resist loss: tensor([ 0.6375], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4031789302825928
[INFO: train.py:  316]: Interation 8543 took 1.4070103168487549
[INFO: train.py:  558]: resist loss: tensor([ 5.0253], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6963162422180176
[INFO: train.py:  316]: Interation 8544 took 1.6999659538269043
[INFO: train.py:  558]: resist loss: tensor([ 14.7566], device='cuda:0')
[INFO: train.py:  310]: g step took 2.253417491912842
[INFO: train.py:  316]: Interation 8545 took 2.257385492324829
[INFO: train.py:  558]: resist loss: tensor([ 1.0039], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6055595874786377
[INFO: train.py:  316]: Interation 8546 took 1.6095266342163086
[INFO: train.py:  558]: resist loss: tensor([ 11.6097], device='cuda:0')
[INFO: train.py:  310]: g step took 2.143730401992798
[INFO: train.py:  316]: Interation 8547 took 2.147350549697876
[INFO: train.py:  558]: resist loss: tensor([ 6.0976], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9635274410247803
[INFO: train.py:  316]: Interation 8548 took 1.9674699306488037
[INFO: train.py:  558]: resist loss: tensor([ 7.0871], device='cuda:0')
[INFO: train.py:  310]: g step took 2.457691192626953
[INFO: train.py:  316]: Interation 8549 took 2.4616005420684814
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 540, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 540, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 679, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 679, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 485, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 485, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 559, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 559, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 561, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 561, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 635, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 635, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 596, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 596, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 452, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 452, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 676, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 676, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 620, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 620, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 429, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 429, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 129, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 129, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 794, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 794, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 803, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 803, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 722, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 722, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 645, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 645, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 809, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 809, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 683, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 683, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 887, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 887, 2])
[INFO: train.py:  338]:   [val] ade: 0.631
[INFO: train.py:  338]:   [val] ade_l: 1.389
[INFO: train.py:  338]:   [val] ade_nl: 1.155
[INFO: train.py:  338]:   [val] d_loss: 1.415
[INFO: train.py:  338]:   [val] fde: 1.260
[INFO: train.py:  338]:   [val] fde_l: 2.775
[INFO: train.py:  338]:   [val] fde_nl: 2.309
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.446
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.446
[INFO: train.py:  338]:   [val] resist_count: 2898.000
[INFO: train.py:  338]:   [val] resist_loss: 0.300
[INFO: train.py:  341]:   [train] ade: 0.645
[INFO: train.py:  341]:   [train] ade_l: 1.346
[INFO: train.py:  341]:   [train] ade_nl: 1.240
[INFO: train.py:  341]:   [train] d_loss: 1.402
[INFO: train.py:  341]:   [train] fde: 1.218
[INFO: train.py:  341]:   [train] fde_l: 2.540
[INFO: train.py:  341]:   [train] fde_nl: 2.340
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.422
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.422
[INFO: train.py:  341]:   [train] resist_count: 2810.000
[INFO: train.py:  341]:   [train] resist_loss: 0.173
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 10.5732], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9470188617706299
[INFO: train.py:  316]: Interation 8550 took 10.6105318069458
[INFO: train.py:  558]: resist loss: tensor([ 10.9626], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2032761573791504
[INFO: train.py:  316]: Interation 8551 took 2.2070672512054443
[INFO: train.py:  558]: resist loss: tensor([ 2.7871], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9849748611450195
[INFO: train.py:  316]: Interation 8552 took 1.988793134689331
[INFO: train.py:  558]: resist loss: tensor([ 7.2492], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7001011371612549
[INFO: train.py:  316]: Interation 8553 took 1.7043650150299072
[INFO: train.py:  558]: resist loss: tensor([ 0.5454], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6592354774475098
[INFO: train.py:  316]: Interation 8554 took 1.663036584854126
[INFO: train.py:  558]: resist loss: tensor([ 10.7995], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8547906875610352
[INFO: train.py:  316]: Interation 8555 took 1.8583695888519287
[INFO: train.py:  558]: resist loss: tensor([ 5.7373], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8559966087341309
[INFO: train.py:  316]: Interation 8556 took 1.8599367141723633
[INFO: train.py:  558]: resist loss: tensor([ 2.0169], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5274803638458252
[INFO: train.py:  316]: Interation 8557 took 1.5312862396240234
[INFO: train.py:  558]: resist loss: tensor([ 1.0995], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9904251098632812
[INFO: train.py:  316]: Interation 8558 took 1.9941825866699219
[INFO: train.py:  558]: resist loss: tensor([ 2.5830], device='cuda:0')
[INFO: train.py:  310]: g step took 2.239759683609009
[INFO: train.py:  316]: Interation 8559 took 2.243568181991577
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 552, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 552, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 597, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 597, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 590, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 590, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 603, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 603, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 544, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 544, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 535, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 535, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 518, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 518, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 619, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 619, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 459, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 459, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 573, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 573, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 639, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 639, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 132, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 132, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 767, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 767, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 780, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 780, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 808, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 808, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 635, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 635, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 825, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 825, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 797, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 797, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 894, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 894, 2])
[INFO: train.py:  338]:   [val] ade: 0.650
[INFO: train.py:  338]:   [val] ade_l: 1.431
[INFO: train.py:  338]:   [val] ade_nl: 1.191
[INFO: train.py:  338]:   [val] d_loss: 1.418
[INFO: train.py:  338]:   [val] fde: 1.361
[INFO: train.py:  338]:   [val] fde_l: 2.996
[INFO: train.py:  338]:   [val] fde_nl: 2.493
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.474
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.474
[INFO: train.py:  338]:   [val] resist_count: 3792.000
[INFO: train.py:  338]:   [val] resist_loss: 0.407
[INFO: train.py:  341]:   [train] ade: 0.664
[INFO: train.py:  341]:   [train] ade_l: 1.414
[INFO: train.py:  341]:   [train] ade_nl: 1.253
[INFO: train.py:  341]:   [train] d_loss: 1.410
[INFO: train.py:  341]:   [train] fde: 1.312
[INFO: train.py:  341]:   [train] fde_l: 2.792
[INFO: train.py:  341]:   [train] fde_nl: 2.475
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.435
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.435
[INFO: train.py:  341]:   [train] resist_count: 3672.000
[INFO: train.py:  341]:   [train] resist_loss: 0.254
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 4.2341], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7240746021270752
[INFO: train.py:  316]: Interation 8560 took 10.432824850082397
[INFO: train.py:  558]: resist loss: tensor([ 11.4959], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6468095779418945
[INFO: train.py:  316]: Interation 8561 took 1.650653600692749
[INFO: train.py:  558]: resist loss: tensor([ 12.0240], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0454728603363037
[INFO: train.py:  316]: Interation 8562 took 2.049325466156006
[INFO: train.py:  558]: resist loss: tensor([ 12.1048], device='cuda:0')
[INFO: train.py:  310]: g step took 2.392911911010742
[INFO: train.py:  316]: Interation 8563 took 2.3967089653015137
[INFO: train.py:  558]: resist loss: tensor([ 7.4242], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4237289428710938
[INFO: train.py:  316]: Interation 8564 took 2.4276397228240967
[INFO: train.py:  558]: resist loss: tensor([ 10.2647], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8841276168823242
[INFO: train.py:  316]: Interation 8565 took 1.8875436782836914
[INFO: train.py:  558]: resist loss: tensor([ 1.1477], device='cuda:0')
[INFO: train.py:  310]: g step took 0.21847081184387207
[INFO: train.py:  316]: Interation 8566 took 0.22234296798706055
[INFO: train.py:  279]: Starting epoch 201
[INFO: train.py:  280]: Epoch resist loss: tensor([ 274.0167])
[INFO: train.py:  558]: resist loss: tensor([ 2.1373], device='cuda:0')
[INFO: train.py:  310]: g step took 2.008115530014038
[INFO: train.py:  316]: Interation 8567 took 2.376988649368286
[INFO: train.py:  558]: resist loss: tensor([ 10.1636], device='cuda:0')
[INFO: train.py:  310]: g step took 2.150707960128784
[INFO: train.py:  316]: Interation 8568 took 2.1663219928741455
[INFO: train.py:  558]: resist loss: tensor([ 1.7855], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8541510105133057
[INFO: train.py:  316]: Interation 8569 took 1.8545079231262207
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 484, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 484, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 609, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 609, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 587, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 587, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 443, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 443, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 675, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 675, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 577, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 577, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 514, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 514, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 488, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 488, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 516, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 516, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 685, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 685, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 646, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 646, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 137, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 137, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 684, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 684, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 872, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 872, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 730, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 730, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 826, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 826, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 691, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 691, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 702, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 702, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 882, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 882, 2])
[INFO: train.py:  338]:   [val] ade: 0.615
[INFO: train.py:  338]:   [val] ade_l: 1.354
[INFO: train.py:  338]:   [val] ade_nl: 1.127
[INFO: train.py:  338]:   [val] d_loss: 1.402
[INFO: train.py:  338]:   [val] fde: 1.215
[INFO: train.py:  338]:   [val] fde_l: 2.676
[INFO: train.py:  338]:   [val] fde_nl: 2.227
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.435
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.435
[INFO: train.py:  338]:   [val] resist_count: 2901.000
[INFO: train.py:  338]:   [val] resist_loss: 0.322
[INFO: train.py:  341]:   [train] ade: 0.627
[INFO: train.py:  341]:   [train] ade_l: 1.335
[INFO: train.py:  341]:   [train] ade_nl: 1.181
[INFO: train.py:  341]:   [train] d_loss: 1.399
[INFO: train.py:  341]:   [train] fde: 1.185
[INFO: train.py:  341]:   [train] fde_l: 2.525
[INFO: train.py:  341]:   [train] fde_nl: 2.234
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.407
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.407
[INFO: train.py:  341]:   [train] resist_count: 2931.000
[INFO: train.py:  341]:   [train] resist_loss: 0.182
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.9860], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8870067596435547
[INFO: train.py:  316]: Interation 8570 took 10.644866228103638
[INFO: train.py:  558]: resist loss: tensor([ 16.9246], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1671853065490723
[INFO: train.py:  316]: Interation 8571 took 2.1704719066619873
[INFO: train.py:  558]: resist loss: tensor([ 5.2458], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0084240436553955
[INFO: train.py:  316]: Interation 8572 took 2.00876784324646
[INFO: train.py:  558]: resist loss: tensor([ 0.5739], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5488255023956299
[INFO: train.py:  316]: Interation 8573 took 1.549144983291626
[INFO: train.py:  558]: resist loss: tensor([ 0.5251], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8379228115081787
[INFO: train.py:  316]: Interation 8574 took 1.845560073852539
[INFO: train.py:  558]: resist loss: tensor([ 2.7845], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6202614307403564
[INFO: train.py:  316]: Interation 8575 took 1.6241564750671387
[INFO: train.py:  558]: resist loss: tensor([ 14.1016], device='cuda:0')
[INFO: train.py:  310]: g step took 2.355687379837036
[INFO: train.py:  316]: Interation 8576 took 2.3725478649139404
[INFO: train.py:  558]: resist loss: tensor([ 1.4132], device='cuda:0')
[INFO: train.py:  310]: g step took 2.119495391845703
[INFO: train.py:  316]: Interation 8577 took 2.119852066040039
[INFO: train.py:  558]: resist loss: tensor([ 1.4844], device='cuda:0')
[INFO: train.py:  310]: g step took 1.976961374282837
[INFO: train.py:  316]: Interation 8578 took 1.977306604385376
[INFO: train.py:  558]: resist loss: tensor([ 7.1288], device='cuda:0')
[INFO: train.py:  310]: g step took 2.45279598236084
[INFO: train.py:  316]: Interation 8579 took 2.4560935497283936
[INFO: train.py:  327]: Checking stats on val ...
Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7fc4e2964630>>
Traceback (most recent call last):
  File "/data/xinjiey/Group_Navi_GAN/env/lib/python3.5/site-packages/torch/utils/data/dataloader.py", line 349, in __del__
    self._shutdown_workers()
  File "/data/xinjiey/Group_Navi_GAN/env/lib/python3.5/site-packages/torch/utils/data/dataloader.py", line 328, in _shutdown_workers
    self.worker_result_queue.get()
  File "/usr/lib/python3.5/multiprocessing/queues.py", line 345, in get
    return ForkingPickler.loads(res)
  File "/data/xinjiey/Group_Navi_GAN/env/lib/python3.5/site-packages/torch/multiprocessing/reductions.py", line 70, in rebuild_storage_fd
    fd = df.detach()
  File "/usr/lib/python3.5/multiprocessing/resource_sharer.py", line 58, in detach
    return reduction.recv_handle(conn)
  File "/usr/lib/python3.5/multiprocessing/reduction.py", line 181, in recv_handle
    return recvfds(s, 1)[0]
  File "/usr/lib/python3.5/multiprocessing/reduction.py", line 152, in recvfds
    msg, ancdata, flags, addr = sock.recvmsg(1, socket.CMSG_LEN(bytes_size))
ConnectionResetError: [Errno 104] Connection reset by peer
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 536, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 536, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 557, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 557, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 562, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 562, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 560, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 560, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 588, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 588, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 588, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 588, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 503, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 503, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 532, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 532, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 584, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 584, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 671, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 671, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 514, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 514, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 166, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 166, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 977, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 977, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 640, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 640, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 767, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 767, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 645, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 645, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 885, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 885, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 851, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 851, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 809, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 809, 2])
[INFO: train.py:  338]:   [val] ade: 0.710
[INFO: train.py:  338]:   [val] ade_l: 1.563
[INFO: train.py:  338]:   [val] ade_nl: 1.300
[INFO: train.py:  338]:   [val] d_loss: 1.414
[INFO: train.py:  338]:   [val] fde: 1.303
[INFO: train.py:  338]:   [val] fde_l: 2.868
[INFO: train.py:  338]:   [val] fde_nl: 2.386
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.493
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.493
[INFO: train.py:  338]:   [val] resist_count: 3199.000
[INFO: train.py:  338]:   [val] resist_loss: 0.390
[INFO: train.py:  341]:   [train] ade: 0.717
[INFO: train.py:  341]:   [train] ade_l: 1.518
[INFO: train.py:  341]:   [train] ade_nl: 1.360
[INFO: train.py:  341]:   [train] d_loss: 1.413
[INFO: train.py:  341]:   [train] fde: 1.230
[INFO: train.py:  341]:   [train] fde_l: 2.602
[INFO: train.py:  341]:   [train] fde_nl: 2.331
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.472
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.472
[INFO: train.py:  341]:   [train] resist_count: 3909.000
[INFO: train.py:  341]:   [train] resist_loss: 0.247
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 1.8973], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0976076126098633
[INFO: train.py:  316]: Interation 8580 took 11.289150476455688
[INFO: train.py:  558]: resist loss: tensor([ 3.1098], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9930932521820068
[INFO: train.py:  316]: Interation 8581 took 1.993494987487793
[INFO: train.py:  558]: resist loss: tensor([ 12.4888], device='cuda:0')
[INFO: train.py:  310]: g step took 2.16630482673645
[INFO: train.py:  316]: Interation 8582 took 2.166701316833496
[INFO: train.py:  558]: resist loss: tensor([ 10.3029], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7571122646331787
[INFO: train.py:  316]: Interation 8583 took 1.761131763458252
[INFO: train.py:  558]: resist loss: tensor([ 0.7554], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7104337215423584
[INFO: train.py:  316]: Interation 8584 took 1.714341402053833
[INFO: train.py:  558]: resist loss: tensor([ 2.9704], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8423359394073486
[INFO: train.py:  316]: Interation 8585 took 1.8462448120117188
[INFO: train.py:  558]: resist loss: tensor([ 0.6370], device='cuda:0')
[INFO: train.py:  310]: g step took 2.25669002532959
[INFO: train.py:  316]: Interation 8586 took 2.260742425918579
[INFO: train.py:  558]: resist loss: tensor([ 0.7648], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6828761100769043
[INFO: train.py:  316]: Interation 8587 took 1.6861398220062256
[INFO: train.py:  558]: resist loss: tensor([ 2.0202], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8100879192352295
[INFO: train.py:  316]: Interation 8588 took 1.8139734268188477
[INFO: train.py:  558]: resist loss: tensor([ 7.6104], device='cuda:0')
[INFO: train.py:  310]: g step took 2.324385166168213
[INFO: train.py:  316]: Interation 8589 took 2.3281919956207275
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 523, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 523, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 577, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 577, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 472, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 472, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 528, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 528, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 655, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 655, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 557, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 557, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 544, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 544, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 532, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 532, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 569, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 569, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 550, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 550, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 642, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 642, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 212, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 212, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 866, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 866, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 717, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 717, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 792, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 792, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 867, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 867, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 663, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 663, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 901, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 901, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 777, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 777, 2])
[INFO: train.py:  338]:   [val] ade: 0.626
[INFO: train.py:  338]:   [val] ade_l: 1.378
[INFO: train.py:  338]:   [val] ade_nl: 1.146
[INFO: train.py:  338]:   [val] d_loss: 1.416
[INFO: train.py:  338]:   [val] fde: 1.234
[INFO: train.py:  338]:   [val] fde_l: 2.717
[INFO: train.py:  338]:   [val] fde_nl: 2.261
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.443
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.443
[INFO: train.py:  338]:   [val] resist_count: 3132.000
[INFO: train.py:  338]:   [val] resist_loss: 0.338
[INFO: train.py:  341]:   [train] ade: 0.624
[INFO: train.py:  341]:   [train] ade_l: 1.299
[INFO: train.py:  341]:   [train] ade_nl: 1.201
[INFO: train.py:  341]:   [train] d_loss: 1.405
[INFO: train.py:  341]:   [train] fde: 1.159
[INFO: train.py:  341]:   [train] fde_l: 2.412
[INFO: train.py:  341]:   [train] fde_nl: 2.230
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.393
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.393
[INFO: train.py:  341]:   [train] resist_count: 3656.000
[INFO: train.py:  341]:   [train] resist_loss: 0.214
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 12.0310], device='cuda:0')
[INFO: train.py:  310]: g step took 2.022897481918335
[INFO: train.py:  316]: Interation 8590 took 10.777979373931885
[INFO: train.py:  558]: resist loss: tensor([ 0.9080], device='cuda:0')
[INFO: train.py:  310]: g step took 1.782320261001587
[INFO: train.py:  316]: Interation 8591 took 1.786043643951416
[INFO: train.py:  558]: resist loss: tensor([ 7.1069], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5619492530822754
[INFO: train.py:  316]: Interation 8592 took 1.5658268928527832
[INFO: train.py:  558]: resist loss: tensor([ 16.1417], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0037665367126465
[INFO: train.py:  316]: Interation 8593 took 2.0082807540893555
[INFO: train.py:  558]: resist loss: tensor([ 3.2390], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8911247253417969
[INFO: train.py:  316]: Interation 8594 took 1.8951263427734375
[INFO: train.py:  558]: resist loss: tensor([ 1.9933], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0028676986694336
[INFO: train.py:  316]: Interation 8595 took 2.0066051483154297
[INFO: train.py:  558]: resist loss: tensor([ 6.2968], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8903188705444336
[INFO: train.py:  316]: Interation 8596 took 1.8940472602844238
[INFO: train.py:  558]: resist loss: tensor([ 4.2660], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9467451572418213
[INFO: train.py:  316]: Interation 8597 took 1.9504659175872803
[INFO: train.py:  558]: resist loss: tensor([ 5.9011], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9867031574249268
[INFO: train.py:  316]: Interation 8598 took 1.9905517101287842
[INFO: train.py:  558]: resist loss: tensor([ 13.7913], device='cuda:0')
[INFO: train.py:  310]: g step took 2.165181875228882
[INFO: train.py:  316]: Interation 8599 took 2.168935537338257
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 583, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 583, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 463, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 463, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 466, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 466, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 578, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 578, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 669, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 669, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 476, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 476, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 515, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 515, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 627, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 627, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 593, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 593, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 636, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 636, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 606, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 606, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 149, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 149, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 785, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 785, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 808, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 808, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 591, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 591, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 838, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 838, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 852, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 852, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 781, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 781, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 886, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 886, 2])
[INFO: train.py:  338]:   [val] ade: 0.717
[INFO: train.py:  338]:   [val] ade_l: 1.578
[INFO: train.py:  338]:   [val] ade_nl: 1.313
[INFO: train.py:  338]:   [val] d_loss: 1.419
[INFO: train.py:  338]:   [val] fde: 1.254
[INFO: train.py:  338]:   [val] fde_l: 2.760
[INFO: train.py:  338]:   [val] fde_nl: 2.297
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.515
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.515
[INFO: train.py:  338]:   [val] resist_count: 3120.000
[INFO: train.py:  338]:   [val] resist_loss: 0.372
[INFO: train.py:  341]:   [train] ade: 0.714
[INFO: train.py:  341]:   [train] ade_l: 1.512
[INFO: train.py:  341]:   [train] ade_nl: 1.352
[INFO: train.py:  341]:   [train] d_loss: 1.420
[INFO: train.py:  341]:   [train] fde: 1.185
[INFO: train.py:  341]:   [train] fde_l: 2.510
[INFO: train.py:  341]:   [train] fde_nl: 2.245
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.461
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.461
[INFO: train.py:  341]:   [train] resist_count: 3662.000
[INFO: train.py:  341]:   [train] resist_loss: 0.213
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 5.4462], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9045124053955078
[INFO: train.py:  316]: Interation 8600 took 10.698832511901855
[INFO: train.py:  558]: resist loss: tensor([ 7.9808], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6742424964904785
[INFO: train.py:  316]: Interation 8601 took 1.6782379150390625
[INFO: train.py:  558]: resist loss: tensor([ 17.4660], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9705960750579834
[INFO: train.py:  316]: Interation 8602 took 1.974670648574829
[INFO: train.py:  558]: resist loss: tensor([ 1.7265], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8490421772003174
[INFO: train.py:  316]: Interation 8603 took 1.8523051738739014
[INFO: train.py:  558]: resist loss: tensor([ 10.8657], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9444212913513184
[INFO: train.py:  316]: Interation 8604 took 1.9481892585754395
[INFO: train.py:  558]: resist loss: tensor([ 5.3953], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0195422172546387
[INFO: train.py:  316]: Interation 8605 took 2.023452043533325
[INFO: train.py:  558]: resist loss: tensor([ 8.0057], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8123281002044678
[INFO: train.py:  316]: Interation 8606 took 1.816056728363037
[INFO: train.py:  558]: resist loss: tensor([ 1.9773], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8729915618896484
[INFO: train.py:  316]: Interation 8607 took 1.8767099380493164
[INFO: train.py:  558]: resist loss: tensor([ 2.9368], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2698471546173096
[INFO: train.py:  316]: Interation 8608 took 2.2735393047332764
[INFO: train.py:  558]: resist loss: tensor([ 0.1311], device='cuda:0')
[INFO: train.py:  310]: g step took 0.2696232795715332
[INFO: train.py:  316]: Interation 8609 took 0.2735331058502197
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 630, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 630, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 621, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 621, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 613, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 613, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 448, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 448, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 624, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 624, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 542, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 542, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 594, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 594, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 547, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 547, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 529, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 529, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 546, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 546, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 530, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 530, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 137, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 137, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 780, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 780, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 1009, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 1009, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 860, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 860, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 665, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 665, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 603, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 603, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 1039, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 1039, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 739, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 739, 2])
[INFO: train.py:  338]:   [val] ade: 0.637
[INFO: train.py:  338]:   [val] ade_l: 1.402
[INFO: train.py:  338]:   [val] ade_nl: 1.166
[INFO: train.py:  338]:   [val] d_loss: 1.413
[INFO: train.py:  338]:   [val] fde: 1.315
[INFO: train.py:  338]:   [val] fde_l: 2.894
[INFO: train.py:  338]:   [val] fde_nl: 2.408
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.471
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.471
[INFO: train.py:  338]:   [val] resist_count: 2643.000
[INFO: train.py:  338]:   [val] resist_loss: 0.305
[INFO: train.py:  341]:   [train] ade: 0.662
[INFO: train.py:  341]:   [train] ade_l: 1.377
[INFO: train.py:  341]:   [train] ade_nl: 1.277
[INFO: train.py:  341]:   [train] d_loss: 1.395
[INFO: train.py:  341]:   [train] fde: 1.275
[INFO: train.py:  341]:   [train] fde_l: 2.650
[INFO: train.py:  341]:   [train] fde_nl: 2.458
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.444
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.444
[INFO: train.py:  341]:   [train] resist_count: 2978.000
[INFO: train.py:  341]:   [train] resist_loss: 0.196
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  279]: Starting epoch 202
[INFO: train.py:  280]: Epoch resist loss: tensor([ 241.4181])
[INFO: train.py:  558]: resist loss: tensor([ 5.2654], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9815354347229004
[INFO: train.py:  316]: Interation 8610 took 11.02423906326294
[INFO: train.py:  558]: resist loss: tensor([ 6.2576], device='cuda:0')
[INFO: train.py:  310]: g step took 2.10713267326355
[INFO: train.py:  316]: Interation 8611 took 2.107726812362671
[INFO: train.py:  558]: resist loss: tensor([ 14.0599], device='cuda:0')
[INFO: train.py:  310]: g step took 2.120650053024292
[INFO: train.py:  316]: Interation 8612 took 2.121044158935547
[INFO: train.py:  558]: resist loss: tensor([ 15.8896], device='cuda:0')
[INFO: train.py:  310]: g step took 2.22168231010437
[INFO: train.py:  316]: Interation 8613 took 2.2220523357391357
[INFO: train.py:  558]: resist loss: tensor([ 2.7605], device='cuda:0')
[INFO: train.py:  310]: g step took 2.134770393371582
[INFO: train.py:  316]: Interation 8614 took 2.1352052688598633
[INFO: train.py:  558]: resist loss: tensor([ 0.7009], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9430673122406006
[INFO: train.py:  316]: Interation 8615 took 1.9472236633300781
[INFO: train.py:  558]: resist loss: tensor([ 3.1455], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9141895771026611
[INFO: train.py:  316]: Interation 8616 took 1.9145452976226807
[INFO: train.py:  558]: resist loss: tensor([ 9.2383], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2839252948760986
[INFO: train.py:  316]: Interation 8617 took 2.2842369079589844
[INFO: train.py:  558]: resist loss: tensor([ 0.5349], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0216336250305176
[INFO: train.py:  316]: Interation 8618 took 2.0489540100097656
[INFO: train.py:  558]: resist loss: tensor([ 1.9501], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9517662525177002
[INFO: train.py:  316]: Interation 8619 took 1.9521093368530273
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 627, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 627, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 496, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 496, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 551, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 551, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 497, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 497, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 547, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 547, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 613, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 613, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 584, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 584, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 508, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 508, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 576, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 576, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 570, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 570, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 632, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 632, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 160, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 160, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 847, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 847, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 969, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 969, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 776, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 776, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 809, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 809, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 728, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 728, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 890, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 890, 2])
[INFO: train.py:  338]:   [val] ade: 0.659
[INFO: train.py:  338]:   [val] ade_l: 1.450
[INFO: train.py:  338]:   [val] ade_nl: 1.206
[INFO: train.py:  338]:   [val] d_loss: 1.410
[INFO: train.py:  338]:   [val] fde: 1.397
[INFO: train.py:  338]:   [val] fde_l: 3.077
[INFO: train.py:  338]:   [val] fde_nl: 2.560
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.485
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.485
[INFO: train.py:  338]:   [val] resist_count: 3436.000
[INFO: train.py:  338]:   [val] resist_loss: 0.324
[INFO: train.py:  341]:   [train] ade: 0.639
[INFO: train.py:  341]:   [train] ade_l: 1.353
[INFO: train.py:  341]:   [train] ade_nl: 1.212
[INFO: train.py:  341]:   [train] d_loss: 1.411
[INFO: train.py:  341]:   [train] fde: 1.285
[INFO: train.py:  341]:   [train] fde_l: 2.718
[INFO: train.py:  341]:   [train] fde_nl: 2.436
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.406
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.406
[INFO: train.py:  341]:   [train] resist_count: 3272.000
[INFO: train.py:  341]:   [train] resist_loss: 0.183
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.6788], device='cuda:0')
[INFO: train.py:  310]: g step took 1.89774751663208
[INFO: train.py:  316]: Interation 8620 took 10.050967931747437
[INFO: train.py:  558]: resist loss: tensor([ 6.4256], device='cuda:0')
[INFO: train.py:  310]: g step took 1.556894063949585
[INFO: train.py:  316]: Interation 8621 took 1.5572311878204346
[INFO: train.py:  558]: resist loss: tensor([ 9.6460], device='cuda:0')
[INFO: train.py:  310]: g step took 1.895660638809204
[INFO: train.py:  316]: Interation 8622 took 1.8960208892822266
[INFO: train.py:  558]: resist loss: tensor([ 4.0004], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1144959926605225
[INFO: train.py:  316]: Interation 8623 took 2.114854097366333
[INFO: train.py:  558]: resist loss: tensor([ 0.3572], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0068554878234863
[INFO: train.py:  316]: Interation 8624 took 2.007167339324951
[INFO: train.py:  558]: resist loss: tensor([ 7.3271], device='cuda:0')
[INFO: train.py:  310]: g step took 2.035506248474121
[INFO: train.py:  316]: Interation 8625 took 2.0358688831329346
[INFO: train.py:  558]: resist loss: tensor([ 5.4704], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8875515460968018
[INFO: train.py:  316]: Interation 8626 took 1.8907997608184814
[INFO: train.py:  558]: resist loss: tensor([ 6.3470], device='cuda:0')
[INFO: train.py:  310]: g step took 2.080411195755005
[INFO: train.py:  316]: Interation 8627 took 2.084285259246826
[INFO: train.py:  558]: resist loss: tensor([ 6.2140], device='cuda:0')
[INFO: train.py:  310]: g step took 2.324225902557373
[INFO: train.py:  316]: Interation 8628 took 2.327976703643799
[INFO: train.py:  558]: resist loss: tensor([ 0.5017], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0400071144104004
[INFO: train.py:  316]: Interation 8629 took 2.0442299842834473
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 562, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 562, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 560, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 560, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 661, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 661, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 653, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 653, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 541, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 541, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 599, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 599, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 574, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 574, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 531, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 531, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 499, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 499, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 544, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 544, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 504, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 504, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 133, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 133, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 676, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 676, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 1020, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 1020, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 803, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 803, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 828, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 828, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 665, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 665, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 580, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 580, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 730, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 730, 2])
[INFO: train.py:  338]:   [val] ade: 0.641
[INFO: train.py:  338]:   [val] ade_l: 1.411
[INFO: train.py:  338]:   [val] ade_nl: 1.174
[INFO: train.py:  338]:   [val] d_loss: 1.417
[INFO: train.py:  338]:   [val] fde: 1.373
[INFO: train.py:  338]:   [val] fde_l: 3.023
[INFO: train.py:  338]:   [val] fde_nl: 2.515
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.495
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.495
[INFO: train.py:  338]:   [val] resist_count: 3363.000
[INFO: train.py:  338]:   [val] resist_loss: 0.301
[INFO: train.py:  341]:   [train] ade: 0.629
[INFO: train.py:  341]:   [train] ade_l: 1.310
[INFO: train.py:  341]:   [train] ade_nl: 1.212
[INFO: train.py:  341]:   [train] d_loss: 1.381
[INFO: train.py:  341]:   [train] fde: 1.297
[INFO: train.py:  341]:   [train] fde_l: 2.699
[INFO: train.py:  341]:   [train] fde_nl: 2.497
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.421
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.421
[INFO: train.py:  341]:   [train] resist_count: 2924.000
[INFO: train.py:  341]:   [train] resist_loss: 0.159
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 8.5072], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9813103675842285
[INFO: train.py:  316]: Interation 8630 took 10.318015575408936
[INFO: train.py:  558]: resist loss: tensor([ 9.1190], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9247329235076904
[INFO: train.py:  316]: Interation 8631 took 1.9285855293273926
[INFO: train.py:  558]: resist loss: tensor([ 1.8404], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7481284141540527
[INFO: train.py:  316]: Interation 8632 took 1.7516825199127197
[INFO: train.py:  558]: resist loss: tensor([ 0.5870], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6336779594421387
[INFO: train.py:  316]: Interation 8633 took 1.6375432014465332
[INFO: train.py:  558]: resist loss: tensor([ 0.9396], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9355814456939697
[INFO: train.py:  316]: Interation 8634 took 1.9385497570037842
[INFO: train.py:  558]: resist loss: tensor([ 6.4298], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1509623527526855
[INFO: train.py:  316]: Interation 8635 took 2.154831647872925
[INFO: train.py:  558]: resist loss: tensor([ 2.7116], device='cuda:0')
[INFO: train.py:  310]: g step took 2.269970655441284
[INFO: train.py:  316]: Interation 8636 took 2.2734622955322266
[INFO: train.py:  558]: resist loss: tensor([ 4.8505], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7707622051239014
[INFO: train.py:  316]: Interation 8637 took 1.7746124267578125
[INFO: train.py:  558]: resist loss: tensor([ 1.7597], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9417667388916016
[INFO: train.py:  316]: Interation 8638 took 1.945472240447998
[INFO: train.py:  558]: resist loss: tensor([ 9.1136], device='cuda:0')
[INFO: train.py:  310]: g step took 2.196331739425659
[INFO: train.py:  316]: Interation 8639 took 2.2001466751098633
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 547, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 547, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 561, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 561, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 610, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 610, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 543, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 543, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 537, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 537, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 533, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 533, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 505, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 505, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 581, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 581, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 631, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 631, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 613, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 613, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 570, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 570, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 130, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 130, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 917, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 917, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 842, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 842, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 781, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 781, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 880, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 880, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 805, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 805, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 992, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 992, 2])
[INFO: train.py:  338]:   [val] ade: 0.659
[INFO: train.py:  338]:   [val] ade_l: 1.452
[INFO: train.py:  338]:   [val] ade_nl: 1.208
[INFO: train.py:  338]:   [val] d_loss: 1.403
[INFO: train.py:  338]:   [val] fde: 1.436
[INFO: train.py:  338]:   [val] fde_l: 3.163
[INFO: train.py:  338]:   [val] fde_nl: 2.632
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.541
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.541
[INFO: train.py:  338]:   [val] resist_count: 2509.000
[INFO: train.py:  338]:   [val] resist_loss: 0.229
[INFO: train.py:  341]:   [train] ade: 0.651
[INFO: train.py:  341]:   [train] ade_l: 1.368
[INFO: train.py:  341]:   [train] ade_nl: 1.241
[INFO: train.py:  341]:   [train] d_loss: 1.399
[INFO: train.py:  341]:   [train] fde: 1.326
[INFO: train.py:  341]:   [train] fde_l: 2.788
[INFO: train.py:  341]:   [train] fde_nl: 2.528
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.461
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.461
[INFO: train.py:  341]:   [train] resist_count: 2333.000
[INFO: train.py:  341]:   [train] resist_loss: 0.110
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 3.4805], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5871860980987549
[INFO: train.py:  316]: Interation 8640 took 9.78708529472351
[INFO: train.py:  558]: resist loss: tensor([ 3.1178], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9018640518188477
[INFO: train.py:  316]: Interation 8641 took 1.9055440425872803
[INFO: train.py:  558]: resist loss: tensor([ 1.2813], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4664218425750732
[INFO: train.py:  316]: Interation 8642 took 1.4696812629699707
[INFO: train.py:  558]: resist loss: tensor([ 6.9552], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9260480403900146
[INFO: train.py:  316]: Interation 8643 took 1.929884433746338
[INFO: train.py:  558]: resist loss: tensor([ 1.9765], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0248682498931885
[INFO: train.py:  316]: Interation 8644 took 2.0281412601470947
[INFO: train.py:  558]: resist loss: tensor([ 2.7400], device='cuda:0')
[INFO: train.py:  310]: g step took 2.083132028579712
[INFO: train.py:  316]: Interation 8645 took 2.0870375633239746
[INFO: train.py:  558]: resist loss: tensor([ 1.2694], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0116078853607178
[INFO: train.py:  316]: Interation 8646 took 2.015392303466797
[INFO: train.py:  558]: resist loss: tensor([ 1.0054], device='cuda:0')
[INFO: train.py:  310]: g step took 1.843834638595581
[INFO: train.py:  316]: Interation 8647 took 1.847644329071045
[INFO: train.py:  558]: resist loss: tensor([ 15.6916], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9681775569915771
[INFO: train.py:  316]: Interation 8648 took 1.971897840499878
[INFO: train.py:  558]: resist loss: tensor([ 8.3858], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6576614379882812
[INFO: train.py:  316]: Interation 8649 took 1.661468267440796
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 606, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 606, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 581, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 581, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 596, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 596, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 498, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 498, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 574, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 574, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 565, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 565, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 552, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 552, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 486, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 486, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 625, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 625, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 519, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 519, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 569, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 569, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 190, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 190, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 739, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 739, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 792, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 792, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 1000, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 1000, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 888, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 888, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 933, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 933, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 877, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 877, 2])
[INFO: train.py:  338]:   [val] ade: 0.630
[INFO: train.py:  338]:   [val] ade_l: 1.388
[INFO: train.py:  338]:   [val] ade_nl: 1.155
[INFO: train.py:  338]:   [val] d_loss: 1.417
[INFO: train.py:  338]:   [val] fde: 1.357
[INFO: train.py:  338]:   [val] fde_l: 2.987
[INFO: train.py:  338]:   [val] fde_nl: 2.485
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.499
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.499
[INFO: train.py:  338]:   [val] resist_count: 3097.000
[INFO: train.py:  338]:   [val] resist_loss: 0.315
[INFO: train.py:  341]:   [train] ade: 0.606
[INFO: train.py:  341]:   [train] ade_l: 1.259
[INFO: train.py:  341]:   [train] ade_nl: 1.168
[INFO: train.py:  341]:   [train] d_loss: 1.400
[INFO: train.py:  341]:   [train] fde: 1.222
[INFO: train.py:  341]:   [train] fde_l: 2.539
[INFO: train.py:  341]:   [train] fde_nl: 2.356
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.381
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.381
[INFO: train.py:  341]:   [train] resist_count: 3038.000
[INFO: train.py:  341]:   [train] resist_loss: 0.160
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 3.2469], device='cuda:0')
[INFO: train.py:  310]: g step took 2.505744218826294
[INFO: train.py:  316]: Interation 8650 took 11.212249994277954
[INFO: train.py:  558]: resist loss: tensor([ 6.3666], device='cuda:0')
[INFO: train.py:  310]: g step took 2.365635395050049
[INFO: train.py:  316]: Interation 8651 took 2.369978666305542
[INFO: train.py:  558]: resist loss: tensor([ 0.], device='cuda:0')
[INFO: train.py:  310]: g step took 0.18935704231262207
[INFO: train.py:  316]: Interation 8652 took 0.19318580627441406
[INFO: train.py:  279]: Starting epoch 203
[INFO: train.py:  280]: Epoch resist loss: tensor([ 210.1464])
[INFO: train.py:  558]: resist loss: tensor([ 0.6830], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2413415908813477
[INFO: train.py:  316]: Interation 8653 took 2.593292713165283
[INFO: train.py:  558]: resist loss: tensor([ 12.7779], device='cuda:0')
[INFO: train.py:  310]: g step took 2.5228021144866943
[INFO: train.py:  316]: Interation 8654 took 2.530609369277954
[INFO: train.py:  558]: resist loss: tensor([ 7.5788], device='cuda:0')
[INFO: train.py:  310]: g step took 2.327714681625366
[INFO: train.py:  316]: Interation 8655 took 2.3320882320404053
[INFO: train.py:  558]: resist loss: tensor([ 7.3858], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3928420543670654
[INFO: train.py:  316]: Interation 8656 took 2.4039695262908936
[INFO: train.py:  558]: resist loss: tensor([ 2.8470], device='cuda:0')
[INFO: train.py:  310]: g step took 2.070814371109009
[INFO: train.py:  316]: Interation 8657 took 2.071213722229004
[INFO: train.py:  558]: resist loss: tensor([ 4.1174], device='cuda:0')
[INFO: train.py:  310]: g step took 2.354740619659424
[INFO: train.py:  316]: Interation 8658 took 2.3660659790039062
[INFO: train.py:  558]: resist loss: tensor([ 7.3242], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1299831867218018
[INFO: train.py:  316]: Interation 8659 took 2.130347967147827
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 572, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 572, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 656, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 656, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 474, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 474, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 596, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 596, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 690, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 690, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 589, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 589, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 503, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 503, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 511, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 511, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 522, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 522, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 628, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 628, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 489, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 489, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 131, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 131, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 621, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 621, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 762, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 762, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 688, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 688, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 901, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 901, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 555, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 555, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 946, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 946, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 824, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 824, 2])
[INFO: train.py:  338]:   [val] ade: 0.629
[INFO: train.py:  338]:   [val] ade_l: 1.385
[INFO: train.py:  338]:   [val] ade_nl: 1.153
[INFO: train.py:  338]:   [val] d_loss: 1.408
[INFO: train.py:  338]:   [val] fde: 1.337
[INFO: train.py:  338]:   [val] fde_l: 2.944
[INFO: train.py:  338]:   [val] fde_nl: 2.450
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.476
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.476
[INFO: train.py:  338]:   [val] resist_count: 3096.000
[INFO: train.py:  338]:   [val] resist_loss: 0.318
[INFO: train.py:  341]:   [train] ade: 0.611
[INFO: train.py:  341]:   [train] ade_l: 1.301
[INFO: train.py:  341]:   [train] ade_nl: 1.151
[INFO: train.py:  341]:   [train] d_loss: 1.398
[INFO: train.py:  341]:   [train] fde: 1.256
[INFO: train.py:  341]:   [train] fde_l: 2.676
[INFO: train.py:  341]:   [train] fde_nl: 2.368
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.394
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.394
[INFO: train.py:  341]:   [train] resist_count: 2674.000
[INFO: train.py:  341]:   [train] resist_loss: 0.160
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 10.4009], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3405861854553223
[INFO: train.py:  316]: Interation 8660 took 11.987353801727295
[INFO: train.py:  558]: resist loss: tensor([ 1.7317], device='cuda:0')
[INFO: train.py:  310]: g step took 2.7004880905151367
[INFO: train.py:  316]: Interation 8661 took 2.7044689655303955
[INFO: train.py:  558]: resist loss: tensor([ 4.8829], device='cuda:0')
[INFO: train.py:  310]: g step took 2.656325340270996
[INFO: train.py:  316]: Interation 8662 took 2.6566808223724365
[INFO: train.py:  558]: resist loss: tensor([ 7.2568], device='cuda:0')
[INFO: train.py:  310]: g step took 2.807098150253296
[INFO: train.py:  316]: Interation 8663 took 2.81131911277771
[INFO: train.py:  558]: resist loss: tensor([ 2.5962], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1322872638702393
[INFO: train.py:  316]: Interation 8664 took 2.1388497352600098
[INFO: train.py:  558]: resist loss: tensor([ 1.9976], device='cuda:0')
[INFO: train.py:  310]: g step took 2.261054754257202
[INFO: train.py:  316]: Interation 8665 took 2.2614388465881348
[INFO: train.py:  558]: resist loss: tensor([ 7.7455], device='cuda:0')
[INFO: train.py:  310]: g step took 2.6454033851623535
[INFO: train.py:  316]: Interation 8666 took 2.6526620388031006
[INFO: train.py:  558]: resist loss: tensor([ 0.7771], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0877299308776855
[INFO: train.py:  316]: Interation 8667 took 2.088148832321167
[INFO: train.py:  558]: resist loss: tensor([ 1.0232], device='cuda:0')
[INFO: train.py:  310]: g step took 2.5902810096740723
[INFO: train.py:  316]: Interation 8668 took 2.5906982421875
[INFO: train.py:  558]: resist loss: tensor([ 0.7422], device='cuda:0')
[INFO: train.py:  310]: g step took 2.071794033050537
[INFO: train.py:  316]: Interation 8669 took 2.075854778289795
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 612, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 612, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 540, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 540, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 461, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 461, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 567, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 567, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 645, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 645, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 499, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 499, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 516, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 516, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 594, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 594, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 648, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 648, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 487, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 487, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 633, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 633, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 159, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 159, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 795, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 795, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 761, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 761, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 734, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 734, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 803, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 803, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 852, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 852, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 850, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 850, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 636, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 636, 2])
[INFO: train.py:  338]:   [val] ade: 0.641
[INFO: train.py:  338]:   [val] ade_l: 1.412
[INFO: train.py:  338]:   [val] ade_nl: 1.175
[INFO: train.py:  338]:   [val] d_loss: 1.407
[INFO: train.py:  338]:   [val] fde: 1.325
[INFO: train.py:  338]:   [val] fde_l: 2.917
[INFO: train.py:  338]:   [val] fde_nl: 2.427
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.498
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.498
[INFO: train.py:  338]:   [val] resist_count: 3016.000
[INFO: train.py:  338]:   [val] resist_loss: 0.281
[INFO: train.py:  341]:   [train] ade: 0.622
[INFO: train.py:  341]:   [train] ade_l: 1.287
[INFO: train.py:  341]:   [train] ade_nl: 1.204
[INFO: train.py:  341]:   [train] d_loss: 1.407
[INFO: train.py:  341]:   [train] fde: 1.250
[INFO: train.py:  341]:   [train] fde_l: 2.586
[INFO: train.py:  341]:   [train] fde_nl: 2.419
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.430
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.430
[INFO: train.py:  341]:   [train] resist_count: 3133.000
[INFO: train.py:  341]:   [train] resist_loss: 0.169
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 1.5147], device='cuda:0')
[INFO: train.py:  310]: g step took 2.442413568496704
[INFO: train.py:  316]: Interation 8670 took 12.208387613296509
[INFO: train.py:  558]: resist loss: tensor([ 10.8558], device='cuda:0')
[INFO: train.py:  310]: g step took 2.096670150756836
[INFO: train.py:  316]: Interation 8671 took 2.101083993911743
[INFO: train.py:  558]: resist loss: tensor([ 9.7750], device='cuda:0')
[INFO: train.py:  310]: g step took 2.490670919418335
[INFO: train.py:  316]: Interation 8672 took 2.4948244094848633
[INFO: train.py:  558]: resist loss: tensor([ 2.9587], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2451443672180176
[INFO: train.py:  316]: Interation 8673 took 2.248479127883911
[INFO: train.py:  558]: resist loss: tensor([ 2.5907], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1694533824920654
[INFO: train.py:  316]: Interation 8674 took 2.1734983921051025
[INFO: train.py:  558]: resist loss: tensor([ 3.2578], device='cuda:0')
[INFO: train.py:  310]: g step took 2.113293170928955
[INFO: train.py:  316]: Interation 8675 took 2.117316722869873
[INFO: train.py:  558]: resist loss: tensor([ 1.2655], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9082801342010498
[INFO: train.py:  316]: Interation 8676 took 1.91231369972229
[INFO: train.py:  558]: resist loss: tensor([ 2.9673], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0858101844787598
[INFO: train.py:  316]: Interation 8677 took 2.089771270751953
[INFO: train.py:  558]: resist loss: tensor([ 3.1542], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3838050365448
[INFO: train.py:  316]: Interation 8678 took 2.387869358062744
[INFO: train.py:  558]: resist loss: tensor([ 14.5289], device='cuda:0')
[INFO: train.py:  310]: g step took 2.5248355865478516
[INFO: train.py:  316]: Interation 8679 took 2.528949022293091
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 490, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 490, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 630, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 630, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 537, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 537, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 556, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 556, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 496, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 496, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 503, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 503, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 636, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 636, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 568, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 568, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 488, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 488, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 577, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 577, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 723, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 723, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 157, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 157, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 885, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 885, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 698, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 698, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 626, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 626, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 996, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 996, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 687, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 687, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 798, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 798, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 712, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 712, 2])
[INFO: train.py:  338]:   [val] ade: 0.638
[INFO: train.py:  338]:   [val] ade_l: 1.405
[INFO: train.py:  338]:   [val] ade_nl: 1.169
[INFO: train.py:  338]:   [val] d_loss: 1.409
[INFO: train.py:  338]:   [val] fde: 1.282
[INFO: train.py:  338]:   [val] fde_l: 2.823
[INFO: train.py:  338]:   [val] fde_nl: 2.349
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.491
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.491
[INFO: train.py:  338]:   [val] resist_count: 2915.000
[INFO: train.py:  338]:   [val] resist_loss: 0.326
[INFO: train.py:  341]:   [train] ade: 0.639
[INFO: train.py:  341]:   [train] ade_l: 1.334
[INFO: train.py:  341]:   [train] ade_nl: 1.227
[INFO: train.py:  341]:   [train] d_loss: 1.405
[INFO: train.py:  341]:   [train] fde: 1.216
[INFO: train.py:  341]:   [train] fde_l: 2.536
[INFO: train.py:  341]:   [train] fde_nl: 2.334
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.429
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.429
[INFO: train.py:  341]:   [train] resist_count: 3116.000
[INFO: train.py:  341]:   [train] resist_loss: 0.208
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 7.6212], device='cuda:0')
[INFO: train.py:  310]: g step took 2.54929256439209
[INFO: train.py:  316]: Interation 8680 took 12.484875917434692
[INFO: train.py:  558]: resist loss: tensor([ 4.4012], device='cuda:0')
[INFO: train.py:  310]: g step took 2.128411054611206
[INFO: train.py:  316]: Interation 8681 took 2.131519317626953
[INFO: train.py:  558]: resist loss: tensor([ 2.1230], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4355645179748535
[INFO: train.py:  316]: Interation 8682 took 2.439391613006592
[INFO: train.py:  558]: resist loss: tensor([ 2.5858], device='cuda:0')
[INFO: train.py:  310]: g step took 2.212890148162842
[INFO: train.py:  316]: Interation 8683 took 2.216731071472168
[INFO: train.py:  558]: resist loss: tensor([ 0.3999], device='cuda:0')
[INFO: train.py:  310]: g step took 2.381221294403076
[INFO: train.py:  316]: Interation 8684 took 2.384995222091675
[INFO: train.py:  558]: resist loss: tensor([ 6.3325], device='cuda:0')
[INFO: train.py:  310]: g step took 2.268942356109619
[INFO: train.py:  316]: Interation 8685 took 2.2727463245391846
[INFO: train.py:  558]: resist loss: tensor([ 5.0855], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2394251823425293
[INFO: train.py:  316]: Interation 8686 took 2.2435171604156494
[INFO: train.py:  558]: resist loss: tensor([ 3.3850], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3589112758636475
[INFO: train.py:  316]: Interation 8687 took 2.362725257873535
[INFO: train.py:  558]: resist loss: tensor([ 1.6045], device='cuda:0')
[INFO: train.py:  310]: g step took 2.069943428039551
[INFO: train.py:  316]: Interation 8688 took 2.0738134384155273
[INFO: train.py:  558]: resist loss: tensor([ 0.5029], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8879389762878418
[INFO: train.py:  316]: Interation 8689 took 1.8912601470947266
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 583, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 583, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 553, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 553, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 503, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 503, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 653, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 653, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 613, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 613, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 552, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 552, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 515, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 515, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 528, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 528, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 546, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 546, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 648, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 648, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 519, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 519, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 148, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 148, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 845, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 845, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 638, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 638, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 681, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 681, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 614, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 614, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 650, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 650, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 660, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 660, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 747, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 747, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 986, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 986, 2])
[INFO: train.py:  338]:   [val] ade: 0.626
[INFO: train.py:  338]:   [val] ade_l: 1.379
[INFO: train.py:  338]:   [val] ade_nl: 1.148
[INFO: train.py:  338]:   [val] d_loss: 1.414
[INFO: train.py:  338]:   [val] fde: 1.299
[INFO: train.py:  338]:   [val] fde_l: 2.861
[INFO: train.py:  338]:   [val] fde_nl: 2.380
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.472
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.472
[INFO: train.py:  338]:   [val] resist_count: 3148.000
[INFO: train.py:  338]:   [val] resist_loss: 0.314
[INFO: train.py:  341]:   [train] ade: 0.630
[INFO: train.py:  341]:   [train] ade_l: 1.367
[INFO: train.py:  341]:   [train] ade_nl: 1.169
[INFO: train.py:  341]:   [train] d_loss: 1.411
[INFO: train.py:  341]:   [train] fde: 1.253
[INFO: train.py:  341]:   [train] fde_l: 2.718
[INFO: train.py:  341]:   [train] fde_nl: 2.324
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.424
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.424
[INFO: train.py:  341]:   [train] resist_count: 3069.000
[INFO: train.py:  341]:   [train] resist_loss: 0.197
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 3.1910], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2306580543518066
[INFO: train.py:  316]: Interation 8690 took 12.395864486694336
[INFO: train.py:  558]: resist loss: tensor([ 0.5898], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4951250553131104
[INFO: train.py:  316]: Interation 8691 took 2.49904727935791
[INFO: train.py:  558]: resist loss: tensor([ 5.6120], device='cuda:0')
[INFO: train.py:  310]: g step took 2.363212823867798
[INFO: train.py:  316]: Interation 8692 took 2.3670129776000977
[INFO: train.py:  558]: resist loss: tensor([ 1.2003], device='cuda:0')
[INFO: train.py:  310]: g step took 2.18613600730896
[INFO: train.py:  316]: Interation 8693 took 2.1900739669799805
[INFO: train.py:  558]: resist loss: tensor([ 10.8652], device='cuda:0')
[INFO: train.py:  310]: g step took 2.419203996658325
[INFO: train.py:  316]: Interation 8694 took 2.4230332374572754
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 4.7680], device='cuda:0')
[INFO: train.py:  310]: g step took 0.2070324420928955
[INFO: train.py:  316]: Interation 8695 took 0.21104168891906738
[INFO: train.py:  279]: Starting epoch 204
[INFO: train.py:  280]: Epoch resist loss: tensor([ 190.2841])
[INFO: train.py:  558]: resist loss: tensor([ 13.3008], device='cuda:0')
[INFO: train.py:  310]: g step took 2.579125165939331
[INFO: train.py:  316]: Interation 8696 took 2.929760217666626
[INFO: train.py:  558]: resist loss: tensor([ 6.6067], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2285444736480713
[INFO: train.py:  316]: Interation 8697 took 2.2329649925231934
[INFO: train.py:  558]: resist loss: tensor([ 1.9172], device='cuda:0')
[INFO: train.py:  310]: g step took 2.354360818862915
[INFO: train.py:  316]: Interation 8698 took 2.3789119720458984
[INFO: train.py:  558]: resist loss: tensor([ 4.2630], device='cuda:0')
[INFO: train.py:  310]: g step took 2.326845407485962
[INFO: train.py:  316]: Interation 8699 took 2.327183485031128
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 550, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 550, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 569, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 569, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 628, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 628, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 453, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 453, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 510, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 510, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 731, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 731, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 577, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 577, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 570, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 570, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 637, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 637, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 536, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 536, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 454, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 454, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 146, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 146, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 713, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 713, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 573, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 573, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 809, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 809, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 978, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 978, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 734, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 734, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 750, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 750, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 809, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 809, 2])
[INFO: train.py:  338]:   [val] ade: 0.616
[INFO: train.py:  338]:   [val] ade_l: 1.356
[INFO: train.py:  338]:   [val] ade_nl: 1.128
[INFO: train.py:  338]:   [val] d_loss: 1.422
[INFO: train.py:  338]:   [val] fde: 1.258
[INFO: train.py:  338]:   [val] fde_l: 2.770
[INFO: train.py:  338]:   [val] fde_nl: 2.305
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.431
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.431
[INFO: train.py:  338]:   [val] resist_count: 3004.000
[INFO: train.py:  338]:   [val] resist_loss: 0.344
[INFO: train.py:  341]:   [train] ade: 0.612
[INFO: train.py:  341]:   [train] ade_l: 1.267
[INFO: train.py:  341]:   [train] ade_nl: 1.186
[INFO: train.py:  341]:   [train] d_loss: 1.390
[INFO: train.py:  341]:   [train] fde: 1.159
[INFO: train.py:  341]:   [train] fde_l: 2.398
[INFO: train.py:  341]:   [train] fde_nl: 2.244
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.377
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.377
[INFO: train.py:  341]:   [train] resist_count: 2673.000
[INFO: train.py:  341]:   [train] resist_loss: 0.183
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 6.6667], device='cuda:0')
[INFO: train.py:  310]: g step took 2.269913673400879
[INFO: train.py:  316]: Interation 8700 took 11.297149181365967
[INFO: train.py:  558]: resist loss: tensor([ 4.4059], device='cuda:0')
[INFO: train.py:  310]: g step took 1.914921522140503
[INFO: train.py:  316]: Interation 8701 took 1.9153187274932861
[INFO: train.py:  558]: resist loss: tensor([ 4.9599], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6740226745605469
[INFO: train.py:  316]: Interation 8702 took 1.674408197402954
[INFO: train.py:  558]: resist loss: tensor([ 5.3095], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6635205745697021
[INFO: train.py:  316]: Interation 8703 took 1.6638858318328857
[INFO: train.py:  558]: resist loss: tensor([ 11.7056], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8084888458251953
[INFO: train.py:  316]: Interation 8704 took 1.8088853359222412
[INFO: train.py:  558]: resist loss: tensor([ 11.1683], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2052831649780273
[INFO: train.py:  316]: Interation 8705 took 2.209263563156128
[INFO: train.py:  558]: resist loss: tensor([ 10.7200], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1607160568237305
[INFO: train.py:  316]: Interation 8706 took 2.171689510345459
[INFO: train.py:  558]: resist loss: tensor([ 1.8072], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8394579887390137
[INFO: train.py:  316]: Interation 8707 took 1.8398089408874512
[INFO: train.py:  558]: resist loss: tensor([ 0.4286], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7399601936340332
[INFO: train.py:  316]: Interation 8708 took 1.7403671741485596
[INFO: train.py:  558]: resist loss: tensor([ 1.9422], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8724339008331299
[INFO: train.py:  316]: Interation 8709 took 1.8728346824645996
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 656, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 656, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 580, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 580, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 554, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 554, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 569, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 569, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 565, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 565, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 547, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 547, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 528, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 528, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 478, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 478, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 524, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 524, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 572, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 572, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 579, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 579, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 209, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 209, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 845, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 845, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 674, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 674, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 624, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 624, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 670, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 670, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 897, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 897, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 631, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 631, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 795, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 795, 2])
[INFO: train.py:  338]:   [val] ade: 0.625
[INFO: train.py:  338]:   [val] ade_l: 1.377
[INFO: train.py:  338]:   [val] ade_nl: 1.146
[INFO: train.py:  338]:   [val] d_loss: 1.407
[INFO: train.py:  338]:   [val] fde: 1.259
[INFO: train.py:  338]:   [val] fde_l: 2.772
[INFO: train.py:  338]:   [val] fde_nl: 2.306
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.452
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.452
[INFO: train.py:  338]:   [val] resist_count: 3451.000
[INFO: train.py:  338]:   [val] resist_loss: 0.380
[INFO: train.py:  341]:   [train] ade: 0.629
[INFO: train.py:  341]:   [train] ade_l: 1.334
[INFO: train.py:  341]:   [train] ade_nl: 1.189
[INFO: train.py:  341]:   [train] d_loss: 1.395
[INFO: train.py:  341]:   [train] fde: 1.204
[INFO: train.py:  341]:   [train] fde_l: 2.555
[INFO: train.py:  341]:   [train] fde_nl: 2.277
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.411
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.411
[INFO: train.py:  341]:   [train] resist_count: 3213.000
[INFO: train.py:  341]:   [train] resist_loss: 0.213
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.6366], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9746453762054443
[INFO: train.py:  316]: Interation 8710 took 11.557521104812622
[INFO: train.py:  558]: resist loss: tensor([ 11.2732], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3872947692871094
[INFO: train.py:  316]: Interation 8711 took 2.387629270553589
[INFO: train.py:  558]: resist loss: tensor([ 12.4834], device='cuda:0')
[INFO: train.py:  310]: g step took 2.8047196865081787
[INFO: train.py:  316]: Interation 8712 took 2.8086671829223633
[INFO: train.py:  558]: resist loss: tensor([ 1.9471], device='cuda:0')
[INFO: train.py:  310]: g step took 2.326848268508911
[INFO: train.py:  316]: Interation 8713 took 2.330913782119751
[INFO: train.py:  558]: resist loss: tensor([ 6.0874], device='cuda:0')
[INFO: train.py:  310]: g step took 2.422717332839966
[INFO: train.py:  316]: Interation 8714 took 2.426586627960205
[INFO: train.py:  558]: resist loss: tensor([ 11.9827], device='cuda:0')
[INFO: train.py:  310]: g step took 2.45314621925354
[INFO: train.py:  316]: Interation 8715 took 2.45711088180542
[INFO: train.py:  558]: resist loss: tensor([ 9.3016], device='cuda:0')
[INFO: train.py:  310]: g step took 2.5087978839874268
[INFO: train.py:  316]: Interation 8716 took 2.5127947330474854
[INFO: train.py:  558]: resist loss: tensor([ 5.2666], device='cuda:0')
[INFO: train.py:  310]: g step took 2.757255792617798
[INFO: train.py:  316]: Interation 8717 took 2.7605667114257812
[INFO: train.py:  558]: resist loss: tensor([ 5.5488], device='cuda:0')
[INFO: train.py:  310]: g step took 2.166456460952759
[INFO: train.py:  316]: Interation 8718 took 2.1704254150390625
[INFO: train.py:  558]: resist loss: tensor([ 2.2133], device='cuda:0')
[INFO: train.py:  310]: g step took 2.428331136703491
[INFO: train.py:  316]: Interation 8719 took 2.432283878326416
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 612, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 612, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 556, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 556, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 609, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 609, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 607, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 607, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 500, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 500, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 472, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 472, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 501, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 501, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 551, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 551, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 576, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 576, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 679, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 679, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 550, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 550, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 148, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 148, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 792, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 792, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 649, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 649, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 935, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 935, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 646, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 646, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 724, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 724, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 742, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 742, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 801, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 801, 2])
[INFO: train.py:  338]:   [val] ade: 0.636
[INFO: train.py:  338]:   [val] ade_l: 1.400
[INFO: train.py:  338]:   [val] ade_nl: 1.165
[INFO: train.py:  338]:   [val] d_loss: 1.404
[INFO: train.py:  338]:   [val] fde: 1.275
[INFO: train.py:  338]:   [val] fde_l: 2.808
[INFO: train.py:  338]:   [val] fde_nl: 2.336
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.452
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.452
[INFO: train.py:  338]:   [val] resist_count: 2897.000
[INFO: train.py:  338]:   [val] resist_loss: 0.360
[INFO: train.py:  341]:   [train] ade: 0.643
[INFO: train.py:  341]:   [train] ade_l: 1.386
[INFO: train.py:  341]:   [train] ade_nl: 1.201
[INFO: train.py:  341]:   [train] d_loss: 1.406
[INFO: train.py:  341]:   [train] fde: 1.233
[INFO: train.py:  341]:   [train] fde_l: 2.655
[INFO: train.py:  341]:   [train] fde_nl: 2.300
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.420
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.420
[INFO: train.py:  341]:   [train] resist_count: 2417.000
[INFO: train.py:  341]:   [train] resist_loss: 0.167
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.4302], device='cuda:0')
[INFO: train.py:  310]: g step took 2.081775665283203
[INFO: train.py:  316]: Interation 8720 took 11.94395637512207
[INFO: train.py:  558]: resist loss: tensor([ 7.6040], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0007376670837402
[INFO: train.py:  316]: Interation 8721 took 2.0048987865448
[INFO: train.py:  558]: resist loss: tensor([ 10.7939], device='cuda:0')
[INFO: train.py:  310]: g step took 2.292059898376465
[INFO: train.py:  316]: Interation 8722 took 2.296062469482422
[INFO: train.py:  558]: resist loss: tensor([ 1.9729], device='cuda:0')
[INFO: train.py:  310]: g step took 2.012763738632202
[INFO: train.py:  316]: Interation 8723 took 2.0166194438934326
[INFO: train.py:  558]: resist loss: tensor([ 4.5305], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0763986110687256
[INFO: train.py:  316]: Interation 8724 took 2.0804286003112793
[INFO: train.py:  558]: resist loss: tensor([ 1.3617], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8530547618865967
[INFO: train.py:  316]: Interation 8725 took 1.8566884994506836
[INFO: train.py:  558]: resist loss: tensor([ 0.4822], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1298139095306396
[INFO: train.py:  316]: Interation 8726 took 2.1330199241638184
[INFO: train.py:  558]: resist loss: tensor([ 10.3538], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3159356117248535
[INFO: train.py:  316]: Interation 8727 took 2.319805860519409
[INFO: train.py:  558]: resist loss: tensor([ 5.3685], device='cuda:0')
[INFO: train.py:  310]: g step took 2.000488758087158
[INFO: train.py:  316]: Interation 8728 took 2.0043039321899414
[INFO: train.py:  558]: resist loss: tensor([ 17.7133], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4142937660217285
[INFO: train.py:  316]: Interation 8729 took 2.418149471282959
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 603, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 603, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 664, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 664, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 602, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 602, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 491, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 491, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 543, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 543, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 497, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 497, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 561, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 561, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 597, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 597, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 510, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 510, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 649, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 649, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 528, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 528, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 116, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 116, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 858, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 858, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 872, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 872, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 697, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 697, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 696, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 696, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 683, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 683, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 793, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 793, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 876, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 876, 2])
[INFO: train.py:  338]:   [val] ade: 0.615
[INFO: train.py:  338]:   [val] ade_l: 1.355
[INFO: train.py:  338]:   [val] ade_nl: 1.127
[INFO: train.py:  338]:   [val] d_loss: 1.406
[INFO: train.py:  338]:   [val] fde: 1.276
[INFO: train.py:  338]:   [val] fde_l: 2.811
[INFO: train.py:  338]:   [val] fde_nl: 2.339
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.455
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.455
[INFO: train.py:  338]:   [val] resist_count: 2533.000
[INFO: train.py:  338]:   [val] resist_loss: 0.269
[INFO: train.py:  341]:   [train] ade: 0.607
[INFO: train.py:  341]:   [train] ade_l: 1.264
[INFO: train.py:  341]:   [train] ade_nl: 1.168
[INFO: train.py:  341]:   [train] d_loss: 1.401
[INFO: train.py:  341]:   [train] fde: 1.210
[INFO: train.py:  341]:   [train] fde_l: 2.520
[INFO: train.py:  341]:   [train] fde_nl: 2.328
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.391
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.391
[INFO: train.py:  341]:   [train] resist_count: 2558.000
[INFO: train.py:  341]:   [train] resist_loss: 0.149
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 3.3286], device='cuda:0')
[INFO: train.py:  310]: g step took 1.78019118309021
[INFO: train.py:  316]: Interation 8730 took 10.380881547927856
[INFO: train.py:  558]: resist loss: tensor([ 10.2949], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8992218971252441
[INFO: train.py:  316]: Interation 8731 took 1.9032647609710693
[INFO: train.py:  558]: resist loss: tensor([ 10.5214], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5968072414398193
[INFO: train.py:  316]: Interation 8732 took 1.6006805896759033
[INFO: train.py:  558]: resist loss: tensor([ 4.3170], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1316046714782715
[INFO: train.py:  316]: Interation 8733 took 2.134887218475342
[INFO: train.py:  558]: resist loss: tensor([ 2.1929], device='cuda:0')
[INFO: train.py:  310]: g step took 1.787372350692749
[INFO: train.py:  316]: Interation 8734 took 1.7910826206207275
[INFO: train.py:  558]: resist loss: tensor([ 6.8109], device='cuda:0')
[INFO: train.py:  310]: g step took 2.035468578338623
[INFO: train.py:  316]: Interation 8735 took 2.0393807888031006
[INFO: train.py:  558]: resist loss: tensor([ 4.0560], device='cuda:0')
[INFO: train.py:  310]: g step took 2.164358377456665
[INFO: train.py:  316]: Interation 8736 took 2.168128252029419
[INFO: train.py:  558]: resist loss: tensor([ 1.2370], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8694484233856201
[INFO: train.py:  316]: Interation 8737 took 1.873220682144165
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 4.5644], device='cuda:0')
[INFO: train.py:  310]: g step took 0.22268939018249512
[INFO: train.py:  316]: Interation 8738 took 0.22615623474121094
[INFO: train.py:  279]: Starting epoch 205
[INFO: train.py:  280]: Epoch resist loss: tensor([ 257.3579])
[INFO: train.py:  558]: resist loss: tensor([ 5.4412], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7967658042907715
[INFO: train.py:  316]: Interation 8739 took 2.1607513427734375
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 596, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 596, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 535, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 535, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 522, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 522, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 543, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 543, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 574, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 574, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 604, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 604, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 478, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 478, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 592, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 592, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 706, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 706, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 550, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 550, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 503, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 503, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 158, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 158, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 801, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 801, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 760, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 760, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 578, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 578, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 748, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 748, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 907, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 907, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 819, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 819, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 868, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 868, 2])
[INFO: train.py:  338]:   [val] ade: 0.666
[INFO: train.py:  338]:   [val] ade_l: 1.466
[INFO: train.py:  338]:   [val] ade_nl: 1.220
[INFO: train.py:  338]:   [val] d_loss: 1.407
[INFO: train.py:  338]:   [val] fde: 1.466
[INFO: train.py:  338]:   [val] fde_l: 3.228
[INFO: train.py:  338]:   [val] fde_nl: 2.686
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.562
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.562
[INFO: train.py:  338]:   [val] resist_count: 3333.000
[INFO: train.py:  338]:   [val] resist_loss: 0.294
[INFO: train.py:  341]:   [train] ade: 0.652
[INFO: train.py:  341]:   [train] ade_l: 1.389
[INFO: train.py:  341]:   [train] ade_nl: 1.228
[INFO: train.py:  341]:   [train] d_loss: 1.391
[INFO: train.py:  341]:   [train] fde: 1.397
[INFO: train.py:  341]:   [train] fde_l: 2.979
[INFO: train.py:  341]:   [train] fde_nl: 2.632
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.484
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.484
[INFO: train.py:  341]:   [train] resist_count: 3244.000
[INFO: train.py:  341]:   [train] resist_loss: 0.181
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 8.1512], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6403117179870605
[INFO: train.py:  316]: Interation 8740 took 10.353788137435913
[INFO: train.py:  558]: resist loss: tensor([ 4.6370], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9039721488952637
[INFO: train.py:  316]: Interation 8741 took 1.9082610607147217
[INFO: train.py:  558]: resist loss: tensor([ 17.8534], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4166738986968994
[INFO: train.py:  316]: Interation 8742 took 2.4171016216278076
[INFO: train.py:  558]: resist loss: tensor([ 9.6531], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0813381671905518
[INFO: train.py:  316]: Interation 8743 took 2.0891878604888916
[INFO: train.py:  558]: resist loss: tensor([ 9.0472], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1479029655456543
[INFO: train.py:  316]: Interation 8744 took 2.14823317527771
[INFO: train.py:  558]: resist loss: tensor([ 3.4089], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7107429504394531
[INFO: train.py:  316]: Interation 8745 took 1.7110862731933594
[INFO: train.py:  558]: resist loss: tensor([ 0.6638], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9276952743530273
[INFO: train.py:  316]: Interation 8746 took 1.9280319213867188
[INFO: train.py:  558]: resist loss: tensor([ 4.9126], device='cuda:0')
[INFO: train.py:  310]: g step took 2.21211576461792
[INFO: train.py:  316]: Interation 8747 took 2.219857692718506
[INFO: train.py:  558]: resist loss: tensor([ 8.7737], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7797629833221436
[INFO: train.py:  316]: Interation 8748 took 1.7905142307281494
[INFO: train.py:  558]: resist loss: tensor([ 4.6472], device='cuda:0')
[INFO: train.py:  310]: g step took 1.990295171737671
[INFO: train.py:  316]: Interation 8749 took 1.997809886932373
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 574, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 574, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 497, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 497, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 541, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 541, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 544, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 544, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 497, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 497, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 527, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 527, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 638, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 638, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 482, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 482, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 664, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 664, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 691, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 691, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 527, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 527, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 179, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 179, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 839, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 839, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 797, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 797, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 864, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 864, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 779, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 779, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 761, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 761, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 626, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 626, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 566, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 566, 2])
[INFO: train.py:  338]:   [val] ade: 0.692
[INFO: train.py:  338]:   [val] ade_l: 1.523
[INFO: train.py:  338]:   [val] ade_nl: 1.267
[INFO: train.py:  338]:   [val] d_loss: 1.403
[INFO: train.py:  338]:   [val] fde: 1.504
[INFO: train.py:  338]:   [val] fde_l: 3.312
[INFO: train.py:  338]:   [val] fde_nl: 2.756
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.562
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.562
[INFO: train.py:  338]:   [val] resist_count: 3517.000
[INFO: train.py:  338]:   [val] resist_loss: 0.327
[INFO: train.py:  341]:   [train] ade: 0.666
[INFO: train.py:  341]:   [train] ade_l: 1.401
[INFO: train.py:  341]:   [train] ade_nl: 1.271
[INFO: train.py:  341]:   [train] d_loss: 1.389
[INFO: train.py:  341]:   [train] fde: 1.402
[INFO: train.py:  341]:   [train] fde_l: 2.949
[INFO: train.py:  341]:   [train] fde_nl: 2.674
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.472
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.472
[INFO: train.py:  341]:   [train] resist_count: 2775.000
[INFO: train.py:  341]:   [train] resist_loss: 0.173
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 1.9245], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2304527759552
[INFO: train.py:  316]: Interation 8750 took 10.745328664779663
[INFO: train.py:  558]: resist loss: tensor([ 2.1376], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8486998081207275
[INFO: train.py:  316]: Interation 8751 took 1.8491699695587158
[INFO: train.py:  558]: resist loss: tensor([ 6.7089], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8224644660949707
[INFO: train.py:  316]: Interation 8752 took 1.8229279518127441
[INFO: train.py:  558]: resist loss: tensor([ 2.2028], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9057061672210693
[INFO: train.py:  316]: Interation 8753 took 1.9098718166351318
[INFO: train.py:  558]: resist loss: tensor([ 1.5996], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3531861305236816
[INFO: train.py:  316]: Interation 8754 took 2.3535358905792236
[INFO: train.py:  558]: resist loss: tensor([ 0.8046], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9855773448944092
[INFO: train.py:  316]: Interation 8755 took 1.9898004531860352
[INFO: train.py:  558]: resist loss: tensor([ 8.7534], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9410672187805176
[INFO: train.py:  316]: Interation 8756 took 1.9453084468841553
[INFO: train.py:  558]: resist loss: tensor([ 1.2713], device='cuda:0')
[INFO: train.py:  310]: g step took 2.107041120529175
[INFO: train.py:  316]: Interation 8757 took 2.110949754714966
[INFO: train.py:  558]: resist loss: tensor([ 1.3663], device='cuda:0')
[INFO: train.py:  310]: g step took 1.95699143409729
[INFO: train.py:  316]: Interation 8758 took 1.9606866836547852
[INFO: train.py:  558]: resist loss: tensor([ 2.7106], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0279688835144043
[INFO: train.py:  316]: Interation 8759 took 2.0320167541503906
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 682, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 682, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 522, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 522, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 462, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 462, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 519, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 519, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 528, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 528, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 494, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 494, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 525, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 525, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 581, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 581, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 540, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 540, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 722, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 722, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 628, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 628, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 158, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 158, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 682, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 682, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 674, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 674, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 869, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 869, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 703, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 703, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 785, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 785, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 681, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 681, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 625, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 625, 2])
[INFO: train.py:  338]:   [val] ade: 0.629
[INFO: train.py:  338]:   [val] ade_l: 1.386
[INFO: train.py:  338]:   [val] ade_nl: 1.153
[INFO: train.py:  338]:   [val] d_loss: 1.407
[INFO: train.py:  338]:   [val] fde: 1.329
[INFO: train.py:  338]:   [val] fde_l: 2.926
[INFO: train.py:  338]:   [val] fde_nl: 2.435
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.472
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.472
[INFO: train.py:  338]:   [val] resist_count: 3210.000
[INFO: train.py:  338]:   [val] resist_loss: 0.322
[INFO: train.py:  341]:   [train] ade: 0.609
[INFO: train.py:  341]:   [train] ade_l: 1.248
[INFO: train.py:  341]:   [train] ade_nl: 1.190
[INFO: train.py:  341]:   [train] d_loss: 1.414
[INFO: train.py:  341]:   [train] fde: 1.230
[INFO: train.py:  341]:   [train] fde_l: 2.520
[INFO: train.py:  341]:   [train] fde_nl: 2.401
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.400
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.400
[INFO: train.py:  341]:   [train] resist_count: 2790.000
[INFO: train.py:  341]:   [train] resist_loss: 0.185
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 1.1689], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7715661525726318
[INFO: train.py:  316]: Interation 8760 took 9.909938335418701
[INFO: train.py:  558]: resist loss: tensor([ 12.2582], device='cuda:0')
[INFO: train.py:  310]: g step took 2.510355234146118
[INFO: train.py:  316]: Interation 8761 took 2.5144166946411133
[INFO: train.py:  558]: resist loss: tensor([ 3.6209], device='cuda:0')
[INFO: train.py:  310]: g step took 1.942685604095459
[INFO: train.py:  316]: Interation 8762 took 1.9466166496276855
[INFO: train.py:  558]: resist loss: tensor([ 2.2906], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8916220664978027
[INFO: train.py:  316]: Interation 8763 took 1.8956894874572754
[INFO: train.py:  558]: resist loss: tensor([ 0.5800], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6730787754058838
[INFO: train.py:  316]: Interation 8764 took 1.6771211624145508
[INFO: train.py:  558]: resist loss: tensor([ 6.5913], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7502458095550537
[INFO: train.py:  316]: Interation 8765 took 1.7542741298675537
[INFO: train.py:  558]: resist loss: tensor([ 2.8707], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8297619819641113
[INFO: train.py:  316]: Interation 8766 took 1.8332679271697998
[INFO: train.py:  558]: resist loss: tensor([ 0.8955], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7315411567687988
[INFO: train.py:  316]: Interation 8767 took 1.7354741096496582
[INFO: train.py:  558]: resist loss: tensor([ 1.0336], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6275115013122559
[INFO: train.py:  316]: Interation 8768 took 1.6313178539276123
[INFO: train.py:  558]: resist loss: tensor([ 0.2751], device='cuda:0')
[INFO: train.py:  310]: g step took 2.15621018409729
[INFO: train.py:  316]: Interation 8769 took 2.1600582599639893
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 570, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 570, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 521, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 521, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 574, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 574, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 482, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 482, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 492, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 492, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 553, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 553, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 539, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 539, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 692, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 692, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 540, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 540, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 617, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 617, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 542, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 542, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 239, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 239, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 755, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 755, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 986, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 986, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 832, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 832, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 989, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 989, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 793, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 793, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 661, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 661, 2])
[INFO: train.py:  338]:   [val] ade: 0.639
[INFO: train.py:  338]:   [val] ade_l: 1.407
[INFO: train.py:  338]:   [val] ade_nl: 1.171
[INFO: train.py:  338]:   [val] d_loss: 1.400
[INFO: train.py:  338]:   [val] fde: 1.353
[INFO: train.py:  338]:   [val] fde_l: 2.979
[INFO: train.py:  338]:   [val] fde_nl: 2.479
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.474
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.474
[INFO: train.py:  338]:   [val] resist_count: 3848.000
[INFO: train.py:  338]:   [val] resist_loss: 0.371
[INFO: train.py:  341]:   [train] ade: 0.641
[INFO: train.py:  341]:   [train] ade_l: 1.328
[INFO: train.py:  341]:   [train] ade_nl: 1.238
[INFO: train.py:  341]:   [train] d_loss: 1.392
[INFO: train.py:  341]:   [train] fde: 1.270
[INFO: train.py:  341]:   [train] fde_l: 2.633
[INFO: train.py:  341]:   [train] fde_nl: 2.454
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.416
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.416
[INFO: train.py:  341]:   [train] resist_count: 3126.000
[INFO: train.py:  341]:   [train] resist_loss: 0.197
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 10.9652], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9785597324371338
[INFO: train.py:  316]: Interation 8770 took 10.284865379333496
[INFO: train.py:  558]: resist loss: tensor([ 5.2083], device='cuda:0')
[INFO: train.py:  310]: g step took 2.119441509246826
[INFO: train.py:  316]: Interation 8771 took 2.1234209537506104
[INFO: train.py:  558]: resist loss: tensor([ 1.4890], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8871848583221436
[INFO: train.py:  316]: Interation 8772 took 1.8910784721374512
[INFO: train.py:  558]: resist loss: tensor([ 6.0311], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0287070274353027
[INFO: train.py:  316]: Interation 8773 took 2.0327205657958984
[INFO: train.py:  558]: resist loss: tensor([ 2.3385], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6875839233398438
[INFO: train.py:  316]: Interation 8774 took 1.6914279460906982
[INFO: train.py:  558]: resist loss: tensor([ 1.1271], device='cuda:0')
[INFO: train.py:  310]: g step took 2.120309829711914
[INFO: train.py:  316]: Interation 8775 took 2.1242878437042236
[INFO: train.py:  558]: resist loss: tensor([ 7.8243], device='cuda:0')
[INFO: train.py:  310]: g step took 2.324720859527588
[INFO: train.py:  316]: Interation 8776 took 2.328646659851074
[INFO: train.py:  558]: resist loss: tensor([ 3.4549], device='cuda:0')
[INFO: train.py:  310]: g step took 1.740290880203247
[INFO: train.py:  316]: Interation 8777 took 1.7441582679748535
[INFO: train.py:  558]: resist loss: tensor([ 10.4402], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9899253845214844
[INFO: train.py:  316]: Interation 8778 took 1.9934511184692383
[INFO: train.py:  558]: resist loss: tensor([ 6.8632], device='cuda:0')
[INFO: train.py:  310]: g step took 2.139677047729492
[INFO: train.py:  316]: Interation 8779 took 2.1432411670684814
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 495, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 495, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 523, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 523, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 587, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 587, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 600, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 600, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 512, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 512, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 617, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 617, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 542, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 542, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 644, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 644, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 562, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 562, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 595, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 595, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 562, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 562, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 122, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 122, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 658, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 658, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 629, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 629, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 707, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 707, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 820, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 820, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 937, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 937, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 666, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 666, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 708, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 708, 2])
[INFO: train.py:  338]:   [val] ade: 0.613
[INFO: train.py:  338]:   [val] ade_l: 1.349
[INFO: train.py:  338]:   [val] ade_nl: 1.122
[INFO: train.py:  338]:   [val] d_loss: 1.410
[INFO: train.py:  338]:   [val] fde: 1.238
[INFO: train.py:  338]:   [val] fde_l: 2.726
[INFO: train.py:  338]:   [val] fde_nl: 2.268
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.437
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.437
[INFO: train.py:  338]:   [val] resist_count: 2994.000
[INFO: train.py:  338]:   [val] resist_loss: 0.360
[INFO: train.py:  341]:   [train] ade: 0.623
[INFO: train.py:  341]:   [train] ade_l: 1.330
[INFO: train.py:  341]:   [train] ade_nl: 1.171
[INFO: train.py:  341]:   [train] d_loss: 1.390
[INFO: train.py:  341]:   [train] fde: 1.197
[INFO: train.py:  341]:   [train] fde_l: 2.557
[INFO: train.py:  341]:   [train] fde_nl: 2.250
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.400
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.400
[INFO: train.py:  341]:   [train] resist_count: 2484.000
[INFO: train.py:  341]:   [train] resist_loss: 0.166
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.7596], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2412028312683105
[INFO: train.py:  316]: Interation 8780 took 10.355163335800171
[INFO: train.py:  558]: resist loss: tensor([ 1.8866], device='cuda:0')
[INFO: train.py:  310]: g step took 0.23224139213562012
[INFO: train.py:  316]: Interation 8781 took 0.23616933822631836
[INFO: train.py:  279]: Starting epoch 206
[INFO: train.py:  280]: Epoch resist loss: tensor([ 196.6419])
[INFO: train.py:  558]: resist loss: tensor([ 1.1859], device='cuda:0')
[INFO: train.py:  310]: g step took 1.982994556427002
[INFO: train.py:  316]: Interation 8782 took 2.35207200050354
[INFO: train.py:  558]: resist loss: tensor([ 1.3389], device='cuda:0')
[INFO: train.py:  310]: g step took 2.324690103530884
[INFO: train.py:  316]: Interation 8783 took 2.3543612957000732
[INFO: train.py:  558]: resist loss: tensor([ 9.6896], device='cuda:0')
[INFO: train.py:  310]: g step took 2.085481882095337
[INFO: train.py:  316]: Interation 8784 took 2.0858521461486816
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 9.6092], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6746129989624023
[INFO: train.py:  316]: Interation 8785 took 1.6749625205993652
[INFO: train.py:  558]: resist loss: tensor([ 1.7870], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9257512092590332
[INFO: train.py:  316]: Interation 8786 took 1.9260916709899902
[INFO: train.py:  558]: resist loss: tensor([ 4.4693], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3917288780212402
[INFO: train.py:  316]: Interation 8787 took 2.392070770263672
[INFO: train.py:  558]: resist loss: tensor([ 9.6937], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3573415279388428
[INFO: train.py:  316]: Interation 8788 took 2.3577728271484375
[INFO: train.py:  558]: resist loss: tensor([ 0.5198], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5907647609710693
[INFO: train.py:  316]: Interation 8789 took 1.591170310974121
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 491, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 491, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 601, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 601, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 611, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 611, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 483, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 483, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 622, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 622, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 510, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 510, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 567, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 567, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 556, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 556, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 691, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 691, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 533, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 533, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 580, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 580, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 116, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 116, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 656, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 656, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 740, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 740, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 817, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 817, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 1015, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 1015, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 633, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 633, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 857, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 857, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 552, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 552, 2])
[INFO: train.py:  338]:   [val] ade: 0.670
[INFO: train.py:  338]:   [val] ade_l: 1.476
[INFO: train.py:  338]:   [val] ade_nl: 1.228
[INFO: train.py:  338]:   [val] d_loss: 1.403
[INFO: train.py:  338]:   [val] fde: 1.430
[INFO: train.py:  338]:   [val] fde_l: 3.149
[INFO: train.py:  338]:   [val] fde_nl: 2.620
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.565
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.565
[INFO: train.py:  338]:   [val] resist_count: 2872.000
[INFO: train.py:  338]:   [val] resist_loss: 0.319
[INFO: train.py:  341]:   [train] ade: 0.665
[INFO: train.py:  341]:   [train] ade_l: 1.379
[INFO: train.py:  341]:   [train] ade_nl: 1.282
[INFO: train.py:  341]:   [train] d_loss: 1.398
[INFO: train.py:  341]:   [train] fde: 1.361
[INFO: train.py:  341]:   [train] fde_l: 2.825
[INFO: train.py:  341]:   [train] fde_nl: 2.626
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.483
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.483
[INFO: train.py:  341]:   [train] resist_count: 2660.000
[INFO: train.py:  341]:   [train] resist_loss: 0.153
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 3.6341], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2939319610595703
[INFO: train.py:  316]: Interation 8790 took 10.301230669021606
[INFO: train.py:  558]: resist loss: tensor([ 4.7293], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7711713314056396
[INFO: train.py:  316]: Interation 8791 took 1.7894911766052246
[INFO: train.py:  558]: resist loss: tensor([ 1.8435], device='cuda:0')
[INFO: train.py:  310]: g step took 1.963829755783081
[INFO: train.py:  316]: Interation 8792 took 1.9679088592529297
[INFO: train.py:  558]: resist loss: tensor([ 1.4659], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9183485507965088
[INFO: train.py:  316]: Interation 8793 took 1.918703556060791
[INFO: train.py:  558]: resist loss: tensor([ 4.8898], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0297417640686035
[INFO: train.py:  316]: Interation 8794 took 2.03013277053833
[INFO: train.py:  558]: resist loss: tensor([ 2.5590], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9911484718322754
[INFO: train.py:  316]: Interation 8795 took 1.991511583328247
[INFO: train.py:  558]: resist loss: tensor([ 7.8921], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8647119998931885
[INFO: train.py:  316]: Interation 8796 took 1.8650693893432617
[INFO: train.py:  558]: resist loss: tensor([ 19.4877], device='cuda:0')
[INFO: train.py:  310]: g step took 2.559922933578491
[INFO: train.py:  316]: Interation 8797 took 2.5602900981903076
[INFO: train.py:  558]: resist loss: tensor([ 4.2280], device='cuda:0')
[INFO: train.py:  310]: g step took 1.876168966293335
[INFO: train.py:  316]: Interation 8798 took 1.8805088996887207
[INFO: train.py:  558]: resist loss: tensor([ 11.8769], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0372707843780518
[INFO: train.py:  316]: Interation 8799 took 2.0412797927856445
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 577, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 577, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 583, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 583, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 619, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 619, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 588, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 588, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 495, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 495, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 552, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 552, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 552, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 552, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 475, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 475, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 526, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 526, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 635, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 635, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 593, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 593, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 166, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 166, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 721, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 721, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 626, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 626, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 859, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 859, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 769, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 769, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 850, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 850, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 756, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 756, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 892, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 892, 2])
[INFO: train.py:  338]:   [val] ade: 0.656
[INFO: train.py:  338]:   [val] ade_l: 1.444
[INFO: train.py:  338]:   [val] ade_nl: 1.202
[INFO: train.py:  338]:   [val] d_loss: 1.413
[INFO: train.py:  338]:   [val] fde: 1.408
[INFO: train.py:  338]:   [val] fde_l: 3.100
[INFO: train.py:  338]:   [val] fde_nl: 2.579
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.536
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.536
[INFO: train.py:  338]:   [val] resist_count: 2758.000
[INFO: train.py:  338]:   [val] resist_loss: 0.274
[INFO: train.py:  341]:   [train] ade: 0.636
[INFO: train.py:  341]:   [train] ade_l: 1.346
[INFO: train.py:  341]:   [train] ade_nl: 1.206
[INFO: train.py:  341]:   [train] d_loss: 1.401
[INFO: train.py:  341]:   [train] fde: 1.312
[INFO: train.py:  341]:   [train] fde_l: 2.776
[INFO: train.py:  341]:   [train] fde_nl: 2.489
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.442
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.442
[INFO: train.py:  341]:   [train] resist_count: 2663.000
[INFO: train.py:  341]:   [train] resist_loss: 0.173
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 8.5984], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0207431316375732
[INFO: train.py:  316]: Interation 8800 took 10.592714071273804
[INFO: train.py:  558]: resist loss: tensor([ 11.0261], device='cuda:0')
[INFO: train.py:  310]: g step took 1.981523036956787
[INFO: train.py:  316]: Interation 8801 took 1.985595464706421
[INFO: train.py:  558]: resist loss: tensor([ 6.8845], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7577521800994873
[INFO: train.py:  316]: Interation 8802 took 1.7616300582885742
[INFO: train.py:  558]: resist loss: tensor([ 1.0631], device='cuda:0')
[INFO: train.py:  310]: g step took 1.970879077911377
[INFO: train.py:  316]: Interation 8803 took 1.9747850894927979
[INFO: train.py:  558]: resist loss: tensor([ 2.0426], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9928948879241943
[INFO: train.py:  316]: Interation 8804 took 1.9964282512664795
[INFO: train.py:  558]: resist loss: tensor([ 11.0910], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8734915256500244
[INFO: train.py:  316]: Interation 8805 took 1.8773510456085205
[INFO: train.py:  558]: resist loss: tensor([ 4.4013], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4400155544281006
[INFO: train.py:  316]: Interation 8806 took 2.4439802169799805
[INFO: train.py:  558]: resist loss: tensor([ 7.1821], device='cuda:0')
[INFO: train.py:  310]: g step took 2.102996587753296
[INFO: train.py:  316]: Interation 8807 took 2.1072402000427246
[INFO: train.py:  558]: resist loss: tensor([ 3.5310], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9653956890106201
[INFO: train.py:  316]: Interation 8808 took 1.9693782329559326
[INFO: train.py:  558]: resist loss: tensor([ 0.9350], device='cuda:0')
[INFO: train.py:  310]: g step took 1.890580654144287
[INFO: train.py:  316]: Interation 8809 took 1.8943865299224854
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 517, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 517, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 662, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 662, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 695, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 695, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 590, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 590, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 601, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 601, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 502, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 502, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 554, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 554, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 590, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 590, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 568, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 568, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 474, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 474, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 472, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 472, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 136, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 136, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 851, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 851, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 794, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 794, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 876, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 876, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 771, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 771, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 842, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 842, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 741, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 741, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 637, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 637, 2])
[INFO: train.py:  338]:   [val] ade: 0.604
[INFO: train.py:  338]:   [val] ade_l: 1.331
[INFO: train.py:  338]:   [val] ade_nl: 1.107
[INFO: train.py:  338]:   [val] d_loss: 1.415
[INFO: train.py:  338]:   [val] fde: 1.256
[INFO: train.py:  338]:   [val] fde_l: 2.765
[INFO: train.py:  338]:   [val] fde_nl: 2.301
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.450
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.450
[INFO: train.py:  338]:   [val] resist_count: 3336.000
[INFO: train.py:  338]:   [val] resist_loss: 0.381
[INFO: train.py:  341]:   [train] ade: 0.591
[INFO: train.py:  341]:   [train] ade_l: 1.320
[INFO: train.py:  341]:   [train] ade_nl: 1.069
[INFO: train.py:  341]:   [train] d_loss: 1.414
[INFO: train.py:  341]:   [train] fde: 1.170
[INFO: train.py:  341]:   [train] fde_l: 2.614
[INFO: train.py:  341]:   [train] fde_nl: 2.118
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.360
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.360
[INFO: train.py:  341]:   [train] resist_count: 3251.000
[INFO: train.py:  341]:   [train] resist_loss: 0.186
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 6.7167], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0166354179382324
[INFO: train.py:  316]: Interation 8810 took 10.674620866775513
[INFO: train.py:  558]: resist loss: tensor([ 1.1006], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9791595935821533
[INFO: train.py:  316]: Interation 8811 took 1.9832422733306885
[INFO: train.py:  558]: resist loss: tensor([ 1.3820], device='cuda:0')
[INFO: train.py:  310]: g step took 2.02594256401062
[INFO: train.py:  316]: Interation 8812 took 2.029811143875122
[INFO: train.py:  558]: resist loss: tensor([ 0.4403], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8916893005371094
[INFO: train.py:  316]: Interation 8813 took 1.8955748081207275
[INFO: train.py:  558]: resist loss: tensor([ 10.8260], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9975271224975586
[INFO: train.py:  316]: Interation 8814 took 2.001112461090088
[INFO: train.py:  558]: resist loss: tensor([ 8.3071], device='cuda:0')
[INFO: train.py:  310]: g step took 2.207880735397339
[INFO: train.py:  316]: Interation 8815 took 2.211836576461792
[INFO: train.py:  558]: resist loss: tensor([ 1.2897], device='cuda:0')
[INFO: train.py:  310]: g step took 1.49365234375
[INFO: train.py:  316]: Interation 8816 took 1.4976203441619873
[INFO: train.py:  558]: resist loss: tensor([ 3.7095], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9558498859405518
[INFO: train.py:  316]: Interation 8817 took 1.9594547748565674
[INFO: train.py:  558]: resist loss: tensor([ 2.2478], device='cuda:0')
[INFO: train.py:  310]: g step took 1.611374855041504
[INFO: train.py:  316]: Interation 8818 took 1.6151018142700195
[INFO: train.py:  558]: resist loss: tensor([ 0.7244], device='cuda:0')
[INFO: train.py:  310]: g step took 1.844630479812622
[INFO: train.py:  316]: Interation 8819 took 1.8490045070648193
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 599, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 599, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 475, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 475, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 540, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 540, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 501, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 501, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 563, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 563, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 540, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 540, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 604, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 604, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 549, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 549, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 725, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 725, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 572, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 572, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 522, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 522, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 171, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 171, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 698, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 698, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 734, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 734, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 734, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 734, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 826, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 826, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 755, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 755, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 1003, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 1003, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 839, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 839, 2])
[INFO: train.py:  338]:   [val] ade: 0.662
[INFO: train.py:  338]:   [val] ade_l: 1.457
[INFO: train.py:  338]:   [val] ade_nl: 1.212
[INFO: train.py:  338]:   [val] d_loss: 1.423
[INFO: train.py:  338]:   [val] fde: 1.339
[INFO: train.py:  338]:   [val] fde_l: 2.948
[INFO: train.py:  338]:   [val] fde_nl: 2.453
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.516
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.516
[INFO: train.py:  338]:   [val] resist_count: 2903.000
[INFO: train.py:  338]:   [val] resist_loss: 0.326
[INFO: train.py:  341]:   [train] ade: 0.642
[INFO: train.py:  341]:   [train] ade_l: 1.330
[INFO: train.py:  341]:   [train] ade_nl: 1.241
[INFO: train.py:  341]:   [train] d_loss: 1.409
[INFO: train.py:  341]:   [train] fde: 1.221
[INFO: train.py:  341]:   [train] fde_l: 2.528
[INFO: train.py:  341]:   [train] fde_nl: 2.360
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.407
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.407
[INFO: train.py:  341]:   [train] resist_count: 3321.000
[INFO: train.py:  341]:   [train] resist_loss: 0.191
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 5.2450], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8557403087615967
[INFO: train.py:  316]: Interation 8820 took 10.473546743392944
[INFO: train.py:  558]: resist loss: tensor([ 4.8074], device='cuda:0')
[INFO: train.py:  310]: g step took 2.040170669555664
[INFO: train.py:  316]: Interation 8821 took 2.043888568878174
[INFO: train.py:  558]: resist loss: tensor([ 0.4413], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8553204536437988
[INFO: train.py:  316]: Interation 8822 took 1.8591890335083008
[INFO: train.py:  558]: resist loss: tensor([ 4.2575], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9945943355560303
[INFO: train.py:  316]: Interation 8823 took 1.9975924491882324
[INFO: train.py:  558]: resist loss: tensor([ 0.], device='cuda:0')
[INFO: train.py:  310]: g step took 0.11138486862182617
[INFO: train.py:  316]: Interation 8824 took 0.11522412300109863
[INFO: train.py:  279]: Starting epoch 207
[INFO: train.py:  280]: Epoch resist loss: tensor([ 199.6367])
[INFO: train.py:  558]: resist loss: tensor([ 16.0035], device='cuda:0')
[INFO: train.py:  310]: g step took 2.192626953125
[INFO: train.py:  316]: Interation 8825 took 2.5476746559143066
[INFO: train.py:  558]: resist loss: tensor([ 3.0270], device='cuda:0')
[INFO: train.py:  310]: g step took 1.955352544784546
[INFO: train.py:  316]: Interation 8826 took 1.9557511806488037
[INFO: train.py:  558]: resist loss: tensor([ 0.3558], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9375627040863037
[INFO: train.py:  316]: Interation 8827 took 1.9492502212524414
[INFO: train.py:  558]: resist loss: tensor([ 2.5996], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0073161125183105
[INFO: train.py:  316]: Interation 8828 took 2.0189459323883057
[INFO: train.py:  558]: resist loss: tensor([ 4.3148], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2732505798339844
[INFO: train.py:  316]: Interation 8829 took 2.2774367332458496
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 582, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 582, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 593, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 593, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 644, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 644, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 555, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 555, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 497, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 497, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 550, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 550, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 516, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 516, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 623, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 623, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 554, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 554, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 555, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 555, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 600, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 600, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 92, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 92, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 637, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 637, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 802, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 802, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 805, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 805, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 904, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 904, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 656, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 656, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 733, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 733, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 801, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 801, 2])
[INFO: train.py:  338]:   [val] ade: 0.623
[INFO: train.py:  338]:   [val] ade_l: 1.372
[INFO: train.py:  338]:   [val] ade_nl: 1.141
[INFO: train.py:  338]:   [val] d_loss: 1.407
[INFO: train.py:  338]:   [val] fde: 1.320
[INFO: train.py:  338]:   [val] fde_l: 2.906
[INFO: train.py:  338]:   [val] fde_nl: 2.418
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.482
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.482
[INFO: train.py:  338]:   [val] resist_count: 2873.000
[INFO: train.py:  338]:   [val] resist_loss: 0.326
[INFO: train.py:  341]:   [train] ade: 0.606
[INFO: train.py:  341]:   [train] ade_l: 1.282
[INFO: train.py:  341]:   [train] ade_nl: 1.148
[INFO: train.py:  341]:   [train] d_loss: 1.409
[INFO: train.py:  341]:   [train] fde: 1.214
[INFO: train.py:  341]:   [train] fde_l: 2.569
[INFO: train.py:  341]:   [train] fde_nl: 2.301
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.392
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.392
[INFO: train.py:  341]:   [train] resist_count: 2616.000
[INFO: train.py:  341]:   [train] resist_loss: 0.177
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.1967], device='cuda:0')
[INFO: train.py:  310]: g step took 2.187013864517212
[INFO: train.py:  316]: Interation 8830 took 10.647915124893188
[INFO: train.py:  558]: resist loss: tensor([ 2.3780], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8664398193359375
[INFO: train.py:  316]: Interation 8831 took 1.866870641708374
[INFO: train.py:  558]: resist loss: tensor([ 7.8246], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9768595695495605
[INFO: train.py:  316]: Interation 8832 took 1.9772663116455078
[INFO: train.py:  558]: resist loss: tensor([ 16.4500], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9291808605194092
[INFO: train.py:  316]: Interation 8833 took 1.9367692470550537
[INFO: train.py:  558]: resist loss: tensor([ 4.2377], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9414808750152588
[INFO: train.py:  316]: Interation 8834 took 1.941884994506836
[INFO: train.py:  558]: resist loss: tensor([ 4.7970], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8549175262451172
[INFO: train.py:  316]: Interation 8835 took 1.8622472286224365
[INFO: train.py:  558]: resist loss: tensor([ 3.3341], device='cuda:0')
[INFO: train.py:  310]: g step took 1.996274471282959
[INFO: train.py:  316]: Interation 8836 took 2.0032882690429688
[INFO: train.py:  558]: resist loss: tensor([ 7.7437], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7782328128814697
[INFO: train.py:  316]: Interation 8837 took 1.7822215557098389
[INFO: train.py:  558]: resist loss: tensor([ 15.8197], device='cuda:0')
[INFO: train.py:  310]: g step took 2.5152552127838135
[INFO: train.py:  316]: Interation 8838 took 2.5156185626983643
[INFO: train.py:  558]: resist loss: tensor([ 4.5260], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7263143062591553
[INFO: train.py:  316]: Interation 8839 took 1.726715326309204
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 580, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 580, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 511, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 511, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 612, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 612, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 555, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 555, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 489, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 489, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 520, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 520, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 789, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 789, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 502, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 502, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 600, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 600, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 524, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 524, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 582, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 582, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 97, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 97, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 918, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 918, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 609, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 609, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 807, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 807, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 958, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 958, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 828, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 828, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 851, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 851, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 805, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 805, 2])
[INFO: train.py:  338]:   [val] ade: 0.643
[INFO: train.py:  338]:   [val] ade_l: 1.415
[INFO: train.py:  338]:   [val] ade_nl: 1.178
[INFO: train.py:  338]:   [val] d_loss: 1.409
[INFO: train.py:  338]:   [val] fde: 1.378
[INFO: train.py:  338]:   [val] fde_l: 3.035
[INFO: train.py:  338]:   [val] fde_nl: 2.525
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.500
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.500
[INFO: train.py:  338]:   [val] resist_count: 2863.000
[INFO: train.py:  338]:   [val] resist_loss: 0.263
[INFO: train.py:  341]:   [train] ade: 0.643
[INFO: train.py:  341]:   [train] ade_l: 1.363
[INFO: train.py:  341]:   [train] ade_nl: 1.218
[INFO: train.py:  341]:   [train] d_loss: 1.398
[INFO: train.py:  341]:   [train] fde: 1.303
[INFO: train.py:  341]:   [train] fde_l: 2.762
[INFO: train.py:  341]:   [train] fde_nl: 2.466
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.431
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.431
[INFO: train.py:  341]:   [train] resist_count: 2783.000
[INFO: train.py:  341]:   [train] resist_loss: 0.146
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 6.0725], device='cuda:0')
[INFO: train.py:  310]: g step took 2.31282901763916
[INFO: train.py:  316]: Interation 8840 took 11.839321374893188
[INFO: train.py:  558]: resist loss: tensor([ 6.1509], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3043830394744873
[INFO: train.py:  316]: Interation 8841 took 2.3084192276000977
[INFO: train.py:  558]: resist loss: tensor([ 0.4014], device='cuda:0')
[INFO: train.py:  310]: g step took 2.385315418243408
[INFO: train.py:  316]: Interation 8842 took 2.389289140701294
[INFO: train.py:  558]: resist loss: tensor([ 0.6754], device='cuda:0')
[INFO: train.py:  310]: g step took 2.23078989982605
[INFO: train.py:  316]: Interation 8843 took 2.234774112701416
[INFO: train.py:  558]: resist loss: tensor([ 1.4269], device='cuda:0')
[INFO: train.py:  310]: g step took 2.267021417617798
[INFO: train.py:  316]: Interation 8844 took 2.2705368995666504
[INFO: train.py:  558]: resist loss: tensor([ 3.0438], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3448984622955322
[INFO: train.py:  316]: Interation 8845 took 2.3488893508911133
[INFO: train.py:  558]: resist loss: tensor([ 6.5665], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8296170234680176
[INFO: train.py:  316]: Interation 8846 took 1.8336827754974365
[INFO: train.py:  558]: resist loss: tensor([ 0.6912], device='cuda:0')
[INFO: train.py:  310]: g step took 2.194479465484619
[INFO: train.py:  316]: Interation 8847 took 2.1984763145446777
[INFO: train.py:  558]: resist loss: tensor([ 7.1674], device='cuda:0')
[INFO: train.py:  310]: g step took 2.27116322517395
[INFO: train.py:  316]: Interation 8848 took 2.2751307487487793
[INFO: train.py:  558]: resist loss: tensor([ 1.9898], device='cuda:0')
[INFO: train.py:  310]: g step took 2.177316904067993
[INFO: train.py:  316]: Interation 8849 took 2.181303024291992
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 600, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 600, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 618, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 618, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 480, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 480, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 572, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 572, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 541, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 541, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 630, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 630, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 520, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 520, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 482, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 482, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 534, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 534, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 512, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 512, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 711, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 711, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 161, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 161, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 809, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 809, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 703, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 703, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 820, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 820, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 698, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 698, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 769, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 769, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 762, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 762, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 708, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 708, 2])
[INFO: train.py:  338]:   [val] ade: 0.650
[INFO: train.py:  338]:   [val] ade_l: 1.432
[INFO: train.py:  338]:   [val] ade_nl: 1.191
[INFO: train.py:  338]:   [val] d_loss: 1.401
[INFO: train.py:  338]:   [val] fde: 1.376
[INFO: train.py:  338]:   [val] fde_l: 3.030
[INFO: train.py:  338]:   [val] fde_nl: 2.522
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.500
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.500
[INFO: train.py:  338]:   [val] resist_count: 2817.000
[INFO: train.py:  338]:   [val] resist_loss: 0.259
[INFO: train.py:  341]:   [train] ade: 0.644
[INFO: train.py:  341]:   [train] ade_l: 1.361
[INFO: train.py:  341]:   [train] ade_nl: 1.223
[INFO: train.py:  341]:   [train] d_loss: 1.405
[INFO: train.py:  341]:   [train] fde: 1.299
[INFO: train.py:  341]:   [train] fde_l: 2.745
[INFO: train.py:  341]:   [train] fde_nl: 2.467
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.442
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.442
[INFO: train.py:  341]:   [train] resist_count: 2512.000
[INFO: train.py:  341]:   [train] resist_loss: 0.147
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.5608], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9530439376831055
[INFO: train.py:  316]: Interation 8850 took 11.833553552627563
[INFO: train.py:  558]: resist loss: tensor([ 1.5072], device='cuda:0')
[INFO: train.py:  310]: g step took 2.352339267730713
[INFO: train.py:  316]: Interation 8851 took 2.3564274311065674
[INFO: train.py:  558]: resist loss: tensor([ 14.8694], device='cuda:0')
[INFO: train.py:  310]: g step took 2.5290846824645996
[INFO: train.py:  316]: Interation 8852 took 2.5324413776397705
[INFO: train.py:  558]: resist loss: tensor([ 12.0517], device='cuda:0')
[INFO: train.py:  310]: g step took 2.119313955307007
[INFO: train.py:  316]: Interation 8853 took 2.12320613861084
[INFO: train.py:  558]: resist loss: tensor([ 0.4681], device='cuda:0')
[INFO: train.py:  310]: g step took 2.044675588607788
[INFO: train.py:  316]: Interation 8854 took 2.048633337020874
[INFO: train.py:  558]: resist loss: tensor([ 0.6235], device='cuda:0')
[INFO: train.py:  310]: g step took 2.099472999572754
[INFO: train.py:  316]: Interation 8855 took 2.1027235984802246
[INFO: train.py:  558]: resist loss: tensor([ 1.8336], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1256942749023438
[INFO: train.py:  316]: Interation 8856 took 2.129578113555908
[INFO: train.py:  558]: resist loss: tensor([ 1.0270], device='cuda:0')
[INFO: train.py:  310]: g step took 2.48229718208313
[INFO: train.py:  316]: Interation 8857 took 2.4861679077148438
[INFO: train.py:  558]: resist loss: tensor([ 0.6952], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4857804775238037
[INFO: train.py:  316]: Interation 8858 took 2.4897775650024414
[INFO: train.py:  558]: resist loss: tensor([ 1.3662], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4064693450927734
[INFO: train.py:  316]: Interation 8859 took 2.4103286266326904
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 470, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 470, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 683, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 683, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 455, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 455, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 540, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 540, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 539, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 539, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 542, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 542, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 646, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 646, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 594, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 594, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 558, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 558, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 734, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 734, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 459, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 459, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 141, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 141, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 968, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 968, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 716, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 716, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 822, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 822, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 821, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 821, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 814, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 814, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 890, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 890, 2])
[INFO: train.py:  338]:   [val] ade: 0.623
[INFO: train.py:  338]:   [val] ade_l: 1.372
[INFO: train.py:  338]:   [val] ade_nl: 1.142
[INFO: train.py:  338]:   [val] d_loss: 1.414
[INFO: train.py:  338]:   [val] fde: 1.168
[INFO: train.py:  338]:   [val] fde_l: 2.572
[INFO: train.py:  338]:   [val] fde_nl: 2.140
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.435
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.435
[INFO: train.py:  338]:   [val] resist_count: 3030.000
[INFO: train.py:  338]:   [val] resist_loss: 0.345
[INFO: train.py:  341]:   [train] ade: 0.618
[INFO: train.py:  341]:   [train] ade_l: 1.298
[INFO: train.py:  341]:   [train] ade_nl: 1.181
[INFO: train.py:  341]:   [train] d_loss: 1.398
[INFO: train.py:  341]:   [train] fde: 1.075
[INFO: train.py:  341]:   [train] fde_l: 2.256
[INFO: train.py:  341]:   [train] fde_nl: 2.053
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.366
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.366
[INFO: train.py:  341]:   [train] resist_count: 2998.000
[INFO: train.py:  341]:   [train] resist_loss: 0.166
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 10.2805], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8862144947052002
[INFO: train.py:  316]: Interation 8860 took 10.887490510940552
[INFO: train.py:  558]: resist loss: tensor([ 1.4815], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6988747119903564
[INFO: train.py:  316]: Interation 8861 took 1.7026925086975098
[INFO: train.py:  558]: resist loss: tensor([ 18.0338], device='cuda:0')
[INFO: train.py:  310]: g step took 2.633925676345825
[INFO: train.py:  316]: Interation 8862 took 2.638032913208008
[INFO: train.py:  558]: resist loss: tensor([ 2.3601], device='cuda:0')
[INFO: train.py:  310]: g step took 2.35597825050354
[INFO: train.py:  316]: Interation 8863 took 2.3599636554718018
[INFO: train.py:  558]: resist loss: tensor([ 8.8751], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3643481731414795
[INFO: train.py:  316]: Interation 8864 took 2.3683059215545654
[INFO: train.py:  558]: resist loss: tensor([ 3.3764], device='cuda:0')
[INFO: train.py:  310]: g step took 2.268120288848877
[INFO: train.py:  316]: Interation 8865 took 2.27211332321167
[INFO: train.py:  558]: resist loss: tensor([ 10.0944], device='cuda:0')
[INFO: train.py:  310]: g step took 2.814000129699707
[INFO: train.py:  316]: Interation 8866 took 2.8180103302001953
[INFO: train.py:  558]: resist loss: tensor([ 0.8088], device='cuda:0')
[INFO: train.py:  310]: g step took 0.20381546020507812
[INFO: train.py:  316]: Interation 8867 took 0.20773744583129883
[INFO: train.py:  279]: Starting epoch 208
[INFO: train.py:  280]: Epoch resist loss: tensor([ 214.0958])
[INFO: train.py:  558]: resist loss: tensor([ 4.8023], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4176926612854004
[INFO: train.py:  316]: Interation 8868 took 2.7933318614959717
[INFO: train.py:  558]: resist loss: tensor([ 0.1860], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9914929866790771
[INFO: train.py:  316]: Interation 8869 took 1.9923744201660156
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 590, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 590, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 628, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 628, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 582, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 582, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 657, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 657, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 581, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 581, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 531, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 531, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 563, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 563, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 543, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 543, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 554, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 554, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 555, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 555, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 490, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 490, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 87, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 87, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 640, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 640, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 664, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 664, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 709, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 709, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 1054, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 1054, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 683, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 683, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 876, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 876, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 823, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 823, 2])
[INFO: train.py:  338]:   [val] ade: 0.649
[INFO: train.py:  338]:   [val] ade_l: 1.429
[INFO: train.py:  338]:   [val] ade_nl: 1.189
[INFO: train.py:  338]:   [val] d_loss: 1.422
[INFO: train.py:  338]:   [val] fde: 1.268
[INFO: train.py:  338]:   [val] fde_l: 2.793
[INFO: train.py:  338]:   [val] fde_nl: 2.324
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.457
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.457
[INFO: train.py:  338]:   [val] resist_count: 2822.000
[INFO: train.py:  338]:   [val] resist_loss: 0.315
[INFO: train.py:  341]:   [train] ade: 0.663
[INFO: train.py:  341]:   [train] ade_l: 1.422
[INFO: train.py:  341]:   [train] ade_nl: 1.241
[INFO: train.py:  341]:   [train] d_loss: 1.408
[INFO: train.py:  341]:   [train] fde: 1.206
[INFO: train.py:  341]:   [train] fde_l: 2.587
[INFO: train.py:  341]:   [train] fde_nl: 2.258
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.423
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.423
[INFO: train.py:  341]:   [train] resist_count: 2869.000
[INFO: train.py:  341]:   [train] resist_loss: 0.185
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 4.3460], device='cuda:0')
[INFO: train.py:  310]: g step took 2.511636734008789
[INFO: train.py:  316]: Interation 8870 took 11.80250883102417
[INFO: train.py:  558]: resist loss: tensor([ 9.9725], device='cuda:0')
[INFO: train.py:  310]: g step took 2.364901065826416
[INFO: train.py:  316]: Interation 8871 took 2.369062900543213
[INFO: train.py:  558]: resist loss: tensor([ 11.0174], device='cuda:0')
[INFO: train.py:  310]: g step took 2.414604663848877
[INFO: train.py:  316]: Interation 8872 took 2.4149842262268066
[INFO: train.py:  558]: resist loss: tensor([ 1.8502], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2969369888305664
[INFO: train.py:  316]: Interation 8873 took 2.2973084449768066
[INFO: train.py:  558]: resist loss: tensor([ 8.5248], device='cuda:0')
[INFO: train.py:  310]: g step took 2.45513653755188
[INFO: train.py:  316]: Interation 8874 took 2.459301471710205
[INFO: train.py:  558]: resist loss: tensor([ 4.0155], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4284653663635254
[INFO: train.py:  316]: Interation 8875 took 2.428865909576416
[INFO: train.py:  558]: resist loss: tensor([ 3.8449], device='cuda:0')
[INFO: train.py:  310]: g step took 2.5290067195892334
[INFO: train.py:  316]: Interation 8876 took 2.547727108001709
[INFO: train.py:  558]: resist loss: tensor([ 6.2838], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4342682361602783
[INFO: train.py:  316]: Interation 8877 took 2.43467378616333
[INFO: train.py:  558]: resist loss: tensor([ 20.7811], device='cuda:0')
[INFO: train.py:  310]: g step took 2.8156933784484863
[INFO: train.py:  316]: Interation 8878 took 2.8196935653686523
[INFO: train.py:  558]: resist loss: tensor([ 0.5160], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8725192546844482
[INFO: train.py:  316]: Interation 8879 took 1.872913122177124
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 631, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 631, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 534, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 534, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 466, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 466, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 657, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 657, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 571, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 571, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 494, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 494, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 502, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 502, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 723, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 723, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 499, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 499, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 591, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 591, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 567, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 567, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 126, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 126, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 887, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 887, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 856, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 856, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 844, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 844, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 765, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 765, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 602, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 602, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 715, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 715, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 791, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 791, 2])
[INFO: train.py:  338]:   [val] ade: 0.646
[INFO: train.py:  338]:   [val] ade_l: 1.422
[INFO: train.py:  338]:   [val] ade_nl: 1.184
[INFO: train.py:  338]:   [val] d_loss: 1.412
[INFO: train.py:  338]:   [val] fde: 1.315
[INFO: train.py:  338]:   [val] fde_l: 2.896
[INFO: train.py:  338]:   [val] fde_nl: 2.410
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.479
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.479
[INFO: train.py:  338]:   [val] resist_count: 2739.000
[INFO: train.py:  338]:   [val] resist_loss: 0.264
[INFO: train.py:  341]:   [train] ade: 0.645
[INFO: train.py:  341]:   [train] ade_l: 1.377
[INFO: train.py:  341]:   [train] ade_nl: 1.214
[INFO: train.py:  341]:   [train] d_loss: 1.405
[INFO: train.py:  341]:   [train] fde: 1.249
[INFO: train.py:  341]:   [train] fde_l: 2.664
[INFO: train.py:  341]:   [train] fde_nl: 2.350
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.421
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.421
[INFO: train.py:  341]:   [train] resist_count: 2741.000
[INFO: train.py:  341]:   [train] resist_loss: 0.165
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.3525], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0267231464385986
[INFO: train.py:  316]: Interation 8880 took 10.829466819763184
[INFO: train.py:  558]: resist loss: tensor([ 3.7924], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7232768535614014
[INFO: train.py:  316]: Interation 8881 took 1.7236604690551758
[INFO: train.py:  558]: resist loss: tensor([ 0.8676], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3477704524993896
[INFO: train.py:  316]: Interation 8882 took 2.351949691772461
[INFO: train.py:  558]: resist loss: tensor([ 4.6605], device='cuda:0')
[INFO: train.py:  310]: g step took 1.960352897644043
[INFO: train.py:  316]: Interation 8883 took 1.960709810256958
[INFO: train.py:  558]: resist loss: tensor([ 5.8554], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9559903144836426
[INFO: train.py:  316]: Interation 8884 took 1.9600703716278076
[INFO: train.py:  558]: resist loss: tensor([ 0.4505], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8232431411743164
[INFO: train.py:  316]: Interation 8885 took 1.827219009399414
[INFO: train.py:  558]: resist loss: tensor([ 9.1117], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7782864570617676
[INFO: train.py:  316]: Interation 8886 took 1.7820603847503662
[INFO: train.py:  558]: resist loss: tensor([ 2.6127], device='cuda:0')
[INFO: train.py:  310]: g step took 2.001610040664673
[INFO: train.py:  316]: Interation 8887 took 2.005077838897705
[INFO: train.py:  558]: resist loss: tensor([ 0.6900], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6160614490509033
[INFO: train.py:  316]: Interation 8888 took 1.6195173263549805
[INFO: train.py:  558]: resist loss: tensor([ 2.3130], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8887073993682861
[INFO: train.py:  316]: Interation 8889 took 1.89286208152771
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 661, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 661, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 422, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 422, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 532, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 532, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 595, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 595, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 553, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 553, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 560, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 560, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 573, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 573, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 747, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 747, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 437, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 437, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 548, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 548, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 563, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 563, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 170, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 170, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 957, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 957, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 786, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 786, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 809, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 809, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 736, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 736, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 696, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 696, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 717, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 717, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 875, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 875, 2])
[INFO: train.py:  338]:   [val] ade: 0.590
[INFO: train.py:  338]:   [val] ade_l: 1.300
[INFO: train.py:  338]:   [val] ade_nl: 1.081
[INFO: train.py:  338]:   [val] d_loss: 1.407
[INFO: train.py:  338]:   [val] fde: 1.257
[INFO: train.py:  338]:   [val] fde_l: 2.768
[INFO: train.py:  338]:   [val] fde_nl: 2.303
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.438
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.438
[INFO: train.py:  338]:   [val] resist_count: 2630.000
[INFO: train.py:  338]:   [val] resist_loss: 0.265
[INFO: train.py:  341]:   [train] ade: 0.603
[INFO: train.py:  341]:   [train] ade_l: 1.287
[INFO: train.py:  341]:   [train] ade_nl: 1.134
[INFO: train.py:  341]:   [train] d_loss: 1.412
[INFO: train.py:  341]:   [train] fde: 1.219
[INFO: train.py:  341]:   [train] fde_l: 2.602
[INFO: train.py:  341]:   [train] fde_nl: 2.293
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.398
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.398
[INFO: train.py:  341]:   [train] resist_count: 2836.000
[INFO: train.py:  341]:   [train] resist_loss: 0.159
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 12.3569], device='cuda:0')
[INFO: train.py:  310]: g step took 2.664364814758301
[INFO: train.py:  316]: Interation 8890 took 11.502361059188843
[INFO: train.py:  558]: resist loss: tensor([ 11.7496], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8703041076660156
[INFO: train.py:  316]: Interation 8891 took 1.8744618892669678
[INFO: train.py:  558]: resist loss: tensor([ 9.1361], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8103885650634766
[INFO: train.py:  316]: Interation 8892 took 1.814347743988037
[INFO: train.py:  558]: resist loss: tensor([ 2.6748], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7132933139801025
[INFO: train.py:  316]: Interation 8893 took 1.7172939777374268
[INFO: train.py:  558]: resist loss: tensor([ 13.0267], device='cuda:0')
[INFO: train.py:  310]: g step took 2.080043077468872
[INFO: train.py:  316]: Interation 8894 took 2.084186315536499
[INFO: train.py:  558]: resist loss: tensor([ 1.1741], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9259445667266846
[INFO: train.py:  316]: Interation 8895 took 1.9289748668670654
[INFO: train.py:  558]: resist loss: tensor([ 1.8336], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7589468955993652
[INFO: train.py:  316]: Interation 8896 took 1.7628061771392822
[INFO: train.py:  558]: resist loss: tensor([ 2.5134], device='cuda:0')
[INFO: train.py:  310]: g step took 1.754288911819458
[INFO: train.py:  316]: Interation 8897 took 1.758279800415039
[INFO: train.py:  558]: resist loss: tensor([ 3.3117], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2249152660369873
[INFO: train.py:  316]: Interation 8898 took 2.2291951179504395
[INFO: train.py:  558]: resist loss: tensor([ 1.7750], device='cuda:0')
[INFO: train.py:  310]: g step took 2.288900375366211
[INFO: train.py:  316]: Interation 8899 took 2.292823314666748
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 455, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 455, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 617, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 617, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 551, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 551, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 579, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 579, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 588, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 588, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 629, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 629, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 466, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 466, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 507, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 507, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 634, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 634, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 504, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 504, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 686, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 686, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 145, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 145, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 712, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 712, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 710, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 710, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 769, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 769, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 868, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 868, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 779, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 779, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 920, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 920, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 928, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 928, 2])
[INFO: train.py:  338]:   [val] ade: 0.578
[INFO: train.py:  338]:   [val] ade_l: 1.272
[INFO: train.py:  338]:   [val] ade_nl: 1.059
[INFO: train.py:  338]:   [val] d_loss: 1.409
[INFO: train.py:  338]:   [val] fde: 1.256
[INFO: train.py:  338]:   [val] fde_l: 2.765
[INFO: train.py:  338]:   [val] fde_nl: 2.301
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.423
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.423
[INFO: train.py:  338]:   [val] resist_count: 2855.000
[INFO: train.py:  338]:   [val] resist_loss: 0.293
[INFO: train.py:  341]:   [train] ade: 0.589
[INFO: train.py:  341]:   [train] ade_l: 1.250
[INFO: train.py:  341]:   [train] ade_nl: 1.113
[INFO: train.py:  341]:   [train] d_loss: 1.411
[INFO: train.py:  341]:   [train] fde: 1.205
[INFO: train.py:  341]:   [train] fde_l: 2.557
[INFO: train.py:  341]:   [train] fde_nl: 2.278
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.381
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.381
[INFO: train.py:  341]:   [train] resist_count: 2930.000
[INFO: train.py:  341]:   [train] resist_loss: 0.159
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 1.5379], device='cuda:0')
[INFO: train.py:  310]: g step took 2.5691893100738525
[INFO: train.py:  316]: Interation 8900 took 12.40962553024292
[INFO: train.py:  558]: resist loss: tensor([ 6.1956], device='cuda:0')
[INFO: train.py:  310]: g step took 2.54664945602417
[INFO: train.py:  316]: Interation 8901 took 2.550618886947632
[INFO: train.py:  558]: resist loss: tensor([ 0.8330], device='cuda:0')
[INFO: train.py:  310]: g step took 2.223287343978882
[INFO: train.py:  316]: Interation 8902 took 2.227327585220337
[INFO: train.py:  558]: resist loss: tensor([ 0.6259], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2624967098236084
[INFO: train.py:  316]: Interation 8903 took 2.266031265258789
[INFO: train.py:  558]: resist loss: tensor([ 0.1501], device='cuda:0')
[INFO: train.py:  310]: g step took 2.076352119445801
[INFO: train.py:  316]: Interation 8904 took 2.0802743434906006
[INFO: train.py:  558]: resist loss: tensor([ 2.9639], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1519296169281006
[INFO: train.py:  316]: Interation 8905 took 2.1557350158691406
[INFO: train.py:  558]: resist loss: tensor([ 2.0872], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1598358154296875
[INFO: train.py:  316]: Interation 8906 took 2.163731575012207
[INFO: train.py:  558]: resist loss: tensor([ 0.3662], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1824870109558105
[INFO: train.py:  316]: Interation 8907 took 2.1863884925842285
[INFO: train.py:  558]: resist loss: tensor([ 0.7114], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4072718620300293
[INFO: train.py:  316]: Interation 8908 took 2.4111669063568115
[INFO: train.py:  558]: resist loss: tensor([ 11.1824], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4082465171813965
[INFO: train.py:  316]: Interation 8909 took 2.412254810333252
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 557, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 557, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 588, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 588, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 539, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 539, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 629, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 629, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 465, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 465, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 530, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 530, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 478, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 478, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 570, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 570, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 676, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 676, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 530, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 530, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 638, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 638, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 161, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 161, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 766, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 766, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 922, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 922, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 812, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 812, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 717, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 717, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 823, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 823, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 765, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 765, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 711, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 711, 2])
[INFO: train.py:  338]:   [val] ade: 0.591
[INFO: train.py:  338]:   [val] ade_l: 1.302
[INFO: train.py:  338]:   [val] ade_nl: 1.083
[INFO: train.py:  338]:   [val] d_loss: 1.411
[INFO: train.py:  338]:   [val] fde: 1.266
[INFO: train.py:  338]:   [val] fde_l: 2.788
[INFO: train.py:  338]:   [val] fde_nl: 2.320
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.440
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.440
[INFO: train.py:  338]:   [val] resist_count: 2931.000
[INFO: train.py:  338]:   [val] resist_loss: 0.323
[INFO: train.py:  341]:   [train] ade: 0.586
[INFO: train.py:  341]:   [train] ade_l: 1.209
[INFO: train.py:  341]:   [train] ade_nl: 1.136
[INFO: train.py:  341]:   [train] d_loss: 1.408
[INFO: train.py:  341]:   [train] fde: 1.185
[INFO: train.py:  341]:   [train] fde_l: 2.446
[INFO: train.py:  341]:   [train] fde_nl: 2.298
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.380
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.380
[INFO: train.py:  341]:   [train] resist_count: 3020.000
[INFO: train.py:  341]:   [train] resist_loss: 0.191
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.1856], device='cuda:0')
[INFO: train.py:  310]: g step took 0.1437392234802246
[INFO: train.py:  316]: Interation 8910 took 9.313167810440063
[INFO: train.py:  279]: Starting epoch 209
[INFO: train.py:  280]: Epoch resist loss: tensor([ 195.2377])
[INFO: train.py:  558]: resist loss: tensor([ 3.5857], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9724392890930176
[INFO: train.py:  316]: Interation 8911 took 2.3885319232940674
[INFO: train.py:  558]: resist loss: tensor([ 17.1055], device='cuda:0')
[INFO: train.py:  310]: g step took 2.24453067779541
[INFO: train.py:  316]: Interation 8912 took 2.249166965484619
[INFO: train.py:  558]: resist loss: tensor([ 1.0908], device='cuda:0')
[INFO: train.py:  310]: g step took 1.637190818786621
[INFO: train.py:  316]: Interation 8913 took 1.645275354385376
[INFO: train.py:  558]: resist loss: tensor([ 11.3724], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9438512325286865
[INFO: train.py:  316]: Interation 8914 took 1.944227933883667
[INFO: train.py:  558]: resist loss: tensor([ 0.7768], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9878313541412354
[INFO: train.py:  316]: Interation 8915 took 1.9882044792175293
[INFO: train.py:  558]: resist loss: tensor([ 2.3334], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8669109344482422
[INFO: train.py:  316]: Interation 8916 took 1.8673298358917236
[INFO: train.py:  558]: resist loss: tensor([ 4.1785], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8378627300262451
[INFO: train.py:  316]: Interation 8917 took 1.8382301330566406
[INFO: train.py:  558]: resist loss: tensor([ 0.1616], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0512757301330566
[INFO: train.py:  316]: Interation 8918 took 2.051645517349243
[INFO: train.py:  558]: resist loss: tensor([ 6.4499], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0998294353485107
[INFO: train.py:  316]: Interation 8919 took 2.1039397716522217
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 454, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 454, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 628, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 628, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 632, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 632, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 605, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 605, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 541, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 541, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 608, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 608, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 526, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 526, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 467, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 467, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 558, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 558, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 600, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 600, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 626, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 626, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 116, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 116, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 757, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 757, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 821, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 821, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 765, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 765, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 650, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 650, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 906, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 906, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 797, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 797, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 816, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 816, 2])
[INFO: train.py:  338]:   [val] ade: 0.638
[INFO: train.py:  338]:   [val] ade_l: 1.405
[INFO: train.py:  338]:   [val] ade_nl: 1.169
[INFO: train.py:  338]:   [val] d_loss: 1.399
[INFO: train.py:  338]:   [val] fde: 1.344
[INFO: train.py:  338]:   [val] fde_l: 2.959
[INFO: train.py:  338]:   [val] fde_nl: 2.462
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.473
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.473
[INFO: train.py:  338]:   [val] resist_count: 2949.000
[INFO: train.py:  338]:   [val] resist_loss: 0.275
[INFO: train.py:  341]:   [train] ade: 0.629
[INFO: train.py:  341]:   [train] ade_l: 1.290
[INFO: train.py:  341]:   [train] ade_nl: 1.227
[INFO: train.py:  341]:   [train] d_loss: 1.403
[INFO: train.py:  341]:   [train] fde: 1.262
[INFO: train.py:  341]:   [train] fde_l: 2.588
[INFO: train.py:  341]:   [train] fde_nl: 2.462
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.419
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.419
[INFO: train.py:  341]:   [train] resist_count: 2948.000
[INFO: train.py:  341]:   [train] resist_loss: 0.162
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 3.7524], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6175768375396729
[INFO: train.py:  316]: Interation 8920 took 10.248197793960571
[INFO: train.py:  558]: resist loss: tensor([ 2.1893], device='cuda:0')
[INFO: train.py:  310]: g step took 1.959784984588623
[INFO: train.py:  316]: Interation 8921 took 1.9641497135162354
[INFO: train.py:  558]: resist loss: tensor([ 19.8839], device='cuda:0')
[INFO: train.py:  310]: g step took 2.299395799636841
[INFO: train.py:  316]: Interation 8922 took 2.2998087406158447
[INFO: train.py:  558]: resist loss: tensor([ 1.0161], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0181758403778076
[INFO: train.py:  316]: Interation 8923 took 2.0186121463775635
[INFO: train.py:  558]: resist loss: tensor([ 8.7428], device='cuda:0')
[INFO: train.py:  310]: g step took 1.849482536315918
[INFO: train.py:  316]: Interation 8924 took 1.849837303161621
[INFO: train.py:  558]: resist loss: tensor([ 5.4492], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8304214477539062
[INFO: train.py:  316]: Interation 8925 took 1.8307509422302246
[INFO: train.py:  558]: resist loss: tensor([ 0.7844], device='cuda:0')
[INFO: train.py:  310]: g step took 2.077688217163086
[INFO: train.py:  316]: Interation 8926 took 2.078033924102783
[INFO: train.py:  558]: resist loss: tensor([ 9.3757], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2554168701171875
[INFO: train.py:  316]: Interation 8927 took 2.2594993114471436
[INFO: train.py:  558]: resist loss: tensor([ 7.7156], device='cuda:0')
[INFO: train.py:  310]: g step took 1.91839599609375
[INFO: train.py:  316]: Interation 8928 took 1.922386646270752
[INFO: train.py:  558]: resist loss: tensor([ 3.6930], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1406137943267822
[INFO: train.py:  316]: Interation 8929 took 2.1445515155792236
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 615, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 615, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 513, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 513, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 713, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 713, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 469, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 469, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 563, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 563, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 570, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 570, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 451, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 451, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 489, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 489, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 610, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 610, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 610, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 610, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 569, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 569, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 189, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 189, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 831, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 831, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 803, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 803, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 775, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 775, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 696, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 696, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 754, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 754, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 1033, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 1033, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 745, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 745, 2])
[INFO: train.py:  338]:   [val] ade: 0.647
[INFO: train.py:  338]:   [val] ade_l: 1.425
[INFO: train.py:  338]:   [val] ade_nl: 1.186
[INFO: train.py:  338]:   [val] d_loss: 1.408
[INFO: train.py:  338]:   [val] fde: 1.302
[INFO: train.py:  338]:   [val] fde_l: 2.866
[INFO: train.py:  338]:   [val] fde_nl: 2.385
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.470
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.470
[INFO: train.py:  338]:   [val] resist_count: 3215.000
[INFO: train.py:  338]:   [val] resist_loss: 0.360
[INFO: train.py:  341]:   [train] ade: 0.652
[INFO: train.py:  341]:   [train] ade_l: 1.355
[INFO: train.py:  341]:   [train] ade_nl: 1.256
[INFO: train.py:  341]:   [train] d_loss: 1.389
[INFO: train.py:  341]:   [train] fde: 1.241
[INFO: train.py:  341]:   [train] fde_l: 2.579
[INFO: train.py:  341]:   [train] fde_nl: 2.392
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.423
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.423
[INFO: train.py:  341]:   [train] resist_count: 3340.000
[INFO: train.py:  341]:   [train] resist_loss: 0.183
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.3010], device='cuda:0')
[INFO: train.py:  310]: g step took 1.917130947113037
[INFO: train.py:  316]: Interation 8930 took 10.564757585525513
[INFO: train.py:  558]: resist loss: tensor([ 5.1095], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4662964344024658
[INFO: train.py:  316]: Interation 8931 took 1.4702069759368896
[INFO: train.py:  558]: resist loss: tensor([ 0.1923], device='cuda:0')
[INFO: train.py:  310]: g step took 1.634584903717041
[INFO: train.py:  316]: Interation 8932 took 1.6382956504821777
[INFO: train.py:  558]: resist loss: tensor([ 9.7519], device='cuda:0')
[INFO: train.py:  310]: g step took 2.280642509460449
[INFO: train.py:  316]: Interation 8933 took 2.284749746322632
[INFO: train.py:  558]: resist loss: tensor([ 1.4566], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1509480476379395
[INFO: train.py:  316]: Interation 8934 took 2.154844284057617
[INFO: train.py:  558]: resist loss: tensor([ 2.5642], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9079785346984863
[INFO: train.py:  316]: Interation 8935 took 1.9118585586547852
[INFO: train.py:  558]: resist loss: tensor([ 2.1719], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8276457786560059
[INFO: train.py:  316]: Interation 8936 took 1.831510305404663
[INFO: train.py:  558]: resist loss: tensor([ 10.5699], device='cuda:0')
[INFO: train.py:  310]: g step took 2.076662540435791
[INFO: train.py:  316]: Interation 8937 took 2.0806543827056885
[INFO: train.py:  558]: resist loss: tensor([ 6.2554], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1636292934417725
[INFO: train.py:  316]: Interation 8938 took 2.167581796646118
[INFO: train.py:  558]: resist loss: tensor([ 1.0404], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3609743118286133
[INFO: train.py:  316]: Interation 8939 took 2.3647844791412354
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 628, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 628, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 587, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 587, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 581, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 581, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 637, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 637, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 597, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 597, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 512, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 512, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 503, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 503, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 608, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 608, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 500, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 500, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 512, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 512, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 574, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 574, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 122, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 122, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 647, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 647, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 933, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 933, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 807, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 807, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 610, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 610, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 747, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 747, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 660, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 660, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 669, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 669, 2])
[INFO: train.py:  338]:   [val] ade: 0.658
[INFO: train.py:  338]:   [val] ade_l: 1.448
[INFO: train.py:  338]:   [val] ade_nl: 1.205
[INFO: train.py:  338]:   [val] d_loss: 1.406
[INFO: train.py:  338]:   [val] fde: 1.296
[INFO: train.py:  338]:   [val] fde_l: 2.853
[INFO: train.py:  338]:   [val] fde_nl: 2.374
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.473
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.473
[INFO: train.py:  338]:   [val] resist_count: 3121.000
[INFO: train.py:  338]:   [val] resist_loss: 0.356
[INFO: train.py:  341]:   [train] ade: 0.661
[INFO: train.py:  341]:   [train] ade_l: 1.410
[INFO: train.py:  341]:   [train] ade_nl: 1.245
[INFO: train.py:  341]:   [train] d_loss: 1.416
[INFO: train.py:  341]:   [train] fde: 1.231
[INFO: train.py:  341]:   [train] fde_l: 2.626
[INFO: train.py:  341]:   [train] fde_nl: 2.319
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.433
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.433
[INFO: train.py:  341]:   [train] resist_count: 2653.000
[INFO: train.py:  341]:   [train] resist_loss: 0.161
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.4363], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4180908203125
[INFO: train.py:  316]: Interation 8940 took 9.609305381774902
[INFO: train.py:  558]: resist loss: tensor([ 0.9523], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0258071422576904
[INFO: train.py:  316]: Interation 8941 took 2.0295865535736084
[INFO: train.py:  558]: resist loss: tensor([ 0.3736], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7558543682098389
[INFO: train.py:  316]: Interation 8942 took 1.759636640548706
[INFO: train.py:  558]: resist loss: tensor([ 5.1997], device='cuda:0')
[INFO: train.py:  310]: g step took 2.101562261581421
[INFO: train.py:  316]: Interation 8943 took 2.105315685272217
[INFO: train.py:  558]: resist loss: tensor([ 0.4747], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6301651000976562
[INFO: train.py:  316]: Interation 8944 took 1.6339781284332275
[INFO: train.py:  558]: resist loss: tensor([ 7.7062], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0501725673675537
[INFO: train.py:  316]: Interation 8945 took 2.0539283752441406
[INFO: train.py:  558]: resist loss: tensor([ 4.5439], device='cuda:0')
[INFO: train.py:  310]: g step took 2.262542724609375
[INFO: train.py:  316]: Interation 8946 took 2.2661476135253906
[INFO: train.py:  558]: resist loss: tensor([ 4.7511], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7204701900482178
[INFO: train.py:  316]: Interation 8947 took 1.724381446838379
[INFO: train.py:  558]: resist loss: tensor([ 5.2261], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7606480121612549
[INFO: train.py:  316]: Interation 8948 took 1.7646117210388184
[INFO: train.py:  558]: resist loss: tensor([ 3.5389], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1274473667144775
[INFO: train.py:  316]: Interation 8949 took 2.131282329559326
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 539, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 539, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 503, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 503, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 528, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 528, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 561, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 561, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 495, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 495, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 542, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 542, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 499, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 499, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 626, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 626, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 617, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 617, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 646, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 646, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 635, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 635, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 170, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 170, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 679, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 679, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 839, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 839, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 789, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 789, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 752, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 752, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 792, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 792, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 745, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 745, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 755, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 755, 2])
[INFO: train.py:  338]:   [val] ade: 0.621
[INFO: train.py:  338]:   [val] ade_l: 1.366
[INFO: train.py:  338]:   [val] ade_nl: 1.137
[INFO: train.py:  338]:   [val] d_loss: 1.391
[INFO: train.py:  338]:   [val] fde: 1.260
[INFO: train.py:  338]:   [val] fde_l: 2.775
[INFO: train.py:  338]:   [val] fde_nl: 2.309
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.443
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.443
[INFO: train.py:  338]:   [val] resist_count: 3079.000
[INFO: train.py:  338]:   [val] resist_loss: 0.369
[INFO: train.py:  341]:   [train] ade: 0.613
[INFO: train.py:  341]:   [train] ade_l: 1.295
[INFO: train.py:  341]:   [train] ade_nl: 1.162
[INFO: train.py:  341]:   [train] d_loss: 1.403
[INFO: train.py:  341]:   [train] fde: 1.189
[INFO: train.py:  341]:   [train] fde_l: 2.515
[INFO: train.py:  341]:   [train] fde_nl: 2.256
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.383
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.383
[INFO: train.py:  341]:   [train] resist_count: 2492.000
[INFO: train.py:  341]:   [train] resist_loss: 0.157
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 11.4371], device='cuda:0')
[INFO: train.py:  310]: g step took 2.6383919715881348
[INFO: train.py:  316]: Interation 8950 took 11.544212579727173
[INFO: train.py:  558]: resist loss: tensor([ 0.2704], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4099974632263184
[INFO: train.py:  316]: Interation 8951 took 2.4138288497924805
[INFO: train.py:  558]: resist loss: tensor([ 13.1330], device='cuda:0')
[INFO: train.py:  310]: g step took 2.6605827808380127
[INFO: train.py:  316]: Interation 8952 took 2.664405345916748
[INFO: train.py:  558]: resist loss: tensor([ 0.2190], device='cuda:0')
[INFO: train.py:  310]: g step took 0.28670287132263184
[INFO: train.py:  316]: Interation 8953 took 0.2903714179992676
[INFO: train.py:  279]: Starting epoch 210
[INFO: train.py:  280]: Epoch resist loss: tensor([ 209.3326])
[INFO: train.py:  558]: resist loss: tensor([ 2.4438], device='cuda:0')
[INFO: train.py:  310]: g step took 2.6014304161071777
[INFO: train.py:  316]: Interation 8954 took 2.9767141342163086
[INFO: train.py:  558]: resist loss: tensor([ 0.6382], device='cuda:0')
[INFO: train.py:  310]: g step took 2.5600314140319824
[INFO: train.py:  316]: Interation 8955 took 2.5675058364868164
[INFO: train.py:  558]: resist loss: tensor([ 6.6600], device='cuda:0')
[INFO: train.py:  310]: g step took 2.6343891620635986
[INFO: train.py:  316]: Interation 8956 took 2.6451807022094727
[INFO: train.py:  558]: resist loss: tensor([ 1.8707], device='cuda:0')
[INFO: train.py:  310]: g step took 1.974060297012329
[INFO: train.py:  316]: Interation 8957 took 1.974458932876587
[INFO: train.py:  558]: resist loss: tensor([ 9.1204], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2012157440185547
[INFO: train.py:  316]: Interation 8958 took 2.209411144256592
[INFO: train.py:  558]: resist loss: tensor([ 10.0567], device='cuda:0')
[INFO: train.py:  310]: g step took 2.390460968017578
[INFO: train.py:  316]: Interation 8959 took 2.390915632247925
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 473, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 473, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 626, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 626, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 687, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 687, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 538, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 538, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 541, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 541, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 512, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 512, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 566, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 566, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 612, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 612, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 581, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 581, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 568, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 568, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 518, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 518, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 139, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 139, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 954, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 954, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 863, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 863, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 838, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 838, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 874, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 874, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 610, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 610, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 651, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 651, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 894, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 894, 2])
[INFO: train.py:  338]:   [val] ade: 0.634
[INFO: train.py:  338]:   [val] ade_l: 1.395
[INFO: train.py:  338]:   [val] ade_nl: 1.161
[INFO: train.py:  338]:   [val] d_loss: 1.409
[INFO: train.py:  338]:   [val] fde: 1.341
[INFO: train.py:  338]:   [val] fde_l: 2.952
[INFO: train.py:  338]:   [val] fde_nl: 2.457
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.487
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.487
[INFO: train.py:  338]:   [val] resist_count: 2547.000
[INFO: train.py:  338]:   [val] resist_loss: 0.291
[INFO: train.py:  341]:   [train] ade: 0.635
[INFO: train.py:  341]:   [train] ade_l: 1.336
[INFO: train.py:  341]:   [train] ade_nl: 1.212
[INFO: train.py:  341]:   [train] d_loss: 1.400
[INFO: train.py:  341]:   [train] fde: 1.253
[INFO: train.py:  341]:   [train] fde_l: 2.635
[INFO: train.py:  341]:   [train] fde_nl: 2.391
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.417
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.417
[INFO: train.py:  341]:   [train] resist_count: 2973.000
[INFO: train.py:  341]:   [train] resist_loss: 0.178
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.2189], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4979948997497559
[INFO: train.py:  316]: Interation 8960 took 10.029305219650269
[INFO: train.py:  558]: resist loss: tensor([ 4.8633], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1869049072265625
[INFO: train.py:  316]: Interation 8961 took 2.187300205230713
[INFO: train.py:  558]: resist loss: tensor([ 9.0597], device='cuda:0')
[INFO: train.py:  310]: g step took 2.182964563369751
[INFO: train.py:  316]: Interation 8962 took 2.1865451335906982
[INFO: train.py:  558]: resist loss: tensor([ 1.0639], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8894460201263428
[INFO: train.py:  316]: Interation 8963 took 1.8966128826141357
[INFO: train.py:  558]: resist loss: tensor([ 8.5690], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0276105403900146
[INFO: train.py:  316]: Interation 8964 took 2.0448198318481445
[INFO: train.py:  558]: resist loss: tensor([ 11.3745], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2635886669158936
[INFO: train.py:  316]: Interation 8965 took 2.2639169692993164
[INFO: train.py:  558]: resist loss: tensor([ 4.9266], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5826165676116943
[INFO: train.py:  316]: Interation 8966 took 1.582977294921875
[INFO: train.py:  558]: resist loss: tensor([ 2.4778], device='cuda:0')
[INFO: train.py:  310]: g step took 2.276540994644165
[INFO: train.py:  316]: Interation 8967 took 2.276880979537964
[INFO: train.py:  558]: resist loss: tensor([ 13.2700], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0091195106506348
[INFO: train.py:  316]: Interation 8968 took 2.009547710418701
[INFO: train.py:  558]: resist loss: tensor([ 0.5116], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9699163436889648
[INFO: train.py:  316]: Interation 8969 took 1.9703540802001953
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 544, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 544, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 628, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 628, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 516, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 516, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 561, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 561, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 548, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 548, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 506, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 506, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 539, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 539, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 584, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 584, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 503, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 503, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 732, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 732, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 546, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 546, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 154, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 154, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 847, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 847, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 887, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 887, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 868, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 868, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 673, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 673, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 867, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 867, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 680, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 680, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 703, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 703, 2])
[INFO: train.py:  338]:   [val] ade: 0.590
[INFO: train.py:  338]:   [val] ade_l: 1.298
[INFO: train.py:  338]:   [val] ade_nl: 1.080
[INFO: train.py:  338]:   [val] d_loss: 1.414
[INFO: train.py:  338]:   [val] fde: 1.234
[INFO: train.py:  338]:   [val] fde_l: 2.716
[INFO: train.py:  338]:   [val] fde_nl: 2.260
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.437
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.437
[INFO: train.py:  338]:   [val] resist_count: 2775.000
[INFO: train.py:  338]:   [val] resist_loss: 0.299
[INFO: train.py:  341]:   [train] ade: 0.623
[INFO: train.py:  341]:   [train] ade_l: 1.312
[INFO: train.py:  341]:   [train] ade_nl: 1.187
[INFO: train.py:  341]:   [train] d_loss: 1.414
[INFO: train.py:  341]:   [train] fde: 1.221
[INFO: train.py:  341]:   [train] fde_l: 2.571
[INFO: train.py:  341]:   [train] fde_nl: 2.325
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.426
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.426
[INFO: train.py:  341]:   [train] resist_count: 2858.000
[INFO: train.py:  341]:   [train] resist_loss: 0.163
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 3.8884], device='cuda:0')
[INFO: train.py:  310]: g step took 1.877960205078125
[INFO: train.py:  316]: Interation 8970 took 10.494396209716797
[INFO: train.py:  558]: resist loss: tensor([ 0.8315], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0722663402557373
[INFO: train.py:  316]: Interation 8971 took 2.075878620147705
[INFO: train.py:  558]: resist loss: tensor([ 11.6305], device='cuda:0')
[INFO: train.py:  310]: g step took 2.085359811782837
[INFO: train.py:  316]: Interation 8972 took 2.0889203548431396
[INFO: train.py:  558]: resist loss: tensor([ 9.1064], device='cuda:0')
[INFO: train.py:  310]: g step took 2.077023983001709
[INFO: train.py:  316]: Interation 8973 took 2.0806453227996826
[INFO: train.py:  558]: resist loss: tensor([ 13.6071], device='cuda:0')
[INFO: train.py:  310]: g step took 2.107234477996826
[INFO: train.py:  316]: Interation 8974 took 2.1111724376678467
[INFO: train.py:  558]: resist loss: tensor([ 2.6016], device='cuda:0')
[INFO: train.py:  310]: g step took 1.908752679824829
[INFO: train.py:  316]: Interation 8975 took 1.9123425483703613
[INFO: train.py:  558]: resist loss: tensor([ 0.3078], device='cuda:0')
[INFO: train.py:  310]: g step took 1.912449598312378
[INFO: train.py:  316]: Interation 8976 took 1.9164717197418213
[INFO: train.py:  558]: resist loss: tensor([ 0.5737], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7361252307891846
[INFO: train.py:  316]: Interation 8977 took 1.7400250434875488
[INFO: train.py:  558]: resist loss: tensor([ 0.5062], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9088444709777832
[INFO: train.py:  316]: Interation 8978 took 1.9119861125946045
[INFO: train.py:  558]: resist loss: tensor([ 5.6449], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0037968158721924
[INFO: train.py:  316]: Interation 8979 took 2.007600784301758
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 523, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 523, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 633, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 633, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 655, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 655, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 564, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 564, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 562, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 562, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 518, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 518, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 582, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 582, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 514, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 514, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 647, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 647, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 501, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 501, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 513, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 513, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 149, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 149, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 744, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 744, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 711, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 711, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 773, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 773, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 845, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 845, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 819, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 819, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 814, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 814, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 602, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 602, 2])
[INFO: train.py:  338]:   [val] ade: 0.605
[INFO: train.py:  338]:   [val] ade_l: 1.332
[INFO: train.py:  338]:   [val] ade_nl: 1.108
[INFO: train.py:  338]:   [val] d_loss: 1.406
[INFO: train.py:  338]:   [val] fde: 1.294
[INFO: train.py:  338]:   [val] fde_l: 2.849
[INFO: train.py:  338]:   [val] fde_nl: 2.371
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.460
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.460
[INFO: train.py:  338]:   [val] resist_count: 3270.000
[INFO: train.py:  338]:   [val] resist_loss: 0.343
[INFO: train.py:  341]:   [train] ade: 0.595
[INFO: train.py:  341]:   [train] ade_l: 1.213
[INFO: train.py:  341]:   [train] ade_nl: 1.167
[INFO: train.py:  341]:   [train] d_loss: 1.395
[INFO: train.py:  341]:   [train] fde: 1.224
[INFO: train.py:  341]:   [train] fde_l: 2.497
[INFO: train.py:  341]:   [train] fde_nl: 2.401
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.382
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.382
[INFO: train.py:  341]:   [train] resist_count: 3223.000
[INFO: train.py:  341]:   [train] resist_loss: 0.181
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 19.4256], device='cuda:0')
[INFO: train.py:  310]: g step took 2.8399126529693604
[INFO: train.py:  316]: Interation 8980 took 12.873143672943115
[INFO: train.py:  558]: resist loss: tensor([ 3.9384], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7283210754394531
[INFO: train.py:  316]: Interation 8981 took 1.7323977947235107
[INFO: train.py:  558]: resist loss: tensor([ 6.9406], device='cuda:0')
[INFO: train.py:  310]: g step took 2.389228105545044
[INFO: train.py:  316]: Interation 8982 took 2.3931446075439453
[INFO: train.py:  558]: resist loss: tensor([ 1.9818], device='cuda:0')
[INFO: train.py:  310]: g step took 2.5350868701934814
[INFO: train.py:  316]: Interation 8983 took 2.539168119430542
[INFO: train.py:  558]: resist loss: tensor([ 2.0503], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3693251609802246
[INFO: train.py:  316]: Interation 8984 took 2.373678684234619
[INFO: train.py:  558]: resist loss: tensor([ 3.6650], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3290293216705322
[INFO: train.py:  316]: Interation 8985 took 2.332981824874878
[INFO: train.py:  558]: resist loss: tensor([ 3.3274], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9042460918426514
[INFO: train.py:  316]: Interation 8986 took 1.908132791519165
[INFO: train.py:  558]: resist loss: tensor([ 10.3894], device='cuda:0')
[INFO: train.py:  310]: g step took 2.357672691345215
[INFO: train.py:  316]: Interation 8987 took 2.3618836402893066
[INFO: train.py:  558]: resist loss: tensor([ 10.1915], device='cuda:0')
[INFO: train.py:  310]: g step took 2.747865915298462
[INFO: train.py:  316]: Interation 8988 took 2.7517592906951904
[INFO: train.py:  558]: resist loss: tensor([ 5.4308], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8572731018066406
[INFO: train.py:  316]: Interation 8989 took 1.861328125
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 517, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 517, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 728, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 728, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 599, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 599, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 566, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 566, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 603, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 603, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 615, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 615, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 525, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 525, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 513, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 513, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 505, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 505, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 478, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 478, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 556, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 556, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 156, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 156, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 866, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 866, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 957, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 957, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 704, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 704, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 860, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 860, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 817, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 817, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 638, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 638, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 692, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 692, 2])
[INFO: train.py:  338]:   [val] ade: 0.627
[INFO: train.py:  338]:   [val] ade_l: 1.381
[INFO: train.py:  338]:   [val] ade_nl: 1.149
[INFO: train.py:  338]:   [val] d_loss: 1.411
[INFO: train.py:  338]:   [val] fde: 1.280
[INFO: train.py:  338]:   [val] fde_l: 2.819
[INFO: train.py:  338]:   [val] fde_nl: 2.346
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.450
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.450
[INFO: train.py:  338]:   [val] resist_count: 3125.000
[INFO: train.py:  338]:   [val] resist_loss: 0.311
[INFO: train.py:  341]:   [train] ade: 0.625
[INFO: train.py:  341]:   [train] ade_l: 1.277
[INFO: train.py:  341]:   [train] ade_nl: 1.222
[INFO: train.py:  341]:   [train] d_loss: 1.404
[INFO: train.py:  341]:   [train] fde: 1.210
[INFO: train.py:  341]:   [train] fde_l: 2.474
[INFO: train.py:  341]:   [train] fde_nl: 2.367
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.401
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.401
[INFO: train.py:  341]:   [train] resist_count: 3095.000
[INFO: train.py:  341]:   [train] resist_loss: 0.181
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.8736], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6827738285064697
[INFO: train.py:  316]: Interation 8990 took 11.667506694793701
[INFO: train.py:  558]: resist loss: tensor([ 1.7975], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6552085876464844
[INFO: train.py:  316]: Interation 8991 took 1.6590662002563477
[INFO: train.py:  558]: resist loss: tensor([ 5.5469], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7040808200836182
[INFO: train.py:  316]: Interation 8992 took 1.7079963684082031
[INFO: train.py:  558]: resist loss: tensor([ 4.2967], device='cuda:0')
[INFO: train.py:  310]: g step took 2.020117998123169
[INFO: train.py:  316]: Interation 8993 took 2.0240209102630615
[INFO: train.py:  558]: resist loss: tensor([ 0.9893], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7543349266052246
[INFO: train.py:  316]: Interation 8994 took 1.7581961154937744
[INFO: train.py:  558]: resist loss: tensor([ 1.3666], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0725889205932617
[INFO: train.py:  316]: Interation 8995 took 2.0765039920806885
[INFO: train.py:  558]: resist loss: tensor([ 0.3323], device='cuda:0')
[INFO: train.py:  310]: g step took 0.2960362434387207
[INFO: train.py:  316]: Interation 8996 took 0.2999703884124756
[INFO: train.py:  279]: Starting epoch 211
[INFO: train.py:  280]: Epoch resist loss: tensor([ 222.3669])
[INFO: train.py:  558]: resist loss: tensor([ 0.6426], device='cuda:0')
[INFO: train.py:  310]: g step took 1.947176218032837
[INFO: train.py:  316]: Interation 8997 took 2.3072619438171387
[INFO: train.py:  558]: resist loss: tensor([ 16.7499], device='cuda:0')
[INFO: train.py:  310]: g step took 1.946075439453125
[INFO: train.py:  316]: Interation 8998 took 1.9768946170806885
[INFO: train.py:  558]: resist loss: tensor([ 1.6148], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0981311798095703
[INFO: train.py:  316]: Interation 8999 took 2.098494529724121
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 515, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 515, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 532, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 532, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 522, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 522, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 571, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 571, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 522, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 522, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 732, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 732, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 595, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 595, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 510, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 510, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 564, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 564, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 567, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 567, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 541, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 541, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 190, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 190, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 638, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 638, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 785, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 785, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 740, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 740, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 791, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 791, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 786, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 786, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 740, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 740, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 849, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 849, 2])
[INFO: train.py:  338]:   [val] ade: 0.681
[INFO: train.py:  338]:   [val] ade_l: 1.500
[INFO: train.py:  338]:   [val] ade_nl: 1.248
[INFO: train.py:  338]:   [val] d_loss: 1.412
[INFO: train.py:  338]:   [val] fde: 1.283
[INFO: train.py:  338]:   [val] fde_l: 2.826
[INFO: train.py:  338]:   [val] fde_nl: 2.351
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.509
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.509
[INFO: train.py:  338]:   [val] resist_count: 2974.000
[INFO: train.py:  338]:   [val] resist_loss: 0.328
[INFO: train.py:  341]:   [train] ade: 0.668
[INFO: train.py:  341]:   [train] ade_l: 1.399
[INFO: train.py:  341]:   [train] ade_nl: 1.278
[INFO: train.py:  341]:   [train] d_loss: 1.416
[INFO: train.py:  341]:   [train] fde: 1.192
[INFO: train.py:  341]:   [train] fde_l: 2.497
[INFO: train.py:  341]:   [train] fde_nl: 2.280
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.440
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.440
[INFO: train.py:  341]:   [train] resist_count: 2901.000
[INFO: train.py:  341]:   [train] resist_loss: 0.166
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 12.3748], device='cuda:0')
[INFO: train.py:  310]: g step took 2.113518476486206
[INFO: train.py:  316]: Interation 9000 took 10.855390787124634
[INFO: train.py:  558]: resist loss: tensor([ 2.0674], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8789525032043457
[INFO: train.py:  316]: Interation 9001 took 1.8793761730194092
[INFO: train.py:  558]: resist loss: tensor([ 14.6000], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0975704193115234
[INFO: train.py:  316]: Interation 9002 took 2.0979583263397217
[INFO: train.py:  558]: resist loss: tensor([ 9.5076], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9110572338104248
[INFO: train.py:  316]: Interation 9003 took 1.911452054977417
[INFO: train.py:  558]: resist loss: tensor([ 2.0970], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7751567363739014
[INFO: train.py:  316]: Interation 9004 took 1.7755727767944336
[INFO: train.py:  558]: resist loss: tensor([ 0.3209], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8441877365112305
[INFO: train.py:  316]: Interation 9005 took 1.8446128368377686
[INFO: train.py:  558]: resist loss: tensor([ 1.2179], device='cuda:0')
[INFO: train.py:  310]: g step took 2.089848518371582
[INFO: train.py:  316]: Interation 9006 took 2.1040823459625244
[INFO: train.py:  558]: resist loss: tensor([ 6.0081], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3558194637298584
[INFO: train.py:  316]: Interation 9007 took 2.359783887863159
[INFO: train.py:  558]: resist loss: tensor([ 1.9680], device='cuda:0')
[INFO: train.py:  310]: g step took 2.010342597961426
[INFO: train.py:  316]: Interation 9008 took 2.0107343196868896
[INFO: train.py:  558]: resist loss: tensor([ 19.0965], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1659979820251465
[INFO: train.py:  316]: Interation 9009 took 2.1665351390838623
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 530, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 530, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 478, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 478, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 587, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 587, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 512, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 512, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 506, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 506, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 723, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 723, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 619, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 619, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 723, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 723, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 554, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 554, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 536, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 536, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 480, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 480, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 113, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 113, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 671, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 671, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 646, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 646, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 735, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 735, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 676, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 676, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 725, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 725, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 1008, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 1008, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 814, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 814, 2])
[INFO: train.py:  338]:   [val] ade: 0.627
[INFO: train.py:  338]:   [val] ade_l: 1.381
[INFO: train.py:  338]:   [val] ade_nl: 1.149
[INFO: train.py:  338]:   [val] d_loss: 1.426
[INFO: train.py:  338]:   [val] fde: 1.210
[INFO: train.py:  338]:   [val] fde_l: 2.665
[INFO: train.py:  338]:   [val] fde_nl: 2.217
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.443
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.443
[INFO: train.py:  338]:   [val] resist_count: 3304.000
[INFO: train.py:  338]:   [val] resist_loss: 0.360
[INFO: train.py:  341]:   [train] ade: 0.612
[INFO: train.py:  341]:   [train] ade_l: 1.310
[INFO: train.py:  341]:   [train] ade_nl: 1.150
[INFO: train.py:  341]:   [train] d_loss: 1.404
[INFO: train.py:  341]:   [train] fde: 1.139
[INFO: train.py:  341]:   [train] fde_l: 2.437
[INFO: train.py:  341]:   [train] fde_nl: 2.140
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.364
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.364
[INFO: train.py:  341]:   [train] resist_count: 3122.000
[INFO: train.py:  341]:   [train] resist_loss: 0.192
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 1.0270], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8070650100708008
[INFO: train.py:  316]: Interation 9010 took 10.606911659240723
[INFO: train.py:  558]: resist loss: tensor([ 8.3104], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7534854412078857
[INFO: train.py:  316]: Interation 9011 took 1.7578604221343994
[INFO: train.py:  558]: resist loss: tensor([ 9.3114], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3895299434661865
[INFO: train.py:  316]: Interation 9012 took 2.3899102210998535
[INFO: train.py:  558]: resist loss: tensor([ 5.4834], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6518807411193848
[INFO: train.py:  316]: Interation 9013 took 1.6552951335906982
[INFO: train.py:  558]: resist loss: tensor([ 0.9398], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9360485076904297
[INFO: train.py:  316]: Interation 9014 took 1.9399826526641846
[INFO: train.py:  558]: resist loss: tensor([ 1.9845], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7725658416748047
[INFO: train.py:  316]: Interation 9015 took 1.7764863967895508
[INFO: train.py:  558]: resist loss: tensor([ 4.0151], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0463955402374268
[INFO: train.py:  316]: Interation 9016 took 2.0501973628997803
[INFO: train.py:  558]: resist loss: tensor([ 5.0016], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8151733875274658
[INFO: train.py:  316]: Interation 9017 took 1.8190624713897705
[INFO: train.py:  558]: resist loss: tensor([ 4.5451], device='cuda:0')
[INFO: train.py:  310]: g step took 1.802154779434204
[INFO: train.py:  316]: Interation 9018 took 1.8058457374572754
[INFO: train.py:  558]: resist loss: tensor([ 7.1486], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9721248149871826
[INFO: train.py:  316]: Interation 9019 took 1.9761168956756592
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 599, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 599, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 583, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 583, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 454, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 454, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 534, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 534, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 648, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 648, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 496, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 496, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 595, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 595, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 584, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 584, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 520, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 520, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 587, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 587, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 631, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 631, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 130, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 130, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 746, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 746, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 708, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 708, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 774, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 774, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 939, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 939, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 805, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 805, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 796, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 796, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 810, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 810, 2])
[INFO: train.py:  338]:   [val] ade: 0.630
[INFO: train.py:  338]:   [val] ade_l: 1.387
[INFO: train.py:  338]:   [val] ade_nl: 1.154
[INFO: train.py:  338]:   [val] d_loss: 1.411
[INFO: train.py:  338]:   [val] fde: 1.224
[INFO: train.py:  338]:   [val] fde_l: 2.696
[INFO: train.py:  338]:   [val] fde_nl: 2.243
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.449
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.449
[INFO: train.py:  338]:   [val] resist_count: 2852.000
[INFO: train.py:  338]:   [val] resist_loss: 0.350
[INFO: train.py:  341]:   [train] ade: 0.642
[INFO: train.py:  341]:   [train] ade_l: 1.347
[INFO: train.py:  341]:   [train] ade_nl: 1.228
[INFO: train.py:  341]:   [train] d_loss: 1.400
[INFO: train.py:  341]:   [train] fde: 1.193
[INFO: train.py:  341]:   [train] fde_l: 2.502
[INFO: train.py:  341]:   [train] fde_nl: 2.281
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.419
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.419
[INFO: train.py:  341]:   [train] resist_count: 3058.000
[INFO: train.py:  341]:   [train] resist_loss: 0.183
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 1.2842], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6192171573638916
[INFO: train.py:  316]: Interation 9020 took 10.382614374160767
[INFO: train.py:  558]: resist loss: tensor([ 1.5254], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8537986278533936
[INFO: train.py:  316]: Interation 9021 took 1.8572211265563965
[INFO: train.py:  558]: resist loss: tensor([ 15.2517], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1535449028015137
[INFO: train.py:  316]: Interation 9022 took 2.157548427581787
[INFO: train.py:  558]: resist loss: tensor([ 0.9386], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6938598155975342
[INFO: train.py:  316]: Interation 9023 took 1.6980602741241455
[INFO: train.py:  558]: resist loss: tensor([ 12.2228], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1606013774871826
[INFO: train.py:  316]: Interation 9024 took 2.1644952297210693
[INFO: train.py:  558]: resist loss: tensor([ 6.3309], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5355017185211182
[INFO: train.py:  316]: Interation 9025 took 1.5395145416259766
[INFO: train.py:  558]: resist loss: tensor([ 5.1047], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1757872104644775
[INFO: train.py:  316]: Interation 9026 took 2.179104804992676
[INFO: train.py:  558]: resist loss: tensor([ 15.4458], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3277480602264404
[INFO: train.py:  316]: Interation 9027 took 2.33152437210083
[INFO: train.py:  558]: resist loss: tensor([ 2.2718], device='cuda:0')
[INFO: train.py:  310]: g step took 1.831486463546753
[INFO: train.py:  316]: Interation 9028 took 1.8353934288024902
[INFO: train.py:  558]: resist loss: tensor([ 1.4969], device='cuda:0')
[INFO: train.py:  310]: g step took 1.905683994293213
[INFO: train.py:  316]: Interation 9029 took 1.9088525772094727
[INFO: train.py:  327]: Checking stats on val ...
Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7fc4e2a05358>>
Traceback (most recent call last):
  File "/data/xinjiey/Group_Navi_GAN/env/lib/python3.5/site-packages/torch/utils/data/dataloader.py", line 349, in __del__
    self._shutdown_workers()
  File "/data/xinjiey/Group_Navi_GAN/env/lib/python3.5/site-packages/torch/utils/data/dataloader.py", line 328, in _shutdown_workers
    self.worker_result_queue.get()
  File "/usr/lib/python3.5/multiprocessing/queues.py", line 345, in get
    return ForkingPickler.loads(res)
  File "/data/xinjiey/Group_Navi_GAN/env/lib/python3.5/site-packages/torch/multiprocessing/reductions.py", line 70, in rebuild_storage_fd
    fd = df.detach()
  File "/usr/lib/python3.5/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/usr/lib/python3.5/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 494, in Client
    deliver_challenge(c, authkey)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 722, in deliver_challenge
    response = connection.recv_bytes(256)        # reject large message
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError: 
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 566, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 566, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 583, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 583, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 536, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 536, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 635, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 635, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 562, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 562, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 586, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 586, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 565, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 565, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 500, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 500, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 617, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 617, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 515, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 515, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 575, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 575, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 121, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 121, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 819, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 819, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 914, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 914, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 576, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 576, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 765, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 765, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 748, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 748, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 781, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 781, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 763, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 763, 2])
[INFO: train.py:  338]:   [val] ade: 0.620
[INFO: train.py:  338]:   [val] ade_l: 1.365
[INFO: train.py:  338]:   [val] ade_nl: 1.136
[INFO: train.py:  338]:   [val] d_loss: 1.408
[INFO: train.py:  338]:   [val] fde: 1.240
[INFO: train.py:  338]:   [val] fde_l: 2.731
[INFO: train.py:  338]:   [val] fde_nl: 2.272
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.455
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.455
[INFO: train.py:  338]:   [val] resist_count: 2859.000
[INFO: train.py:  338]:   [val] resist_loss: 0.315
[INFO: train.py:  341]:   [train] ade: 0.623
[INFO: train.py:  341]:   [train] ade_l: 1.301
[INFO: train.py:  341]:   [train] ade_nl: 1.194
[INFO: train.py:  341]:   [train] d_loss: 1.401
[INFO: train.py:  341]:   [train] fde: 1.164
[INFO: train.py:  341]:   [train] fde_l: 2.433
[INFO: train.py:  341]:   [train] fde_nl: 2.233
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.400
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.400
[INFO: train.py:  341]:   [train] resist_count: 3057.000
[INFO: train.py:  341]:   [train] resist_loss: 0.177
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.9008], device='cuda:0')
[INFO: train.py:  310]: g step took 1.884777545928955
[INFO: train.py:  316]: Interation 9030 took 10.260321140289307
[INFO: train.py:  558]: resist loss: tensor([ 6.7415], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7893733978271484
[INFO: train.py:  316]: Interation 9031 took 1.7931740283966064
[INFO: train.py:  558]: resist loss: tensor([ 4.7969], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8095693588256836
[INFO: train.py:  316]: Interation 9032 took 1.813138723373413
[INFO: train.py:  558]: resist loss: tensor([ 0.9063], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1587648391723633
[INFO: train.py:  316]: Interation 9033 took 2.1626596450805664
[INFO: train.py:  558]: resist loss: tensor([ 6.8350], device='cuda:0')
[INFO: train.py:  310]: g step took 2.186583995819092
[INFO: train.py:  316]: Interation 9034 took 2.190145969390869
[INFO: train.py:  558]: resist loss: tensor([ 9.5983], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2096474170684814
[INFO: train.py:  316]: Interation 9035 took 2.213439464569092
[INFO: train.py:  558]: resist loss: tensor([ 0.8210], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1507418155670166
[INFO: train.py:  316]: Interation 9036 took 2.1546709537506104
[INFO: train.py:  558]: resist loss: tensor([ 2.1374], device='cuda:0')
[INFO: train.py:  310]: g step took 2.158748149871826
[INFO: train.py:  316]: Interation 9037 took 2.161876916885376
[INFO: train.py:  558]: resist loss: tensor([ 0.6054], device='cuda:0')
[INFO: train.py:  310]: g step took 2.165632486343384
[INFO: train.py:  316]: Interation 9038 took 2.16949200630188
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 3.0590], device='cuda:0')
[INFO: train.py:  310]: g step took 0.23908162117004395
[INFO: train.py:  316]: Interation 9039 took 0.24291133880615234
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 529, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 529, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 498, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 498, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 532, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 532, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 601, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 601, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 552, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 552, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 439, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 439, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 556, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 556, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 539, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 539, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 505, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 505, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 702, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 702, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 647, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 647, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 261, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 261, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 805, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 805, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 810, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 810, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 656, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 656, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 794, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 794, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 695, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 695, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 807, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 807, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 961, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 961, 2])
[INFO: train.py:  338]:   [val] ade: 0.574
[INFO: train.py:  338]:   [val] ade_l: 1.263
[INFO: train.py:  338]:   [val] ade_nl: 1.051
[INFO: train.py:  338]:   [val] d_loss: 1.409
[INFO: train.py:  338]:   [val] fde: 1.155
[INFO: train.py:  338]:   [val] fde_l: 2.542
[INFO: train.py:  338]:   [val] fde_nl: 2.115
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.403
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.403
[INFO: train.py:  338]:   [val] resist_count: 3244.000
[INFO: train.py:  338]:   [val] resist_loss: 0.313
[INFO: train.py:  341]:   [train] ade: 0.595
[INFO: train.py:  341]:   [train] ade_l: 1.267
[INFO: train.py:  341]:   [train] ade_nl: 1.123
[INFO: train.py:  341]:   [train] d_loss: 1.405
[INFO: train.py:  341]:   [train] fde: 1.144
[INFO: train.py:  341]:   [train] fde_l: 2.435
[INFO: train.py:  341]:   [train] fde_nl: 2.159
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.368
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.368
[INFO: train.py:  341]:   [train] resist_count: 3301.000
[INFO: train.py:  341]:   [train] resist_loss: 0.180
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  279]: Starting epoch 212
[INFO: train.py:  280]: Epoch resist loss: tensor([ 231.2789])
[INFO: train.py:  558]: resist loss: tensor([ 4.8466], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8459506034851074
[INFO: train.py:  316]: Interation 9040 took 10.72896933555603
[INFO: train.py:  558]: resist loss: tensor([ 8.1496], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9251172542572021
[INFO: train.py:  316]: Interation 9041 took 1.9287669658660889
[INFO: train.py:  558]: resist loss: tensor([ 3.9647], device='cuda:0')
[INFO: train.py:  310]: g step took 1.995253086090088
[INFO: train.py:  316]: Interation 9042 took 1.9994654655456543
[INFO: train.py:  558]: resist loss: tensor([ 5.4103], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8384461402893066
[INFO: train.py:  316]: Interation 9043 took 1.8596117496490479
[INFO: train.py:  558]: resist loss: tensor([ 8.2078], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8436079025268555
[INFO: train.py:  316]: Interation 9044 took 1.8439269065856934
[INFO: train.py:  558]: resist loss: tensor([ 9.4387], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2342429161071777
[INFO: train.py:  316]: Interation 9045 took 2.2345871925354004
[INFO: train.py:  558]: resist loss: tensor([ 8.4837], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7843117713928223
[INFO: train.py:  316]: Interation 9046 took 1.7920336723327637
[INFO: train.py:  558]: resist loss: tensor([ 0.9702], device='cuda:0')
[INFO: train.py:  310]: g step took 2.059715509414673
[INFO: train.py:  316]: Interation 9047 took 2.0600852966308594
[INFO: train.py:  558]: resist loss: tensor([ 1.7390], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8529026508331299
[INFO: train.py:  316]: Interation 9048 took 1.8532614707946777
[INFO: train.py:  558]: resist loss: tensor([ 5.1507], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8720269203186035
[INFO: train.py:  316]: Interation 9049 took 1.8795437812805176
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 531, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 531, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 521, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 521, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 480, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 480, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 569, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 569, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 517, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 517, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 663, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 663, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 504, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 504, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 559, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 559, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 603, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 603, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 699, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 699, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 543, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 543, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 172, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 172, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 651, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 651, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 842, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 842, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 815, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 815, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 742, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 742, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 637, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 637, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 646, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 646, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 766, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 766, 2])
[INFO: train.py:  338]:   [val] ade: 0.662
[INFO: train.py:  338]:   [val] ade_l: 1.458
[INFO: train.py:  338]:   [val] ade_nl: 1.213
[INFO: train.py:  338]:   [val] d_loss: 1.414
[INFO: train.py:  338]:   [val] fde: 1.300
[INFO: train.py:  338]:   [val] fde_l: 2.863
[INFO: train.py:  338]:   [val] fde_nl: 2.382
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.493
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.493
[INFO: train.py:  338]:   [val] resist_count: 2530.000
[INFO: train.py:  338]:   [val] resist_loss: 0.315
[INFO: train.py:  341]:   [train] ade: 0.676
[INFO: train.py:  341]:   [train] ade_l: 1.360
[INFO: train.py:  341]:   [train] ade_nl: 1.346
[INFO: train.py:  341]:   [train] d_loss: 1.416
[INFO: train.py:  341]:   [train] fde: 1.253
[INFO: train.py:  341]:   [train] fde_l: 2.520
[INFO: train.py:  341]:   [train] fde_nl: 2.493
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.473
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.473
[INFO: train.py:  341]:   [train] resist_count: 2399.000
[INFO: train.py:  341]:   [train] resist_loss: 0.156
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 1.2035], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3602261543273926
[INFO: train.py:  316]: Interation 9050 took 9.498051643371582
[INFO: train.py:  558]: resist loss: tensor([ 8.7045], device='cuda:0')
[INFO: train.py:  310]: g step took 2.01882004737854
[INFO: train.py:  316]: Interation 9051 took 2.0261523723602295
[INFO: train.py:  558]: resist loss: tensor([ 0.1839], device='cuda:0')
[INFO: train.py:  310]: g step took 1.815112829208374
[INFO: train.py:  316]: Interation 9052 took 1.8154377937316895
[INFO: train.py:  558]: resist loss: tensor([ 13.1110], device='cuda:0')
[INFO: train.py:  310]: g step took 2.240666151046753
[INFO: train.py:  316]: Interation 9053 took 2.2409939765930176
[INFO: train.py:  558]: resist loss: tensor([ 1.3534], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0591723918914795
[INFO: train.py:  316]: Interation 9054 took 2.0631766319274902
[INFO: train.py:  558]: resist loss: tensor([ 9.5750], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8539111614227295
[INFO: train.py:  316]: Interation 9055 took 1.8542609214782715
[INFO: train.py:  558]: resist loss: tensor([ 4.0153], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2054154872894287
[INFO: train.py:  316]: Interation 9056 took 2.209341049194336
[INFO: train.py:  558]: resist loss: tensor([ 5.3365], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0005719661712646
[INFO: train.py:  316]: Interation 9057 took 2.0044243335723877
[INFO: train.py:  558]: resist loss: tensor([ 18.2314], device='cuda:0')
[INFO: train.py:  310]: g step took 2.277082920074463
[INFO: train.py:  316]: Interation 9058 took 2.2811574935913086
[INFO: train.py:  558]: resist loss: tensor([ 4.9032], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8768994808197021
[INFO: train.py:  316]: Interation 9059 took 1.8808846473693848
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 514, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 514, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 706, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 706, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 685, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 685, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 497, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 497, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 597, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 597, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 596, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 596, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 472, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 472, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 527, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 527, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 522, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 522, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 510, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 510, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 605, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 605, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 130, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 130, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 811, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 811, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 911, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 911, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 925, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 925, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 964, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 964, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 851, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 851, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 638, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 638, 2])
[INFO: train.py:  338]:   [val] ade: 0.597
[INFO: train.py:  338]:   [val] ade_l: 1.315
[INFO: train.py:  338]:   [val] ade_nl: 1.094
[INFO: train.py:  338]:   [val] d_loss: 1.414
[INFO: train.py:  338]:   [val] fde: 1.221
[INFO: train.py:  338]:   [val] fde_l: 2.689
[INFO: train.py:  338]:   [val] fde_nl: 2.237
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.434
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.434
[INFO: train.py:  338]:   [val] resist_count: 2958.000
[INFO: train.py:  338]:   [val] resist_loss: 0.291
[INFO: train.py:  341]:   [train] ade: 0.606
[INFO: train.py:  341]:   [train] ade_l: 1.240
[INFO: train.py:  341]:   [train] ade_nl: 1.186
[INFO: train.py:  341]:   [train] d_loss: 1.406
[INFO: train.py:  341]:   [train] fde: 1.149
[INFO: train.py:  341]:   [train] fde_l: 2.352
[INFO: train.py:  341]:   [train] fde_nl: 2.249
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.386
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.386
[INFO: train.py:  341]:   [train] resist_count: 3208.000
[INFO: train.py:  341]:   [train] resist_loss: 0.171
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 5.8730], device='cuda:0')
[INFO: train.py:  310]: g step took 1.940096378326416
[INFO: train.py:  316]: Interation 9060 took 10.252113580703735
[INFO: train.py:  558]: resist loss: tensor([ 3.2555], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0866808891296387
[INFO: train.py:  316]: Interation 9061 took 2.090273857116699
[INFO: train.py:  558]: resist loss: tensor([ 1.5242], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1590521335601807
[INFO: train.py:  316]: Interation 9062 took 2.162672996520996
[INFO: train.py:  558]: resist loss: tensor([ 0.5916], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8642761707305908
[INFO: train.py:  316]: Interation 9063 took 1.8682606220245361
[INFO: train.py:  558]: resist loss: tensor([ 1.5119], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9678189754486084
[INFO: train.py:  316]: Interation 9064 took 1.971703290939331
[INFO: train.py:  558]: resist loss: tensor([ 2.7672], device='cuda:0')
[INFO: train.py:  310]: g step took 1.769413709640503
[INFO: train.py:  316]: Interation 9065 took 1.7734389305114746
[INFO: train.py:  558]: resist loss: tensor([ 4.3498], device='cuda:0')
[INFO: train.py:  310]: g step took 2.31354022026062
[INFO: train.py:  316]: Interation 9066 took 2.3175156116485596
[INFO: train.py:  558]: resist loss: tensor([ 3.2463], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8354754447937012
[INFO: train.py:  316]: Interation 9067 took 1.8391227722167969
[INFO: train.py:  558]: resist loss: tensor([ 2.8300], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7517991065979004
[INFO: train.py:  316]: Interation 9068 took 1.7556211948394775
[INFO: train.py:  558]: resist loss: tensor([ 15.9509], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2537009716033936
[INFO: train.py:  316]: Interation 9069 took 2.2573397159576416
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 629, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 629, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 584, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 584, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 540, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 540, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 533, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 533, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 432, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 432, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 663, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 663, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 482, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 482, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 575, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 575, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 649, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 649, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 575, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 575, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 609, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 609, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 90, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 90, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 664, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 664, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 797, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 797, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 1038, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 1038, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 570, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 570, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 694, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 694, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 882, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 882, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 908, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 908, 2])
[INFO: train.py:  338]:   [val] ade: 0.594
[INFO: train.py:  338]:   [val] ade_l: 1.307
[INFO: train.py:  338]:   [val] ade_nl: 1.088
[INFO: train.py:  338]:   [val] d_loss: 1.414
[INFO: train.py:  338]:   [val] fde: 1.234
[INFO: train.py:  338]:   [val] fde_l: 2.717
[INFO: train.py:  338]:   [val] fde_nl: 2.261
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.424
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.424
[INFO: train.py:  338]:   [val] resist_count: 3310.000
[INFO: train.py:  338]:   [val] resist_loss: 0.335
[INFO: train.py:  341]:   [train] ade: 0.612
[INFO: train.py:  341]:   [train] ade_l: 1.284
[INFO: train.py:  341]:   [train] ade_nl: 1.170
[INFO: train.py:  341]:   [train] d_loss: 1.402
[INFO: train.py:  341]:   [train] fde: 1.192
[INFO: train.py:  341]:   [train] fde_l: 2.501
[INFO: train.py:  341]:   [train] fde_nl: 2.278
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.395
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.395
[INFO: train.py:  341]:   [train] resist_count: 3135.000
[INFO: train.py:  341]:   [train] resist_loss: 0.182
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 10.5150], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1749441623687744
[INFO: train.py:  316]: Interation 9070 took 10.45045781135559
[INFO: train.py:  558]: resist loss: tensor([ 0.6072], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8172869682312012
[INFO: train.py:  316]: Interation 9071 took 1.821035623550415
[INFO: train.py:  558]: resist loss: tensor([ 11.1490], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9009883403778076
[INFO: train.py:  316]: Interation 9072 took 1.904848575592041
[INFO: train.py:  558]: resist loss: tensor([ 7.2566], device='cuda:0')
[INFO: train.py:  310]: g step took 2.062199115753174
[INFO: train.py:  316]: Interation 9073 took 2.066129207611084
[INFO: train.py:  558]: resist loss: tensor([ 11.4288], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2891008853912354
[INFO: train.py:  316]: Interation 9074 took 2.293052911758423
[INFO: train.py:  558]: resist loss: tensor([ 6.9631], device='cuda:0')
[INFO: train.py:  310]: g step took 1.974527359008789
[INFO: train.py:  316]: Interation 9075 took 1.9787940979003906
[INFO: train.py:  558]: resist loss: tensor([ 6.9598], device='cuda:0')
[INFO: train.py:  310]: g step took 2.5476369857788086
[INFO: train.py:  316]: Interation 9076 took 2.55153751373291
[INFO: train.py:  558]: resist loss: tensor([ 15.6510], device='cuda:0')
[INFO: train.py:  310]: g step took 2.248375177383423
[INFO: train.py:  316]: Interation 9077 took 2.2524571418762207
[INFO: train.py:  558]: resist loss: tensor([ 0.3541], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7977054119110107
[INFO: train.py:  316]: Interation 9078 took 1.802065134048462
[INFO: train.py:  558]: resist loss: tensor([ 1.4862], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0049378871917725
[INFO: train.py:  316]: Interation 9079 took 2.008925437927246
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 594, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 594, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 565, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 565, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 605, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 605, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 630, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 630, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 573, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 573, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 621, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 621, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 557, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 557, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 478, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 478, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 549, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 549, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 560, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 560, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 514, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 514, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 115, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 115, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 755, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 755, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 570, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 570, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 753, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 753, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 714, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 714, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 836, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 836, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 615, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 615, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 744, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 744, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 822, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 822, 2])
[INFO: train.py:  338]:   [val] ade: 0.611
[INFO: train.py:  338]:   [val] ade_l: 1.346
[INFO: train.py:  338]:   [val] ade_nl: 1.120
[INFO: train.py:  338]:   [val] d_loss: 1.404
[INFO: train.py:  338]:   [val] fde: 1.326
[INFO: train.py:  338]:   [val] fde_l: 2.919
[INFO: train.py:  338]:   [val] fde_nl: 2.429
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.478
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.478
[INFO: train.py:  338]:   [val] resist_count: 2866.000
[INFO: train.py:  338]:   [val] resist_loss: 0.273
[INFO: train.py:  341]:   [train] ade: 0.599
[INFO: train.py:  341]:   [train] ade_l: 1.254
[INFO: train.py:  341]:   [train] ade_nl: 1.146
[INFO: train.py:  341]:   [train] d_loss: 1.392
[INFO: train.py:  341]:   [train] fde: 1.237
[INFO: train.py:  341]:   [train] fde_l: 2.590
[INFO: train.py:  341]:   [train] fde_nl: 2.367
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.405
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.405
[INFO: train.py:  341]:   [train] resist_count: 2736.000
[INFO: train.py:  341]:   [train] resist_loss: 0.175
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 3.1989], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0480797290802
[INFO: train.py:  316]: Interation 9080 took 10.74093222618103
[INFO: train.py:  558]: resist loss: tensor([ 0.2808], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1437971591949463
[INFO: train.py:  316]: Interation 9081 took 2.147732973098755
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 2.3332], device='cuda:0')
[INFO: train.py:  310]: g step took 0.13217902183532715
[INFO: train.py:  316]: Interation 9082 took 0.13599252700805664
[INFO: train.py:  279]: Starting epoch 213
[INFO: train.py:  280]: Epoch resist loss: tensor([ 240.7530])
[INFO: train.py:  558]: resist loss: tensor([ 1.4245], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1392877101898193
[INFO: train.py:  316]: Interation 9083 took 2.5123775005340576
[INFO: train.py:  558]: resist loss: tensor([ 0.4186], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8594472408294678
[INFO: train.py:  316]: Interation 9084 took 1.8598735332489014
[INFO: train.py:  558]: resist loss: tensor([ 4.8064], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9239611625671387
[INFO: train.py:  316]: Interation 9085 took 1.9386906623840332
[INFO: train.py:  558]: resist loss: tensor([ 1.8359], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9146509170532227
[INFO: train.py:  316]: Interation 9086 took 1.9298508167266846
[INFO: train.py:  558]: resist loss: tensor([ 1.7722], device='cuda:0')
[INFO: train.py:  310]: g step took 1.723430871963501
[INFO: train.py:  316]: Interation 9087 took 1.7237739562988281
[INFO: train.py:  558]: resist loss: tensor([ 0.3600], device='cuda:0')
[INFO: train.py:  310]: g step took 1.786367654800415
[INFO: train.py:  316]: Interation 9088 took 1.7867228984832764
[INFO: train.py:  558]: resist loss: tensor([ 1.2009], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8677892684936523
[INFO: train.py:  316]: Interation 9089 took 1.8720653057098389
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 584, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 584, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 594, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 594, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 483, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 483, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 648, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 648, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 710, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 710, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 546, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 546, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 543, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 543, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 482, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 482, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 527, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 527, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 583, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 583, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 515, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 515, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 146, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 146, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 756, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 756, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 682, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 682, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 671, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 671, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 936, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 936, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 977, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 977, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 1081, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 1081, 2])
[INFO: train.py:  338]:   [val] ade: 0.675
[INFO: train.py:  338]:   [val] ade_l: 1.485
[INFO: train.py:  338]:   [val] ade_nl: 1.236
[INFO: train.py:  338]:   [val] d_loss: 1.415
[INFO: train.py:  338]:   [val] fde: 1.461
[INFO: train.py:  338]:   [val] fde_l: 3.216
[INFO: train.py:  338]:   [val] fde_nl: 2.676
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.550
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.550
[INFO: train.py:  338]:   [val] resist_count: 3374.000
[INFO: train.py:  338]:   [val] resist_loss: 0.325
[INFO: train.py:  341]:   [train] ade: 0.665
[INFO: train.py:  341]:   [train] ade_l: 1.433
[INFO: train.py:  341]:   [train] ade_nl: 1.241
[INFO: train.py:  341]:   [train] d_loss: 1.393
[INFO: train.py:  341]:   [train] fde: 1.364
[INFO: train.py:  341]:   [train] fde_l: 2.940
[INFO: train.py:  341]:   [train] fde_nl: 2.546
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.474
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.474
[INFO: train.py:  341]:   [train] resist_count: 2993.000
[INFO: train.py:  341]:   [train] resist_loss: 0.178
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 15.4627], device='cuda:0')
[INFO: train.py:  310]: g step took 2.181658983230591
[INFO: train.py:  316]: Interation 9090 took 10.467370748519897
[INFO: train.py:  558]: resist loss: tensor([ 11.2012], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4476802349090576
[INFO: train.py:  316]: Interation 9091 took 2.4481499195098877
[INFO: train.py:  558]: resist loss: tensor([ 3.1070], device='cuda:0')
[INFO: train.py:  310]: g step took 1.947890043258667
[INFO: train.py:  316]: Interation 9092 took 1.9484162330627441
[INFO: train.py:  558]: resist loss: tensor([ 11.9967], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1746225357055664
[INFO: train.py:  316]: Interation 9093 took 2.182533025741577
[INFO: train.py:  558]: resist loss: tensor([ 0.5476], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1029648780822754
[INFO: train.py:  316]: Interation 9094 took 2.1070799827575684
[INFO: train.py:  558]: resist loss: tensor([ 8.6207], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2205309867858887
[INFO: train.py:  316]: Interation 9095 took 2.220834255218506
[INFO: train.py:  558]: resist loss: tensor([ 1.8704], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9663007259368896
[INFO: train.py:  316]: Interation 9096 took 1.966641902923584
[INFO: train.py:  558]: resist loss: tensor([ 6.7912], device='cuda:0')
[INFO: train.py:  310]: g step took 2.138000726699829
[INFO: train.py:  316]: Interation 9097 took 2.142211675643921
[INFO: train.py:  558]: resist loss: tensor([ 5.7055], device='cuda:0')
[INFO: train.py:  310]: g step took 1.527688980102539
[INFO: train.py:  316]: Interation 9098 took 1.5280861854553223
[INFO: train.py:  558]: resist loss: tensor([ 2.7711], device='cuda:0')
[INFO: train.py:  310]: g step took 2.235626220703125
[INFO: train.py:  316]: Interation 9099 took 2.2395873069763184
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 533, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 533, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 607, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 607, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 619, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 619, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 595, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 595, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 587, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 587, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 608, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 608, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 425, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 425, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 596, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 596, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 578, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 578, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 526, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 526, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 519, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 519, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 168, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 168, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 857, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 857, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 736, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 736, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 712, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 712, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 829, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 829, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 731, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 731, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 839, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 839, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 669, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 669, 2])
[INFO: train.py:  338]:   [val] ade: 0.638
[INFO: train.py:  338]:   [val] ade_l: 1.404
[INFO: train.py:  338]:   [val] ade_nl: 1.169
[INFO: train.py:  338]:   [val] d_loss: 1.403
[INFO: train.py:  338]:   [val] fde: 1.153
[INFO: train.py:  338]:   [val] fde_l: 2.539
[INFO: train.py:  338]:   [val] fde_nl: 2.112
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.451
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.451
[INFO: train.py:  338]:   [val] resist_count: 3107.000
[INFO: train.py:  338]:   [val] resist_loss: 0.333
[INFO: train.py:  341]:   [train] ade: 0.645
[INFO: train.py:  341]:   [train] ade_l: 1.340
[INFO: train.py:  341]:   [train] ade_nl: 1.243
[INFO: train.py:  341]:   [train] d_loss: 1.406
[INFO: train.py:  341]:   [train] fde: 1.082
[INFO: train.py:  341]:   [train] fde_l: 2.247
[INFO: train.py:  341]:   [train] fde_nl: 2.085
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.400
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.400
[INFO: train.py:  341]:   [train] resist_count: 3171.000
[INFO: train.py:  341]:   [train] resist_loss: 0.185
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 8.4987], device='cuda:0')
[INFO: train.py:  310]: g step took 2.229551315307617
[INFO: train.py:  316]: Interation 9100 took 10.792150259017944
[INFO: train.py:  558]: resist loss: tensor([ 16.8505], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2591300010681152
[INFO: train.py:  316]: Interation 9101 took 2.262773036956787
[INFO: train.py:  558]: resist loss: tensor([ 4.4073], device='cuda:0')
[INFO: train.py:  310]: g step took 2.136540412902832
[INFO: train.py:  316]: Interation 9102 took 2.140536069869995
[INFO: train.py:  558]: resist loss: tensor([ 0.2830], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8963699340820312
[INFO: train.py:  316]: Interation 9103 took 1.900219202041626
[INFO: train.py:  558]: resist loss: tensor([ 0.9752], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7474963665008545
[INFO: train.py:  316]: Interation 9104 took 1.7513959407806396
[INFO: train.py:  558]: resist loss: tensor([ 0.1672], device='cuda:0')
[INFO: train.py:  310]: g step took 1.568765640258789
[INFO: train.py:  316]: Interation 9105 took 1.5724239349365234
[INFO: train.py:  558]: resist loss: tensor([ 8.9136], device='cuda:0')
[INFO: train.py:  310]: g step took 1.822098731994629
[INFO: train.py:  316]: Interation 9106 took 1.8260314464569092
[INFO: train.py:  558]: resist loss: tensor([ 1.5164], device='cuda:0')
[INFO: train.py:  310]: g step took 1.796156406402588
[INFO: train.py:  316]: Interation 9107 took 1.8001418113708496
[INFO: train.py:  558]: resist loss: tensor([ 1.4404], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8417658805847168
[INFO: train.py:  316]: Interation 9108 took 1.8458433151245117
[INFO: train.py:  558]: resist loss: tensor([ 16.5457], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9263861179351807
[INFO: train.py:  316]: Interation 9109 took 1.930100440979004
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 512, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 512, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 613, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 613, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 527, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 527, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 615, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 615, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 596, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 596, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 509, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 509, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 565, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 565, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 676, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 676, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 511, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 511, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 495, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 495, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 600, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 600, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 142, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 142, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 835, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 835, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 911, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 911, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 838, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 838, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 830, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 830, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 586, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 586, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 649, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 649, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 734, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 734, 2])
[INFO: train.py:  338]:   [val] ade: 0.650
[INFO: train.py:  338]:   [val] ade_l: 1.431
[INFO: train.py:  338]:   [val] ade_nl: 1.190
[INFO: train.py:  338]:   [val] d_loss: 1.394
[INFO: train.py:  338]:   [val] fde: 1.380
[INFO: train.py:  338]:   [val] fde_l: 3.039
[INFO: train.py:  338]:   [val] fde_nl: 2.529
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.491
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.491
[INFO: train.py:  338]:   [val] resist_count: 3261.000
[INFO: train.py:  338]:   [val] resist_loss: 0.328
[INFO: train.py:  341]:   [train] ade: 0.640
[INFO: train.py:  341]:   [train] ade_l: 1.327
[INFO: train.py:  341]:   [train] ade_nl: 1.237
[INFO: train.py:  341]:   [train] d_loss: 1.402
[INFO: train.py:  341]:   [train] fde: 1.286
[INFO: train.py:  341]:   [train] fde_l: 2.665
[INFO: train.py:  341]:   [train] fde_nl: 2.485
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.423
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.423
[INFO: train.py:  341]:   [train] resist_count: 3068.000
[INFO: train.py:  341]:   [train] resist_loss: 0.173
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 4.5066], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9036743640899658
[INFO: train.py:  316]: Interation 9110 took 10.745986938476562
[INFO: train.py:  558]: resist loss: tensor([ 1.4793], device='cuda:0')
[INFO: train.py:  310]: g step took 1.883127212524414
[INFO: train.py:  316]: Interation 9111 took 1.8869249820709229
[INFO: train.py:  558]: resist loss: tensor([ 0.6207], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7110285758972168
[INFO: train.py:  316]: Interation 9112 took 1.7148869037628174
[INFO: train.py:  558]: resist loss: tensor([ 1.4224], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9910426139831543
[INFO: train.py:  316]: Interation 9113 took 1.9944920539855957
[INFO: train.py:  558]: resist loss: tensor([ 2.9315], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8017220497131348
[INFO: train.py:  316]: Interation 9114 took 1.8055484294891357
[INFO: train.py:  558]: resist loss: tensor([ 1.3670], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9415092468261719
[INFO: train.py:  316]: Interation 9115 took 1.9453694820404053
[INFO: train.py:  558]: resist loss: tensor([ 10.1364], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0250673294067383
[INFO: train.py:  316]: Interation 9116 took 2.028705358505249
[INFO: train.py:  558]: resist loss: tensor([ 0.9321], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9497904777526855
[INFO: train.py:  316]: Interation 9117 took 1.9533734321594238
[INFO: train.py:  558]: resist loss: tensor([ 2.6291], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6477634906768799
[INFO: train.py:  316]: Interation 9118 took 1.6515681743621826
[INFO: train.py:  558]: resist loss: tensor([ 9.1569], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9179613590240479
[INFO: train.py:  316]: Interation 9119 took 1.9220819473266602
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 574, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 574, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 458, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 458, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 604, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 604, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 607, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 607, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 587, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 587, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 575, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 575, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 607, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 607, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 537, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 537, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 611, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 611, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 506, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 506, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 502, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 502, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 193, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 193, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 639, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 639, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 678, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 678, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 642, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 642, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 850, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 850, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 753, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 753, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 815, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 815, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 1005, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 1005, 2])
[INFO: train.py:  338]:   [val] ade: 0.625
[INFO: train.py:  338]:   [val] ade_l: 1.376
[INFO: train.py:  338]:   [val] ade_nl: 1.145
[INFO: train.py:  338]:   [val] d_loss: 1.402
[INFO: train.py:  338]:   [val] fde: 1.265
[INFO: train.py:  338]:   [val] fde_l: 2.785
[INFO: train.py:  338]:   [val] fde_nl: 2.318
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.462
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.462
[INFO: train.py:  338]:   [val] resist_count: 2658.000
[INFO: train.py:  338]:   [val] resist_loss: 0.238
[INFO: train.py:  341]:   [train] ade: 0.625
[INFO: train.py:  341]:   [train] ade_l: 1.313
[INFO: train.py:  341]:   [train] ade_nl: 1.193
[INFO: train.py:  341]:   [train] d_loss: 1.404
[INFO: train.py:  341]:   [train] fde: 1.197
[INFO: train.py:  341]:   [train] fde_l: 2.514
[INFO: train.py:  341]:   [train] fde_nl: 2.284
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.418
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.418
[INFO: train.py:  341]:   [train] resist_count: 2786.000
[INFO: train.py:  341]:   [train] resist_loss: 0.158
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 15.4352], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9666924476623535
[INFO: train.py:  316]: Interation 9120 took 10.752068519592285
[INFO: train.py:  558]: resist loss: tensor([ 0.1259], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6672687530517578
[INFO: train.py:  316]: Interation 9121 took 1.6708624362945557
[INFO: train.py:  558]: resist loss: tensor([ 0.7827], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0000829696655273
[INFO: train.py:  316]: Interation 9122 took 2.0038743019104004
[INFO: train.py:  558]: resist loss: tensor([ 1.5925], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9323160648345947
[INFO: train.py:  316]: Interation 9123 took 1.9360122680664062
[INFO: train.py:  558]: resist loss: tensor([ 9.8500], device='cuda:0')
[INFO: train.py:  310]: g step took 2.081064462661743
[INFO: train.py:  316]: Interation 9124 took 2.084658145904541
[INFO: train.py:  558]: resist loss: tensor([ 0.3431], device='cuda:0')
[INFO: train.py:  310]: g step took 0.25164198875427246
[INFO: train.py:  316]: Interation 9125 took 0.2552788257598877
[INFO: train.py:  279]: Starting epoch 214
[INFO: train.py:  280]: Epoch resist loss: tensor([ 202.8018])
[INFO: train.py:  558]: resist loss: tensor([ 11.6210], device='cuda:0')
[INFO: train.py:  310]: g step took 2.01778507232666
[INFO: train.py:  316]: Interation 9126 took 2.3786227703094482
[INFO: train.py:  558]: resist loss: tensor([ 13.4963], device='cuda:0')
[INFO: train.py:  310]: g step took 2.127460241317749
[INFO: train.py:  316]: Interation 9127 took 2.1441054344177246
[INFO: train.py:  558]: resist loss: tensor([ 0.1063], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8580129146575928
[INFO: train.py:  316]: Interation 9128 took 1.8586246967315674
[INFO: train.py:  558]: resist loss: tensor([ 1.8918], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2742366790771484
[INFO: train.py:  316]: Interation 9129 took 2.274533748626709
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 447, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 447, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 637, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 637, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 559, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 559, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 537, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 537, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 608, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 608, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 511, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 511, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 589, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 589, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 606, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 606, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 528, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 528, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 631, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 631, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 536, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 536, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 172, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 172, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 779, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 779, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 926, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 926, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 875, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 875, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 885, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 885, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 737, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 737, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 972, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 972, 2])
[INFO: train.py:  338]:   [val] ade: 0.610
[INFO: train.py:  338]:   [val] ade_l: 1.344
[INFO: train.py:  338]:   [val] ade_nl: 1.118
[INFO: train.py:  338]:   [val] d_loss: 1.406
[INFO: train.py:  338]:   [val] fde: 1.263
[INFO: train.py:  338]:   [val] fde_l: 2.780
[INFO: train.py:  338]:   [val] fde_nl: 2.313
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.443
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.443
[INFO: train.py:  338]:   [val] resist_count: 2790.000
[INFO: train.py:  338]:   [val] resist_loss: 0.274
[INFO: train.py:  341]:   [train] ade: 0.617
[INFO: train.py:  341]:   [train] ade_l: 1.299
[INFO: train.py:  341]:   [train] ade_nl: 1.176
[INFO: train.py:  341]:   [train] d_loss: 1.409
[INFO: train.py:  341]:   [train] fde: 1.187
[INFO: train.py:  341]:   [train] fde_l: 2.497
[INFO: train.py:  341]:   [train] fde_nl: 2.262
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.391
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.391
[INFO: train.py:  341]:   [train] resist_count: 2638.000
[INFO: train.py:  341]:   [train] resist_loss: 0.142
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 11.0830], device='cuda:0')
[INFO: train.py:  310]: g step took 2.115842580795288
[INFO: train.py:  316]: Interation 9130 took 10.759811878204346
[INFO: train.py:  558]: resist loss: tensor([ 2.6702], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1292941570281982
[INFO: train.py:  316]: Interation 9131 took 2.129685401916504
[INFO: train.py:  558]: resist loss: tensor([ 13.8526], device='cuda:0')
[INFO: train.py:  310]: g step took 2.105120897293091
[INFO: train.py:  316]: Interation 9132 took 2.109272003173828
[INFO: train.py:  558]: resist loss: tensor([ 0.8686], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9629950523376465
[INFO: train.py:  316]: Interation 9133 took 1.9634084701538086
[INFO: train.py:  558]: resist loss: tensor([ 1.1901], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8828890323638916
[INFO: train.py:  316]: Interation 9134 took 1.8932068347930908
[INFO: train.py:  558]: resist loss: tensor([ 2.0319], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5311434268951416
[INFO: train.py:  316]: Interation 9135 took 1.5415887832641602
[INFO: train.py:  558]: resist loss: tensor([ 8.4076], device='cuda:0')
[INFO: train.py:  310]: g step took 2.16475772857666
[INFO: train.py:  316]: Interation 9136 took 2.165178060531616
[INFO: train.py:  558]: resist loss: tensor([ 2.2555], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8573505878448486
[INFO: train.py:  316]: Interation 9137 took 1.8652088642120361
[INFO: train.py:  558]: resist loss: tensor([ 1.5912], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0300683975219727
[INFO: train.py:  316]: Interation 9138 took 2.0304417610168457
[INFO: train.py:  558]: resist loss: tensor([ 1.1387], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6127269268035889
[INFO: train.py:  316]: Interation 9139 took 1.613070011138916
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 544, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 544, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 506, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 506, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 565, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 565, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 475, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 475, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 446, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 446, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 651, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 651, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 599, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 599, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 570, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 570, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 669, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 669, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 589, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 589, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 606, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 606, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 141, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 141, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 689, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 689, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 721, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 721, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 800, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 800, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 680, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 680, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 812, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 812, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 901, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 901, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 793, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 793, 2])
[INFO: train.py:  338]:   [val] ade: 0.591
[INFO: train.py:  338]:   [val] ade_l: 1.302
[INFO: train.py:  338]:   [val] ade_nl: 1.083
[INFO: train.py:  338]:   [val] d_loss: 1.415
[INFO: train.py:  338]:   [val] fde: 1.218
[INFO: train.py:  338]:   [val] fde_l: 2.681
[INFO: train.py:  338]:   [val] fde_nl: 2.231
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.434
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.434
[INFO: train.py:  338]:   [val] resist_count: 2979.000
[INFO: train.py:  338]:   [val] resist_loss: 0.313
[INFO: train.py:  341]:   [train] ade: 0.582
[INFO: train.py:  341]:   [train] ade_l: 1.225
[INFO: train.py:  341]:   [train] ade_nl: 1.108
[INFO: train.py:  341]:   [train] d_loss: 1.408
[INFO: train.py:  341]:   [train] fde: 1.143
[INFO: train.py:  341]:   [train] fde_l: 2.407
[INFO: train.py:  341]:   [train] fde_nl: 2.178
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.372
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.372
[INFO: train.py:  341]:   [train] resist_count: 2557.000
[INFO: train.py:  341]:   [train] resist_loss: 0.153
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 1.8949], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8285109996795654
[INFO: train.py:  316]: Interation 9140 took 10.684953927993774
[INFO: train.py:  558]: resist loss: tensor([ 9.1274], device='cuda:0')
[INFO: train.py:  310]: g step took 1.963796615600586
[INFO: train.py:  316]: Interation 9141 took 1.9641549587249756
[INFO: train.py:  558]: resist loss: tensor([ 4.0489], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4843244552612305
[INFO: train.py:  316]: Interation 9142 took 1.4883701801300049
[INFO: train.py:  558]: resist loss: tensor([ 2.2127], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9170329570770264
[INFO: train.py:  316]: Interation 9143 took 1.9208056926727295
[INFO: train.py:  558]: resist loss: tensor([ 15.4301], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8793423175811768
[INFO: train.py:  316]: Interation 9144 took 1.8824758529663086
[INFO: train.py:  558]: resist loss: tensor([ 8.8979], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8659687042236328
[INFO: train.py:  316]: Interation 9145 took 1.869969129562378
[INFO: train.py:  558]: resist loss: tensor([ 5.4296], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9016387462615967
[INFO: train.py:  316]: Interation 9146 took 1.905583381652832
[INFO: train.py:  558]: resist loss: tensor([ 2.5973], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8157191276550293
[INFO: train.py:  316]: Interation 9147 took 1.819587230682373
[INFO: train.py:  558]: resist loss: tensor([ 1.7744], device='cuda:0')
[INFO: train.py:  310]: g step took 1.774165391921997
[INFO: train.py:  316]: Interation 9148 took 1.7783775329589844
[INFO: train.py:  558]: resist loss: tensor([ 8.4179], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9973080158233643
[INFO: train.py:  316]: Interation 9149 took 2.0007684230804443
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 596, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 596, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 512, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 512, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 484, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 484, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 572, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 572, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 558, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 558, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 556, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 556, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 704, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 704, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 454, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 454, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 614, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 614, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 602, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 602, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 586, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 586, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 123, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 123, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 762, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 762, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 660, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 660, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 884, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 884, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 983, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 983, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 751, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 751, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 694, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 694, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 737, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 737, 2])
[INFO: train.py:  338]:   [val] ade: 0.617
[INFO: train.py:  338]:   [val] ade_l: 1.359
[INFO: train.py:  338]:   [val] ade_nl: 1.131
[INFO: train.py:  338]:   [val] d_loss: 1.411
[INFO: train.py:  338]:   [val] fde: 1.262
[INFO: train.py:  338]:   [val] fde_l: 2.779
[INFO: train.py:  338]:   [val] fde_nl: 2.312
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.444
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.444
[INFO: train.py:  338]:   [val] resist_count: 3107.000
[INFO: train.py:  338]:   [val] resist_loss: 0.317
[INFO: train.py:  341]:   [train] ade: 0.610
[INFO: train.py:  341]:   [train] ade_l: 1.260
[INFO: train.py:  341]:   [train] ade_nl: 1.182
[INFO: train.py:  341]:   [train] d_loss: 1.408
[INFO: train.py:  341]:   [train] fde: 1.176
[INFO: train.py:  341]:   [train] fde_l: 2.428
[INFO: train.py:  341]:   [train] fde_nl: 2.279
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.383
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.383
[INFO: train.py:  341]:   [train] resist_count: 3133.000
[INFO: train.py:  341]:   [train] resist_loss: 0.181
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 11.6265], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7969040870666504
[INFO: train.py:  316]: Interation 9150 took 10.687575817108154
[INFO: train.py:  558]: resist loss: tensor([ 8.2566], device='cuda:0')
[INFO: train.py:  310]: g step took 2.112731695175171
[INFO: train.py:  316]: Interation 9151 took 2.116490602493286
[INFO: train.py:  558]: resist loss: tensor([ 0.5979], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9534032344818115
[INFO: train.py:  316]: Interation 9152 took 1.9567043781280518
[INFO: train.py:  558]: resist loss: tensor([ 2.8239], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3546273708343506
[INFO: train.py:  316]: Interation 9153 took 2.3584728240966797
[INFO: train.py:  558]: resist loss: tensor([ 4.9210], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1306583881378174
[INFO: train.py:  316]: Interation 9154 took 2.1345129013061523
[INFO: train.py:  558]: resist loss: tensor([ 9.0748], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8426928520202637
[INFO: train.py:  316]: Interation 9155 took 1.8469281196594238
[INFO: train.py:  558]: resist loss: tensor([ 0.8434], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7300491333007812
[INFO: train.py:  316]: Interation 9156 took 1.7338886260986328
[INFO: train.py:  558]: resist loss: tensor([ 4.0565], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7856440544128418
[INFO: train.py:  316]: Interation 9157 took 1.7894518375396729
[INFO: train.py:  558]: resist loss: tensor([ 1.4238], device='cuda:0')
[INFO: train.py:  310]: g step took 2.106090545654297
[INFO: train.py:  316]: Interation 9158 took 2.1104180812835693
[INFO: train.py:  558]: resist loss: tensor([ 12.8622], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2259316444396973
[INFO: train.py:  316]: Interation 9159 took 2.2297940254211426
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 476, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 476, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 560, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 560, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 504, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 504, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 601, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 601, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 654, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 654, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 563, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 563, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 495, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 495, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 542, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 542, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 599, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 599, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 546, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 546, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 593, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 593, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 228, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 228, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 597, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 597, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 686, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 686, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 626, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 626, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 1011, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 1011, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 648, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 648, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 737, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 737, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 810, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 810, 2])
[INFO: train.py:  338]:   [val] ade: 0.647
[INFO: train.py:  338]:   [val] ade_l: 1.424
[INFO: train.py:  338]:   [val] ade_nl: 1.185
[INFO: train.py:  338]:   [val] d_loss: 1.404
[INFO: train.py:  338]:   [val] fde: 1.311
[INFO: train.py:  338]:   [val] fde_l: 2.886
[INFO: train.py:  338]:   [val] fde_nl: 2.402
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.472
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.472
[INFO: train.py:  338]:   [val] resist_count: 2917.000
[INFO: train.py:  338]:   [val] resist_loss: 0.345
[INFO: train.py:  341]:   [train] ade: 0.643
[INFO: train.py:  341]:   [train] ade_l: 1.335
[INFO: train.py:  341]:   [train] ade_nl: 1.240
[INFO: train.py:  341]:   [train] d_loss: 1.412
[INFO: train.py:  341]:   [train] fde: 1.220
[INFO: train.py:  341]:   [train] fde_l: 2.534
[INFO: train.py:  341]:   [train] fde_nl: 2.353
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.416
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.416
[INFO: train.py:  341]:   [train] resist_count: 2773.000
[INFO: train.py:  341]:   [train] resist_loss: 0.190
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.0203], device='cuda:0')
[INFO: train.py:  310]: g step took 2.302088499069214
[INFO: train.py:  316]: Interation 9160 took 11.089764833450317
[INFO: train.py:  558]: resist loss: tensor([ 1.7810], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9989688396453857
[INFO: train.py:  316]: Interation 9161 took 2.0031189918518066
[INFO: train.py:  558]: resist loss: tensor([ 0.5223], device='cuda:0')
[INFO: train.py:  310]: g step took 1.916050910949707
[INFO: train.py:  316]: Interation 9162 took 1.9198017120361328
[INFO: train.py:  558]: resist loss: tensor([ 0.8665], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0140340328216553
[INFO: train.py:  316]: Interation 9163 took 2.017976999282837
[INFO: train.py:  558]: resist loss: tensor([ 4.2028], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6237716674804688
[INFO: train.py:  316]: Interation 9164 took 1.628028392791748
[INFO: train.py:  558]: resist loss: tensor([ 2.6251], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1879169940948486
[INFO: train.py:  316]: Interation 9165 took 2.191763162612915
[INFO: train.py:  558]: resist loss: tensor([ 6.4015], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6979255676269531
[INFO: train.py:  316]: Interation 9166 took 1.7017736434936523
[INFO: train.py:  558]: resist loss: tensor([ 1.3304], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6425104141235352
[INFO: train.py:  316]: Interation 9167 took 1.6460583209991455
[INFO: train.py:  558]: resist loss: tensor([ 0.1601], device='cuda:0')
[INFO: train.py:  310]: g step took 0.12554144859313965
[INFO: train.py:  316]: Interation 9168 took 0.1287229061126709
[INFO: train.py:  279]: Starting epoch 215
[INFO: train.py:  280]: Epoch resist loss: tensor([ 208.4326])
[INFO: train.py:  558]: resist loss: tensor([ 14.2983], device='cuda:0')
[INFO: train.py:  310]: g step took 2.215951442718506
[INFO: train.py:  316]: Interation 9169 took 2.604125499725342
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 600, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 600, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 600, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 600, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 446, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 446, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 535, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 535, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 629, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 629, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 568, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 568, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 535, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 535, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 702, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 702, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 531, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 531, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 503, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 503, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 548, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 548, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 164, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 164, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 825, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 825, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 780, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 780, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 947, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 947, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 750, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 750, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 705, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 705, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 800, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 800, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 806, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 806, 2])
[INFO: train.py:  338]:   [val] ade: 0.665
[INFO: train.py:  338]:   [val] ade_l: 1.463
[INFO: train.py:  338]:   [val] ade_nl: 1.217
[INFO: train.py:  338]:   [val] d_loss: 1.399
[INFO: train.py:  338]:   [val] fde: 1.248
[INFO: train.py:  338]:   [val] fde_l: 2.748
[INFO: train.py:  338]:   [val] fde_nl: 2.286
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.464
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.464
[INFO: train.py:  338]:   [val] resist_count: 3147.000
[INFO: train.py:  338]:   [val] resist_loss: 0.414
[INFO: train.py:  341]:   [train] ade: 0.667
[INFO: train.py:  341]:   [train] ade_l: 1.412
[INFO: train.py:  341]:   [train] ade_nl: 1.262
[INFO: train.py:  341]:   [train] d_loss: 1.400
[INFO: train.py:  341]:   [train] fde: 1.180
[INFO: train.py:  341]:   [train] fde_l: 2.500
[INFO: train.py:  341]:   [train] fde_nl: 2.235
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.415
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.415
[INFO: train.py:  341]:   [train] resist_count: 3165.000
[INFO: train.py:  341]:   [train] resist_loss: 0.214
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 10.4757], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8671319484710693
[INFO: train.py:  316]: Interation 9170 took 10.785648107528687
[INFO: train.py:  558]: resist loss: tensor([ 8.8138], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9253807067871094
[INFO: train.py:  316]: Interation 9171 took 1.9295308589935303
[INFO: train.py:  558]: resist loss: tensor([ 1.7629], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9845378398895264
[INFO: train.py:  316]: Interation 9172 took 1.992152214050293
[INFO: train.py:  558]: resist loss: tensor([ 13.6429], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9949865341186523
[INFO: train.py:  316]: Interation 9173 took 1.9953699111938477
[INFO: train.py:  558]: resist loss: tensor([ 0.4099], device='cuda:0')
[INFO: train.py:  310]: g step took 1.855881690979004
[INFO: train.py:  316]: Interation 9174 took 1.856316328048706
[INFO: train.py:  558]: resist loss: tensor([ 1.5948], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9157395362854004
[INFO: train.py:  316]: Interation 9175 took 1.9160873889923096
[INFO: train.py:  558]: resist loss: tensor([ 10.6477], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9784977436065674
[INFO: train.py:  316]: Interation 9176 took 1.9788947105407715
[INFO: train.py:  558]: resist loss: tensor([ 4.5867], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1391921043395996
[INFO: train.py:  316]: Interation 9177 took 2.1395318508148193
[INFO: train.py:  558]: resist loss: tensor([ 8.0904], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8822507858276367
[INFO: train.py:  316]: Interation 9178 took 1.9016940593719482
[INFO: train.py:  558]: resist loss: tensor([ 11.1196], device='cuda:0')
[INFO: train.py:  310]: g step took 2.186628580093384
[INFO: train.py:  316]: Interation 9179 took 2.190561056137085
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 640, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 640, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 661, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 661, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 540, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 540, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 505, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 505, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 661, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 661, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 483, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 483, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 560, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 560, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 628, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 628, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 445, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 445, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 637, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 637, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 485, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 485, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 116, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 116, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 652, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 652, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 828, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 828, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 605, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 605, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 958, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 958, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 664, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 664, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 698, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 698, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 754, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 754, 2])
[INFO: train.py:  338]:   [val] ade: 0.640
[INFO: train.py:  338]:   [val] ade_l: 1.410
[INFO: train.py:  338]:   [val] ade_nl: 1.173
[INFO: train.py:  338]:   [val] d_loss: 1.410
[INFO: train.py:  338]:   [val] fde: 1.324
[INFO: train.py:  338]:   [val] fde_l: 2.914
[INFO: train.py:  338]:   [val] fde_nl: 2.425
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.467
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.467
[INFO: train.py:  338]:   [val] resist_count: 3184.000
[INFO: train.py:  338]:   [val] resist_loss: 0.286
[INFO: train.py:  341]:   [train] ade: 0.633
[INFO: train.py:  341]:   [train] ade_l: 1.300
[INFO: train.py:  341]:   [train] ade_nl: 1.234
[INFO: train.py:  341]:   [train] d_loss: 1.414
[INFO: train.py:  341]:   [train] fde: 1.243
[INFO: train.py:  341]:   [train] fde_l: 2.552
[INFO: train.py:  341]:   [train] fde_nl: 2.422
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.401
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.401
[INFO: train.py:  341]:   [train] resist_count: 2933.000
[INFO: train.py:  341]:   [train] resist_loss: 0.201
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.8401], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6542344093322754
[INFO: train.py:  316]: Interation 9180 took 10.281440734863281
[INFO: train.py:  558]: resist loss: tensor([ 9.9531], device='cuda:0')
[INFO: train.py:  310]: g step took 1.960921049118042
[INFO: train.py:  316]: Interation 9181 took 1.96126389503479
[INFO: train.py:  558]: resist loss: tensor([ 14.3918], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2955384254455566
[INFO: train.py:  316]: Interation 9182 took 2.2959868907928467
[INFO: train.py:  558]: resist loss: tensor([ 7.2450], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9883661270141602
[INFO: train.py:  316]: Interation 9183 took 1.9888827800750732
[INFO: train.py:  558]: resist loss: tensor([ 4.0735], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9640836715698242
[INFO: train.py:  316]: Interation 9184 took 1.9644744396209717
[INFO: train.py:  558]: resist loss: tensor([ 4.5842], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7003142833709717
[INFO: train.py:  316]: Interation 9185 took 1.7043602466583252
[INFO: train.py:  558]: resist loss: tensor([ 8.4872], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8766758441925049
[INFO: train.py:  316]: Interation 9186 took 1.8806297779083252
[INFO: train.py:  558]: resist loss: tensor([ 2.7193], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9102919101715088
[INFO: train.py:  316]: Interation 9187 took 1.914039134979248
[INFO: train.py:  558]: resist loss: tensor([ 4.4455], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8817927837371826
[INFO: train.py:  316]: Interation 9188 took 1.885798692703247
[INFO: train.py:  558]: resist loss: tensor([ 10.3270], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1231377124786377
[INFO: train.py:  316]: Interation 9189 took 2.1270270347595215
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 679, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 679, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 635, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 635, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 597, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 597, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 535, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 535, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 578, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 578, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 517, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 517, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 553, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 553, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 649, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 649, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 548, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 548, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 474, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 474, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 498, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 498, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 98, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 98, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 850, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 850, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 706, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 706, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 868, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 868, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 763, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 763, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 832, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 832, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 807, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 807, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 889, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 889, 2])
[INFO: train.py:  338]:   [val] ade: 0.609
[INFO: train.py:  338]:   [val] ade_l: 1.341
[INFO: train.py:  338]:   [val] ade_nl: 1.116
[INFO: train.py:  338]:   [val] d_loss: 1.412
[INFO: train.py:  338]:   [val] fde: 1.304
[INFO: train.py:  338]:   [val] fde_l: 2.870
[INFO: train.py:  338]:   [val] fde_nl: 2.388
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.452
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.452
[INFO: train.py:  338]:   [val] resist_count: 2765.000
[INFO: train.py:  338]:   [val] resist_loss: 0.256
[INFO: train.py:  341]:   [train] ade: 0.598
[INFO: train.py:  341]:   [train] ade_l: 1.216
[INFO: train.py:  341]:   [train] ade_nl: 1.175
[INFO: train.py:  341]:   [train] d_loss: 1.416
[INFO: train.py:  341]:   [train] fde: 1.196
[INFO: train.py:  341]:   [train] fde_l: 2.433
[INFO: train.py:  341]:   [train] fde_nl: 2.352
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.378
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.378
[INFO: train.py:  341]:   [train] resist_count: 2828.000
[INFO: train.py:  341]:   [train] resist_loss: 0.161
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 12.8515], device='cuda:0')
[INFO: train.py:  310]: g step took 2.251554012298584
[INFO: train.py:  316]: Interation 9190 took 11.057287693023682
[INFO: train.py:  558]: resist loss: tensor([ 1.7076], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1898837089538574
[INFO: train.py:  316]: Interation 9191 took 2.1942129135131836
[INFO: train.py:  558]: resist loss: tensor([ 1.9797], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2093334197998047
[INFO: train.py:  316]: Interation 9192 took 2.213088035583496
[INFO: train.py:  558]: resist loss: tensor([ 1.8377], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9468231201171875
[INFO: train.py:  316]: Interation 9193 took 1.9509503841400146
[INFO: train.py:  558]: resist loss: tensor([ 0.7713], device='cuda:0')
[INFO: train.py:  310]: g step took 2.527048110961914
[INFO: train.py:  316]: Interation 9194 took 2.531022787094116
[INFO: train.py:  558]: resist loss: tensor([ 0.2871], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0321483612060547
[INFO: train.py:  316]: Interation 9195 took 2.0362188816070557
[INFO: train.py:  558]: resist loss: tensor([ 0.8432], device='cuda:0')
[INFO: train.py:  310]: g step took 2.255833864212036
[INFO: train.py:  316]: Interation 9196 took 2.2601242065429688
[INFO: train.py:  558]: resist loss: tensor([ 0.3734], device='cuda:0')
[INFO: train.py:  310]: g step took 2.08504319190979
[INFO: train.py:  316]: Interation 9197 took 2.089087724685669
[INFO: train.py:  558]: resist loss: tensor([ 4.1815], device='cuda:0')
[INFO: train.py:  310]: g step took 2.378330707550049
[INFO: train.py:  316]: Interation 9198 took 2.3822057247161865
[INFO: train.py:  558]: resist loss: tensor([ 2.9426], device='cuda:0')
[INFO: train.py:  310]: g step took 2.639681577682495
[INFO: train.py:  316]: Interation 9199 took 2.6435434818267822
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 640, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 640, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 635, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 635, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 608, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 608, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 522, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 522, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 601, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 601, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 526, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 526, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 603, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 603, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 592, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 592, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 460, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 460, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 518, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 518, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 533, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 533, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 123, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 123, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 771, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 771, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 772, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 772, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 796, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 796, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 853, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 853, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 656, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 656, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 925, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 925, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 928, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 928, 2])
[INFO: train.py:  338]:   [val] ade: 0.604
[INFO: train.py:  338]:   [val] ade_l: 1.331
[INFO: train.py:  338]:   [val] ade_nl: 1.107
[INFO: train.py:  338]:   [val] d_loss: 1.415
[INFO: train.py:  338]:   [val] fde: 1.273
[INFO: train.py:  338]:   [val] fde_l: 2.803
[INFO: train.py:  338]:   [val] fde_nl: 2.333
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.432
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.432
[INFO: train.py:  338]:   [val] resist_count: 2921.000
[INFO: train.py:  338]:   [val] resist_loss: 0.324
[INFO: train.py:  341]:   [train] ade: 0.598
[INFO: train.py:  341]:   [train] ade_l: 1.245
[INFO: train.py:  341]:   [train] ade_nl: 1.151
[INFO: train.py:  341]:   [train] d_loss: 1.408
[INFO: train.py:  341]:   [train] fde: 1.184
[INFO: train.py:  341]:   [train] fde_l: 2.464
[INFO: train.py:  341]:   [train] fde_nl: 2.279
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.367
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.367
[INFO: train.py:  341]:   [train] resist_count: 3215.000
[INFO: train.py:  341]:   [train] resist_loss: 0.200
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 1.8777], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2891664505004883
[INFO: train.py:  316]: Interation 9200 took 12.057562351226807
[INFO: train.py:  558]: resist loss: tensor([ 5.4626], device='cuda:0')
[INFO: train.py:  310]: g step took 2.9064338207244873
[INFO: train.py:  316]: Interation 9201 took 2.9103968143463135
[INFO: train.py:  558]: resist loss: tensor([ 5.4800], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3373665809631348
[INFO: train.py:  316]: Interation 9202 took 2.3412861824035645
[INFO: train.py:  558]: resist loss: tensor([ 0.4822], device='cuda:0')
[INFO: train.py:  310]: g step took 2.7429604530334473
[INFO: train.py:  316]: Interation 9203 took 2.746861219406128
[INFO: train.py:  558]: resist loss: tensor([ 11.4341], device='cuda:0')
[INFO: train.py:  310]: g step took 2.6324634552001953
[INFO: train.py:  316]: Interation 9204 took 2.636446475982666
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 4.5182], device='cuda:0')
[INFO: train.py:  310]: g step took 1.763380527496338
[INFO: train.py:  316]: Interation 9205 took 1.7672982215881348
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 4.9812], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2572755813598633
[INFO: train.py:  316]: Interation 9206 took 2.261112928390503
[INFO: train.py:  558]: resist loss: tensor([ 12.8524], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4231979846954346
[INFO: train.py:  316]: Interation 9207 took 2.427119731903076
[INFO: train.py:  558]: resist loss: tensor([ 5.1956], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0157246589660645
[INFO: train.py:  316]: Interation 9208 took 2.019552230834961
[INFO: train.py:  558]: resist loss: tensor([ 9.4450], device='cuda:0')
[INFO: train.py:  310]: g step took 2.5257925987243652
[INFO: train.py:  316]: Interation 9209 took 2.5297744274139404
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 692, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 692, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 621, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 621, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 573, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 573, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 607, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 607, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 503, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 503, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 499, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 499, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 599, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 599, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 611, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 611, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 556, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 556, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 506, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 506, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 427, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 427, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 167, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 167, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 784, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 784, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 762, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 762, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 834, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 834, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 848, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 848, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 801, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 801, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 871, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 871, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 779, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 779, 2])
[INFO: train.py:  338]:   [val] ade: 0.587
[INFO: train.py:  338]:   [val] ade_l: 1.291
[INFO: train.py:  338]:   [val] ade_nl: 1.075
[INFO: train.py:  338]:   [val] d_loss: 1.416
[INFO: train.py:  338]:   [val] fde: 1.259
[INFO: train.py:  338]:   [val] fde_l: 2.773
[INFO: train.py:  338]:   [val] fde_nl: 2.307
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.428
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.428
[INFO: train.py:  338]:   [val] resist_count: 3048.000
[INFO: train.py:  338]:   [val] resist_loss: 0.318
[INFO: train.py:  341]:   [train] ade: 0.610
[INFO: train.py:  341]:   [train] ade_l: 1.343
[INFO: train.py:  341]:   [train] ade_nl: 1.119
[INFO: train.py:  341]:   [train] d_loss: 1.397
[INFO: train.py:  341]:   [train] fde: 1.243
[INFO: train.py:  341]:   [train] fde_l: 2.735
[INFO: train.py:  341]:   [train] fde_nl: 2.279
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.401
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.401
[INFO: train.py:  341]:   [train] resist_count: 3199.000
[INFO: train.py:  341]:   [train] resist_loss: 0.185
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 4.1320], device='cuda:0')
[INFO: train.py:  310]: g step took 2.281913995742798
[INFO: train.py:  316]: Interation 9210 took 12.402137041091919
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 1.3734], device='cuda:0')
[INFO: train.py:  310]: g step took 0.24730730056762695
[INFO: train.py:  316]: Interation 9211 took 0.2511272430419922
[INFO: train.py:  279]: Starting epoch 216
[INFO: train.py:  280]: Epoch resist loss: tensor([ 236.7552])
[INFO: train.py:  558]: resist loss: tensor([ 4.0966], device='cuda:0')
[INFO: train.py:  310]: g step took 2.5563595294952393
[INFO: train.py:  316]: Interation 9212 took 2.954850435256958
[INFO: train.py:  558]: resist loss: tensor([ 6.7014], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4631309509277344
[INFO: train.py:  316]: Interation 9213 took 2.463596820831299
[INFO: train.py:  558]: resist loss: tensor([ 1.6907], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4566123485565186
[INFO: train.py:  316]: Interation 9214 took 2.4571046829223633
[INFO: train.py:  558]: resist loss: tensor([ 2.7824], device='cuda:0')
[INFO: train.py:  310]: g step took 2.272268772125244
[INFO: train.py:  316]: Interation 9215 took 2.2727737426757812
[INFO: train.py:  558]: resist loss: tensor([ 1.3597], device='cuda:0')
[INFO: train.py:  310]: g step took 2.719646692276001
[INFO: train.py:  316]: Interation 9216 took 2.7200779914855957
[INFO: train.py:  558]: resist loss: tensor([ 7.9785], device='cuda:0')
[INFO: train.py:  310]: g step took 2.155139923095703
[INFO: train.py:  316]: Interation 9217 took 2.155578374862671
[INFO: train.py:  558]: resist loss: tensor([ 2.0798], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4967575073242188
[INFO: train.py:  316]: Interation 9218 took 2.497159719467163
[INFO: train.py:  558]: resist loss: tensor([ 0.5758], device='cuda:0')
[INFO: train.py:  310]: g step took 2.7270307540893555
[INFO: train.py:  316]: Interation 9219 took 2.7273666858673096
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 665, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 665, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 440, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 440, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 431, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 431, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 631, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 631, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 626, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 626, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 568, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 568, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 567, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 567, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 572, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 572, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 606, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 606, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 570, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 570, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 552, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 552, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 133, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 133, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 942, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 942, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 643, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 643, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 918, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 918, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 910, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 910, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 690, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 690, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 788, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 788, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 904, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 904, 2])
[INFO: train.py:  338]:   [val] ade: 0.660
[INFO: train.py:  338]:   [val] ade_l: 1.454
[INFO: train.py:  338]:   [val] ade_nl: 1.210
[INFO: train.py:  338]:   [val] d_loss: 1.405
[INFO: train.py:  338]:   [val] fde: 1.407
[INFO: train.py:  338]:   [val] fde_l: 3.099
[INFO: train.py:  338]:   [val] fde_nl: 2.578
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.518
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.518
[INFO: train.py:  338]:   [val] resist_count: 2755.000
[INFO: train.py:  338]:   [val] resist_loss: 0.278
[INFO: train.py:  341]:   [train] ade: 0.660
[INFO: train.py:  341]:   [train] ade_l: 1.428
[INFO: train.py:  341]:   [train] ade_nl: 1.228
[INFO: train.py:  341]:   [train] d_loss: 1.396
[INFO: train.py:  341]:   [train] fde: 1.347
[INFO: train.py:  341]:   [train] fde_l: 2.913
[INFO: train.py:  341]:   [train] fde_nl: 2.506
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.470
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.470
[INFO: train.py:  341]:   [train] resist_count: 2619.000
[INFO: train.py:  341]:   [train] resist_loss: 0.149
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.2198], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3038926124572754
[INFO: train.py:  316]: Interation 9220 took 12.205779552459717
[INFO: train.py:  558]: resist loss: tensor([ 6.4383], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4029953479766846
[INFO: train.py:  316]: Interation 9221 took 2.4033758640289307
[INFO: train.py:  558]: resist loss: tensor([ 3.2257], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9156208038330078
[INFO: train.py:  316]: Interation 9222 took 1.9160141944885254
[INFO: train.py:  558]: resist loss: tensor([ 6.1272], device='cuda:0')
[INFO: train.py:  310]: g step took 2.362563371658325
[INFO: train.py:  316]: Interation 9223 took 2.362933874130249
[INFO: train.py:  558]: resist loss: tensor([ 2.2473], device='cuda:0')
[INFO: train.py:  310]: g step took 2.146730661392212
[INFO: train.py:  316]: Interation 9224 took 2.1471219062805176
[INFO: train.py:  558]: resist loss: tensor([ 1.1706], device='cuda:0')
[INFO: train.py:  310]: g step took 2.128842353820801
[INFO: train.py:  316]: Interation 9225 took 2.129171133041382
[INFO: train.py:  558]: resist loss: tensor([ 1.1127], device='cuda:0')
[INFO: train.py:  310]: g step took 2.507402181625366
[INFO: train.py:  316]: Interation 9226 took 2.5077970027923584
[INFO: train.py:  558]: resist loss: tensor([ 5.5773], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4953925609588623
[INFO: train.py:  316]: Interation 9227 took 2.4957308769226074
[INFO: train.py:  558]: resist loss: tensor([ 7.8499], device='cuda:0')
[INFO: train.py:  310]: g step took 2.352262020111084
[INFO: train.py:  316]: Interation 9228 took 2.3563029766082764
[INFO: train.py:  558]: resist loss: tensor([ 4.0648], device='cuda:0')
[INFO: train.py:  310]: g step took 2.240281343460083
[INFO: train.py:  316]: Interation 9229 took 2.2443301677703857
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 531, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 531, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 615, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 615, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 559, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 559, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 520, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 520, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 795, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 795, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 570, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 570, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 526, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 526, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 519, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 519, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 538, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 538, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 525, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 525, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 532, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 532, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 131, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 131, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 799, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 799, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 921, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 921, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 671, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 671, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 586, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 586, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 787, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 787, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 803, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 803, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 733, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 733, 2])
[INFO: train.py:  338]:   [val] ade: 0.617
[INFO: train.py:  338]:   [val] ade_l: 1.359
[INFO: train.py:  338]:   [val] ade_nl: 1.131
[INFO: train.py:  338]:   [val] d_loss: 1.418
[INFO: train.py:  338]:   [val] fde: 1.330
[INFO: train.py:  338]:   [val] fde_l: 2.929
[INFO: train.py:  338]:   [val] fde_nl: 2.437
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.469
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.469
[INFO: train.py:  338]:   [val] resist_count: 2753.000
[INFO: train.py:  338]:   [val] resist_loss: 0.287
[INFO: train.py:  341]:   [train] ade: 0.618
[INFO: train.py:  341]:   [train] ade_l: 1.307
[INFO: train.py:  341]:   [train] ade_nl: 1.174
[INFO: train.py:  341]:   [train] d_loss: 1.404
[INFO: train.py:  341]:   [train] fde: 1.260
[INFO: train.py:  341]:   [train] fde_l: 2.663
[INFO: train.py:  341]:   [train] fde_nl: 2.392
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.418
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.418
[INFO: train.py:  341]:   [train] resist_count: 2573.000
[INFO: train.py:  341]:   [train] resist_loss: 0.154
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 7.3270], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9293272495269775
[INFO: train.py:  316]: Interation 9230 took 10.96855640411377
[INFO: train.py:  558]: resist loss: tensor([ 0.5034], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0322091579437256
[INFO: train.py:  316]: Interation 9231 took 2.0365359783172607
[INFO: train.py:  558]: resist loss: tensor([ 3.3832], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9449124336242676
[INFO: train.py:  316]: Interation 9232 took 1.9488072395324707
[INFO: train.py:  558]: resist loss: tensor([ 6.6803], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3018386363983154
[INFO: train.py:  316]: Interation 9233 took 2.3055732250213623
[INFO: train.py:  558]: resist loss: tensor([ 10.0863], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1767940521240234
[INFO: train.py:  316]: Interation 9234 took 2.181387424468994
[INFO: train.py:  558]: resist loss: tensor([ 4.4566], device='cuda:0')
[INFO: train.py:  310]: g step took 2.026815891265869
[INFO: train.py:  316]: Interation 9235 took 2.030449867248535
[INFO: train.py:  558]: resist loss: tensor([ 3.2542], device='cuda:0')
[INFO: train.py:  310]: g step took 2.281127452850342
[INFO: train.py:  316]: Interation 9236 took 2.285224199295044
[INFO: train.py:  558]: resist loss: tensor([ 6.3093], device='cuda:0')
[INFO: train.py:  310]: g step took 2.03047251701355
[INFO: train.py:  316]: Interation 9237 took 2.0344879627227783
[INFO: train.py:  558]: resist loss: tensor([ 8.3889], device='cuda:0')
[INFO: train.py:  310]: g step took 2.081421375274658
[INFO: train.py:  316]: Interation 9238 took 2.085841178894043
[INFO: train.py:  558]: resist loss: tensor([ 5.8028], device='cuda:0')
[INFO: train.py:  310]: g step took 2.142085075378418
[INFO: train.py:  316]: Interation 9239 took 2.1458139419555664
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 570, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 570, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 580, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 580, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 514, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 514, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 625, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 625, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 565, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 565, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 531, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 531, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 561, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 561, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 548, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 548, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 570, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 570, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 510, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 510, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 672, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 672, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 115, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 115, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 702, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 702, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 754, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 754, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 760, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 760, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 844, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 844, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 1019, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 1019, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 958, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 958, 2])
[INFO: train.py:  338]:   [val] ade: 0.658
[INFO: train.py:  338]:   [val] ade_l: 1.448
[INFO: train.py:  338]:   [val] ade_nl: 1.205
[INFO: train.py:  338]:   [val] d_loss: 1.401
[INFO: train.py:  338]:   [val] fde: 1.318
[INFO: train.py:  338]:   [val] fde_l: 2.902
[INFO: train.py:  338]:   [val] fde_nl: 2.415
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.476
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.476
[INFO: train.py:  338]:   [val] resist_count: 3044.000
[INFO: train.py:  338]:   [val] resist_loss: 0.382
[INFO: train.py:  341]:   [train] ade: 0.691
[INFO: train.py:  341]:   [train] ade_l: 1.499
[INFO: train.py:  341]:   [train] ade_nl: 1.280
[INFO: train.py:  341]:   [train] d_loss: 1.398
[INFO: train.py:  341]:   [train] fde: 1.275
[INFO: train.py:  341]:   [train] fde_l: 2.768
[INFO: train.py:  341]:   [train] fde_nl: 2.364
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.466
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.466
[INFO: train.py:  341]:   [train] resist_count: 2776.000
[INFO: train.py:  341]:   [train] resist_loss: 0.182
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 1.2805], device='cuda:0')
[INFO: train.py:  310]: g step took 2.080406665802002
[INFO: train.py:  316]: Interation 9240 took 10.495165824890137
[INFO: train.py:  558]: resist loss: tensor([ 3.6117], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6767761707305908
[INFO: train.py:  316]: Interation 9241 took 1.6811954975128174
[INFO: train.py:  558]: resist loss: tensor([ 1.5292], device='cuda:0')
[INFO: train.py:  310]: g step took 1.871262550354004
[INFO: train.py:  316]: Interation 9242 took 1.8752052783966064
[INFO: train.py:  558]: resist loss: tensor([ 6.6893], device='cuda:0')
[INFO: train.py:  310]: g step took 1.917273998260498
[INFO: train.py:  316]: Interation 9243 took 1.921102523803711
[INFO: train.py:  558]: resist loss: tensor([ 0.6325], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6609084606170654
[INFO: train.py:  316]: Interation 9244 took 1.6652193069458008
[INFO: train.py:  558]: resist loss: tensor([ 10.2955], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8608288764953613
[INFO: train.py:  316]: Interation 9245 took 1.864626407623291
[INFO: train.py:  558]: resist loss: tensor([ 17.0805], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0610783100128174
[INFO: train.py:  316]: Interation 9246 took 2.0649161338806152
[INFO: train.py:  558]: resist loss: tensor([ 9.6397], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9470560550689697
[INFO: train.py:  316]: Interation 9247 took 1.9505071640014648
[INFO: train.py:  558]: resist loss: tensor([ 4.2605], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8482003211975098
[INFO: train.py:  316]: Interation 9248 took 1.8521087169647217
[INFO: train.py:  558]: resist loss: tensor([ 1.4578], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6074600219726562
[INFO: train.py:  316]: Interation 9249 took 1.6114583015441895
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 429, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 429, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 592, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 592, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 578, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 578, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 678, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 678, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 577, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 577, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 533, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 533, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 574, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 574, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 586, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 586, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 545, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 545, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 545, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 545, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 563, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 563, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 161, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 161, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 834, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 834, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 859, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 859, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 762, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 762, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 790, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 790, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 650, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 650, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 765, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 765, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 775, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 775, 2])
[INFO: train.py:  338]:   [val] ade: 0.630
[INFO: train.py:  338]:   [val] ade_l: 1.386
[INFO: train.py:  338]:   [val] ade_nl: 1.153
[INFO: train.py:  338]:   [val] d_loss: 1.406
[INFO: train.py:  338]:   [val] fde: 1.367
[INFO: train.py:  338]:   [val] fde_l: 3.011
[INFO: train.py:  338]:   [val] fde_nl: 2.505
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.468
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.468
[INFO: train.py:  338]:   [val] resist_count: 3867.000
[INFO: train.py:  338]:   [val] resist_loss: 0.415
[INFO: train.py:  341]:   [train] ade: 0.612
[INFO: train.py:  341]:   [train] ade_l: 1.229
[INFO: train.py:  341]:   [train] ade_nl: 1.218
[INFO: train.py:  341]:   [train] d_loss: 1.404
[INFO: train.py:  341]:   [train] fde: 1.265
[INFO: train.py:  341]:   [train] fde_l: 2.541
[INFO: train.py:  341]:   [train] fde_nl: 2.519
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.391
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.391
[INFO: train.py:  341]:   [train] resist_count: 3561.000
[INFO: train.py:  341]:   [train] resist_loss: 0.210
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 3.3475], device='cuda:0')
[INFO: train.py:  310]: g step took 1.733940601348877
[INFO: train.py:  316]: Interation 9250 took 10.961997509002686
[INFO: train.py:  558]: resist loss: tensor([ 3.0859], device='cuda:0')
[INFO: train.py:  310]: g step took 2.362133502960205
[INFO: train.py:  316]: Interation 9251 took 2.366034984588623
[INFO: train.py:  558]: resist loss: tensor([ 6.2902], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1258163452148438
[INFO: train.py:  316]: Interation 9252 took 2.130255937576294
[INFO: train.py:  558]: resist loss: tensor([ 4.1480], device='cuda:0')
[INFO: train.py:  310]: g step took 1.72609281539917
[INFO: train.py:  316]: Interation 9253 took 1.730010747909546
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 1.8511], device='cuda:0')
[INFO: train.py:  310]: g step took 0.1574699878692627
[INFO: train.py:  316]: Interation 9254 took 0.1616966724395752
[INFO: train.py:  279]: Starting epoch 217
[INFO: train.py:  280]: Epoch resist loss: tensor([ 196.8578])
[INFO: train.py:  558]: resist loss: tensor([ 2.0976], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8703887462615967
[INFO: train.py:  316]: Interation 9255 took 2.2444918155670166
[INFO: train.py:  558]: resist loss: tensor([ 14.6355], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0769734382629395
[INFO: train.py:  316]: Interation 9256 took 2.088392734527588
[INFO: train.py:  558]: resist loss: tensor([ 2.3326], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1803066730499268
[INFO: train.py:  316]: Interation 9257 took 2.1844918727874756
[INFO: train.py:  558]: resist loss: tensor([ 3.5625], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1697959899902344
[INFO: train.py:  316]: Interation 9258 took 2.184917449951172
[INFO: train.py:  558]: resist loss: tensor([ 3.9125], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6478707790374756
[INFO: train.py:  316]: Interation 9259 took 1.6482219696044922
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 669, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 669, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 483, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 483, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 459, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 459, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 495, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 495, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 605, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 605, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 692, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 692, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 552, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 552, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 527, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 527, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 465, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 465, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 596, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 596, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 671, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 671, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 147, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 147, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 668, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 668, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 970, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 970, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 727, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 727, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 736, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 736, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 825, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 825, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 590, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 590, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 740, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 740, 2])
[INFO: train.py:  338]:   [val] ade: 0.697
[INFO: train.py:  338]:   [val] ade_l: 1.534
[INFO: train.py:  338]:   [val] ade_nl: 1.277
[INFO: train.py:  338]:   [val] d_loss: 1.408
[INFO: train.py:  338]:   [val] fde: 1.446
[INFO: train.py:  338]:   [val] fde_l: 3.183
[INFO: train.py:  338]:   [val] fde_nl: 2.649
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.536
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.536
[INFO: train.py:  338]:   [val] resist_count: 3367.000
[INFO: train.py:  338]:   [val] resist_loss: 0.352
[INFO: train.py:  341]:   [train] ade: 0.694
[INFO: train.py:  341]:   [train] ade_l: 1.459
[INFO: train.py:  341]:   [train] ade_nl: 1.323
[INFO: train.py:  341]:   [train] d_loss: 1.407
[INFO: train.py:  341]:   [train] fde: 1.363
[INFO: train.py:  341]:   [train] fde_l: 2.866
[INFO: train.py:  341]:   [train] fde_nl: 2.598
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.478
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.478
[INFO: train.py:  341]:   [train] resist_count: 3231.000
[INFO: train.py:  341]:   [train] resist_loss: 0.199
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 9.6217], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9935705661773682
[INFO: train.py:  316]: Interation 9260 took 10.040832281112671
[INFO: train.py:  558]: resist loss: tensor([ 1.2109], device='cuda:0')
[INFO: train.py:  310]: g step took 2.071718692779541
[INFO: train.py:  316]: Interation 9261 took 2.072157382965088
[INFO: train.py:  558]: resist loss: tensor([ 5.8749], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0131523609161377
[INFO: train.py:  316]: Interation 9262 took 2.0135388374328613
[INFO: train.py:  558]: resist loss: tensor([ 1.4736], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5343456268310547
[INFO: train.py:  316]: Interation 9263 took 1.5347001552581787
[INFO: train.py:  558]: resist loss: tensor([ 5.8452], device='cuda:0')
[INFO: train.py:  310]: g step took 2.245231866836548
[INFO: train.py:  316]: Interation 9264 took 2.2559750080108643
[INFO: train.py:  558]: resist loss: tensor([ 1.2665], device='cuda:0')
[INFO: train.py:  310]: g step took 2.104684591293335
[INFO: train.py:  316]: Interation 9265 took 2.108893871307373
[INFO: train.py:  558]: resist loss: tensor([ 8.5092], device='cuda:0')
[INFO: train.py:  310]: g step took 2.059216022491455
[INFO: train.py:  316]: Interation 9266 took 2.070136547088623
[INFO: train.py:  558]: resist loss: tensor([ 0.4733], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7799036502838135
[INFO: train.py:  316]: Interation 9267 took 1.7843732833862305
[INFO: train.py:  558]: resist loss: tensor([ 2.3898], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9911835193634033
[INFO: train.py:  316]: Interation 9268 took 1.991499423980713
[INFO: train.py:  558]: resist loss: tensor([ 0.3665], device='cuda:0')
[INFO: train.py:  310]: g step took 2.106459617614746
[INFO: train.py:  316]: Interation 9269 took 2.106839418411255
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 556, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 556, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 562, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 562, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 535, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 535, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 638, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 638, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 588, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 588, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 520, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 520, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 575, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 575, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 638, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 638, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 539, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 539, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 595, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 595, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 520, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 520, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 95, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 95, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 826, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 826, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 877, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 877, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 766, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 766, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 673, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 673, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 798, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 798, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 814, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 814, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 744, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 744, 2])
[INFO: train.py:  338]:   [val] ade: 0.639
[INFO: train.py:  338]:   [val] ade_l: 1.407
[INFO: train.py:  338]:   [val] ade_nl: 1.171
[INFO: train.py:  338]:   [val] d_loss: 1.400
[INFO: train.py:  338]:   [val] fde: 1.387
[INFO: train.py:  338]:   [val] fde_l: 3.053
[INFO: train.py:  338]:   [val] fde_nl: 2.540
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.493
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.493
[INFO: train.py:  338]:   [val] resist_count: 2786.000
[INFO: train.py:  338]:   [val] resist_loss: 0.262
[INFO: train.py:  341]:   [train] ade: 0.626
[INFO: train.py:  341]:   [train] ade_l: 1.275
[INFO: train.py:  341]:   [train] ade_nl: 1.231
[INFO: train.py:  341]:   [train] d_loss: 1.406
[INFO: train.py:  341]:   [train] fde: 1.267
[INFO: train.py:  341]:   [train] fde_l: 2.578
[INFO: train.py:  341]:   [train] fde_nl: 2.490
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.417
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.417
[INFO: train.py:  341]:   [train] resist_count: 2731.000
[INFO: train.py:  341]:   [train] resist_loss: 0.136
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.2344], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0775701999664307
[INFO: train.py:  316]: Interation 9270 took 10.599219799041748
[INFO: train.py:  558]: resist loss: tensor([ 0.6068], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8965184688568115
[INFO: train.py:  316]: Interation 9271 took 1.8969414234161377
[INFO: train.py:  558]: resist loss: tensor([ 12.7619], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0615200996398926
[INFO: train.py:  316]: Interation 9272 took 2.065795421600342
[INFO: train.py:  558]: resist loss: tensor([ 2.1941], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9881656169891357
[INFO: train.py:  316]: Interation 9273 took 1.9923443794250488
[INFO: train.py:  558]: resist loss: tensor([ 1.3177], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2942559719085693
[INFO: train.py:  316]: Interation 9274 took 2.2980282306671143
[INFO: train.py:  558]: resist loss: tensor([ 3.2541], device='cuda:0')
[INFO: train.py:  310]: g step took 1.585862159729004
[INFO: train.py:  316]: Interation 9275 took 1.589789867401123
[INFO: train.py:  558]: resist loss: tensor([ 7.0423], device='cuda:0')
[INFO: train.py:  310]: g step took 2.005216360092163
[INFO: train.py:  316]: Interation 9276 took 2.009136199951172
[INFO: train.py:  558]: resist loss: tensor([ 1.5505], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5961687564849854
[INFO: train.py:  316]: Interation 9277 took 1.599928379058838
[INFO: train.py:  558]: resist loss: tensor([ 1.2603], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4066851139068604
[INFO: train.py:  316]: Interation 9278 took 2.4107015132904053
[INFO: train.py:  558]: resist loss: tensor([ 4.2892], device='cuda:0')
[INFO: train.py:  310]: g step took 1.552248239517212
[INFO: train.py:  316]: Interation 9279 took 1.555859088897705
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 522, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 522, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 577, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 577, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 636, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 636, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 589, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 589, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 530, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 530, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 432, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 432, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 587, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 587, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 648, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 648, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 616, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 616, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 542, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 542, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 550, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 550, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 132, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 132, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 668, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 668, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 706, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 706, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 815, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 815, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 786, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 786, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 933, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 933, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 812, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 812, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 773, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 773, 2])
[INFO: train.py:  338]:   [val] ade: 0.642
[INFO: train.py:  338]:   [val] ade_l: 1.413
[INFO: train.py:  338]:   [val] ade_nl: 1.176
[INFO: train.py:  338]:   [val] d_loss: 1.394
[INFO: train.py:  338]:   [val] fde: 1.374
[INFO: train.py:  338]:   [val] fde_l: 3.025
[INFO: train.py:  338]:   [val] fde_nl: 2.517
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.491
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.491
[INFO: train.py:  338]:   [val] resist_count: 2822.000
[INFO: train.py:  338]:   [val] resist_loss: 0.253
[INFO: train.py:  341]:   [train] ade: 0.633
[INFO: train.py:  341]:   [train] ade_l: 1.345
[INFO: train.py:  341]:   [train] ade_nl: 1.196
[INFO: train.py:  341]:   [train] d_loss: 1.396
[INFO: train.py:  341]:   [train] fde: 1.280
[INFO: train.py:  341]:   [train] fde_l: 2.720
[INFO: train.py:  341]:   [train] fde_nl: 2.419
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.427
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.427
[INFO: train.py:  341]:   [train] resist_count: 2831.000
[INFO: train.py:  341]:   [train] resist_loss: 0.151
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 14.7437], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3259685039520264
[INFO: train.py:  316]: Interation 9280 took 10.8108971118927
[INFO: train.py:  558]: resist loss: tensor([ 5.7633], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0897154808044434
[INFO: train.py:  316]: Interation 9281 took 2.093628406524658
[INFO: train.py:  558]: resist loss: tensor([ 0.9857], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0056755542755127
[INFO: train.py:  316]: Interation 9282 took 2.0095481872558594
[INFO: train.py:  558]: resist loss: tensor([ 0.9944], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7246060371398926
[INFO: train.py:  316]: Interation 9283 took 1.7278053760528564
[INFO: train.py:  558]: resist loss: tensor([ 0.7350], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9071736335754395
[INFO: train.py:  316]: Interation 9284 took 1.911036491394043
[INFO: train.py:  558]: resist loss: tensor([ 6.7984], device='cuda:0')
[INFO: train.py:  310]: g step took 2.33917498588562
[INFO: train.py:  316]: Interation 9285 took 2.3429958820343018
[INFO: train.py:  558]: resist loss: tensor([ 3.3265], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7945129871368408
[INFO: train.py:  316]: Interation 9286 took 1.7984049320220947
[INFO: train.py:  558]: resist loss: tensor([ 0.9427], device='cuda:0')
[INFO: train.py:  310]: g step took 2.133890390396118
[INFO: train.py:  316]: Interation 9287 took 2.137852668762207
[INFO: train.py:  558]: resist loss: tensor([ 5.8529], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8683664798736572
[INFO: train.py:  316]: Interation 9288 took 1.8722598552703857
[INFO: train.py:  558]: resist loss: tensor([ 2.0729], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1807217597961426
[INFO: train.py:  316]: Interation 9289 took 2.1846604347229004
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 495, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 495, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 587, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 587, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 721, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 721, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 596, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 596, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 585, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 585, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 651, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 651, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 554, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 554, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 575, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 575, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 463, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 463, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 444, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 444, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 523, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 523, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 167, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 167, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 887, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 887, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 732, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 732, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 731, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 731, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 609, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 609, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 906, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 906, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 858, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 858, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 678, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 678, 2])
[INFO: train.py:  338]:   [val] ade: 0.639
[INFO: train.py:  338]:   [val] ade_l: 1.407
[INFO: train.py:  338]:   [val] ade_nl: 1.171
[INFO: train.py:  338]:   [val] d_loss: 1.417
[INFO: train.py:  338]:   [val] fde: 1.338
[INFO: train.py:  338]:   [val] fde_l: 2.946
[INFO: train.py:  338]:   [val] fde_nl: 2.452
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.469
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.469
[INFO: train.py:  338]:   [val] resist_count: 2911.000
[INFO: train.py:  338]:   [val] resist_loss: 0.276
[INFO: train.py:  341]:   [train] ade: 0.620
[INFO: train.py:  341]:   [train] ade_l: 1.280
[INFO: train.py:  341]:   [train] ade_nl: 1.202
[INFO: train.py:  341]:   [train] d_loss: 1.394
[INFO: train.py:  341]:   [train] fde: 1.238
[INFO: train.py:  341]:   [train] fde_l: 2.557
[INFO: train.py:  341]:   [train] fde_nl: 2.401
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.400
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.400
[INFO: train.py:  341]:   [train] resist_count: 2665.000
[INFO: train.py:  341]:   [train] resist_loss: 0.163
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 12.6597], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8827016353607178
[INFO: train.py:  316]: Interation 9290 took 10.6372652053833
[INFO: train.py:  558]: resist loss: tensor([ 0.9880], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4174022674560547
[INFO: train.py:  316]: Interation 9291 took 2.421241521835327
[INFO: train.py:  558]: resist loss: tensor([ 1.0805], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9668309688568115
[INFO: train.py:  316]: Interation 9292 took 1.9706385135650635
[INFO: train.py:  558]: resist loss: tensor([ 3.6135], device='cuda:0')
[INFO: train.py:  310]: g step took 1.808356523513794
[INFO: train.py:  316]: Interation 9293 took 1.8122060298919678
[INFO: train.py:  558]: resist loss: tensor([ 3.9761], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9265902042388916
[INFO: train.py:  316]: Interation 9294 took 1.9304203987121582
[INFO: train.py:  558]: resist loss: tensor([ 3.1323], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0576837062835693
[INFO: train.py:  316]: Interation 9295 took 2.0615601539611816
[INFO: train.py:  558]: resist loss: tensor([ 0.3857], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5310511589050293
[INFO: train.py:  316]: Interation 9296 took 1.5349466800689697
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 1.9583], device='cuda:0')
[INFO: train.py:  310]: g step took 0.1947035789489746
[INFO: train.py:  316]: Interation 9297 took 0.1985487937927246
[INFO: train.py:  279]: Starting epoch 218
[INFO: train.py:  280]: Epoch resist loss: tensor([ 166.1542])
[INFO: train.py:  558]: resist loss: tensor([ 7.6038], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8794903755187988
[INFO: train.py:  316]: Interation 9298 took 2.24877667427063
[INFO: train.py:  558]: resist loss: tensor([ 3.1104], device='cuda:0')
[INFO: train.py:  310]: g step took 2.171468734741211
[INFO: train.py:  316]: Interation 9299 took 2.179321765899658
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 509, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 509, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 686, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 686, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 499, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 499, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 556, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 556, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 605, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 605, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 522, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 522, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 527, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 527, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 511, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 511, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 643, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 643, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 623, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 623, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 520, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 520, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 160, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 160, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 690, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 690, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 796, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 796, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 915, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 915, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 1033, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 1033, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 848, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 848, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 964, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 964, 2])
[INFO: train.py:  338]:   [val] ade: 0.669
[INFO: train.py:  338]:   [val] ade_l: 1.474
[INFO: train.py:  338]:   [val] ade_nl: 1.226
[INFO: train.py:  338]:   [val] d_loss: 1.411
[INFO: train.py:  338]:   [val] fde: 1.409
[INFO: train.py:  338]:   [val] fde_l: 3.103
[INFO: train.py:  338]:   [val] fde_nl: 2.582
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.501
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.501
[INFO: train.py:  338]:   [val] resist_count: 3204.000
[INFO: train.py:  338]:   [val] resist_loss: 0.327
[INFO: train.py:  341]:   [train] ade: 0.675
[INFO: train.py:  341]:   [train] ade_l: 1.390
[INFO: train.py:  341]:   [train] ade_nl: 1.311
[INFO: train.py:  341]:   [train] d_loss: 1.400
[INFO: train.py:  341]:   [train] fde: 1.331
[INFO: train.py:  341]:   [train] fde_l: 2.743
[INFO: train.py:  341]:   [train] fde_nl: 2.586
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.456
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.456
[INFO: train.py:  341]:   [train] resist_count: 3163.000
[INFO: train.py:  341]:   [train] resist_loss: 0.164
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 8.4780], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0219969749450684
[INFO: train.py:  316]: Interation 9300 took 10.178519010543823
[INFO: train.py:  558]: resist loss: tensor([ 5.0254], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6334080696105957
[INFO: train.py:  316]: Interation 9301 took 1.6338744163513184
[INFO: train.py:  558]: resist loss: tensor([ 6.9956], device='cuda:0')
[INFO: train.py:  310]: g step took 1.917175054550171
[INFO: train.py:  316]: Interation 9302 took 1.9211506843566895
[INFO: train.py:  558]: resist loss: tensor([ 12.0251], device='cuda:0')
[INFO: train.py:  310]: g step took 2.280205726623535
[INFO: train.py:  316]: Interation 9303 took 2.284360408782959
[INFO: train.py:  558]: resist loss: tensor([ 1.0866], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6840064525604248
[INFO: train.py:  316]: Interation 9304 took 1.6844606399536133
[INFO: train.py:  558]: resist loss: tensor([ 0.6919], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9471080303192139
[INFO: train.py:  316]: Interation 9305 took 1.9515423774719238
[INFO: train.py:  558]: resist loss: tensor([ 9.2909], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9851360321044922
[INFO: train.py:  316]: Interation 9306 took 2.002401828765869
[INFO: train.py:  558]: resist loss: tensor([ 28.2158], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4406919479370117
[INFO: train.py:  316]: Interation 9307 took 2.451117515563965
[INFO: train.py:  558]: resist loss: tensor([ 1.9608], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3908329010009766
[INFO: train.py:  316]: Interation 9308 took 1.3912498950958252
[INFO: train.py:  558]: resist loss: tensor([ 16.6182], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9342210292816162
[INFO: train.py:  316]: Interation 9309 took 1.9345290660858154
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 567, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 567, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 636, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 636, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 511, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 511, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 522, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 522, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 497, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 497, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 499, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 499, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 659, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 659, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 525, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 525, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 579, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 579, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 610, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 610, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 607, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 607, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 149, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 149, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 830, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 830, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 812, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 812, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 682, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 682, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 842, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 842, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 748, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 748, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 601, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 601, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 865, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 865, 2])
[INFO: train.py:  338]:   [val] ade: 0.631
[INFO: train.py:  338]:   [val] ade_l: 1.389
[INFO: train.py:  338]:   [val] ade_nl: 1.156
[INFO: train.py:  338]:   [val] d_loss: 1.414
[INFO: train.py:  338]:   [val] fde: 1.263
[INFO: train.py:  338]:   [val] fde_l: 2.780
[INFO: train.py:  338]:   [val] fde_nl: 2.313
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.442
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.442
[INFO: train.py:  338]:   [val] resist_count: 2881.000
[INFO: train.py:  338]:   [val] resist_loss: 0.340
[INFO: train.py:  341]:   [train] ade: 0.641
[INFO: train.py:  341]:   [train] ade_l: 1.342
[INFO: train.py:  341]:   [train] ade_nl: 1.226
[INFO: train.py:  341]:   [train] d_loss: 1.393
[INFO: train.py:  341]:   [train] fde: 1.197
[INFO: train.py:  341]:   [train] fde_l: 2.507
[INFO: train.py:  341]:   [train] fde_nl: 2.291
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.415
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.415
[INFO: train.py:  341]:   [train] resist_count: 2879.000
[INFO: train.py:  341]:   [train] resist_loss: 0.181
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 1.4623], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6853680610656738
[INFO: train.py:  316]: Interation 9310 took 10.453827857971191
[INFO: train.py:  558]: resist loss: tensor([ 0.4072], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0661137104034424
[INFO: train.py:  316]: Interation 9311 took 2.066450595855713
[INFO: train.py:  558]: resist loss: tensor([ 0.5067], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0067012310028076
[INFO: train.py:  316]: Interation 9312 took 2.007035255432129
[INFO: train.py:  558]: resist loss: tensor([ 2.5669], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8636536598205566
[INFO: train.py:  316]: Interation 9313 took 1.8639912605285645
[INFO: train.py:  558]: resist loss: tensor([ 12.6202], device='cuda:0')
[INFO: train.py:  310]: g step took 2.147287368774414
[INFO: train.py:  316]: Interation 9314 took 2.151379346847534
[INFO: train.py:  558]: resist loss: tensor([ 0.8885], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8058595657348633
[INFO: train.py:  316]: Interation 9315 took 1.809866189956665
[INFO: train.py:  558]: resist loss: tensor([ 7.2442], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9596290588378906
[INFO: train.py:  316]: Interation 9316 took 1.9635860919952393
[INFO: train.py:  558]: resist loss: tensor([ 3.1621], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9172272682189941
[INFO: train.py:  316]: Interation 9317 took 1.9213249683380127
[INFO: train.py:  558]: resist loss: tensor([ 3.4177], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7271983623504639
[INFO: train.py:  316]: Interation 9318 took 1.73052978515625
[INFO: train.py:  558]: resist loss: tensor([ 4.4070], device='cuda:0')
[INFO: train.py:  310]: g step took 1.909303903579712
[INFO: train.py:  316]: Interation 9319 took 1.912963628768921
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 462, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 462, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 516, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 516, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 601, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 601, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 564, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 564, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 545, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 545, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 560, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 560, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 613, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 613, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 549, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 549, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 591, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 591, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 637, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 637, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 531, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 531, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 192, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 192, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 610, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 610, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 576, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 576, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 780, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 780, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 763, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 763, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 877, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 877, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 668, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 668, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 826, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 826, 2])
[INFO: train.py:  338]:   [val] ade: 0.648
[INFO: train.py:  338]:   [val] ade_l: 1.426
[INFO: train.py:  338]:   [val] ade_nl: 1.187
[INFO: train.py:  338]:   [val] d_loss: 1.403
[INFO: train.py:  338]:   [val] fde: 1.357
[INFO: train.py:  338]:   [val] fde_l: 2.988
[INFO: train.py:  338]:   [val] fde_nl: 2.486
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.478
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.478
[INFO: train.py:  338]:   [val] resist_count: 3057.000
[INFO: train.py:  338]:   [val] resist_loss: 0.274
[INFO: train.py:  341]:   [train] ade: 0.654
[INFO: train.py:  341]:   [train] ade_l: 1.363
[INFO: train.py:  341]:   [train] ade_nl: 1.258
[INFO: train.py:  341]:   [train] d_loss: 1.410
[INFO: train.py:  341]:   [train] fde: 1.299
[INFO: train.py:  341]:   [train] fde_l: 2.706
[INFO: train.py:  341]:   [train] fde_nl: 2.497
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.440
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.440
[INFO: train.py:  341]:   [train] resist_count: 2505.000
[INFO: train.py:  341]:   [train] resist_loss: 0.166
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 10.6550], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1908438205718994
[INFO: train.py:  316]: Interation 9320 took 10.82802677154541
[INFO: train.py:  558]: resist loss: tensor([ 10.0432], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2170510292053223
[INFO: train.py:  316]: Interation 9321 took 2.220752716064453
[INFO: train.py:  558]: resist loss: tensor([ 1.2678], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8529331684112549
[INFO: train.py:  316]: Interation 9322 took 1.8569221496582031
[INFO: train.py:  558]: resist loss: tensor([ 0.7593], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8764243125915527
[INFO: train.py:  316]: Interation 9323 took 1.8804130554199219
[INFO: train.py:  558]: resist loss: tensor([ 13.3344], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9348595142364502
[INFO: train.py:  316]: Interation 9324 took 1.9388134479522705
[INFO: train.py:  558]: resist loss: tensor([ 1.2105], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7963035106658936
[INFO: train.py:  316]: Interation 9325 took 1.8002123832702637
[INFO: train.py:  558]: resist loss: tensor([ 9.0270], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0090696811676025
[INFO: train.py:  316]: Interation 9326 took 2.012354850769043
[INFO: train.py:  558]: resist loss: tensor([ 5.5354], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0832560062408447
[INFO: train.py:  316]: Interation 9327 took 2.087244987487793
[INFO: train.py:  558]: resist loss: tensor([ 0.5502], device='cuda:0')
[INFO: train.py:  310]: g step took 1.829554557800293
[INFO: train.py:  316]: Interation 9328 took 1.8336565494537354
[INFO: train.py:  558]: resist loss: tensor([ 3.1869], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0239768028259277
[INFO: train.py:  316]: Interation 9329 took 2.027801036834717
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 536, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 536, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 592, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 592, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 492, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 492, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 540, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 540, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 602, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 602, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 476, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 476, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 609, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 609, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 557, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 557, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 619, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 619, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 621, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 621, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 589, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 589, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 128, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 128, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 705, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 705, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 791, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 791, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 819, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 819, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 859, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 859, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 513, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 513, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 663, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 663, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 876, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 876, 2])
[INFO: train.py:  338]:   [val] ade: 0.651
[INFO: train.py:  338]:   [val] ade_l: 1.434
[INFO: train.py:  338]:   [val] ade_nl: 1.194
[INFO: train.py:  338]:   [val] d_loss: 1.414
[INFO: train.py:  338]:   [val] fde: 1.390
[INFO: train.py:  338]:   [val] fde_l: 3.060
[INFO: train.py:  338]:   [val] fde_nl: 2.546
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.495
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.495
[INFO: train.py:  338]:   [val] resist_count: 3429.000
[INFO: train.py:  338]:   [val] resist_loss: 0.298
[INFO: train.py:  341]:   [train] ade: 0.636
[INFO: train.py:  341]:   [train] ade_l: 1.288
[INFO: train.py:  341]:   [train] ade_nl: 1.254
[INFO: train.py:  341]:   [train] d_loss: 1.408
[INFO: train.py:  341]:   [train] fde: 1.294
[INFO: train.py:  341]:   [train] fde_l: 2.623
[INFO: train.py:  341]:   [train] fde_nl: 2.553
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.425
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.425
[INFO: train.py:  341]:   [train] resist_count: 2993.000
[INFO: train.py:  341]:   [train] resist_loss: 0.199
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.6278], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1853044033050537
[INFO: train.py:  316]: Interation 9330 took 10.937137365341187
[INFO: train.py:  558]: resist loss: tensor([ 10.6074], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4592576026916504
[INFO: train.py:  316]: Interation 9331 took 2.4634041786193848
[INFO: train.py:  558]: resist loss: tensor([ 6.3633], device='cuda:0')
[INFO: train.py:  310]: g step took 2.029653549194336
[INFO: train.py:  316]: Interation 9332 took 2.033592700958252
[INFO: train.py:  558]: resist loss: tensor([ 2.9800], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9641928672790527
[INFO: train.py:  316]: Interation 9333 took 1.9680898189544678
[INFO: train.py:  558]: resist loss: tensor([ 9.1584], device='cuda:0')
[INFO: train.py:  310]: g step took 2.149766683578491
[INFO: train.py:  316]: Interation 9334 took 2.1530613899230957
[INFO: train.py:  558]: resist loss: tensor([ 3.1196], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8351879119873047
[INFO: train.py:  316]: Interation 9335 took 1.8391971588134766
[INFO: train.py:  558]: resist loss: tensor([ 7.2832], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8061838150024414
[INFO: train.py:  316]: Interation 9336 took 1.8099961280822754
[INFO: train.py:  558]: resist loss: tensor([ 2.6301], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9820990562438965
[INFO: train.py:  316]: Interation 9337 took 1.9861984252929688
[INFO: train.py:  558]: resist loss: tensor([ 1.8787], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9027292728424072
[INFO: train.py:  316]: Interation 9338 took 1.9065825939178467
[INFO: train.py:  558]: resist loss: tensor([ 8.1891], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6890437602996826
[INFO: train.py:  316]: Interation 9339 took 1.6928622722625732
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 535, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 535, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 607, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 607, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 679, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 679, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 548, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 548, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 612, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 612, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 610, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 610, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 625, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 625, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 599, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 599, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 505, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 505, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 446, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 446, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 416, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 416, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 179, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 179, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 758, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 758, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 849, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 849, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 661, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 661, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 780, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 780, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 752, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 752, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 755, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 755, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 634, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 634, 2])
[INFO: train.py:  338]:   [val] ade: 0.612
[INFO: train.py:  338]:   [val] ade_l: 1.349
[INFO: train.py:  338]:   [val] ade_nl: 1.122
[INFO: train.py:  338]:   [val] d_loss: 1.413
[INFO: train.py:  338]:   [val] fde: 1.188
[INFO: train.py:  338]:   [val] fde_l: 2.617
[INFO: train.py:  338]:   [val] fde_nl: 2.177
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.427
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.427
[INFO: train.py:  338]:   [val] resist_count: 3005.000
[INFO: train.py:  338]:   [val] resist_loss: 0.358
[INFO: train.py:  341]:   [train] ade: 0.618
[INFO: train.py:  341]:   [train] ade_l: 1.304
[INFO: train.py:  341]:   [train] ade_nl: 1.176
[INFO: train.py:  341]:   [train] d_loss: 1.410
[INFO: train.py:  341]:   [train] fde: 1.137
[INFO: train.py:  341]:   [train] fde_l: 2.398
[INFO: train.py:  341]:   [train] fde_nl: 2.162
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.382
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.382
[INFO: train.py:  341]:   [train] resist_count: 2976.000
[INFO: train.py:  341]:   [train] resist_loss: 0.177
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.2300], device='cuda:0')
[INFO: train.py:  310]: g step took 0.14638018608093262
[INFO: train.py:  316]: Interation 9340 took 8.679061889648438
[INFO: train.py:  279]: Starting epoch 219
[INFO: train.py:  280]: Epoch resist loss: tensor([ 248.4224])
[INFO: train.py:  558]: resist loss: tensor([ 3.9391], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3576345443725586
[INFO: train.py:  316]: Interation 9341 took 1.7364892959594727
[INFO: train.py:  558]: resist loss: tensor([ 2.4405], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6685020923614502
[INFO: train.py:  316]: Interation 9342 took 1.6766228675842285
[INFO: train.py:  558]: resist loss: tensor([ 15.2202], device='cuda:0')
[INFO: train.py:  310]: g step took 2.522120237350464
[INFO: train.py:  316]: Interation 9343 took 2.5262768268585205
[INFO: train.py:  558]: resist loss: tensor([ 0.5987], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8511977195739746
[INFO: train.py:  316]: Interation 9344 took 1.8659894466400146
[INFO: train.py:  558]: resist loss: tensor([ 0.6393], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6060004234313965
[INFO: train.py:  316]: Interation 9345 took 1.606391429901123
[INFO: train.py:  558]: resist loss: tensor([ 2.1226], device='cuda:0')
[INFO: train.py:  310]: g step took 1.869368553161621
[INFO: train.py:  316]: Interation 9346 took 1.8697476387023926
[INFO: train.py:  558]: resist loss: tensor([ 3.8557], device='cuda:0')
[INFO: train.py:  310]: g step took 2.142591953277588
[INFO: train.py:  316]: Interation 9347 took 2.1429693698883057
[INFO: train.py:  558]: resist loss: tensor([ 8.2695], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9223909378051758
[INFO: train.py:  316]: Interation 9348 took 1.9227395057678223
[INFO: train.py:  558]: resist loss: tensor([ 4.7962], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1571035385131836
[INFO: train.py:  316]: Interation 9349 took 2.16428542137146
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 489, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 489, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 625, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 625, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 656, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 656, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 656, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 656, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 477, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 477, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 505, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 505, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 510, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 510, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 438, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 438, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 584, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 584, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 625, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 625, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 602, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 602, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 194, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 194, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 880, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 880, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 962, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 962, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 886, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 886, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 598, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 598, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 841, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 841, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 693, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 693, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 763, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 763, 2])
[INFO: train.py:  338]:   [val] ade: 0.626
[INFO: train.py:  338]:   [val] ade_l: 1.377
[INFO: train.py:  338]:   [val] ade_nl: 1.146
[INFO: train.py:  338]:   [val] d_loss: 1.412
[INFO: train.py:  338]:   [val] fde: 1.251
[INFO: train.py:  338]:   [val] fde_l: 2.754
[INFO: train.py:  338]:   [val] fde_nl: 2.291
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.449
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.449
[INFO: train.py:  338]:   [val] resist_count: 2865.000
[INFO: train.py:  338]:   [val] resist_loss: 0.363
[INFO: train.py:  341]:   [train] ade: 0.610
[INFO: train.py:  341]:   [train] ade_l: 1.262
[INFO: train.py:  341]:   [train] ade_nl: 1.181
[INFO: train.py:  341]:   [train] d_loss: 1.422
[INFO: train.py:  341]:   [train] fde: 1.146
[INFO: train.py:  341]:   [train] fde_l: 2.370
[INFO: train.py:  341]:   [train] fde_nl: 2.219
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.379
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.379
[INFO: train.py:  341]:   [train] resist_count: 2915.000
[INFO: train.py:  341]:   [train] resist_loss: 0.181
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.3064], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9428768157958984
[INFO: train.py:  316]: Interation 9350 took 11.122558832168579
[INFO: train.py:  558]: resist loss: tensor([ 5.1725], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3395771980285645
[INFO: train.py:  316]: Interation 9351 took 2.339960813522339
[INFO: train.py:  558]: resist loss: tensor([ 12.6969], device='cuda:0')
[INFO: train.py:  310]: g step took 1.913783073425293
[INFO: train.py:  316]: Interation 9352 took 1.9251551628112793
[INFO: train.py:  558]: resist loss: tensor([ 6.8037], device='cuda:0')
[INFO: train.py:  310]: g step took 1.733696699142456
[INFO: train.py:  316]: Interation 9353 took 1.734159231185913
[INFO: train.py:  558]: resist loss: tensor([ 15.3513], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1494967937469482
[INFO: train.py:  316]: Interation 9354 took 2.149848699569702
[INFO: train.py:  558]: resist loss: tensor([ 9.0464], device='cuda:0')
[INFO: train.py:  310]: g step took 2.177619457244873
[INFO: train.py:  316]: Interation 9355 took 2.1781258583068848
[INFO: train.py:  558]: resist loss: tensor([ 5.6015], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8925397396087646
[INFO: train.py:  316]: Interation 9356 took 1.8929228782653809
[INFO: train.py:  558]: resist loss: tensor([ 4.1317], device='cuda:0')
[INFO: train.py:  310]: g step took 2.5272223949432373
[INFO: train.py:  316]: Interation 9357 took 2.531458854675293
[INFO: train.py:  558]: resist loss: tensor([ 0.5882], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9159901142120361
[INFO: train.py:  316]: Interation 9358 took 1.919933795928955
[INFO: train.py:  558]: resist loss: tensor([ 12.1092], device='cuda:0')
[INFO: train.py:  310]: g step took 2.099294900894165
[INFO: train.py:  316]: Interation 9359 took 2.1032025814056396
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 563, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 563, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 558, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 558, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 514, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 514, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 661, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 661, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 529, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 529, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 558, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 558, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 594, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 594, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 470, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 470, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 645, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 645, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 487, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 487, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 633, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 633, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 149, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 149, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 865, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 865, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 853, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 853, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 853, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 853, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 760, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 760, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 628, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 628, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 694, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 694, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 854, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 854, 2])
[INFO: train.py:  338]:   [val] ade: 0.651
[INFO: train.py:  338]:   [val] ade_l: 1.433
[INFO: train.py:  338]:   [val] ade_nl: 1.193
[INFO: train.py:  338]:   [val] d_loss: 1.416
[INFO: train.py:  338]:   [val] fde: 1.332
[INFO: train.py:  338]:   [val] fde_l: 2.932
[INFO: train.py:  338]:   [val] fde_nl: 2.440
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.489
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.489
[INFO: train.py:  338]:   [val] resist_count: 2723.000
[INFO: train.py:  338]:   [val] resist_loss: 0.305
[INFO: train.py:  341]:   [train] ade: 0.660
[INFO: train.py:  341]:   [train] ade_l: 1.379
[INFO: train.py:  341]:   [train] ade_nl: 1.264
[INFO: train.py:  341]:   [train] d_loss: 1.399
[INFO: train.py:  341]:   [train] fde: 1.271
[INFO: train.py:  341]:   [train] fde_l: 2.657
[INFO: train.py:  341]:   [train] fde_nl: 2.436
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.454
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.454
[INFO: train.py:  341]:   [train] resist_count: 2732.000
[INFO: train.py:  341]:   [train] resist_loss: 0.174
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 11.3892], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9555325508117676
[INFO: train.py:  316]: Interation 9360 took 10.651848077774048
[INFO: train.py:  558]: resist loss: tensor([ 13.0678], device='cuda:0')
[INFO: train.py:  310]: g step took 1.942586898803711
[INFO: train.py:  316]: Interation 9361 took 1.9466025829315186
[INFO: train.py:  558]: resist loss: tensor([ 10.0415], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9397382736206055
[INFO: train.py:  316]: Interation 9362 took 1.943108081817627
[INFO: train.py:  558]: resist loss: tensor([ 1.3695], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7276318073272705
[INFO: train.py:  316]: Interation 9363 took 1.7315068244934082
[INFO: train.py:  558]: resist loss: tensor([ 0.7937], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8587779998779297
[INFO: train.py:  316]: Interation 9364 took 1.8625481128692627
[INFO: train.py:  558]: resist loss: tensor([ 6.8947], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5460748672485352
[INFO: train.py:  316]: Interation 9365 took 1.5499916076660156
[INFO: train.py:  558]: resist loss: tensor([ 1.1174], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1526365280151367
[INFO: train.py:  316]: Interation 9366 took 2.156508445739746
[INFO: train.py:  558]: resist loss: tensor([ 15.0426], device='cuda:0')
[INFO: train.py:  310]: g step took 2.643913984298706
[INFO: train.py:  316]: Interation 9367 took 2.6479337215423584
[INFO: train.py:  558]: resist loss: tensor([ 0.7288], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7296736240386963
[INFO: train.py:  316]: Interation 9368 took 1.7337892055511475
[INFO: train.py:  558]: resist loss: tensor([ 8.4757], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9591648578643799
[INFO: train.py:  316]: Interation 9369 took 1.9629735946655273
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 529, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 529, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 552, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 552, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 621, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 621, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 495, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 495, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 594, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 594, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 550, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 550, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 553, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 553, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 581, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 581, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 525, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 525, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 606, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 606, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 576, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 576, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 179, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 179, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 961, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 961, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 837, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 837, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 848, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 848, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 960, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 960, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 767, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 767, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 746, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 746, 2])
[INFO: train.py:  338]:   [val] ade: 0.664
[INFO: train.py:  338]:   [val] ade_l: 1.462
[INFO: train.py:  338]:   [val] ade_nl: 1.216
[INFO: train.py:  338]:   [val] d_loss: 1.405
[INFO: train.py:  338]:   [val] fde: 1.395
[INFO: train.py:  338]:   [val] fde_l: 3.072
[INFO: train.py:  338]:   [val] fde_nl: 2.556
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.529
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.529
[INFO: train.py:  338]:   [val] resist_count: 2689.000
[INFO: train.py:  338]:   [val] resist_loss: 0.235
[INFO: train.py:  341]:   [train] ade: 0.639
[INFO: train.py:  341]:   [train] ade_l: 1.305
[INFO: train.py:  341]:   [train] ade_nl: 1.252
[INFO: train.py:  341]:   [train] d_loss: 1.404
[INFO: train.py:  341]:   [train] fde: 1.277
[INFO: train.py:  341]:   [train] fde_l: 2.608
[INFO: train.py:  341]:   [train] fde_nl: 2.502
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.431
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.431
[INFO: train.py:  341]:   [train] resist_count: 2568.000
[INFO: train.py:  341]:   [train] resist_loss: 0.128
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 10.5973], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9525082111358643
[INFO: train.py:  316]: Interation 9370 took 10.374813318252563
[INFO: train.py:  558]: resist loss: tensor([ 7.8454], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6983447074890137
[INFO: train.py:  316]: Interation 9371 took 1.7022302150726318
[INFO: train.py:  558]: resist loss: tensor([ 2.5988], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8992621898651123
[INFO: train.py:  316]: Interation 9372 took 1.9032042026519775
[INFO: train.py:  558]: resist loss: tensor([ 15.3084], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8351490497589111
[INFO: train.py:  316]: Interation 9373 took 1.839012622833252
[INFO: train.py:  558]: resist loss: tensor([ 6.3041], device='cuda:0')
[INFO: train.py:  310]: g step took 2.073181390762329
[INFO: train.py:  316]: Interation 9374 took 2.07712721824646
[INFO: train.py:  558]: resist loss: tensor([ 1.2235], device='cuda:0')
[INFO: train.py:  310]: g step took 2.219358444213867
[INFO: train.py:  316]: Interation 9375 took 2.223191022872925
[INFO: train.py:  558]: resist loss: tensor([ 9.9717], device='cuda:0')
[INFO: train.py:  310]: g step took 1.952683448791504
[INFO: train.py:  316]: Interation 9376 took 1.9565224647521973
[INFO: train.py:  558]: resist loss: tensor([ 2.3177], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5666298866271973
[INFO: train.py:  316]: Interation 9377 took 1.5704495906829834
[INFO: train.py:  558]: resist loss: tensor([ 1.1190], device='cuda:0')
[INFO: train.py:  310]: g step took 2.091989517211914
[INFO: train.py:  316]: Interation 9378 took 2.095937728881836
[INFO: train.py:  558]: resist loss: tensor([ 8.9427], device='cuda:0')
[INFO: train.py:  310]: g step took 2.098881959915161
[INFO: train.py:  316]: Interation 9379 took 2.1026899814605713
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 545, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 545, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 521, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 521, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 618, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 618, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 549, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 549, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 531, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 531, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 660, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 660, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 591, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 591, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 570, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 570, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 439, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 439, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 566, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 566, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 637, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 637, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 134, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 134, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 804, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 804, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 766, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 766, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 639, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 639, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 830, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 830, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 732, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 732, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 711, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 711, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 742, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 742, 2])
[INFO: train.py:  338]:   [val] ade: 0.630
[INFO: train.py:  338]:   [val] ade_l: 1.386
[INFO: train.py:  338]:   [val] ade_nl: 1.153
[INFO: train.py:  338]:   [val] d_loss: 1.416
[INFO: train.py:  338]:   [val] fde: 1.337
[INFO: train.py:  338]:   [val] fde_l: 2.945
[INFO: train.py:  338]:   [val] fde_nl: 2.450
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.468
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.468
[INFO: train.py:  338]:   [val] resist_count: 3287.000
[INFO: train.py:  338]:   [val] resist_loss: 0.323
[INFO: train.py:  341]:   [train] ade: 0.624
[INFO: train.py:  341]:   [train] ade_l: 1.322
[INFO: train.py:  341]:   [train] ade_nl: 1.183
[INFO: train.py:  341]:   [train] d_loss: 1.407
[INFO: train.py:  341]:   [train] fde: 1.270
[INFO: train.py:  341]:   [train] fde_l: 2.688
[INFO: train.py:  341]:   [train] fde_nl: 2.407
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.423
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.423
[INFO: train.py:  341]:   [train] resist_count: 2971.000
[INFO: train.py:  341]:   [train] resist_loss: 0.169
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 4.5026], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7250139713287354
[INFO: train.py:  316]: Interation 9380 took 10.219513654708862
[INFO: train.py:  558]: resist loss: tensor([ 0.6564], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7549889087677002
[INFO: train.py:  316]: Interation 9381 took 1.7587683200836182
[INFO: train.py:  558]: resist loss: tensor([ 2.6718], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8301012516021729
[INFO: train.py:  316]: Interation 9382 took 1.8340532779693604
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 7.8901], device='cuda:0')
[INFO: train.py:  310]: g step took 0.20349693298339844
[INFO: train.py:  316]: Interation 9383 took 0.20715093612670898
[INFO: train.py:  279]: Starting epoch 220
[INFO: train.py:  280]: Epoch resist loss: tensor([ 258.7487])
[INFO: train.py:  558]: resist loss: tensor([ 8.8883], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1261119842529297
[INFO: train.py:  316]: Interation 9384 took 2.498589277267456
[INFO: train.py:  558]: resist loss: tensor([ 0.8056], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8737432956695557
[INFO: train.py:  316]: Interation 9385 took 1.885179042816162
[INFO: train.py:  558]: resist loss: tensor([ 16.2670], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2209160327911377
[INFO: train.py:  316]: Interation 9386 took 2.221287727355957
[INFO: train.py:  558]: resist loss: tensor([ 1.4647], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8302347660064697
[INFO: train.py:  316]: Interation 9387 took 1.8306324481964111
[INFO: train.py:  558]: resist loss: tensor([ 0.9815], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5940728187561035
[INFO: train.py:  316]: Interation 9388 took 1.5982651710510254
[INFO: train.py:  558]: resist loss: tensor([ 11.3668], device='cuda:0')
[INFO: train.py:  310]: g step took 2.090751886367798
[INFO: train.py:  316]: Interation 9389 took 2.091169595718384
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 524, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 524, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 594, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 594, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 524, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 524, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 602, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 602, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 476, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 476, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 543, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 543, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 559, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 559, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 728, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 728, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 633, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 633, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 499, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 499, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 577, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 577, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 102, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 102, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 794, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 794, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 834, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 834, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 773, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 773, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 945, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 945, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 776, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 776, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 642, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 642, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 623, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 623, 2])
[INFO: train.py:  338]:   [val] ade: 0.688
[INFO: train.py:  338]:   [val] ade_l: 1.514
[INFO: train.py:  338]:   [val] ade_nl: 1.260
[INFO: train.py:  338]:   [val] d_loss: 1.405
[INFO: train.py:  338]:   [val] fde: 1.448
[INFO: train.py:  338]:   [val] fde_l: 3.188
[INFO: train.py:  338]:   [val] fde_nl: 2.653
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.558
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.558
[INFO: train.py:  338]:   [val] resist_count: 2651.000
[INFO: train.py:  338]:   [val] resist_loss: 0.255
[INFO: train.py:  341]:   [train] ade: 0.679
[INFO: train.py:  341]:   [train] ade_l: 1.385
[INFO: train.py:  341]:   [train] ade_nl: 1.332
[INFO: train.py:  341]:   [train] d_loss: 1.388
[INFO: train.py:  341]:   [train] fde: 1.366
[INFO: train.py:  341]:   [train] fde_l: 2.787
[INFO: train.py:  341]:   [train] fde_nl: 2.681
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.500
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.500
[INFO: train.py:  341]:   [train] resist_count: 2530.000
[INFO: train.py:  341]:   [train] resist_loss: 0.148
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.4049], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8542072772979736
[INFO: train.py:  316]: Interation 9390 took 10.45308256149292
[INFO: train.py:  558]: resist loss: tensor([ 2.3839], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7182722091674805
[INFO: train.py:  316]: Interation 9391 took 1.718646764755249
[INFO: train.py:  558]: resist loss: tensor([ 3.1472], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8399395942687988
[INFO: train.py:  316]: Interation 9392 took 1.8475937843322754
[INFO: train.py:  558]: resist loss: tensor([ 14.6361], device='cuda:0')
[INFO: train.py:  310]: g step took 2.305410623550415
[INFO: train.py:  316]: Interation 9393 took 2.3153367042541504
[INFO: train.py:  558]: resist loss: tensor([ 2.4707], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9062068462371826
[INFO: train.py:  316]: Interation 9394 took 1.9065284729003906
[INFO: train.py:  558]: resist loss: tensor([ 8.5533], device='cuda:0')
[INFO: train.py:  310]: g step took 2.024364709854126
[INFO: train.py:  316]: Interation 9395 took 2.024714946746826
[INFO: train.py:  558]: resist loss: tensor([ 0.7092], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0133111476898193
[INFO: train.py:  316]: Interation 9396 took 2.017303466796875
[INFO: train.py:  558]: resist loss: tensor([ 1.0523], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1205010414123535
[INFO: train.py:  316]: Interation 9397 took 2.1208252906799316
[INFO: train.py:  558]: resist loss: tensor([ 10.2132], device='cuda:0')
[INFO: train.py:  310]: g step took 1.722107172012329
[INFO: train.py:  316]: Interation 9398 took 1.7260699272155762
[INFO: train.py:  558]: resist loss: tensor([ 1.4898], device='cuda:0')
[INFO: train.py:  310]: g step took 1.819058895111084
[INFO: train.py:  316]: Interation 9399 took 1.819415807723999
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 717, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 717, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 459, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 459, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 509, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 509, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 638, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 638, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 558, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 558, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 544, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 544, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 496, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 496, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 483, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 483, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 505, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 505, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 738, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 738, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 533, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 533, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 181, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 181, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 653, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 653, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 916, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 916, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 662, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 662, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 699, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 699, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 806, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 806, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 789, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 789, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 830, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 830, 2])
[INFO: train.py:  338]:   [val] ade: 0.609
[INFO: train.py:  338]:   [val] ade_l: 1.341
[INFO: train.py:  338]:   [val] ade_nl: 1.116
[INFO: train.py:  338]:   [val] d_loss: 1.415
[INFO: train.py:  338]:   [val] fde: 1.314
[INFO: train.py:  338]:   [val] fde_l: 2.894
[INFO: train.py:  338]:   [val] fde_nl: 2.408
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.469
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.469
[INFO: train.py:  338]:   [val] resist_count: 2617.000
[INFO: train.py:  338]:   [val] resist_loss: 0.226
[INFO: train.py:  341]:   [train] ade: 0.610
[INFO: train.py:  341]:   [train] ade_l: 1.259
[INFO: train.py:  341]:   [train] ade_nl: 1.184
[INFO: train.py:  341]:   [train] d_loss: 1.393
[INFO: train.py:  341]:   [train] fde: 1.250
[INFO: train.py:  341]:   [train] fde_l: 2.579
[INFO: train.py:  341]:   [train] fde_nl: 2.426
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.403
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.403
[INFO: train.py:  341]:   [train] resist_count: 2522.000
[INFO: train.py:  341]:   [train] resist_loss: 0.129
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.3343], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9638609886169434
[INFO: train.py:  316]: Interation 9400 took 10.286981344223022
[INFO: train.py:  558]: resist loss: tensor([ 0.5301], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0048108100891113
[INFO: train.py:  316]: Interation 9401 took 2.008875608444214
[INFO: train.py:  558]: resist loss: tensor([ 0.5602], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9834623336791992
[INFO: train.py:  316]: Interation 9402 took 1.9873154163360596
[INFO: train.py:  558]: resist loss: tensor([ 0.5574], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9768319129943848
[INFO: train.py:  316]: Interation 9403 took 1.9807231426239014
[INFO: train.py:  558]: resist loss: tensor([ 5.4743], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1406478881835938
[INFO: train.py:  316]: Interation 9404 took 2.144591808319092
[INFO: train.py:  558]: resist loss: tensor([ 1.4494], device='cuda:0')
[INFO: train.py:  310]: g step took 2.112092971801758
[INFO: train.py:  316]: Interation 9405 took 2.1160197257995605
[INFO: train.py:  558]: resist loss: tensor([ 2.2984], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9564568996429443
[INFO: train.py:  316]: Interation 9406 took 1.960397481918335
[INFO: train.py:  558]: resist loss: tensor([ 6.8572], device='cuda:0')
[INFO: train.py:  310]: g step took 2.055982828140259
[INFO: train.py:  316]: Interation 9407 took 2.059828042984009
[INFO: train.py:  558]: resist loss: tensor([ 0.3695], device='cuda:0')
[INFO: train.py:  310]: g step took 2.240847587585449
[INFO: train.py:  316]: Interation 9408 took 2.2450077533721924
[INFO: train.py:  558]: resist loss: tensor([ 4.6107], device='cuda:0')
[INFO: train.py:  310]: g step took 1.984323501586914
[INFO: train.py:  316]: Interation 9409 took 1.9876906871795654
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 634, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 634, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 476, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 476, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 516, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 516, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 564, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 564, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 518, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 518, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 813, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 813, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 542, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 542, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 509, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 509, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 490, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 490, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 576, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 576, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 524, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 524, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 199, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 199, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 784, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 784, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 823, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 823, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 628, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 628, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 757, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 757, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 702, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 702, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 820, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 820, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 849, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 849, 2])
[INFO: train.py:  338]:   [val] ade: 0.626
[INFO: train.py:  338]:   [val] ade_l: 1.378
[INFO: train.py:  338]:   [val] ade_nl: 1.146
[INFO: train.py:  338]:   [val] d_loss: 1.406
[INFO: train.py:  338]:   [val] fde: 1.338
[INFO: train.py:  338]:   [val] fde_l: 2.946
[INFO: train.py:  338]:   [val] fde_nl: 2.452
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.472
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.472
[INFO: train.py:  338]:   [val] resist_count: 2689.000
[INFO: train.py:  338]:   [val] resist_loss: 0.261
[INFO: train.py:  341]:   [train] ade: 0.639
[INFO: train.py:  341]:   [train] ade_l: 1.341
[INFO: train.py:  341]:   [train] ade_nl: 1.221
[INFO: train.py:  341]:   [train] d_loss: 1.407
[INFO: train.py:  341]:   [train] fde: 1.286
[INFO: train.py:  341]:   [train] fde_l: 2.700
[INFO: train.py:  341]:   [train] fde_nl: 2.457
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.428
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.428
[INFO: train.py:  341]:   [train] resist_count: 2700.000
[INFO: train.py:  341]:   [train] resist_loss: 0.155
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 7.9792], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7647936344146729
[INFO: train.py:  316]: Interation 9410 took 10.068814516067505
[INFO: train.py:  558]: resist loss: tensor([ 1.4910], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8331530094146729
[INFO: train.py:  316]: Interation 9411 took 1.83674955368042
[INFO: train.py:  558]: resist loss: tensor([ 2.1271], device='cuda:0')
[INFO: train.py:  310]: g step took 1.955958366394043
[INFO: train.py:  316]: Interation 9412 took 1.9597256183624268
[INFO: train.py:  558]: resist loss: tensor([ 3.0008], device='cuda:0')
[INFO: train.py:  310]: g step took 2.077838897705078
[INFO: train.py:  316]: Interation 9413 took 2.0816843509674072
[INFO: train.py:  558]: resist loss: tensor([ 13.4257], device='cuda:0')
[INFO: train.py:  310]: g step took 2.205810070037842
[INFO: train.py:  316]: Interation 9414 took 2.209604024887085
[INFO: train.py:  558]: resist loss: tensor([ 1.0191], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2037127017974854
[INFO: train.py:  316]: Interation 9415 took 2.207510232925415
[INFO: train.py:  558]: resist loss: tensor([ 9.0446], device='cuda:0')
[INFO: train.py:  310]: g step took 2.095471143722534
[INFO: train.py:  316]: Interation 9416 took 2.0993449687957764
[INFO: train.py:  558]: resist loss: tensor([ 11.0346], device='cuda:0')
[INFO: train.py:  310]: g step took 2.189149856567383
[INFO: train.py:  316]: Interation 9417 took 2.192411184310913
[INFO: train.py:  558]: resist loss: tensor([ 9.3462], device='cuda:0')
[INFO: train.py:  310]: g step took 2.010411262512207
[INFO: train.py:  316]: Interation 9418 took 2.0143446922302246
[INFO: train.py:  558]: resist loss: tensor([ 1.5532], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0090556144714355
[INFO: train.py:  316]: Interation 9419 took 2.012911796569824
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 492, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 492, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 603, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 603, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 562, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 562, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 558, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 558, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 606, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 606, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 629, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 629, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 534, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 534, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 634, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 634, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 562, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 562, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 562, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 562, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 530, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 530, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 89, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 89, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 845, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 845, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 670, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 670, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 900, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 900, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 727, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 727, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 841, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 841, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 858, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 858, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 930, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 930, 2])
[INFO: train.py:  338]:   [val] ade: 0.641
[INFO: train.py:  338]:   [val] ade_l: 1.412
[INFO: train.py:  338]:   [val] ade_nl: 1.175
[INFO: train.py:  338]:   [val] d_loss: 1.416
[INFO: train.py:  338]:   [val] fde: 1.355
[INFO: train.py:  338]:   [val] fde_l: 2.984
[INFO: train.py:  338]:   [val] fde_nl: 2.483
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.487
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.487
[INFO: train.py:  338]:   [val] resist_count: 2853.000
[INFO: train.py:  338]:   [val] resist_loss: 0.250
[INFO: train.py:  341]:   [train] ade: 0.636
[INFO: train.py:  341]:   [train] ade_l: 1.359
[INFO: train.py:  341]:   [train] ade_nl: 1.195
[INFO: train.py:  341]:   [train] d_loss: 1.396
[INFO: train.py:  341]:   [train] fde: 1.266
[INFO: train.py:  341]:   [train] fde_l: 2.704
[INFO: train.py:  341]:   [train] fde_nl: 2.379
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.421
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.421
[INFO: train.py:  341]:   [train] resist_count: 3252.000
[INFO: train.py:  341]:   [train] resist_loss: 0.171
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 13.7983], device='cuda:0')
[INFO: train.py:  310]: g step took 2.344655752182007
[INFO: train.py:  316]: Interation 9420 took 10.804012537002563
[INFO: train.py:  558]: resist loss: tensor([ 1.5040], device='cuda:0')
[INFO: train.py:  310]: g step took 2.061971426010132
[INFO: train.py:  316]: Interation 9421 took 2.0662806034088135
[INFO: train.py:  558]: resist loss: tensor([ 1.3751], device='cuda:0')
[INFO: train.py:  310]: g step took 1.757154941558838
[INFO: train.py:  316]: Interation 9422 took 1.7608368396759033
[INFO: train.py:  558]: resist loss: tensor([ 3.8630], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0922141075134277
[INFO: train.py:  316]: Interation 9423 took 2.0960867404937744
[INFO: train.py:  558]: resist loss: tensor([ 9.7510], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7895960807800293
[INFO: train.py:  316]: Interation 9424 took 1.7936265468597412
[INFO: train.py:  558]: resist loss: tensor([ 2.6318], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9631850719451904
[INFO: train.py:  316]: Interation 9425 took 1.9671504497528076
[INFO: train.py:  558]: resist loss: tensor([ 1.2147], device='cuda:0')
[INFO: train.py:  310]: g step took 0.31020212173461914
[INFO: train.py:  316]: Interation 9426 took 0.31401681900024414
[INFO: train.py:  279]: Starting epoch 221
[INFO: train.py:  280]: Epoch resist loss: tensor([ 202.0358])
Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7fc4dd419518>>
Traceback (most recent call last):
  File "/data/xinjiey/Group_Navi_GAN/env/lib/python3.5/site-packages/torch/utils/data/dataloader.py", line 349, in __del__
    self._shutdown_workers()
  File "/data/xinjiey/Group_Navi_GAN/env/lib/python3.5/site-packages/torch/utils/data/dataloader.py", line 328, in _shutdown_workers
    self.worker_result_queue.get()
  File "/usr/lib/python3.5/multiprocessing/queues.py", line 345, in get
    return ForkingPickler.loads(res)
  File "/data/xinjiey/Group_Navi_GAN/env/lib/python3.5/site-packages/torch/multiprocessing/reductions.py", line 70, in rebuild_storage_fd
    fd = df.detach()
  File "/usr/lib/python3.5/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/usr/lib/python3.5/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 493, in Client
    answer_challenge(c, authkey)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 737, in answer_challenge
    response = connection.recv_bytes(256)        # reject large message
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
ConnectionResetError: [Errno 104] Connection reset by peer
[INFO: train.py:  558]: resist loss: tensor([ 8.1802], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9744889736175537
[INFO: train.py:  316]: Interation 9427 took 2.355506420135498
[INFO: train.py:  558]: resist loss: tensor([ 0.4088], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6531245708465576
[INFO: train.py:  316]: Interation 9428 took 1.674973964691162
[INFO: train.py:  558]: resist loss: tensor([ 10.1692], device='cuda:0')
[INFO: train.py:  310]: g step took 1.840540885925293
[INFO: train.py:  316]: Interation 9429 took 1.8450400829315186
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 399, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 399, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 604, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 604, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 637, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 637, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 578, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 578, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 603, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 603, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 592, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 592, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 608, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 608, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 524, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 524, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 539, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 539, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 431, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 431, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 652, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 652, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 194, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 194, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 717, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 717, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 958, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 958, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 636, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 636, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 639, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 639, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 777, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 777, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 766, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 766, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 919, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 919, 2])
[INFO: train.py:  338]:   [val] ade: 0.625
[INFO: train.py:  338]:   [val] ade_l: 1.375
[INFO: train.py:  338]:   [val] ade_nl: 1.144
[INFO: train.py:  338]:   [val] d_loss: 1.407
[INFO: train.py:  338]:   [val] fde: 1.342
[INFO: train.py:  338]:   [val] fde_l: 2.954
[INFO: train.py:  338]:   [val] fde_nl: 2.458
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.484
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.484
[INFO: train.py:  338]:   [val] resist_count: 2596.000
[INFO: train.py:  338]:   [val] resist_loss: 0.238
[INFO: train.py:  341]:   [train] ade: 0.613
[INFO: train.py:  341]:   [train] ade_l: 1.286
[INFO: train.py:  341]:   [train] ade_nl: 1.173
[INFO: train.py:  341]:   [train] d_loss: 1.407
[INFO: train.py:  341]:   [train] fde: 1.240
[INFO: train.py:  341]:   [train] fde_l: 2.599
[INFO: train.py:  341]:   [train] fde_nl: 2.371
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.399
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.399
[INFO: train.py:  341]:   [train] resist_count: 2608.000
[INFO: train.py:  341]:   [train] resist_loss: 0.151
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.0209], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2491109371185303
[INFO: train.py:  316]: Interation 9430 took 11.578999280929565
[INFO: train.py:  558]: resist loss: tensor([ 17.8441], device='cuda:0')
[INFO: train.py:  310]: g step took 2.6003968715667725
[INFO: train.py:  316]: Interation 9431 took 2.6007347106933594
[INFO: train.py:  558]: resist loss: tensor([ 12.1756], device='cuda:0')
[INFO: train.py:  310]: g step took 2.079091787338257
[INFO: train.py:  316]: Interation 9432 took 2.079460859298706
[INFO: train.py:  558]: resist loss: tensor([ 2.1233], device='cuda:0')
[INFO: train.py:  310]: g step took 2.070361614227295
[INFO: train.py:  316]: Interation 9433 took 2.070732355117798
[INFO: train.py:  558]: resist loss: tensor([ 10.8732], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9627957344055176
[INFO: train.py:  316]: Interation 9434 took 1.9631328582763672
[INFO: train.py:  558]: resist loss: tensor([ 9.8268], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0929248332977295
[INFO: train.py:  316]: Interation 9435 took 2.093478202819824
[INFO: train.py:  558]: resist loss: tensor([ 0.8599], device='cuda:0')
[INFO: train.py:  310]: g step took 1.819289207458496
[INFO: train.py:  316]: Interation 9436 took 1.8370792865753174
[INFO: train.py:  558]: resist loss: tensor([ 1.9343], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1756980419158936
[INFO: train.py:  316]: Interation 9437 took 2.1796226501464844
[INFO: train.py:  558]: resist loss: tensor([ 4.3664], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6242895126342773
[INFO: train.py:  316]: Interation 9438 took 1.6246824264526367
[INFO: train.py:  558]: resist loss: tensor([ 4.2992], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8318910598754883
[INFO: train.py:  316]: Interation 9439 took 1.8322179317474365
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 542, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 542, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 593, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 593, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 607, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 607, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 476, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 476, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 484, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 484, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 611, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 611, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 591, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 591, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 534, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 534, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 547, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 547, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 545, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 545, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 678, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 678, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 153, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 153, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 738, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 738, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 971, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 971, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 695, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 695, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 928, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 928, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 757, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 757, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 623, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 623, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 910, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 910, 2])
[INFO: train.py:  338]:   [val] ade: 0.632
[INFO: train.py:  338]:   [val] ade_l: 1.391
[INFO: train.py:  338]:   [val] ade_nl: 1.157
[INFO: train.py:  338]:   [val] d_loss: 1.402
[INFO: train.py:  338]:   [val] fde: 1.359
[INFO: train.py:  338]:   [val] fde_l: 2.991
[INFO: train.py:  338]:   [val] fde_nl: 2.489
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.495
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.495
[INFO: train.py:  338]:   [val] resist_count: 2704.000
[INFO: train.py:  338]:   [val] resist_loss: 0.231
[INFO: train.py:  341]:   [train] ade: 0.615
[INFO: train.py:  341]:   [train] ade_l: 1.264
[INFO: train.py:  341]:   [train] ade_nl: 1.197
[INFO: train.py:  341]:   [train] d_loss: 1.404
[INFO: train.py:  341]:   [train] fde: 1.272
[INFO: train.py:  341]:   [train] fde_l: 2.614
[INFO: train.py:  341]:   [train] fde_nl: 2.476
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.409
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.409
[INFO: train.py:  341]:   [train] resist_count: 2630.000
[INFO: train.py:  341]:   [train] resist_loss: 0.145
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 5.2026], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1170265674591064
[INFO: train.py:  316]: Interation 9440 took 10.81765866279602
[INFO: train.py:  558]: resist loss: tensor([ 8.6902], device='cuda:0')
[INFO: train.py:  310]: g step took 1.889296054840088
[INFO: train.py:  316]: Interation 9441 took 1.8896737098693848
[INFO: train.py:  558]: resist loss: tensor([ 7.4812], device='cuda:0')
[INFO: train.py:  310]: g step took 2.075416088104248
[INFO: train.py:  316]: Interation 9442 took 2.0757787227630615
[INFO: train.py:  558]: resist loss: tensor([ 0.3135], device='cuda:0')
[INFO: train.py:  310]: g step took 2.029043197631836
[INFO: train.py:  316]: Interation 9443 took 2.0293891429901123
[INFO: train.py:  558]: resist loss: tensor([ 11.8033], device='cuda:0')
[INFO: train.py:  310]: g step took 2.127704620361328
[INFO: train.py:  316]: Interation 9444 took 2.132096529006958
[INFO: train.py:  558]: resist loss: tensor([ 6.8197], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8568572998046875
[INFO: train.py:  316]: Interation 9445 took 1.8608317375183105
[INFO: train.py:  558]: resist loss: tensor([ 16.6520], device='cuda:0')
[INFO: train.py:  310]: g step took 2.148287773132324
[INFO: train.py:  316]: Interation 9446 took 2.152294874191284
[INFO: train.py:  558]: resist loss: tensor([ 7.6445], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2978432178497314
[INFO: train.py:  316]: Interation 9447 took 2.3018076419830322
[INFO: train.py:  558]: resist loss: tensor([ 3.3204], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7407371997833252
[INFO: train.py:  316]: Interation 9448 took 1.745225429534912
[INFO: train.py:  558]: resist loss: tensor([ 7.4858], device='cuda:0')
[INFO: train.py:  310]: g step took 1.985517978668213
[INFO: train.py:  316]: Interation 9449 took 1.989457130432129
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 582, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 582, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 586, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 586, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 651, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 651, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 452, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 452, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 599, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 599, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 615, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 615, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 508, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 508, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 578, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 578, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 470, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 470, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 578, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 578, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 607, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 607, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 135, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 135, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 791, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 791, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 667, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 667, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 743, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 743, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 757, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 757, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 884, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 884, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 667, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 667, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 774, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 774, 2])
[INFO: train.py:  338]:   [val] ade: 0.608
[INFO: train.py:  338]:   [val] ade_l: 1.338
[INFO: train.py:  338]:   [val] ade_nl: 1.113
[INFO: train.py:  338]:   [val] d_loss: 1.420
[INFO: train.py:  338]:   [val] fde: 1.257
[INFO: train.py:  338]:   [val] fde_l: 2.768
[INFO: train.py:  338]:   [val] fde_nl: 2.303
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.431
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.431
[INFO: train.py:  338]:   [val] resist_count: 2804.000
[INFO: train.py:  338]:   [val] resist_loss: 0.286
[INFO: train.py:  341]:   [train] ade: 0.607
[INFO: train.py:  341]:   [train] ade_l: 1.266
[INFO: train.py:  341]:   [train] ade_nl: 1.165
[INFO: train.py:  341]:   [train] d_loss: 1.405
[INFO: train.py:  341]:   [train] fde: 1.171
[INFO: train.py:  341]:   [train] fde_l: 2.444
[INFO: train.py:  341]:   [train] fde_nl: 2.250
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.375
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.375
[INFO: train.py:  341]:   [train] resist_count: 2934.000
[INFO: train.py:  341]:   [train] resist_loss: 0.178
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 8.6424], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0887529850006104
[INFO: train.py:  316]: Interation 9450 took 10.882482528686523
[INFO: train.py:  558]: resist loss: tensor([ 3.5515], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1133663654327393
[INFO: train.py:  316]: Interation 9451 took 2.1171908378601074
[INFO: train.py:  558]: resist loss: tensor([ 5.2279], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0289382934570312
[INFO: train.py:  316]: Interation 9452 took 2.0331695079803467
[INFO: train.py:  558]: resist loss: tensor([ 9.7946], device='cuda:0')
[INFO: train.py:  310]: g step took 2.193195104598999
[INFO: train.py:  316]: Interation 9453 took 2.196958303451538
[INFO: train.py:  558]: resist loss: tensor([ 1.9073], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8086016178131104
[INFO: train.py:  316]: Interation 9454 took 1.8124480247497559
[INFO: train.py:  558]: resist loss: tensor([ 6.3059], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5568146705627441
[INFO: train.py:  316]: Interation 9455 took 1.5600225925445557
[INFO: train.py:  558]: resist loss: tensor([ 7.4250], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0870420932769775
[INFO: train.py:  316]: Interation 9456 took 2.0908429622650146
[INFO: train.py:  558]: resist loss: tensor([ 1.4383], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1003942489624023
[INFO: train.py:  316]: Interation 9457 took 2.1043856143951416
[INFO: train.py:  558]: resist loss: tensor([ 2.2579], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7448389530181885
[INFO: train.py:  316]: Interation 9458 took 1.7487759590148926
[INFO: train.py:  558]: resist loss: tensor([ 9.6926], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1469528675079346
[INFO: train.py:  316]: Interation 9459 took 2.1505279541015625
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 503, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 503, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 643, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 643, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 706, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 706, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 524, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 524, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 478, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 478, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 476, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 476, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 570, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 570, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 676, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 676, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 599, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 599, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 562, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 562, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 521, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 521, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 103, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 103, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 785, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 785, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 715, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 715, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 863, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 863, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 934, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 934, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 965, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 965, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 861, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 861, 2])
[INFO: train.py:  338]:   [val] ade: 0.590
[INFO: train.py:  338]:   [val] ade_l: 1.298
[INFO: train.py:  338]:   [val] ade_nl: 1.080
[INFO: train.py:  338]:   [val] d_loss: 1.403
[INFO: train.py:  338]:   [val] fde: 1.220
[INFO: train.py:  338]:   [val] fde_l: 2.686
[INFO: train.py:  338]:   [val] fde_nl: 2.235
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.416
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.416
[INFO: train.py:  338]:   [val] resist_count: 2789.000
[INFO: train.py:  338]:   [val] resist_loss: 0.323
[INFO: train.py:  341]:   [train] ade: 0.599
[INFO: train.py:  341]:   [train] ade_l: 1.280
[INFO: train.py:  341]:   [train] ade_nl: 1.127
[INFO: train.py:  341]:   [train] d_loss: 1.399
[INFO: train.py:  341]:   [train] fde: 1.172
[INFO: train.py:  341]:   [train] fde_l: 2.502
[INFO: train.py:  341]:   [train] fde_nl: 2.204
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.381
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.381
[INFO: train.py:  341]:   [train] resist_count: 2657.000
[INFO: train.py:  341]:   [train] resist_loss: 0.139
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 3.0684], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2326674461364746
[INFO: train.py:  316]: Interation 9460 took 10.740163087844849
[INFO: train.py:  558]: resist loss: tensor([ 5.5862], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6555359363555908
[INFO: train.py:  316]: Interation 9461 took 1.6594278812408447
[INFO: train.py:  558]: resist loss: tensor([ 0.9296], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8309004306793213
[INFO: train.py:  316]: Interation 9462 took 1.8347439765930176
[INFO: train.py:  558]: resist loss: tensor([ 2.5724], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7355475425720215
[INFO: train.py:  316]: Interation 9463 took 1.7392947673797607
[INFO: train.py:  558]: resist loss: tensor([ 16.7276], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9988980293273926
[INFO: train.py:  316]: Interation 9464 took 2.003305196762085
[INFO: train.py:  558]: resist loss: tensor([ 0.9388], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6859993934631348
[INFO: train.py:  316]: Interation 9465 took 1.6898932456970215
[INFO: train.py:  558]: resist loss: tensor([ 11.8208], device='cuda:0')
[INFO: train.py:  310]: g step took 2.085710287094116
[INFO: train.py:  316]: Interation 9466 took 2.08952260017395
[INFO: train.py:  558]: resist loss: tensor([ 1.1788], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6816976070404053
[INFO: train.py:  316]: Interation 9467 took 1.6847271919250488
[INFO: train.py:  558]: resist loss: tensor([ 8.5311], device='cuda:0')
[INFO: train.py:  310]: g step took 1.94195556640625
[INFO: train.py:  316]: Interation 9468 took 1.9459877014160156
[INFO: train.py:  558]: resist loss: tensor([ 0.3374], device='cuda:0')
[INFO: train.py:  310]: g step took 0.2367539405822754
[INFO: train.py:  316]: Interation 9469 took 0.24064350128173828
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 462, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 462, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 628, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 628, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 577, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 577, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 512, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 512, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 572, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 572, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 555, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 555, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 668, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 668, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 587, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 587, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 527, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 527, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 564, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 564, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 595, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 595, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 114, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 114, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 815, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 815, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 807, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 807, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 722, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 722, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 726, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 726, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 902, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 902, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 740, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 740, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 707, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 707, 2])
[INFO: train.py:  338]:   [val] ade: 0.597
[INFO: train.py:  338]:   [val] ade_l: 1.315
[INFO: train.py:  338]:   [val] ade_nl: 1.094
[INFO: train.py:  338]:   [val] d_loss: 1.405
[INFO: train.py:  338]:   [val] fde: 1.258
[INFO: train.py:  338]:   [val] fde_l: 2.769
[INFO: train.py:  338]:   [val] fde_nl: 2.304
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.428
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.428
[INFO: train.py:  338]:   [val] resist_count: 2695.000
[INFO: train.py:  338]:   [val] resist_loss: 0.272
[INFO: train.py:  341]:   [train] ade: 0.614
[INFO: train.py:  341]:   [train] ade_l: 1.267
[INFO: train.py:  341]:   [train] ade_nl: 1.191
[INFO: train.py:  341]:   [train] d_loss: 1.412
[INFO: train.py:  341]:   [train] fde: 1.204
[INFO: train.py:  341]:   [train] fde_l: 2.485
[INFO: train.py:  341]:   [train] fde_nl: 2.337
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.409
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.409
[INFO: train.py:  341]:   [train] resist_count: 2613.000
[INFO: train.py:  341]:   [train] resist_loss: 0.150
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  279]: Starting epoch 222
[INFO: train.py:  280]: Epoch resist loss: tensor([ 268.4296])
[INFO: train.py:  558]: resist loss: tensor([ 0.7110], device='cuda:0')
[INFO: train.py:  310]: g step took 2.478907823562622
[INFO: train.py:  316]: Interation 9470 took 12.846226692199707
[INFO: train.py:  558]: resist loss: tensor([ 4.9168], device='cuda:0')
[INFO: train.py:  310]: g step took 2.470146417617798
[INFO: train.py:  316]: Interation 9471 took 2.4890971183776855
[INFO: train.py:  558]: resist loss: tensor([ 10.1448], device='cuda:0')
[INFO: train.py:  310]: g step took 2.069516658782959
[INFO: train.py:  316]: Interation 9472 took 2.0775911808013916
[INFO: train.py:  558]: resist loss: tensor([ 5.1675], device='cuda:0')
[INFO: train.py:  310]: g step took 2.5510001182556152
[INFO: train.py:  316]: Interation 9473 took 2.551431179046631
[INFO: train.py:  558]: resist loss: tensor([ 8.4620], device='cuda:0')
[INFO: train.py:  310]: g step took 2.409780502319336
[INFO: train.py:  316]: Interation 9474 took 2.4103386402130127
[INFO: train.py:  558]: resist loss: tensor([ 8.9316], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2460155487060547
[INFO: train.py:  316]: Interation 9475 took 2.2464754581451416
[INFO: train.py:  558]: resist loss: tensor([ 0.8876], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8454194068908691
[INFO: train.py:  316]: Interation 9476 took 1.8459687232971191
[INFO: train.py:  558]: resist loss: tensor([ 12.3685], device='cuda:0')
[INFO: train.py:  310]: g step took 2.6204471588134766
[INFO: train.py:  316]: Interation 9477 took 2.6208443641662598
[INFO: train.py:  558]: resist loss: tensor([ 5.6942], device='cuda:0')
[INFO: train.py:  310]: g step took 2.6924397945404053
[INFO: train.py:  316]: Interation 9478 took 2.6995763778686523
[INFO: train.py:  558]: resist loss: tensor([ 4.6219], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2563202381134033
[INFO: train.py:  316]: Interation 9479 took 2.2671077251434326
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 556, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 556, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 549, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 549, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 490, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 490, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 466, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 466, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 505, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 505, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 626, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 626, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 668, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 668, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 542, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 542, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 663, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 663, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 560, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 560, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 610, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 610, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 126, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 126, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 878, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 878, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 665, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 665, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 839, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 839, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 724, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 724, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 780, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 780, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 797, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 797, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 656, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 656, 2])
[INFO: train.py:  338]:   [val] ade: 0.611
[INFO: train.py:  338]:   [val] ade_l: 1.346
[INFO: train.py:  338]:   [val] ade_nl: 1.120
[INFO: train.py:  338]:   [val] d_loss: 1.418
[INFO: train.py:  338]:   [val] fde: 1.260
[INFO: train.py:  338]:   [val] fde_l: 2.774
[INFO: train.py:  338]:   [val] fde_nl: 2.308
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.428
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.428
[INFO: train.py:  338]:   [val] resist_count: 2773.000
[INFO: train.py:  338]:   [val] resist_loss: 0.302
[INFO: train.py:  341]:   [train] ade: 0.619
[INFO: train.py:  341]:   [train] ade_l: 1.294
[INFO: train.py:  341]:   [train] ade_nl: 1.187
[INFO: train.py:  341]:   [train] d_loss: 1.406
[INFO: train.py:  341]:   [train] fde: 1.200
[INFO: train.py:  341]:   [train] fde_l: 2.507
[INFO: train.py:  341]:   [train] fde_nl: 2.301
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.410
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.410
[INFO: train.py:  341]:   [train] resist_count: 2746.000
[INFO: train.py:  341]:   [train] resist_loss: 0.198
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 1.7719], device='cuda:0')
[INFO: train.py:  310]: g step took 2.5340421199798584
[INFO: train.py:  316]: Interation 9480 took 12.61191701889038
[INFO: train.py:  558]: resist loss: tensor([ 8.5462], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3732428550720215
[INFO: train.py:  316]: Interation 9481 took 2.3736178874969482
[INFO: train.py:  558]: resist loss: tensor([ 11.3736], device='cuda:0')
[INFO: train.py:  310]: g step took 2.451740264892578
[INFO: train.py:  316]: Interation 9482 took 2.452364206314087
[INFO: train.py:  558]: resist loss: tensor([ 1.2067], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1011364459991455
[INFO: train.py:  316]: Interation 9483 took 2.101608991622925
[INFO: train.py:  558]: resist loss: tensor([ 6.4288], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4033780097961426
[INFO: train.py:  316]: Interation 9484 took 2.403705596923828
[INFO: train.py:  558]: resist loss: tensor([ 0.9059], device='cuda:0')
[INFO: train.py:  310]: g step took 2.488741159439087
[INFO: train.py:  316]: Interation 9485 took 2.4891083240509033
[INFO: train.py:  558]: resist loss: tensor([ 7.6690], device='cuda:0')
[INFO: train.py:  310]: g step took 2.528128147125244
[INFO: train.py:  316]: Interation 9486 took 2.5317044258117676
[INFO: train.py:  558]: resist loss: tensor([ 2.3225], device='cuda:0')
[INFO: train.py:  310]: g step took 2.394848108291626
[INFO: train.py:  316]: Interation 9487 took 2.398815393447876
[INFO: train.py:  558]: resist loss: tensor([ 13.9847], device='cuda:0')
[INFO: train.py:  310]: g step took 2.6704652309417725
[INFO: train.py:  316]: Interation 9488 took 2.6743557453155518
[INFO: train.py:  558]: resist loss: tensor([ 4.5321], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2922780513763428
[INFO: train.py:  316]: Interation 9489 took 2.29626727104187
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 496, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 496, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 565, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 565, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 528, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 528, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 578, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 578, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 572, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 572, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 533, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 533, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 701, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 701, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 581, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 581, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 463, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 463, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 686, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 686, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 542, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 542, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 116, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 116, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 716, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 716, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 827, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 827, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 702, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 702, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 852, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 852, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 564, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 564, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 677, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 677, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 912, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 912, 2])
[INFO: train.py:  338]:   [val] ade: 0.594
[INFO: train.py:  338]:   [val] ade_l: 1.309
[INFO: train.py:  338]:   [val] ade_nl: 1.089
[INFO: train.py:  338]:   [val] d_loss: 1.420
[INFO: train.py:  338]:   [val] fde: 1.215
[INFO: train.py:  338]:   [val] fde_l: 2.674
[INFO: train.py:  338]:   [val] fde_nl: 2.225
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.416
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.416
[INFO: train.py:  338]:   [val] resist_count: 2891.000
[INFO: train.py:  338]:   [val] resist_loss: 0.295
[INFO: train.py:  341]:   [train] ade: 0.597
[INFO: train.py:  341]:   [train] ade_l: 1.217
[INFO: train.py:  341]:   [train] ade_nl: 1.170
[INFO: train.py:  341]:   [train] d_loss: 1.401
[INFO: train.py:  341]:   [train] fde: 1.169
[INFO: train.py:  341]:   [train] fde_l: 2.386
[INFO: train.py:  341]:   [train] fde_nl: 2.293
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.369
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.369
[INFO: train.py:  341]:   [train] resist_count: 2649.000
[INFO: train.py:  341]:   [train] resist_loss: 0.175
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 5.9884], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1416146755218506
[INFO: train.py:  316]: Interation 9490 took 11.797861576080322
[INFO: train.py:  558]: resist loss: tensor([ 2.5992], device='cuda:0')
[INFO: train.py:  310]: g step took 2.343045711517334
[INFO: train.py:  316]: Interation 9491 took 2.3467023372650146
[INFO: train.py:  558]: resist loss: tensor([ 4.9408], device='cuda:0')
[INFO: train.py:  310]: g step took 2.094550132751465
[INFO: train.py:  316]: Interation 9492 took 2.0984787940979004
[INFO: train.py:  558]: resist loss: tensor([ 0.6582], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0228004455566406
[INFO: train.py:  316]: Interation 9493 took 2.0262744426727295
[INFO: train.py:  558]: resist loss: tensor([ 4.1051], device='cuda:0')
[INFO: train.py:  310]: g step took 2.5625219345092773
[INFO: train.py:  316]: Interation 9494 took 2.5664303302764893
[INFO: train.py:  558]: resist loss: tensor([ 1.3815], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2544100284576416
[INFO: train.py:  316]: Interation 9495 took 2.2583556175231934
[INFO: train.py:  558]: resist loss: tensor([ 10.8794], device='cuda:0')
[INFO: train.py:  310]: g step took 2.408400058746338
[INFO: train.py:  316]: Interation 9496 took 2.4124319553375244
[INFO: train.py:  558]: resist loss: tensor([ 2.3952], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3295061588287354
[INFO: train.py:  316]: Interation 9497 took 2.332907199859619
[INFO: train.py:  558]: resist loss: tensor([ 16.5700], device='cuda:0')
[INFO: train.py:  310]: g step took 3.020125150680542
[INFO: train.py:  316]: Interation 9498 took 3.023283004760742
[INFO: train.py:  558]: resist loss: tensor([ 11.7552], device='cuda:0')
[INFO: train.py:  310]: g step took 2.199612617492676
[INFO: train.py:  316]: Interation 9499 took 2.2035679817199707
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 728, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 728, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 502, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 502, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 762, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 762, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 525, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 525, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 531, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 531, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 458, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 458, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 480, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 480, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 550, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 550, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 542, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 542, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 542, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 542, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 605, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 605, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 136, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 136, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 728, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 728, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 827, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 827, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 518, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 518, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 696, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 696, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 883, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 883, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 811, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 811, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 689, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 689, 2])
[INFO: train.py:  338]:   [val] ade: 0.620
[INFO: train.py:  338]:   [val] ade_l: 1.364
[INFO: train.py:  338]:   [val] ade_nl: 1.135
[INFO: train.py:  338]:   [val] d_loss: 1.415
[INFO: train.py:  338]:   [val] fde: 1.294
[INFO: train.py:  338]:   [val] fde_l: 2.849
[INFO: train.py:  338]:   [val] fde_nl: 2.371
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.448
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.448
[INFO: train.py:  338]:   [val] resist_count: 2973.000
[INFO: train.py:  338]:   [val] resist_loss: 0.342
[INFO: train.py:  341]:   [train] ade: 0.629
[INFO: train.py:  341]:   [train] ade_l: 1.354
[INFO: train.py:  341]:   [train] ade_nl: 1.175
[INFO: train.py:  341]:   [train] d_loss: 1.415
[INFO: train.py:  341]:   [train] fde: 1.231
[INFO: train.py:  341]:   [train] fde_l: 2.650
[INFO: train.py:  341]:   [train] fde_nl: 2.300
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.413
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.413
[INFO: train.py:  341]:   [train] resist_count: 2553.000
[INFO: train.py:  341]:   [train] resist_loss: 0.162
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 7.1205], device='cuda:0')
[INFO: train.py:  310]: g step took 2.310336112976074
[INFO: train.py:  316]: Interation 9500 took 12.004178285598755
[INFO: train.py:  558]: resist loss: tensor([ 8.5009], device='cuda:0')
[INFO: train.py:  310]: g step took 2.37180233001709
[INFO: train.py:  316]: Interation 9501 took 2.375223398208618
[INFO: train.py:  558]: resist loss: tensor([ 14.8906], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4490301609039307
[INFO: train.py:  316]: Interation 9502 took 2.4529383182525635
[INFO: train.py:  558]: resist loss: tensor([ 1.5876], device='cuda:0')
[INFO: train.py:  310]: g step took 2.348522186279297
[INFO: train.py:  316]: Interation 9503 took 2.3524341583251953
[INFO: train.py:  558]: resist loss: tensor([ 11.2542], device='cuda:0')
[INFO: train.py:  310]: g step took 2.6160011291503906
[INFO: train.py:  316]: Interation 9504 took 2.6198973655700684
[INFO: train.py:  558]: resist loss: tensor([ 1.3206], device='cuda:0')
[INFO: train.py:  310]: g step took 2.234588861465454
[INFO: train.py:  316]: Interation 9505 took 2.2386505603790283
[INFO: train.py:  558]: resist loss: tensor([ 6.0222], device='cuda:0')
[INFO: train.py:  310]: g step took 2.016725778579712
[INFO: train.py:  316]: Interation 9506 took 2.0207502841949463
[INFO: train.py:  558]: resist loss: tensor([ 7.0010], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8592822551727295
[INFO: train.py:  316]: Interation 9507 took 1.8632147312164307
[INFO: train.py:  558]: resist loss: tensor([ 6.2995], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1964616775512695
[INFO: train.py:  316]: Interation 9508 took 2.2003414630889893
[INFO: train.py:  558]: resist loss: tensor([ 1.0301], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1446473598480225
[INFO: train.py:  316]: Interation 9509 took 2.147885799407959
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 582, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 582, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 537, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 537, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 499, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 499, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 684, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 684, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 508, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 508, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 582, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 582, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 516, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 516, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 615, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 615, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 524, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 524, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 540, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 540, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 608, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 608, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 166, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 166, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 634, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 634, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 790, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 790, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 699, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 699, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 861, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 861, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 758, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 758, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 1015, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 1015, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 869, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 869, 2])
[INFO: train.py:  338]:   [val] ade: 0.621
[INFO: train.py:  338]:   [val] ade_l: 1.367
[INFO: train.py:  338]:   [val] ade_nl: 1.137
[INFO: train.py:  338]:   [val] d_loss: 1.407
[INFO: train.py:  338]:   [val] fde: 1.308
[INFO: train.py:  338]:   [val] fde_l: 2.880
[INFO: train.py:  338]:   [val] fde_nl: 2.397
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.459
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.459
[INFO: train.py:  338]:   [val] resist_count: 3518.000
[INFO: train.py:  338]:   [val] resist_loss: 0.275
[INFO: train.py:  341]:   [train] ade: 0.615
[INFO: train.py:  341]:   [train] ade_l: 1.298
[INFO: train.py:  341]:   [train] ade_nl: 1.169
[INFO: train.py:  341]:   [train] d_loss: 1.386
[INFO: train.py:  341]:   [train] fde: 1.219
[INFO: train.py:  341]:   [train] fde_l: 2.573
[INFO: train.py:  341]:   [train] fde_nl: 2.318
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.395
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.395
[INFO: train.py:  341]:   [train] resist_count: 3254.000
[INFO: train.py:  341]:   [train] resist_loss: 0.165
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 5.5244], device='cuda:0')
[INFO: train.py:  310]: g step took 2.235682725906372
[INFO: train.py:  316]: Interation 9510 took 12.618574380874634
[INFO: train.py:  558]: resist loss: tensor([ 4.1885], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0061891078948975
[INFO: train.py:  316]: Interation 9511 took 2.0101094245910645
[INFO: train.py:  558]: resist loss: tensor([ 1.4074], device='cuda:0')
[INFO: train.py:  310]: g step took 0.32610487937927246
[INFO: train.py:  316]: Interation 9512 took 0.3300635814666748
[INFO: train.py:  279]: Starting epoch 223
[INFO: train.py:  280]: Epoch resist loss: tensor([ 258.0680])
[INFO: train.py:  558]: resist loss: tensor([ 11.7563], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3716766834259033
[INFO: train.py:  316]: Interation 9513 took 2.7509565353393555
[INFO: train.py:  558]: resist loss: tensor([ 1.1586], device='cuda:0')
[INFO: train.py:  310]: g step took 2.681349515914917
[INFO: train.py:  316]: Interation 9514 took 2.689713954925537
[INFO: train.py:  558]: resist loss: tensor([ 2.4623], device='cuda:0')
[INFO: train.py:  310]: g step took 2.206547260284424
[INFO: train.py:  316]: Interation 9515 took 2.206925392150879
[INFO: train.py:  558]: resist loss: tensor([ 2.5965], device='cuda:0')
[INFO: train.py:  310]: g step took 2.6261303424835205
[INFO: train.py:  316]: Interation 9516 took 2.632521152496338
[INFO: train.py:  558]: resist loss: tensor([ 1.4951], device='cuda:0')
[INFO: train.py:  310]: g step took 2.120673418045044
[INFO: train.py:  316]: Interation 9517 took 2.121023654937744
[INFO: train.py:  558]: resist loss: tensor([ 1.2716], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3066952228546143
[INFO: train.py:  316]: Interation 9518 took 2.3070194721221924
[INFO: train.py:  558]: resist loss: tensor([ 1.9797], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2563424110412598
[INFO: train.py:  316]: Interation 9519 took 2.2606325149536133
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 481, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 481, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 583, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 583, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 578, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 578, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 499, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 499, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 542, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 542, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 627, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 627, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 490, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 490, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 670, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 670, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 618, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 618, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 478, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 478, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 666, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 666, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 129, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 129, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 649, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 649, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 756, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 756, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 916, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 916, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 807, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 807, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 576, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 576, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 775, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 775, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 869, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 869, 2])
[INFO: train.py:  338]:   [val] ade: 0.602
[INFO: train.py:  338]:   [val] ade_l: 1.326
[INFO: train.py:  338]:   [val] ade_nl: 1.104
[INFO: train.py:  338]:   [val] d_loss: 1.405
[INFO: train.py:  338]:   [val] fde: 1.294
[INFO: train.py:  338]:   [val] fde_l: 2.848
[INFO: train.py:  338]:   [val] fde_nl: 2.370
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.455
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.455
[INFO: train.py:  338]:   [val] resist_count: 2585.000
[INFO: train.py:  338]:   [val] resist_loss: 0.223
[INFO: train.py:  341]:   [train] ade: 0.592
[INFO: train.py:  341]:   [train] ade_l: 1.261
[INFO: train.py:  341]:   [train] ade_nl: 1.114
[INFO: train.py:  341]:   [train] d_loss: 1.406
[INFO: train.py:  341]:   [train] fde: 1.218
[INFO: train.py:  341]:   [train] fde_l: 2.597
[INFO: train.py:  341]:   [train] fde_nl: 2.294
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.386
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.386
[INFO: train.py:  341]:   [train] resist_count: 2480.000
[INFO: train.py:  341]:   [train] resist_loss: 0.144
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.9249], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6579413414001465
[INFO: train.py:  316]: Interation 9520 took 11.103630781173706
[INFO: train.py:  558]: resist loss: tensor([ 11.4380], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7209532260894775
[INFO: train.py:  316]: Interation 9521 took 1.7317631244659424
[INFO: train.py:  558]: resist loss: tensor([ 1.6369], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9432177543640137
[INFO: train.py:  316]: Interation 9522 took 1.9599270820617676
[INFO: train.py:  558]: resist loss: tensor([ 5.9413], device='cuda:0')
[INFO: train.py:  310]: g step took 1.696035385131836
[INFO: train.py:  316]: Interation 9523 took 1.6964130401611328
[INFO: train.py:  558]: resist loss: tensor([ 8.1031], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2760157585144043
[INFO: train.py:  316]: Interation 9524 took 2.2764017581939697
[INFO: train.py:  558]: resist loss: tensor([ 7.6381], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9270820617675781
[INFO: train.py:  316]: Interation 9525 took 1.9275081157684326
[INFO: train.py:  558]: resist loss: tensor([ 1.8535], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1600801944732666
[INFO: train.py:  316]: Interation 9526 took 2.160538673400879
[INFO: train.py:  558]: resist loss: tensor([ 1.5475], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5321040153503418
[INFO: train.py:  316]: Interation 9527 took 1.5324161052703857
[INFO: train.py:  558]: resist loss: tensor([ 13.5515], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1683738231658936
[INFO: train.py:  316]: Interation 9528 took 2.1687538623809814
[INFO: train.py:  558]: resist loss: tensor([ 16.7839], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4167239665985107
[INFO: train.py:  316]: Interation 9529 took 2.4210596084594727
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 606, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 606, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 516, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 516, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 556, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 556, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 529, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 529, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 523, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 523, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 708, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 708, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 472, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 472, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 453, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 453, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 698, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 698, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 558, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 558, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 607, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 607, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 135, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 135, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 695, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 695, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 833, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 833, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 806, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 806, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 785, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 785, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 822, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 822, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 680, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 680, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 740, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 740, 2])
[INFO: train.py:  338]:   [val] ade: 0.644
[INFO: train.py:  338]:   [val] ade_l: 1.418
[INFO: train.py:  338]:   [val] ade_nl: 1.180
[INFO: train.py:  338]:   [val] d_loss: 1.413
[INFO: train.py:  338]:   [val] fde: 1.297
[INFO: train.py:  338]:   [val] fde_l: 2.857
[INFO: train.py:  338]:   [val] fde_nl: 2.377
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.474
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.474
[INFO: train.py:  338]:   [val] resist_count: 2473.000
[INFO: train.py:  338]:   [val] resist_loss: 0.235
[INFO: train.py:  341]:   [train] ade: 0.655
[INFO: train.py:  341]:   [train] ade_l: 1.351
[INFO: train.py:  341]:   [train] ade_nl: 1.270
[INFO: train.py:  341]:   [train] d_loss: 1.390
[INFO: train.py:  341]:   [train] fde: 1.228
[INFO: train.py:  341]:   [train] fde_l: 2.534
[INFO: train.py:  341]:   [train] fde_nl: 2.382
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.444
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.444
[INFO: train.py:  341]:   [train] resist_count: 2580.000
[INFO: train.py:  341]:   [train] resist_loss: 0.142
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 8.0614], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8015072345733643
[INFO: train.py:  316]: Interation 9530 took 10.357580423355103
[INFO: train.py:  558]: resist loss: tensor([ 15.1358], device='cuda:0')
[INFO: train.py:  310]: g step took 2.050281286239624
[INFO: train.py:  316]: Interation 9531 took 2.0539848804473877
[INFO: train.py:  558]: resist loss: tensor([ 5.8913], device='cuda:0')
[INFO: train.py:  310]: g step took 1.613739252090454
[INFO: train.py:  316]: Interation 9532 took 1.6171298027038574
[INFO: train.py:  558]: resist loss: tensor([ 11.0104], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9089281558990479
[INFO: train.py:  316]: Interation 9533 took 1.9121711254119873
[INFO: train.py:  558]: resist loss: tensor([ 0.8072], device='cuda:0')
[INFO: train.py:  310]: g step took 2.017432928085327
[INFO: train.py:  316]: Interation 9534 took 2.0214619636535645
[INFO: train.py:  558]: resist loss: tensor([ 0.9045], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1009633541107178
[INFO: train.py:  316]: Interation 9535 took 2.1049611568450928
[INFO: train.py:  558]: resist loss: tensor([ 0.8934], device='cuda:0')
[INFO: train.py:  310]: g step took 1.774564504623413
[INFO: train.py:  316]: Interation 9536 took 1.7785882949829102
[INFO: train.py:  558]: resist loss: tensor([ 6.8412], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8001744747161865
[INFO: train.py:  316]: Interation 9537 took 1.8041162490844727
[INFO: train.py:  558]: resist loss: tensor([ 7.8959], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4137134552001953
[INFO: train.py:  316]: Interation 9538 took 2.41736102104187
[INFO: train.py:  558]: resist loss: tensor([ 13.0531], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0729141235351562
[INFO: train.py:  316]: Interation 9539 took 2.0766959190368652
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 528, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 528, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 575, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 575, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 518, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 518, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 614, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 614, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 696, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 696, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 547, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 547, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 578, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 578, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 577, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 577, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 524, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 524, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 538, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 538, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 560, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 560, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 106, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 106, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 917, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 917, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 640, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 640, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 645, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 645, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 989, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 989, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 670, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 670, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 796, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 796, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 744, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 744, 2])
[INFO: train.py:  338]:   [val] ade: 0.636
[INFO: train.py:  338]:   [val] ade_l: 1.401
[INFO: train.py:  338]:   [val] ade_nl: 1.166
[INFO: train.py:  338]:   [val] d_loss: 1.415
[INFO: train.py:  338]:   [val] fde: 1.379
[INFO: train.py:  338]:   [val] fde_l: 3.037
[INFO: train.py:  338]:   [val] fde_nl: 2.527
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.501
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.501
[INFO: train.py:  338]:   [val] resist_count: 2664.000
[INFO: train.py:  338]:   [val] resist_loss: 0.244
[INFO: train.py:  341]:   [train] ade: 0.624
[INFO: train.py:  341]:   [train] ade_l: 1.317
[INFO: train.py:  341]:   [train] ade_nl: 1.185
[INFO: train.py:  341]:   [train] d_loss: 1.388
[INFO: train.py:  341]:   [train] fde: 1.287
[INFO: train.py:  341]:   [train] fde_l: 2.715
[INFO: train.py:  341]:   [train] fde_nl: 2.445
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.420
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.420
[INFO: train.py:  341]:   [train] resist_count: 2638.000
[INFO: train.py:  341]:   [train] resist_loss: 0.156
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 8.1223], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1257054805755615
[INFO: train.py:  316]: Interation 9540 took 10.480573892593384
[INFO: train.py:  558]: resist loss: tensor([ 1.3768], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7820110321044922
[INFO: train.py:  316]: Interation 9541 took 1.785079002380371
[INFO: train.py:  558]: resist loss: tensor([ 3.1527], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9908638000488281
[INFO: train.py:  316]: Interation 9542 took 1.9950242042541504
[INFO: train.py:  558]: resist loss: tensor([ 12.6806], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2957170009613037
[INFO: train.py:  316]: Interation 9543 took 2.2995595932006836
[INFO: train.py:  558]: resist loss: tensor([ 2.4214], device='cuda:0')
[INFO: train.py:  310]: g step took 1.871824026107788
[INFO: train.py:  316]: Interation 9544 took 1.875675916671753
[INFO: train.py:  558]: resist loss: tensor([ 0.6755], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8102672100067139
[INFO: train.py:  316]: Interation 9545 took 1.8140897750854492
[INFO: train.py:  558]: resist loss: tensor([ 0.1503], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6243722438812256
[INFO: train.py:  316]: Interation 9546 took 1.628100872039795
[INFO: train.py:  558]: resist loss: tensor([ 4.4229], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2311222553253174
[INFO: train.py:  316]: Interation 9547 took 2.2349650859832764
[INFO: train.py:  558]: resist loss: tensor([ 9.0653], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9072015285491943
[INFO: train.py:  316]: Interation 9548 took 1.9109487533569336
[INFO: train.py:  558]: resist loss: tensor([ 4.9391], device='cuda:0')
[INFO: train.py:  310]: g step took 2.280841588973999
[INFO: train.py:  316]: Interation 9549 took 2.2845723628997803
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 517, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 517, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 583, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 583, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 548, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 548, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 656, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 656, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 496, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 496, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 643, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 643, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 514, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 514, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 590, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 590, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 519, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 519, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 640, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 640, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 505, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 505, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 150, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 150, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 593, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 593, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 942, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 942, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 788, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 788, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 736, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 736, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 617, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 617, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 597, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 597, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 837, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 837, 2])
[INFO: train.py:  338]:   [val] ade: 0.596
[INFO: train.py:  338]:   [val] ade_l: 1.313
[INFO: train.py:  338]:   [val] ade_nl: 1.092
[INFO: train.py:  338]:   [val] d_loss: 1.401
[INFO: train.py:  338]:   [val] fde: 1.260
[INFO: train.py:  338]:   [val] fde_l: 2.774
[INFO: train.py:  338]:   [val] fde_nl: 2.308
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.435
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.435
[INFO: train.py:  338]:   [val] resist_count: 2886.000
[INFO: train.py:  338]:   [val] resist_loss: 0.286
[INFO: train.py:  341]:   [train] ade: 0.593
[INFO: train.py:  341]:   [train] ade_l: 1.255
[INFO: train.py:  341]:   [train] ade_nl: 1.123
[INFO: train.py:  341]:   [train] d_loss: 1.394
[INFO: train.py:  341]:   [train] fde: 1.193
[INFO: train.py:  341]:   [train] fde_l: 2.525
[INFO: train.py:  341]:   [train] fde_nl: 2.261
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.389
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.389
[INFO: train.py:  341]:   [train] resist_count: 2468.000
[INFO: train.py:  341]:   [train] resist_loss: 0.142
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.6180], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9945526123046875
[INFO: train.py:  316]: Interation 9550 took 10.23973822593689
[INFO: train.py:  558]: resist loss: tensor([ 15.1627], device='cuda:0')
[INFO: train.py:  310]: g step took 2.139716625213623
[INFO: train.py:  316]: Interation 9551 took 2.143662929534912
[INFO: train.py:  558]: resist loss: tensor([ 9.3715], device='cuda:0')
[INFO: train.py:  310]: g step took 2.111673355102539
[INFO: train.py:  316]: Interation 9552 took 2.1155529022216797
[INFO: train.py:  558]: resist loss: tensor([ 5.2265], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7075448036193848
[INFO: train.py:  316]: Interation 9553 took 1.7114272117614746
[INFO: train.py:  558]: resist loss: tensor([ 11.0289], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0393965244293213
[INFO: train.py:  316]: Interation 9554 took 2.043407440185547
[INFO: train.py:  558]: resist loss: tensor([ 0.1705], device='cuda:0')
[INFO: train.py:  310]: g step took 0.1988239288330078
[INFO: train.py:  316]: Interation 9555 took 0.20250296592712402
[INFO: train.py:  279]: Starting epoch 224
[INFO: train.py:  280]: Epoch resist loss: tensor([ 253.2179])
[INFO: train.py:  558]: resist loss: tensor([ 7.1110], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8566796779632568
[INFO: train.py:  316]: Interation 9556 took 2.264639139175415
[INFO: train.py:  558]: resist loss: tensor([ 0.2298], device='cuda:0')
[INFO: train.py:  310]: g step took 1.805964708328247
[INFO: train.py:  316]: Interation 9557 took 1.810624122619629
[INFO: train.py:  558]: resist loss: tensor([ 2.6988], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0404226779937744
[INFO: train.py:  316]: Interation 9558 took 2.0407330989837646
[INFO: train.py:  558]: resist loss: tensor([ 8.0672], device='cuda:0')
[INFO: train.py:  310]: g step took 2.025139570236206
[INFO: train.py:  316]: Interation 9559 took 2.0457515716552734
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 625, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 625, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 523, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 523, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 662, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 662, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 538, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 538, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 503, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 503, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 540, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 540, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 582, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 582, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 490, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 490, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 610, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 610, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 590, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 590, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 506, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 506, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 192, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 192, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 920, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 920, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 840, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 840, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 788, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 788, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 828, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 828, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 726, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 726, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 828, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 828, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 766, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 766, 2])
[INFO: train.py:  338]:   [val] ade: 0.669
[INFO: train.py:  338]:   [val] ade_l: 1.472
[INFO: train.py:  338]:   [val] ade_nl: 1.225
[INFO: train.py:  338]:   [val] d_loss: 1.414
[INFO: train.py:  338]:   [val] fde: 1.340
[INFO: train.py:  338]:   [val] fde_l: 2.949
[INFO: train.py:  338]:   [val] fde_nl: 2.454
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.481
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.481
[INFO: train.py:  338]:   [val] resist_count: 3303.000
[INFO: train.py:  338]:   [val] resist_loss: 0.344
[INFO: train.py:  341]:   [train] ade: 0.687
[INFO: train.py:  341]:   [train] ade_l: 1.499
[INFO: train.py:  341]:   [train] ade_nl: 1.268
[INFO: train.py:  341]:   [train] d_loss: 1.397
[INFO: train.py:  341]:   [train] fde: 1.294
[INFO: train.py:  341]:   [train] fde_l: 2.823
[INFO: train.py:  341]:   [train] fde_nl: 2.389
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.458
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.458
[INFO: train.py:  341]:   [train] resist_count: 3545.000
[INFO: train.py:  341]:   [train] resist_loss: 0.218
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.4381], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7991609573364258
[INFO: train.py:  316]: Interation 9560 took 10.418826818466187
[INFO: train.py:  558]: resist loss: tensor([ 4.4485], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8982744216918945
[INFO: train.py:  316]: Interation 9561 took 1.898674488067627
[INFO: train.py:  558]: resist loss: tensor([ 1.0759], device='cuda:0')
[INFO: train.py:  310]: g step took 2.045565128326416
[INFO: train.py:  316]: Interation 9562 took 2.045910596847534
[INFO: train.py:  558]: resist loss: tensor([ 0.9993], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9190900325775146
[INFO: train.py:  316]: Interation 9563 took 1.9194903373718262
[INFO: train.py:  558]: resist loss: tensor([ 16.1988], device='cuda:0')
[INFO: train.py:  310]: g step took 2.21537709236145
[INFO: train.py:  316]: Interation 9564 took 2.225886583328247
[INFO: train.py:  558]: resist loss: tensor([ 6.2106], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8827342987060547
[INFO: train.py:  316]: Interation 9565 took 1.8831291198730469
[INFO: train.py:  558]: resist loss: tensor([ 10.4285], device='cuda:0')
[INFO: train.py:  310]: g step took 2.467191457748413
[INFO: train.py:  316]: Interation 9566 took 2.4675490856170654
[INFO: train.py:  558]: resist loss: tensor([ 2.0833], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3518879413604736
[INFO: train.py:  316]: Interation 9567 took 2.359358787536621
[INFO: train.py:  558]: resist loss: tensor([ 0.8476], device='cuda:0')
[INFO: train.py:  310]: g step took 2.05804705619812
[INFO: train.py:  316]: Interation 9568 took 2.0584347248077393
[INFO: train.py:  558]: resist loss: tensor([ 4.7496], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0936646461486816
[INFO: train.py:  316]: Interation 9569 took 2.0940189361572266
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 522, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 522, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 543, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 543, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 610, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 610, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 620, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 620, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 529, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 529, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 518, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 518, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 495, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 495, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 587, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 587, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 599, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 599, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 594, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 594, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 597, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 597, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 147, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 147, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 740, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 740, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 666, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 666, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 754, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 754, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 880, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 880, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 790, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 790, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 773, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 773, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 851, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 851, 2])
[INFO: train.py:  338]:   [val] ade: 0.580
[INFO: train.py:  338]:   [val] ade_l: 1.278
[INFO: train.py:  338]:   [val] ade_nl: 1.063
[INFO: train.py:  338]:   [val] d_loss: 1.412
[INFO: train.py:  338]:   [val] fde: 1.170
[INFO: train.py:  338]:   [val] fde_l: 2.577
[INFO: train.py:  338]:   [val] fde_nl: 2.144
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.404
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.404
[INFO: train.py:  338]:   [val] resist_count: 2788.000
[INFO: train.py:  338]:   [val] resist_loss: 0.287
[INFO: train.py:  341]:   [train] ade: 0.585
[INFO: train.py:  341]:   [train] ade_l: 1.248
[INFO: train.py:  341]:   [train] ade_nl: 1.100
[INFO: train.py:  341]:   [train] d_loss: 1.396
[INFO: train.py:  341]:   [train] fde: 1.101
[INFO: train.py:  341]:   [train] fde_l: 2.350
[INFO: train.py:  341]:   [train] fde_nl: 2.071
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.355
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.355
[INFO: train.py:  341]:   [train] resist_count: 2807.000
[INFO: train.py:  341]:   [train] resist_loss: 0.165
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 5.1367], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9529407024383545
[INFO: train.py:  316]: Interation 9570 took 10.257804870605469
[INFO: train.py:  558]: resist loss: tensor([ 6.8035], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8850600719451904
[INFO: train.py:  316]: Interation 9571 took 1.8854422569274902
[INFO: train.py:  558]: resist loss: tensor([ 8.8231], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1594927310943604
[INFO: train.py:  316]: Interation 9572 took 2.1635286808013916
[INFO: train.py:  558]: resist loss: tensor([ 3.5035], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7510216236114502
[INFO: train.py:  316]: Interation 9573 took 1.7547564506530762
[INFO: train.py:  558]: resist loss: tensor([ 11.5127], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0592713356018066
[INFO: train.py:  316]: Interation 9574 took 2.0632987022399902
[INFO: train.py:  558]: resist loss: tensor([ 2.4569], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9514431953430176
[INFO: train.py:  316]: Interation 9575 took 1.9554345607757568
[INFO: train.py:  558]: resist loss: tensor([ 0.1502], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8449015617370605
[INFO: train.py:  316]: Interation 9576 took 1.8487434387207031
[INFO: train.py:  558]: resist loss: tensor([ 0.3259], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5952792167663574
[INFO: train.py:  316]: Interation 9577 took 1.5991430282592773
[INFO: train.py:  558]: resist loss: tensor([ 4.2224], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7378761768341064
[INFO: train.py:  316]: Interation 9578 took 1.7417850494384766
[INFO: train.py:  558]: resist loss: tensor([ 8.5078], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7619421482086182
[INFO: train.py:  316]: Interation 9579 took 1.7652466297149658
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 499, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 499, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 653, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 653, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 561, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 561, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 537, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 537, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 646, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 646, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 560, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 560, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 608, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 608, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 495, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 495, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 473, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 473, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 563, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 563, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 583, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 583, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 183, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 183, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 605, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 605, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 856, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 856, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 776, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 776, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 706, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 706, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 747, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 747, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 751, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 751, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 639, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 639, 2])
[INFO: train.py:  338]:   [val] ade: 0.643
[INFO: train.py:  338]:   [val] ade_l: 1.415
[INFO: train.py:  338]:   [val] ade_nl: 1.178
[INFO: train.py:  338]:   [val] d_loss: 1.399
[INFO: train.py:  338]:   [val] fde: 1.395
[INFO: train.py:  338]:   [val] fde_l: 3.071
[INFO: train.py:  338]:   [val] fde_nl: 2.556
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.512
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.512
[INFO: train.py:  338]:   [val] resist_count: 3137.000
[INFO: train.py:  338]:   [val] resist_loss: 0.285
[INFO: train.py:  341]:   [train] ade: 0.643
[INFO: train.py:  341]:   [train] ade_l: 1.351
[INFO: train.py:  341]:   [train] ade_nl: 1.228
[INFO: train.py:  341]:   [train] d_loss: 1.401
[INFO: train.py:  341]:   [train] fde: 1.328
[INFO: train.py:  341]:   [train] fde_l: 2.788
[INFO: train.py:  341]:   [train] fde_nl: 2.535
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.457
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.457
[INFO: train.py:  341]:   [train] resist_count: 3028.000
[INFO: train.py:  341]:   [train] resist_loss: 0.178
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 14.1258], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4825291633605957
[INFO: train.py:  316]: Interation 9580 took 10.713071823120117
[INFO: train.py:  558]: resist loss: tensor([ 0.8833], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6839244365692139
[INFO: train.py:  316]: Interation 9581 took 1.6880006790161133
[INFO: train.py:  558]: resist loss: tensor([ 13.0669], device='cuda:0')
[INFO: train.py:  310]: g step took 2.168283462524414
[INFO: train.py:  316]: Interation 9582 took 2.17223858833313
[INFO: train.py:  558]: resist loss: tensor([ 6.2781], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9271209239959717
[INFO: train.py:  316]: Interation 9583 took 1.9308109283447266
[INFO: train.py:  558]: resist loss: tensor([ 10.6496], device='cuda:0')
[INFO: train.py:  310]: g step took 2.19054913520813
[INFO: train.py:  316]: Interation 9584 took 2.1943678855895996
[INFO: train.py:  558]: resist loss: tensor([ 3.1040], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2294535636901855
[INFO: train.py:  316]: Interation 9585 took 2.2331151962280273
[INFO: train.py:  558]: resist loss: tensor([ 1.7887], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8471829891204834
[INFO: train.py:  316]: Interation 9586 took 1.8510401248931885
[INFO: train.py:  558]: resist loss: tensor([ 2.3235], device='cuda:0')
[INFO: train.py:  310]: g step took 1.91768217086792
[INFO: train.py:  316]: Interation 9587 took 1.9215939044952393
[INFO: train.py:  558]: resist loss: tensor([ 4.1742], device='cuda:0')
[INFO: train.py:  310]: g step took 2.18169903755188
[INFO: train.py:  316]: Interation 9588 took 2.1853296756744385
[INFO: train.py:  558]: resist loss: tensor([ 3.0427], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0184133052825928
[INFO: train.py:  316]: Interation 9589 took 2.0222458839416504
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 457, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 457, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 638, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 638, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 561, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 561, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 458, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 458, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 748, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 748, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 629, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 629, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 630, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 630, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 517, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 517, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 530, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 530, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 566, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 566, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 488, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 488, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 139, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 139, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 804, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 804, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 759, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 759, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 787, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 787, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 873, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 873, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 553, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 553, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 891, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 891, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 757, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 757, 2])
[INFO: train.py:  338]:   [val] ade: 0.696
[INFO: train.py:  338]:   [val] ade_l: 1.532
[INFO: train.py:  338]:   [val] ade_nl: 1.275
[INFO: train.py:  338]:   [val] d_loss: 1.409
[INFO: train.py:  338]:   [val] fde: 1.480
[INFO: train.py:  338]:   [val] fde_l: 3.259
[INFO: train.py:  338]:   [val] fde_nl: 2.711
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.558
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.558
[INFO: train.py:  338]:   [val] resist_count: 3076.000
[INFO: train.py:  338]:   [val] resist_loss: 0.278
[INFO: train.py:  341]:   [train] ade: 0.682
[INFO: train.py:  341]:   [train] ade_l: 1.395
[INFO: train.py:  341]:   [train] ade_nl: 1.334
[INFO: train.py:  341]:   [train] d_loss: 1.412
[INFO: train.py:  341]:   [train] fde: 1.359
[INFO: train.py:  341]:   [train] fde_l: 2.781
[INFO: train.py:  341]:   [train] fde_nl: 2.658
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.475
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.475
[INFO: train.py:  341]:   [train] resist_count: 2706.000
[INFO: train.py:  341]:   [train] resist_loss: 0.149
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 16.8221], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4014878273010254
[INFO: train.py:  316]: Interation 9590 took 10.859679460525513
[INFO: train.py:  558]: resist loss: tensor([ 9.8124], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9648158550262451
[INFO: train.py:  316]: Interation 9591 took 1.968794345855713
[INFO: train.py:  558]: resist loss: tensor([ 4.2268], device='cuda:0')
[INFO: train.py:  310]: g step took 1.934708595275879
[INFO: train.py:  316]: Interation 9592 took 1.9385435581207275
[INFO: train.py:  558]: resist loss: tensor([ 6.9924], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9692683219909668
[INFO: train.py:  316]: Interation 9593 took 1.9731826782226562
[INFO: train.py:  558]: resist loss: tensor([ 3.2117], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9451916217803955
[INFO: train.py:  316]: Interation 9594 took 1.9490525722503662
[INFO: train.py:  558]: resist loss: tensor([ 18.5698], device='cuda:0')
[INFO: train.py:  310]: g step took 2.5476698875427246
[INFO: train.py:  316]: Interation 9595 took 2.5515389442443848
[INFO: train.py:  558]: resist loss: tensor([ 2.3883], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8070344924926758
[INFO: train.py:  316]: Interation 9596 took 1.8109383583068848
[INFO: train.py:  558]: resist loss: tensor([ 9.8592], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8436813354492188
[INFO: train.py:  316]: Interation 9597 took 1.8478214740753174
[INFO: train.py:  558]: resist loss: tensor([ 0.1259], device='cuda:0')
[INFO: train.py:  310]: g step took 0.16446733474731445
[INFO: train.py:  316]: Interation 9598 took 0.1684727668762207
[INFO: train.py:  279]: Starting epoch 225
[INFO: train.py:  280]: Epoch resist loss: tensor([ 248.4748])
[INFO: train.py:  558]: resist loss: tensor([ 0.9696], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8422858715057373
[INFO: train.py:  316]: Interation 9599 took 2.2469100952148438
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 644, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 644, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 542, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 542, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 526, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 526, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 535, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 535, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 551, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 551, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 587, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 587, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 591, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 591, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 579, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 579, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 476, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 476, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 530, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 530, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 653, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 653, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 147, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 147, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 705, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 705, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 739, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 739, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 890, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 890, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 793, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 793, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 709, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 709, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 880, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 880, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 877, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 877, 2])
[INFO: train.py:  338]:   [val] ade: 0.669
[INFO: train.py:  338]:   [val] ade_l: 1.474
[INFO: train.py:  338]:   [val] ade_nl: 1.226
[INFO: train.py:  338]:   [val] d_loss: 1.416
[INFO: train.py:  338]:   [val] fde: 1.248
[INFO: train.py:  338]:   [val] fde_l: 2.748
[INFO: train.py:  338]:   [val] fde_nl: 2.287
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.464
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.464
[INFO: train.py:  338]:   [val] resist_count: 2991.000
[INFO: train.py:  338]:   [val] resist_loss: 0.346
[INFO: train.py:  341]:   [train] ade: 0.693
[INFO: train.py:  341]:   [train] ade_l: 1.447
[INFO: train.py:  341]:   [train] ade_nl: 1.329
[INFO: train.py:  341]:   [train] d_loss: 1.393
[INFO: train.py:  341]:   [train] fde: 1.208
[INFO: train.py:  341]:   [train] fde_l: 2.523
[INFO: train.py:  341]:   [train] fde_nl: 2.317
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.440
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.440
[INFO: train.py:  341]:   [train] resist_count: 3049.000
[INFO: train.py:  341]:   [train] resist_loss: 0.201
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 15.3274], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9514670372009277
[INFO: train.py:  316]: Interation 9600 took 10.526314973831177
[INFO: train.py:  558]: resist loss: tensor([ 5.7552], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8688898086547852
[INFO: train.py:  316]: Interation 9601 took 1.8692572116851807
[INFO: train.py:  558]: resist loss: tensor([ 0.4356], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8859634399414062
[INFO: train.py:  316]: Interation 9602 took 1.8863775730133057
[INFO: train.py:  558]: resist loss: tensor([ 18.4406], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3802402019500732
[INFO: train.py:  316]: Interation 9603 took 2.3805630207061768
[INFO: train.py:  558]: resist loss: tensor([ 0.4756], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7895288467407227
[INFO: train.py:  316]: Interation 9604 took 1.7899723052978516
[INFO: train.py:  558]: resist loss: tensor([ 0.8158], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6807174682617188
[INFO: train.py:  316]: Interation 9605 took 1.6810905933380127
[INFO: train.py:  558]: resist loss: tensor([ 0.4633], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8460290431976318
[INFO: train.py:  316]: Interation 9606 took 1.8463592529296875
[INFO: train.py:  558]: resist loss: tensor([ 10.0015], device='cuda:0')
[INFO: train.py:  310]: g step took 2.007516622543335
[INFO: train.py:  316]: Interation 9607 took 2.00788950920105
[INFO: train.py:  558]: resist loss: tensor([ 0.3446], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6780717372894287
[INFO: train.py:  316]: Interation 9608 took 1.698481559753418
[INFO: train.py:  558]: resist loss: tensor([ 2.6442], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9546246528625488
[INFO: train.py:  316]: Interation 9609 took 1.9549381732940674
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 726, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 726, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 588, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 588, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 556, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 556, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 565, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 565, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 564, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 564, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 622, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 622, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 623, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 623, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 473, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 473, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 495, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 495, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 525, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 525, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 520, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 520, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 104, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 104, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 749, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 749, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 796, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 796, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 855, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 855, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 692, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 692, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 829, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 829, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 801, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 801, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 724, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 724, 2])
[INFO: train.py:  338]:   [val] ade: 0.614
[INFO: train.py:  338]:   [val] ade_l: 1.353
[INFO: train.py:  338]:   [val] ade_nl: 1.126
[INFO: train.py:  338]:   [val] d_loss: 1.406
[INFO: train.py:  338]:   [val] fde: 1.319
[INFO: train.py:  338]:   [val] fde_l: 2.905
[INFO: train.py:  338]:   [val] fde_nl: 2.417
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.457
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.457
[INFO: train.py:  338]:   [val] resist_count: 3035.000
[INFO: train.py:  338]:   [val] resist_loss: 0.301
[INFO: train.py:  341]:   [train] ade: 0.614
[INFO: train.py:  341]:   [train] ade_l: 1.314
[INFO: train.py:  341]:   [train] ade_nl: 1.152
[INFO: train.py:  341]:   [train] d_loss: 1.403
[INFO: train.py:  341]:   [train] fde: 1.247
[INFO: train.py:  341]:   [train] fde_l: 2.669
[INFO: train.py:  341]:   [train] fde_nl: 2.342
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.401
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.401
[INFO: train.py:  341]:   [train] resist_count: 2849.000
[INFO: train.py:  341]:   [train] resist_loss: 0.152
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 1.7192], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9978017807006836
[INFO: train.py:  316]: Interation 9610 took 10.448734045028687
[INFO: train.py:  558]: resist loss: tensor([ 8.8142], device='cuda:0')
[INFO: train.py:  310]: g step took 2.310356378555298
[INFO: train.py:  316]: Interation 9611 took 2.314361572265625
[INFO: train.py:  558]: resist loss: tensor([ 4.3937], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1013295650482178
[INFO: train.py:  316]: Interation 9612 took 2.1017379760742188
[INFO: train.py:  558]: resist loss: tensor([ 3.2073], device='cuda:0')
[INFO: train.py:  310]: g step took 1.721480131149292
[INFO: train.py:  316]: Interation 9613 took 1.7218852043151855
[INFO: train.py:  558]: resist loss: tensor([ 4.3634], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8357460498809814
[INFO: train.py:  316]: Interation 9614 took 1.8362152576446533
[INFO: train.py:  558]: resist loss: tensor([ 0.1362], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4460060596466064
[INFO: train.py:  316]: Interation 9615 took 1.4500408172607422
[INFO: train.py:  558]: resist loss: tensor([ 7.5756], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7273941040039062
[INFO: train.py:  316]: Interation 9616 took 1.731421709060669
[INFO: train.py:  558]: resist loss: tensor([ 13.3872], device='cuda:0')
[INFO: train.py:  310]: g step took 2.206662654876709
[INFO: train.py:  316]: Interation 9617 took 2.2107467651367188
[INFO: train.py:  558]: resist loss: tensor([ 13.7246], device='cuda:0')
[INFO: train.py:  310]: g step took 2.204538583755493
[INFO: train.py:  316]: Interation 9618 took 2.2080485820770264
[INFO: train.py:  558]: resist loss: tensor([ 10.0807], device='cuda:0')
[INFO: train.py:  310]: g step took 2.019843578338623
[INFO: train.py:  316]: Interation 9619 took 2.023688793182373
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 497, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 497, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 661, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 661, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 584, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 584, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 569, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 569, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 478, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 478, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 593, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 593, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 584, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 584, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 545, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 545, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 593, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 593, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 544, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 544, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 556, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 556, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 157, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 157, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 879, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 879, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 839, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 839, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 717, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 717, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 704, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 704, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 616, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 616, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 858, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 858, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 758, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 758, 2])
[INFO: train.py:  338]:   [val] ade: 0.645
[INFO: train.py:  338]:   [val] ade_l: 1.420
[INFO: train.py:  338]:   [val] ade_nl: 1.181
[INFO: train.py:  338]:   [val] d_loss: 1.400
[INFO: train.py:  338]:   [val] fde: 1.310
[INFO: train.py:  338]:   [val] fde_l: 2.884
[INFO: train.py:  338]:   [val] fde_nl: 2.400
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.498
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.498
[INFO: train.py:  338]:   [val] resist_count: 2677.000
[INFO: train.py:  338]:   [val] resist_loss: 0.252
[INFO: train.py:  341]:   [train] ade: 0.647
[INFO: train.py:  341]:   [train] ade_l: 1.414
[INFO: train.py:  341]:   [train] ade_nl: 1.194
[INFO: train.py:  341]:   [train] d_loss: 1.398
[INFO: train.py:  341]:   [train] fde: 1.228
[INFO: train.py:  341]:   [train] fde_l: 2.683
[INFO: train.py:  341]:   [train] fde_nl: 2.264
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.429
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.429
[INFO: train.py:  341]:   [train] resist_count: 2741.000
[INFO: train.py:  341]:   [train] resist_loss: 0.162
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 4.0486], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8839397430419922
[INFO: train.py:  316]: Interation 9620 took 10.697895765304565
[INFO: train.py:  558]: resist loss: tensor([ 3.8284], device='cuda:0')
[INFO: train.py:  310]: g step took 2.21575665473938
[INFO: train.py:  316]: Interation 9621 took 2.219744920730591
[INFO: train.py:  558]: resist loss: tensor([ 0.6192], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4139113426208496
[INFO: train.py:  316]: Interation 9622 took 2.418121099472046
[INFO: train.py:  558]: resist loss: tensor([ 4.5828], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9040625095367432
[INFO: train.py:  316]: Interation 9623 took 1.90806245803833
[INFO: train.py:  558]: resist loss: tensor([ 2.8543], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9347362518310547
[INFO: train.py:  316]: Interation 9624 took 1.9386539459228516
[INFO: train.py:  558]: resist loss: tensor([ 1.8147], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9565744400024414
[INFO: train.py:  316]: Interation 9625 took 1.9603679180145264
[INFO: train.py:  558]: resist loss: tensor([ 6.9552], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8740239143371582
[INFO: train.py:  316]: Interation 9626 took 1.8777005672454834
[INFO: train.py:  558]: resist loss: tensor([ 2.9560], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2314205169677734
[INFO: train.py:  316]: Interation 9627 took 2.2353217601776123
[INFO: train.py:  558]: resist loss: tensor([ 10.5231], device='cuda:0')
[INFO: train.py:  310]: g step took 1.514827013015747
[INFO: train.py:  316]: Interation 9628 took 1.5190656185150146
[INFO: train.py:  558]: resist loss: tensor([ 9.6248], device='cuda:0')
[INFO: train.py:  310]: g step took 2.084573745727539
[INFO: train.py:  316]: Interation 9629 took 2.0884225368499756
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 529, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 529, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 476, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 476, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 579, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 579, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 741, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 741, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 673, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 673, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 450, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 450, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 535, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 535, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 431, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 431, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 529, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 529, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 606, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 606, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 691, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 691, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 121, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 121, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 858, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 858, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 669, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 669, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 854, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 854, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 710, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 710, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 762, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 762, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 727, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 727, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 764, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 764, 2])
[INFO: train.py:  338]:   [val] ade: 0.646
[INFO: train.py:  338]:   [val] ade_l: 1.423
[INFO: train.py:  338]:   [val] ade_nl: 1.184
[INFO: train.py:  338]:   [val] d_loss: 1.416
[INFO: train.py:  338]:   [val] fde: 1.336
[INFO: train.py:  338]:   [val] fde_l: 2.941
[INFO: train.py:  338]:   [val] fde_nl: 2.447
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.482
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.482
[INFO: train.py:  338]:   [val] resist_count: 2985.000
[INFO: train.py:  338]:   [val] resist_loss: 0.296
[INFO: train.py:  341]:   [train] ade: 0.638
[INFO: train.py:  341]:   [train] ade_l: 1.310
[INFO: train.py:  341]:   [train] ade_nl: 1.242
[INFO: train.py:  341]:   [train] d_loss: 1.405
[INFO: train.py:  341]:   [train] fde: 1.237
[INFO: train.py:  341]:   [train] fde_l: 2.541
[INFO: train.py:  341]:   [train] fde_nl: 2.409
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.412
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.412
[INFO: train.py:  341]:   [train] resist_count: 2841.000
[INFO: train.py:  341]:   [train] resist_loss: 0.178
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 8.9448], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8565940856933594
[INFO: train.py:  316]: Interation 9630 took 10.666332006454468
[INFO: train.py:  558]: resist loss: tensor([ 2.1482], device='cuda:0')
[INFO: train.py:  310]: g step took 1.757450819015503
[INFO: train.py:  316]: Interation 9631 took 1.7606055736541748
[INFO: train.py:  558]: resist loss: tensor([ 3.2408], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9240765571594238
[INFO: train.py:  316]: Interation 9632 took 1.9278194904327393
[INFO: train.py:  558]: resist loss: tensor([ 4.5888], device='cuda:0')
[INFO: train.py:  310]: g step took 2.047793388366699
[INFO: train.py:  316]: Interation 9633 took 2.0517020225524902
[INFO: train.py:  558]: resist loss: tensor([ 5.6050], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0013177394866943
[INFO: train.py:  316]: Interation 9634 took 2.0053658485412598
[INFO: train.py:  558]: resist loss: tensor([ 6.8797], device='cuda:0')
[INFO: train.py:  310]: g step took 1.991544485092163
[INFO: train.py:  316]: Interation 9635 took 1.9955930709838867
[INFO: train.py:  558]: resist loss: tensor([ 2.8332], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8731844425201416
[INFO: train.py:  316]: Interation 9636 took 1.8772547245025635
[INFO: train.py:  558]: resist loss: tensor([ 4.1933], device='cuda:0')
[INFO: train.py:  310]: g step took 1.905240774154663
[INFO: train.py:  316]: Interation 9637 took 1.9093294143676758
[INFO: train.py:  558]: resist loss: tensor([ 0.7250], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0705392360687256
[INFO: train.py:  316]: Interation 9638 took 2.0744526386260986
[INFO: train.py:  558]: resist loss: tensor([ 9.5466], device='cuda:0')
[INFO: train.py:  310]: g step took 2.109549045562744
[INFO: train.py:  316]: Interation 9639 took 2.1134092807769775
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 506, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 506, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 524, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 524, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 709, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 709, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 579, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 579, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 560, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 560, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 602, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 602, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 506, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 506, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 453, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 453, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 628, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 628, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 466, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 466, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 604, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 604, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 224, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 224, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 717, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 717, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 954, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 954, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 790, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 790, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 787, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 787, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 792, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 792, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 650, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 650, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 785, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 785, 2])
[INFO: train.py:  338]:   [val] ade: 0.617
[INFO: train.py:  338]:   [val] ade_l: 1.359
[INFO: train.py:  338]:   [val] ade_nl: 1.131
[INFO: train.py:  338]:   [val] d_loss: 1.397
[INFO: train.py:  338]:   [val] fde: 1.337
[INFO: train.py:  338]:   [val] fde_l: 2.945
[INFO: train.py:  338]:   [val] fde_nl: 2.450
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.474
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.474
[INFO: train.py:  338]:   [val] resist_count: 2967.000
[INFO: train.py:  338]:   [val] resist_loss: 0.281
[INFO: train.py:  341]:   [train] ade: 0.608
[INFO: train.py:  341]:   [train] ade_l: 1.296
[INFO: train.py:  341]:   [train] ade_nl: 1.143
[INFO: train.py:  341]:   [train] d_loss: 1.395
[INFO: train.py:  341]:   [train] fde: 1.258
[INFO: train.py:  341]:   [train] fde_l: 2.685
[INFO: train.py:  341]:   [train] fde_nl: 2.368
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.402
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.402
[INFO: train.py:  341]:   [train] resist_count: 2773.000
[INFO: train.py:  341]:   [train] resist_loss: 0.162
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 1.2070], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2001101970672607
[INFO: train.py:  316]: Interation 9640 took 11.343881368637085
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 2.2285], device='cuda:0')
[INFO: train.py:  310]: g step took 0.20416593551635742
[INFO: train.py:  316]: Interation 9641 took 0.20800065994262695
[INFO: train.py:  279]: Starting epoch 226
[INFO: train.py:  280]: Epoch resist loss: tensor([ 220.8172])
[INFO: train.py:  558]: resist loss: tensor([ 4.2382], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2714545726776123
[INFO: train.py:  316]: Interation 9642 took 2.683072328567505
[INFO: train.py:  558]: resist loss: tensor([ 5.7910], device='cuda:0')
[INFO: train.py:  310]: g step took 2.429086208343506
[INFO: train.py:  316]: Interation 9643 took 2.429586172103882
[INFO: train.py:  558]: resist loss: tensor([ 9.5108], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4716832637786865
[INFO: train.py:  316]: Interation 9644 took 2.472031354904175
[INFO: train.py:  558]: resist loss: tensor([ 0.4197], device='cuda:0')
[INFO: train.py:  310]: g step took 2.086920738220215
[INFO: train.py:  316]: Interation 9645 took 2.0967538356781006
[INFO: train.py:  558]: resist loss: tensor([ 9.4616], device='cuda:0')
[INFO: train.py:  310]: g step took 2.640010118484497
[INFO: train.py:  316]: Interation 9646 took 2.6403825283050537
[INFO: train.py:  558]: resist loss: tensor([ 5.4564], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1768691539764404
[INFO: train.py:  316]: Interation 9647 took 2.177309036254883
[INFO: train.py:  558]: resist loss: tensor([ 0.3470], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1669511795043945
[INFO: train.py:  316]: Interation 9648 took 2.1705517768859863
[INFO: train.py:  558]: resist loss: tensor([ 8.1734], device='cuda:0')
[INFO: train.py:  310]: g step took 2.589601755142212
[INFO: train.py:  316]: Interation 9649 took 2.5899696350097656
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 601, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 601, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 588, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 588, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 541, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 541, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 645, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 645, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 549, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 549, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 525, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 525, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 618, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 618, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 576, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 576, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 558, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 558, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 577, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 577, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 457, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 457, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 126, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 126, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 842, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 842, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 778, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 778, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 773, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 773, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 864, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 864, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 896, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 896, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 841, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 841, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 744, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 744, 2])
[INFO: train.py:  338]:   [val] ade: 0.633
[INFO: train.py:  338]:   [val] ade_l: 1.394
[INFO: train.py:  338]:   [val] ade_nl: 1.160
[INFO: train.py:  338]:   [val] d_loss: 1.417
[INFO: train.py:  338]:   [val] fde: 1.321
[INFO: train.py:  338]:   [val] fde_l: 2.909
[INFO: train.py:  338]:   [val] fde_nl: 2.421
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.450
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.450
[INFO: train.py:  338]:   [val] resist_count: 3705.000
[INFO: train.py:  338]:   [val] resist_loss: 0.392
[INFO: train.py:  341]:   [train] ade: 0.627
[INFO: train.py:  341]:   [train] ade_l: 1.307
[INFO: train.py:  341]:   [train] ade_nl: 1.206
[INFO: train.py:  341]:   [train] d_loss: 1.407
[INFO: train.py:  341]:   [train] fde: 1.222
[INFO: train.py:  341]:   [train] fde_l: 2.546
[INFO: train.py:  341]:   [train] fde_nl: 2.348
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.390
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.390
[INFO: train.py:  341]:   [train] resist_count: 4037.000
[INFO: train.py:  341]:   [train] resist_loss: 0.227
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 6.6383], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9921135902404785
[INFO: train.py:  316]: Interation 9650 took 12.401946544647217
[INFO: train.py:  558]: resist loss: tensor([ 3.3962], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2747843265533447
[INFO: train.py:  316]: Interation 9651 took 2.2781295776367188
[INFO: train.py:  558]: resist loss: tensor([ 7.5345], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7970294952392578
[INFO: train.py:  316]: Interation 9652 took 1.8038218021392822
[INFO: train.py:  558]: resist loss: tensor([ 4.5120], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6071910858154297
[INFO: train.py:  316]: Interation 9653 took 1.6175763607025146
[INFO: train.py:  558]: resist loss: tensor([ 2.5646], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7217118740081787
[INFO: train.py:  316]: Interation 9654 took 1.7220253944396973
[INFO: train.py:  558]: resist loss: tensor([ 1.0792], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9903833866119385
[INFO: train.py:  316]: Interation 9655 took 1.9907422065734863
[INFO: train.py:  558]: resist loss: tensor([ 1.0204], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1500136852264404
[INFO: train.py:  316]: Interation 9656 took 2.1539645195007324
[INFO: train.py:  558]: resist loss: tensor([ 7.3622], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2771565914154053
[INFO: train.py:  316]: Interation 9657 took 2.2774782180786133
[INFO: train.py:  558]: resist loss: tensor([ 0.7635], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9680132865905762
[INFO: train.py:  316]: Interation 9658 took 1.9720070362091064
[INFO: train.py:  558]: resist loss: tensor([ 2.6616], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7291970252990723
[INFO: train.py:  316]: Interation 9659 took 1.7322254180908203
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 565, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 565, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 611, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 611, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 561, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 561, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 517, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 517, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 483, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 483, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 497, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 497, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 501, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 501, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 547, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 547, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 607, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 607, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 666, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 666, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 652, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 652, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 154, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 154, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 820, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 820, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 704, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 704, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 652, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 652, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 757, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 757, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 819, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 819, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 643, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 643, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 960, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 960, 2])
[INFO: train.py:  338]:   [val] ade: 0.634
[INFO: train.py:  338]:   [val] ade_l: 1.397
[INFO: train.py:  338]:   [val] ade_nl: 1.162
[INFO: train.py:  338]:   [val] d_loss: 1.395
[INFO: train.py:  338]:   [val] fde: 1.390
[INFO: train.py:  338]:   [val] fde_l: 3.061
[INFO: train.py:  338]:   [val] fde_nl: 2.547
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.503
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.503
[INFO: train.py:  338]:   [val] resist_count: 2829.000
[INFO: train.py:  338]:   [val] resist_loss: 0.291
[INFO: train.py:  341]:   [train] ade: 0.628
[INFO: train.py:  341]:   [train] ade_l: 1.326
[INFO: train.py:  341]:   [train] ade_nl: 1.193
[INFO: train.py:  341]:   [train] d_loss: 1.398
[INFO: train.py:  341]:   [train] fde: 1.320
[INFO: train.py:  341]:   [train] fde_l: 2.787
[INFO: train.py:  341]:   [train] fde_nl: 2.507
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.444
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.444
[INFO: train.py:  341]:   [train] resist_count: 2465.000
[INFO: train.py:  341]:   [train] resist_loss: 0.154
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.3409], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7793335914611816
[INFO: train.py:  316]: Interation 9660 took 11.085180521011353
[INFO: train.py:  558]: resist loss: tensor([ 7.5003], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7020745277404785
[INFO: train.py:  316]: Interation 9661 took 1.706010341644287
[INFO: train.py:  558]: resist loss: tensor([ 1.4884], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6645374298095703
[INFO: train.py:  316]: Interation 9662 took 1.6678221225738525
[INFO: train.py:  558]: resist loss: tensor([ 0.4051], device='cuda:0')
[INFO: train.py:  310]: g step took 2.177614212036133
[INFO: train.py:  316]: Interation 9663 took 2.180850028991699
[INFO: train.py:  558]: resist loss: tensor([ 14.1847], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1500942707061768
[INFO: train.py:  316]: Interation 9664 took 2.1540000438690186
[INFO: train.py:  558]: resist loss: tensor([ 0.2741], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9659326076507568
[INFO: train.py:  316]: Interation 9665 took 1.9701063632965088
[INFO: train.py:  558]: resist loss: tensor([ 0.3615], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7477636337280273
[INFO: train.py:  316]: Interation 9666 took 1.752105712890625
[INFO: train.py:  558]: resist loss: tensor([ 8.6571], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0132477283477783
[INFO: train.py:  316]: Interation 9667 took 2.017188549041748
[INFO: train.py:  558]: resist loss: tensor([ 6.1091], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3088219165802
[INFO: train.py:  316]: Interation 9668 took 2.3129236698150635
[INFO: train.py:  558]: resist loss: tensor([ 3.1209], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9382548332214355
[INFO: train.py:  316]: Interation 9669 took 1.942073106765747
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 485, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 485, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 565, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 565, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 617, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 617, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 507, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 507, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 610, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 610, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 537, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 537, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 627, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 627, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 641, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 641, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 529, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 529, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 534, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 534, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 596, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 596, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 113, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 113, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 738, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 738, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 702, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 702, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 912, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 912, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 732, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 732, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 829, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 829, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 684, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 684, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 812, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 812, 2])
[INFO: train.py:  338]:   [val] ade: 0.633
[INFO: train.py:  338]:   [val] ade_l: 1.395
[INFO: train.py:  338]:   [val] ade_nl: 1.161
[INFO: train.py:  338]:   [val] d_loss: 1.407
[INFO: train.py:  338]:   [val] fde: 1.299
[INFO: train.py:  338]:   [val] fde_l: 2.861
[INFO: train.py:  338]:   [val] fde_nl: 2.380
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.457
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.457
[INFO: train.py:  338]:   [val] resist_count: 2994.000
[INFO: train.py:  338]:   [val] resist_loss: 0.312
[INFO: train.py:  341]:   [train] ade: 0.628
[INFO: train.py:  341]:   [train] ade_l: 1.310
[INFO: train.py:  341]:   [train] ade_nl: 1.207
[INFO: train.py:  341]:   [train] d_loss: 1.400
[INFO: train.py:  341]:   [train] fde: 1.204
[INFO: train.py:  341]:   [train] fde_l: 2.512
[INFO: train.py:  341]:   [train] fde_nl: 2.314
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.404
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.404
[INFO: train.py:  341]:   [train] resist_count: 2951.000
[INFO: train.py:  341]:   [train] resist_loss: 0.175
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 3.5018], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6228399276733398
[INFO: train.py:  316]: Interation 9670 took 10.123038291931152
[INFO: train.py:  558]: resist loss: tensor([ 10.2098], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9518251419067383
[INFO: train.py:  316]: Interation 9671 took 1.955740213394165
[INFO: train.py:  558]: resist loss: tensor([ 14.5059], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2432971000671387
[INFO: train.py:  316]: Interation 9672 took 2.247112512588501
[INFO: train.py:  558]: resist loss: tensor([ 1.2901], device='cuda:0')
[INFO: train.py:  310]: g step took 1.719470500946045
[INFO: train.py:  316]: Interation 9673 took 1.723357915878296
[INFO: train.py:  558]: resist loss: tensor([ 2.5827], device='cuda:0')
[INFO: train.py:  310]: g step took 2.128884792327881
[INFO: train.py:  316]: Interation 9674 took 2.1326866149902344
[INFO: train.py:  558]: resist loss: tensor([ 11.6183], device='cuda:0')
[INFO: train.py:  310]: g step took 2.516641855239868
[INFO: train.py:  316]: Interation 9675 took 2.5205390453338623
[INFO: train.py:  558]: resist loss: tensor([ 5.2701], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4017937183380127
[INFO: train.py:  316]: Interation 9676 took 2.405722141265869
[INFO: train.py:  558]: resist loss: tensor([ 0.1389], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6237361431121826
[INFO: train.py:  316]: Interation 9677 took 1.627906322479248
[INFO: train.py:  558]: resist loss: tensor([ 8.1592], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1460647583007812
[INFO: train.py:  316]: Interation 9678 took 2.1498067378997803
[INFO: train.py:  558]: resist loss: tensor([ 1.1639], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9445006847381592
[INFO: train.py:  316]: Interation 9679 took 1.9483511447906494
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 628, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 628, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 525, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 525, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 685, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 685, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 506, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 506, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 517, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 517, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 565, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 565, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 506, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 506, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 662, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 662, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 655, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 655, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 437, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 437, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 513, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 513, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 162, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 162, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 754, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 754, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 654, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 654, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 742, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 742, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 944, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 944, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 777, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 777, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 798, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 798, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 958, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 958, 2])
[INFO: train.py:  338]:   [val] ade: 0.591
[INFO: train.py:  338]:   [val] ade_l: 1.300
[INFO: train.py:  338]:   [val] ade_nl: 1.082
[INFO: train.py:  338]:   [val] d_loss: 1.404
[INFO: train.py:  338]:   [val] fde: 1.218
[INFO: train.py:  338]:   [val] fde_l: 2.683
[INFO: train.py:  338]:   [val] fde_nl: 2.232
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.435
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.435
[INFO: train.py:  338]:   [val] resist_count: 2625.000
[INFO: train.py:  338]:   [val] resist_loss: 0.281
[INFO: train.py:  341]:   [train] ade: 0.600
[INFO: train.py:  341]:   [train] ade_l: 1.262
[INFO: train.py:  341]:   [train] ade_nl: 1.144
[INFO: train.py:  341]:   [train] d_loss: 1.401
[INFO: train.py:  341]:   [train] fde: 1.164
[INFO: train.py:  341]:   [train] fde_l: 2.449
[INFO: train.py:  341]:   [train] fde_nl: 2.219
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.375
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.375
[INFO: train.py:  341]:   [train] resist_count: 2721.000
[INFO: train.py:  341]:   [train] resist_loss: 0.160
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.4411], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9025084972381592
[INFO: train.py:  316]: Interation 9680 took 10.44922661781311
[INFO: train.py:  558]: resist loss: tensor([ 4.3659], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6963160037994385
[INFO: train.py:  316]: Interation 9681 took 1.700186014175415
[INFO: train.py:  558]: resist loss: tensor([ 2.5568], device='cuda:0')
[INFO: train.py:  310]: g step took 2.011531114578247
[INFO: train.py:  316]: Interation 9682 took 2.0152318477630615
[INFO: train.py:  558]: resist loss: tensor([ 1.0100], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8188722133636475
[INFO: train.py:  316]: Interation 9683 took 1.8227133750915527
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 9.7657], device='cuda:0')
[INFO: train.py:  310]: g step took 0.1857304573059082
[INFO: train.py:  316]: Interation 9684 took 0.18885135650634766
[INFO: train.py:  279]: Starting epoch 227
[INFO: train.py:  280]: Epoch resist loss: tensor([ 190.2849])
[INFO: train.py:  558]: resist loss: tensor([ 5.3619], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8999905586242676
[INFO: train.py:  316]: Interation 9685 took 2.2855417728424072
[INFO: train.py:  558]: resist loss: tensor([ 2.6849], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6806092262268066
[INFO: train.py:  316]: Interation 9686 took 1.6931712627410889
[INFO: train.py:  558]: resist loss: tensor([ 4.2782], device='cuda:0')
[INFO: train.py:  310]: g step took 2.071026086807251
[INFO: train.py:  316]: Interation 9687 took 2.0713882446289062
[INFO: train.py:  558]: resist loss: tensor([ 0.3399], device='cuda:0')
[INFO: train.py:  310]: g step took 2.014310836791992
[INFO: train.py:  316]: Interation 9688 took 2.014662027359009
[INFO: train.py:  558]: resist loss: tensor([ 21.8913], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3454136848449707
[INFO: train.py:  316]: Interation 9689 took 2.3458008766174316
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 536, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 536, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 581, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 581, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 494, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 494, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 595, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 595, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 640, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 640, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 660, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 660, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 571, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 571, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 558, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 558, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 524, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 524, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 567, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 567, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 483, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 483, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 152, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 152, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 835, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 835, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 971, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 971, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 697, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 697, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 835, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 835, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 689, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 689, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 998, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 998, 2])
[INFO: train.py:  338]:   [val] ade: 0.610
[INFO: train.py:  338]:   [val] ade_l: 1.343
[INFO: train.py:  338]:   [val] ade_nl: 1.118
[INFO: train.py:  338]:   [val] d_loss: 1.408
[INFO: train.py:  338]:   [val] fde: 1.281
[INFO: train.py:  338]:   [val] fde_l: 2.821
[INFO: train.py:  338]:   [val] fde_nl: 2.347
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.463
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.463
[INFO: train.py:  338]:   [val] resist_count: 3230.000
[INFO: train.py:  338]:   [val] resist_loss: 0.362
[INFO: train.py:  341]:   [train] ade: 0.605
[INFO: train.py:  341]:   [train] ade_l: 1.265
[INFO: train.py:  341]:   [train] ade_nl: 1.161
[INFO: train.py:  341]:   [train] d_loss: 1.402
[INFO: train.py:  341]:   [train] fde: 1.178
[INFO: train.py:  341]:   [train] fde_l: 2.460
[INFO: train.py:  341]:   [train] fde_nl: 2.258
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.381
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.381
[INFO: train.py:  341]:   [train] resist_count: 3137.000
[INFO: train.py:  341]:   [train] resist_loss: 0.182
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 9.1937], device='cuda:0')
[INFO: train.py:  310]: g step took 2.170567512512207
[INFO: train.py:  316]: Interation 9690 took 10.439388036727905
[INFO: train.py:  558]: resist loss: tensor([ 4.0972], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0730373859405518
[INFO: train.py:  316]: Interation 9691 took 2.0845935344696045
[INFO: train.py:  558]: resist loss: tensor([ 0.4394], device='cuda:0')
[INFO: train.py:  310]: g step took 1.886535882949829
[INFO: train.py:  316]: Interation 9692 took 1.8869059085845947
[INFO: train.py:  558]: resist loss: tensor([ 10.8014], device='cuda:0')
[INFO: train.py:  310]: g step took 1.980541467666626
[INFO: train.py:  316]: Interation 9693 took 1.988029956817627
[INFO: train.py:  558]: resist loss: tensor([ 7.1796], device='cuda:0')
[INFO: train.py:  310]: g step took 2.360820770263672
[INFO: train.py:  316]: Interation 9694 took 2.3788750171661377
[INFO: train.py:  558]: resist loss: tensor([ 0.7736], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7264537811279297
[INFO: train.py:  316]: Interation 9695 took 1.7268249988555908
[INFO: train.py:  558]: resist loss: tensor([ 3.0168], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0557548999786377
[INFO: train.py:  316]: Interation 9696 took 2.056166887283325
[INFO: train.py:  558]: resist loss: tensor([ 0.5815], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7939889430999756
[INFO: train.py:  316]: Interation 9697 took 1.7943220138549805
[INFO: train.py:  558]: resist loss: tensor([ 9.9674], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9686861038208008
[INFO: train.py:  316]: Interation 9698 took 1.9690375328063965
[INFO: train.py:  558]: resist loss: tensor([ 11.3741], device='cuda:0')
[INFO: train.py:  310]: g step took 1.954225778579712
[INFO: train.py:  316]: Interation 9699 took 1.9546189308166504
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 469, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 469, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 610, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 610, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 484, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 484, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 606, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 606, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 604, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 604, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 488, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 488, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 619, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 619, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 542, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 542, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 617, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 617, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 628, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 628, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 552, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 552, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 142, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 142, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 842, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 842, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 922, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 922, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 735, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 735, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 702, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 702, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 779, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 779, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 595, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 595, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 749, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 749, 2])
[INFO: train.py:  338]:   [val] ade: 0.642
[INFO: train.py:  338]:   [val] ade_l: 1.413
[INFO: train.py:  338]:   [val] ade_nl: 1.175
[INFO: train.py:  338]:   [val] d_loss: 1.412
[INFO: train.py:  338]:   [val] fde: 1.333
[INFO: train.py:  338]:   [val] fde_l: 2.935
[INFO: train.py:  338]:   [val] fde_nl: 2.443
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.479
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.479
[INFO: train.py:  338]:   [val] resist_count: 3401.000
[INFO: train.py:  338]:   [val] resist_loss: 0.370
[INFO: train.py:  341]:   [train] ade: 0.640
[INFO: train.py:  341]:   [train] ade_l: 1.344
[INFO: train.py:  341]:   [train] ade_nl: 1.222
[INFO: train.py:  341]:   [train] d_loss: 1.399
[INFO: train.py:  341]:   [train] fde: 1.257
[INFO: train.py:  341]:   [train] fde_l: 2.639
[INFO: train.py:  341]:   [train] fde_nl: 2.399
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.422
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.422
[INFO: train.py:  341]:   [train] resist_count: 3227.000
[INFO: train.py:  341]:   [train] resist_loss: 0.231
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.1446], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0759692192077637
[INFO: train.py:  316]: Interation 9700 took 10.476483583450317
[INFO: train.py:  558]: resist loss: tensor([ 0.3988], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7214837074279785
[INFO: train.py:  316]: Interation 9701 took 1.7255146503448486
[INFO: train.py:  558]: resist loss: tensor([ 0.9414], device='cuda:0')
[INFO: train.py:  310]: g step took 2.139408826828003
[INFO: train.py:  316]: Interation 9702 took 2.1435515880584717
[INFO: train.py:  558]: resist loss: tensor([ 3.9730], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2665038108825684
[INFO: train.py:  316]: Interation 9703 took 2.270503520965576
[INFO: train.py:  558]: resist loss: tensor([ 1.0511], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7255170345306396
[INFO: train.py:  316]: Interation 9704 took 1.7294764518737793
[INFO: train.py:  558]: resist loss: tensor([ 0.8129], device='cuda:0')
[INFO: train.py:  310]: g step took 1.745469570159912
[INFO: train.py:  316]: Interation 9705 took 1.7494256496429443
[INFO: train.py:  558]: resist loss: tensor([ 4.1620], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9334337711334229
[INFO: train.py:  316]: Interation 9706 took 1.9373712539672852
[INFO: train.py:  558]: resist loss: tensor([ 5.3774], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9288983345031738
[INFO: train.py:  316]: Interation 9707 took 1.9328491687774658
[INFO: train.py:  558]: resist loss: tensor([ 4.2563], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1835412979125977
[INFO: train.py:  316]: Interation 9708 took 2.187547206878662
[INFO: train.py:  558]: resist loss: tensor([ 1.2850], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9428536891937256
[INFO: train.py:  316]: Interation 9709 took 1.9467947483062744
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 610, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 610, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 515, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 515, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 539, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 539, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 528, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 528, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 513, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 513, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 622, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 622, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 487, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 487, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 600, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 600, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 618, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 618, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 616, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 616, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 564, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 564, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 149, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 149, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 889, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 889, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 796, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 796, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 835, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 835, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 843, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 843, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 729, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 729, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 711, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 711, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 796, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 796, 2])
[INFO: train.py:  338]:   [val] ade: 0.723
[INFO: train.py:  338]:   [val] ade_l: 1.591
[INFO: train.py:  338]:   [val] ade_nl: 1.324
[INFO: train.py:  338]:   [val] d_loss: 1.425
[INFO: train.py:  338]:   [val] fde: 1.420
[INFO: train.py:  338]:   [val] fde_l: 3.127
[INFO: train.py:  338]:   [val] fde_nl: 2.602
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.560
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.560
[INFO: train.py:  338]:   [val] resist_count: 3482.000
[INFO: train.py:  338]:   [val] resist_loss: 0.365
[INFO: train.py:  341]:   [train] ade: 0.724
[INFO: train.py:  341]:   [train] ade_l: 1.513
[INFO: train.py:  341]:   [train] ade_nl: 1.389
[INFO: train.py:  341]:   [train] d_loss: 1.399
[INFO: train.py:  341]:   [train] fde: 1.331
[INFO: train.py:  341]:   [train] fde_l: 2.782
[INFO: train.py:  341]:   [train] fde_nl: 2.554
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.512
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.512
[INFO: train.py:  341]:   [train] resist_count: 3691.000
[INFO: train.py:  341]:   [train] resist_loss: 0.236
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 1.3200], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8544323444366455
[INFO: train.py:  316]: Interation 9710 took 10.629995346069336
[INFO: train.py:  558]: resist loss: tensor([ 3.3490], device='cuda:0')
[INFO: train.py:  310]: g step took 2.405385732650757
[INFO: train.py:  316]: Interation 9711 took 2.4098384380340576
[INFO: train.py:  558]: resist loss: tensor([ 0.7971], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7399988174438477
[INFO: train.py:  316]: Interation 9712 took 1.7439804077148438
[INFO: train.py:  558]: resist loss: tensor([ 9.3822], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8450677394866943
[INFO: train.py:  316]: Interation 9713 took 1.8488044738769531
[INFO: train.py:  558]: resist loss: tensor([ 8.3927], device='cuda:0')
[INFO: train.py:  310]: g step took 2.198822021484375
[INFO: train.py:  316]: Interation 9714 took 2.2028329372406006
[INFO: train.py:  558]: resist loss: tensor([ 16.6139], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9893412590026855
[INFO: train.py:  316]: Interation 9715 took 1.9933085441589355
[INFO: train.py:  558]: resist loss: tensor([ 5.9862], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9927444458007812
[INFO: train.py:  316]: Interation 9716 took 1.9963290691375732
[INFO: train.py:  558]: resist loss: tensor([ 0.9757], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8325495719909668
[INFO: train.py:  316]: Interation 9717 took 1.8365471363067627
[INFO: train.py:  558]: resist loss: tensor([ 3.2484], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1429755687713623
[INFO: train.py:  316]: Interation 9718 took 2.1472997665405273
[INFO: train.py:  558]: resist loss: tensor([ 1.2317], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7479491233825684
[INFO: train.py:  316]: Interation 9719 took 1.751906394958496
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 759, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 759, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 566, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 566, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 517, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 517, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 744, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 744, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 584, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 584, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 502, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 502, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 453, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 453, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 641, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 641, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 386, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 386, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 497, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 497, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 589, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 589, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 123, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 123, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 806, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 806, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 800, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 800, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 784, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 784, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 864, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 864, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 920, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 920, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 852, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 852, 2])
[INFO: train.py:  338]:   [val] ade: 0.613
[INFO: train.py:  338]:   [val] ade_l: 1.349
[INFO: train.py:  338]:   [val] ade_nl: 1.122
[INFO: train.py:  338]:   [val] d_loss: 1.406
[INFO: train.py:  338]:   [val] fde: 1.216
[INFO: train.py:  338]:   [val] fde_l: 2.678
[INFO: train.py:  338]:   [val] fde_nl: 2.228
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.446
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.446
[INFO: train.py:  338]:   [val] resist_count: 2640.000
[INFO: train.py:  338]:   [val] resist_loss: 0.310
[INFO: train.py:  341]:   [train] ade: 0.632
[INFO: train.py:  341]:   [train] ade_l: 1.309
[INFO: train.py:  341]:   [train] ade_nl: 1.223
[INFO: train.py:  341]:   [train] d_loss: 1.406
[INFO: train.py:  341]:   [train] fde: 1.171
[INFO: train.py:  341]:   [train] fde_l: 2.424
[INFO: train.py:  341]:   [train] fde_nl: 2.266
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.426
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.426
[INFO: train.py:  341]:   [train] resist_count: 2683.000
[INFO: train.py:  341]:   [train] resist_loss: 0.160
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 4.4081], device='cuda:0')
[INFO: train.py:  310]: g step took 2.251882314682007
[INFO: train.py:  316]: Interation 9720 took 10.486000299453735
[INFO: train.py:  558]: resist loss: tensor([ 4.0024], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9658839702606201
[INFO: train.py:  316]: Interation 9721 took 1.9697775840759277
[INFO: train.py:  558]: resist loss: tensor([ 2.4595], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1275906562805176
[INFO: train.py:  316]: Interation 9722 took 2.131519317626953
[INFO: train.py:  558]: resist loss: tensor([ 4.5224], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8198199272155762
[INFO: train.py:  316]: Interation 9723 took 1.823747158050537
[INFO: train.py:  558]: resist loss: tensor([ 5.0461], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9095842838287354
[INFO: train.py:  316]: Interation 9724 took 1.91324782371521
[INFO: train.py:  558]: resist loss: tensor([ 6.9580], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8035154342651367
[INFO: train.py:  316]: Interation 9725 took 1.8072118759155273
[INFO: train.py:  558]: resist loss: tensor([ 3.4481], device='cuda:0')
[INFO: train.py:  310]: g step took 1.899277687072754
[INFO: train.py:  316]: Interation 9726 took 1.9030859470367432
[INFO: train.py:  558]: resist loss: tensor([ 3.1814], device='cuda:0')
[INFO: train.py:  310]: g step took 0.18297457695007324
[INFO: train.py:  316]: Interation 9727 took 0.18724870681762695
[INFO: train.py:  279]: Starting epoch 228
[INFO: train.py:  280]: Epoch resist loss: tensor([ 201.7066])
[INFO: train.py:  558]: resist loss: tensor([ 1.7269], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0679590702056885
[INFO: train.py:  316]: Interation 9728 took 2.4736220836639404
[INFO: train.py:  558]: resist loss: tensor([ 5.1940], device='cuda:0')
[INFO: train.py:  310]: g step took 2.027015209197998
[INFO: train.py:  316]: Interation 9729 took 2.0276989936828613
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 580, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 580, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 542, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 542, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 566, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 566, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 695, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 695, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 650, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 650, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 493, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 493, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 496, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 496, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 539, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 539, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 435, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 435, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 689, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 689, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 574, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 574, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 102, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 102, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 714, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 714, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 734, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 734, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 809, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 809, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 626, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 626, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 666, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 666, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 740, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 740, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 717, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 717, 2])
[INFO: train.py:  338]:   [val] ade: 0.637
[INFO: train.py:  338]:   [val] ade_l: 1.403
[INFO: train.py:  338]:   [val] ade_nl: 1.167
[INFO: train.py:  338]:   [val] d_loss: 1.411
[INFO: train.py:  338]:   [val] fde: 1.290
[INFO: train.py:  338]:   [val] fde_l: 2.841
[INFO: train.py:  338]:   [val] fde_nl: 2.364
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.479
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.479
[INFO: train.py:  338]:   [val] resist_count: 2482.000
[INFO: train.py:  338]:   [val] resist_loss: 0.272
[INFO: train.py:  341]:   [train] ade: 0.645
[INFO: train.py:  341]:   [train] ade_l: 1.327
[INFO: train.py:  341]:   [train] ade_nl: 1.256
[INFO: train.py:  341]:   [train] d_loss: 1.404
[INFO: train.py:  341]:   [train] fde: 1.247
[INFO: train.py:  341]:   [train] fde_l: 2.565
[INFO: train.py:  341]:   [train] fde_nl: 2.428
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.445
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.445
[INFO: train.py:  341]:   [train] resist_count: 2165.000
[INFO: train.py:  341]:   [train] resist_loss: 0.138
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 3.2043], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0469441413879395
[INFO: train.py:  316]: Interation 9730 took 10.155012607574463
[INFO: train.py:  558]: resist loss: tensor([ 1.9457], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8862285614013672
[INFO: train.py:  316]: Interation 9731 took 1.886620044708252
[INFO: train.py:  558]: resist loss: tensor([ 1.5486], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7046418190002441
[INFO: train.py:  316]: Interation 9732 took 1.7050981521606445
[INFO: train.py:  558]: resist loss: tensor([ 4.3128], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5889651775360107
[INFO: train.py:  316]: Interation 9733 took 1.5893731117248535
[INFO: train.py:  558]: resist loss: tensor([ 0.7517], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8894929885864258
[INFO: train.py:  316]: Interation 9734 took 1.893993616104126
[INFO: train.py:  558]: resist loss: tensor([ 14.4755], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4274380207061768
[INFO: train.py:  316]: Interation 9735 took 2.427794933319092
[INFO: train.py:  558]: resist loss: tensor([ 10.6233], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9242548942565918
[INFO: train.py:  316]: Interation 9736 took 1.952742338180542
[INFO: train.py:  558]: resist loss: tensor([ 2.3063], device='cuda:0')
[INFO: train.py:  310]: g step took 1.94309663772583
[INFO: train.py:  316]: Interation 9737 took 1.943528175354004
[INFO: train.py:  558]: resist loss: tensor([ 8.2179], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5394153594970703
[INFO: train.py:  316]: Interation 9738 took 1.5397799015045166
[INFO: train.py:  558]: resist loss: tensor([ 0.5478], device='cuda:0')
[INFO: train.py:  310]: g step took 2.069075345993042
[INFO: train.py:  316]: Interation 9739 took 2.0694379806518555
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 541, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 541, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 502, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 502, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 678, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 678, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 622, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 622, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 477, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 477, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 516, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 516, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 570, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 570, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 478, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 478, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 522, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 522, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 561, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 561, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 762, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 762, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 132, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 132, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 731, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 731, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 1004, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 1004, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 485, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 485, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 762, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 762, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 727, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 727, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 669, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 669, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 821, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 821, 2])
[INFO: train.py:  338]:   [val] ade: 0.603
[INFO: train.py:  338]:   [val] ade_l: 1.328
[INFO: train.py:  338]:   [val] ade_nl: 1.105
[INFO: train.py:  338]:   [val] d_loss: 1.402
[INFO: train.py:  338]:   [val] fde: 1.227
[INFO: train.py:  338]:   [val] fde_l: 2.701
[INFO: train.py:  338]:   [val] fde_nl: 2.247
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.439
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.439
[INFO: train.py:  338]:   [val] resist_count: 2907.000
[INFO: train.py:  338]:   [val] resist_loss: 0.272
[INFO: train.py:  341]:   [train] ade: 0.601
[INFO: train.py:  341]:   [train] ade_l: 1.272
[INFO: train.py:  341]:   [train] ade_nl: 1.138
[INFO: train.py:  341]:   [train] d_loss: 1.398
[INFO: train.py:  341]:   [train] fde: 1.151
[INFO: train.py:  341]:   [train] fde_l: 2.438
[INFO: train.py:  341]:   [train] fde_nl: 2.181
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.370
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.370
[INFO: train.py:  341]:   [train] resist_count: 2677.000
[INFO: train.py:  341]:   [train] resist_loss: 0.139
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 4.2203], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7930610179901123
[INFO: train.py:  316]: Interation 9740 took 10.213876724243164
[INFO: train.py:  558]: resist loss: tensor([ 2.2088], device='cuda:0')
[INFO: train.py:  310]: g step took 2.076059579849243
[INFO: train.py:  316]: Interation 9741 took 2.076402187347412
[INFO: train.py:  558]: resist loss: tensor([ 5.5608], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0921685695648193
[INFO: train.py:  316]: Interation 9742 took 2.092508554458618
[INFO: train.py:  558]: resist loss: tensor([ 10.6726], device='cuda:0')
[INFO: train.py:  310]: g step took 1.904386281967163
[INFO: train.py:  316]: Interation 9743 took 1.904757022857666
[INFO: train.py:  558]: resist loss: tensor([ 0.8103], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1596004962921143
[INFO: train.py:  316]: Interation 9744 took 2.1638991832733154
[INFO: train.py:  558]: resist loss: tensor([ 2.0185], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9660234451293945
[INFO: train.py:  316]: Interation 9745 took 1.9700536727905273
[INFO: train.py:  558]: resist loss: tensor([ 5.6548], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9326462745666504
[INFO: train.py:  316]: Interation 9746 took 1.9367477893829346
[INFO: train.py:  558]: resist loss: tensor([ 4.7276], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9571473598480225
[INFO: train.py:  316]: Interation 9747 took 1.9611287117004395
[INFO: train.py:  558]: resist loss: tensor([ 6.1891], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6659107208251953
[INFO: train.py:  316]: Interation 9748 took 1.670083999633789
[INFO: train.py:  558]: resist loss: tensor([ 2.8460], device='cuda:0')
[INFO: train.py:  310]: g step took 1.737274408340454
[INFO: train.py:  316]: Interation 9749 took 1.7412431240081787
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 492, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 492, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 534, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 534, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 477, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 477, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 559, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 559, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 627, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 627, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 642, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 642, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 479, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 479, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 535, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 535, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 669, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 669, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 620, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 620, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 615, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 615, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 112, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 112, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 765, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 765, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 729, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 729, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 847, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 847, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 975, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 975, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 596, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 596, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 756, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 756, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 846, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 846, 2])
[INFO: train.py:  338]:   [val] ade: 0.613
[INFO: train.py:  338]:   [val] ade_l: 1.351
[INFO: train.py:  338]:   [val] ade_nl: 1.124
[INFO: train.py:  338]:   [val] d_loss: 1.413
[INFO: train.py:  338]:   [val] fde: 1.173
[INFO: train.py:  338]:   [val] fde_l: 2.582
[INFO: train.py:  338]:   [val] fde_nl: 2.149
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.440
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.440
[INFO: train.py:  338]:   [val] resist_count: 2762.000
[INFO: train.py:  338]:   [val] resist_loss: 0.295
[INFO: train.py:  341]:   [train] ade: 0.618
[INFO: train.py:  341]:   [train] ade_l: 1.335
[INFO: train.py:  341]:   [train] ade_nl: 1.152
[INFO: train.py:  341]:   [train] d_loss: 1.407
[INFO: train.py:  341]:   [train] fde: 1.116
[INFO: train.py:  341]:   [train] fde_l: 2.409
[INFO: train.py:  341]:   [train] fde_nl: 2.080
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.386
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.386
[INFO: train.py:  341]:   [train] resist_count: 2879.000
[INFO: train.py:  341]:   [train] resist_loss: 0.165
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 5.8438], device='cuda:0')
[INFO: train.py:  310]: g step took 2.469942092895508
[INFO: train.py:  316]: Interation 9750 took 11.197657346725464
[INFO: train.py:  558]: resist loss: tensor([ 17.1581], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4915409088134766
[INFO: train.py:  316]: Interation 9751 took 2.4956536293029785
[INFO: train.py:  558]: resist loss: tensor([ 5.8310], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1585047245025635
[INFO: train.py:  316]: Interation 9752 took 2.162583827972412
[INFO: train.py:  558]: resist loss: tensor([ 5.4652], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3237502574920654
[INFO: train.py:  316]: Interation 9753 took 2.327867031097412
[INFO: train.py:  558]: resist loss: tensor([ 0.6450], device='cuda:0')
[INFO: train.py:  310]: g step took 1.750849962234497
[INFO: train.py:  316]: Interation 9754 took 1.7548787593841553
[INFO: train.py:  558]: resist loss: tensor([ 9.0115], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9375638961791992
[INFO: train.py:  316]: Interation 9755 took 1.9414470195770264
[INFO: train.py:  558]: resist loss: tensor([ 12.7227], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2006776332855225
[INFO: train.py:  316]: Interation 9756 took 2.2046048641204834
[INFO: train.py:  558]: resist loss: tensor([ 1.3003], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7431628704071045
[INFO: train.py:  316]: Interation 9757 took 1.7474133968353271
[INFO: train.py:  558]: resist loss: tensor([ 6.9797], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7352025508880615
[INFO: train.py:  316]: Interation 9758 took 1.7384710311889648
[INFO: train.py:  558]: resist loss: tensor([ 5.3355], device='cuda:0')
[INFO: train.py:  310]: g step took 1.650510549545288
[INFO: train.py:  316]: Interation 9759 took 1.6543867588043213
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 539, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 539, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 438, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 438, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 709, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 709, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 641, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 641, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 531, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 531, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 516, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 516, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 609, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 609, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 609, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 609, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 651, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 651, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 516, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 516, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 496, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 496, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 106, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 106, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 790, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 790, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 854, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 854, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 777, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 777, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 750, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 750, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 723, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 723, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 850, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 850, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 683, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 683, 2])
[INFO: train.py:  338]:   [val] ade: 0.612
[INFO: train.py:  338]:   [val] ade_l: 1.347
[INFO: train.py:  338]:   [val] ade_nl: 1.121
[INFO: train.py:  338]:   [val] d_loss: 1.406
[INFO: train.py:  338]:   [val] fde: 1.292
[INFO: train.py:  338]:   [val] fde_l: 2.845
[INFO: train.py:  338]:   [val] fde_nl: 2.368
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.462
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.462
[INFO: train.py:  338]:   [val] resist_count: 2451.000
[INFO: train.py:  338]:   [val] resist_loss: 0.240
[INFO: train.py:  341]:   [train] ade: 0.627
[INFO: train.py:  341]:   [train] ade_l: 1.335
[INFO: train.py:  341]:   [train] ade_nl: 1.182
[INFO: train.py:  341]:   [train] d_loss: 1.401
[INFO: train.py:  341]:   [train] fde: 1.252
[INFO: train.py:  341]:   [train] fde_l: 2.666
[INFO: train.py:  341]:   [train] fde_nl: 2.359
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.435
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.435
[INFO: train.py:  341]:   [train] resist_count: 2466.000
[INFO: train.py:  341]:   [train] resist_loss: 0.123
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 1.8515], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0452089309692383
[INFO: train.py:  316]: Interation 9760 took 10.806604862213135
[INFO: train.py:  558]: resist loss: tensor([ 8.1968], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9287173748016357
[INFO: train.py:  316]: Interation 9761 took 1.9327032566070557
[INFO: train.py:  558]: resist loss: tensor([ 4.9302], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4887051582336426
[INFO: train.py:  316]: Interation 9762 took 2.492734670639038
[INFO: train.py:  558]: resist loss: tensor([ 4.4215], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7163994312286377
[INFO: train.py:  316]: Interation 9763 took 1.720449447631836
[INFO: train.py:  558]: resist loss: tensor([ 4.5027], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8419973850250244
[INFO: train.py:  316]: Interation 9764 took 1.8463850021362305
[INFO: train.py:  558]: resist loss: tensor([ 1.6053], device='cuda:0')
[INFO: train.py:  310]: g step took 1.982886552810669
[INFO: train.py:  316]: Interation 9765 took 1.9868402481079102
[INFO: train.py:  558]: resist loss: tensor([ 5.6196], device='cuda:0')
[INFO: train.py:  310]: g step took 1.783031702041626
[INFO: train.py:  316]: Interation 9766 took 1.7868309020996094
[INFO: train.py:  558]: resist loss: tensor([ 3.5660], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9148406982421875
[INFO: train.py:  316]: Interation 9767 took 1.9191038608551025
[INFO: train.py:  558]: resist loss: tensor([ 11.2636], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8434710502624512
[INFO: train.py:  316]: Interation 9768 took 1.8474676609039307
[INFO: train.py:  558]: resist loss: tensor([ 1.4458], device='cuda:0')
[INFO: train.py:  310]: g step took 1.805091142654419
[INFO: train.py:  316]: Interation 9769 took 1.8090486526489258
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 451, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 451, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 564, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 564, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 551, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 551, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 622, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 622, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 500, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 500, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 586, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 586, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 520, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 520, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 646, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 646, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 526, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 526, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 640, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 640, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 574, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 574, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 181, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 181, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 710, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 710, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 847, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 847, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 705, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 705, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 771, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 771, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 957, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 957, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 772, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 772, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 860, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 860, 2])
[INFO: train.py:  338]:   [val] ade: 0.671
[INFO: train.py:  338]:   [val] ade_l: 1.477
[INFO: train.py:  338]:   [val] ade_nl: 1.229
[INFO: train.py:  338]:   [val] d_loss: 1.409
[INFO: train.py:  338]:   [val] fde: 1.393
[INFO: train.py:  338]:   [val] fde_l: 3.067
[INFO: train.py:  338]:   [val] fde_nl: 2.552
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.526
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.526
[INFO: train.py:  338]:   [val] resist_count: 2457.000
[INFO: train.py:  338]:   [val] resist_loss: 0.230
[INFO: train.py:  341]:   [train] ade: 0.687
[INFO: train.py:  341]:   [train] ade_l: 1.460
[INFO: train.py:  341]:   [train] ade_nl: 1.296
[INFO: train.py:  341]:   [train] d_loss: 1.401
[INFO: train.py:  341]:   [train] fde: 1.370
[INFO: train.py:  341]:   [train] fde_l: 2.913
[INFO: train.py:  341]:   [train] fde_nl: 2.586
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.492
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.492
[INFO: train.py:  341]:   [train] resist_count: 2601.000
[INFO: train.py:  341]:   [train] resist_loss: 0.132
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.], device='cuda:0')
[INFO: train.py:  310]: g step took 0.15554118156433105
[INFO: train.py:  316]: Interation 9770 took 8.97401738166809
[INFO: train.py:  279]: Starting epoch 229
[INFO: train.py:  280]: Epoch resist loss: tensor([ 217.4595])
[INFO: train.py:  558]: resist loss: tensor([ 9.0442], device='cuda:0')
[INFO: train.py:  310]: g step took 2.173295736312866
[INFO: train.py:  316]: Interation 9771 took 2.5616204738616943
[INFO: train.py:  558]: resist loss: tensor([ 0.7892], device='cuda:0')
[INFO: train.py:  310]: g step took 2.051767110824585
[INFO: train.py:  316]: Interation 9772 took 2.0629827976226807
[INFO: train.py:  558]: resist loss: tensor([ 5.5656], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0737903118133545
[INFO: train.py:  316]: Interation 9773 took 2.0741167068481445
[INFO: train.py:  558]: resist loss: tensor([ 13.2194], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9171524047851562
[INFO: train.py:  316]: Interation 9774 took 1.9338324069976807
[INFO: train.py:  558]: resist loss: tensor([ 5.1616], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5901758670806885
[INFO: train.py:  316]: Interation 9775 took 1.59059739112854
[INFO: train.py:  558]: resist loss: tensor([ 5.6122], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7587368488311768
[INFO: train.py:  316]: Interation 9776 took 1.7591755390167236
[INFO: train.py:  558]: resist loss: tensor([ 5.4746], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7080557346343994
[INFO: train.py:  316]: Interation 9777 took 1.7084434032440186
[INFO: train.py:  558]: resist loss: tensor([ 5.6721], device='cuda:0')
[INFO: train.py:  310]: g step took 2.075530767440796
[INFO: train.py:  316]: Interation 9778 took 2.0759084224700928
[INFO: train.py:  558]: resist loss: tensor([ 11.0037], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1335272789001465
[INFO: train.py:  316]: Interation 9779 took 2.1406853199005127
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 656, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 656, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 581, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 581, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 633, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 633, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 565, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 565, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 562, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 562, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 526, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 526, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 554, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 554, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 470, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 470, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 489, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 489, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 553, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 553, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 564, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 564, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 208, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 208, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 768, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 768, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 776, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 776, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 877, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 877, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 635, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 635, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 700, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 700, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 727, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 727, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 698, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 698, 2])
[INFO: train.py:  338]:   [val] ade: 0.656
[INFO: train.py:  338]:   [val] ade_l: 1.444
[INFO: train.py:  338]:   [val] ade_nl: 1.202
[INFO: train.py:  338]:   [val] d_loss: 1.395
[INFO: train.py:  338]:   [val] fde: 1.390
[INFO: train.py:  338]:   [val] fde_l: 3.060
[INFO: train.py:  338]:   [val] fde_nl: 2.546
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.509
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.509
[INFO: train.py:  338]:   [val] resist_count: 2720.000
[INFO: train.py:  338]:   [val] resist_loss: 0.284
[INFO: train.py:  341]:   [train] ade: 0.676
[INFO: train.py:  341]:   [train] ade_l: 1.437
[INFO: train.py:  341]:   [train] ade_nl: 1.277
[INFO: train.py:  341]:   [train] d_loss: 1.406
[INFO: train.py:  341]:   [train] fde: 1.385
[INFO: train.py:  341]:   [train] fde_l: 2.943
[INFO: train.py:  341]:   [train] fde_nl: 2.616
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.483
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.483
[INFO: train.py:  341]:   [train] resist_count: 2455.000
[INFO: train.py:  341]:   [train] resist_loss: 0.168
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.8015], device='cuda:0')
[INFO: train.py:  310]: g step took 2.077155590057373
[INFO: train.py:  316]: Interation 9780 took 10.720628499984741
[INFO: train.py:  558]: resist loss: tensor([ 9.6661], device='cuda:0')
[INFO: train.py:  310]: g step took 1.952573537826538
[INFO: train.py:  316]: Interation 9781 took 1.952927589416504
[INFO: train.py:  558]: resist loss: tensor([ 1.8472], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8258333206176758
[INFO: train.py:  316]: Interation 9782 took 1.8399338722229004
[INFO: train.py:  558]: resist loss: tensor([ 0.2611], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7078766822814941
[INFO: train.py:  316]: Interation 9783 took 1.708223819732666
[INFO: train.py:  558]: resist loss: tensor([ 6.5928], device='cuda:0')
[INFO: train.py:  310]: g step took 2.233426094055176
[INFO: train.py:  316]: Interation 9784 took 2.2337396144866943
[INFO: train.py:  558]: resist loss: tensor([ 2.0008], device='cuda:0')
[INFO: train.py:  310]: g step took 1.756340503692627
[INFO: train.py:  316]: Interation 9785 took 1.7567782402038574
[INFO: train.py:  558]: resist loss: tensor([ 0.9669], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5207300186157227
[INFO: train.py:  316]: Interation 9786 took 1.5211505889892578
[INFO: train.py:  558]: resist loss: tensor([ 4.7879], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8604185581207275
[INFO: train.py:  316]: Interation 9787 took 1.864739179611206
[INFO: train.py:  558]: resist loss: tensor([ 1.3793], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8480582237243652
[INFO: train.py:  316]: Interation 9788 took 1.8518321514129639
[INFO: train.py:  558]: resist loss: tensor([ 1.9168], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7987589836120605
[INFO: train.py:  316]: Interation 9789 took 1.8027722835540771
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 599, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 599, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 492, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 492, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 536, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 536, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 497, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 497, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 642, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 642, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 489, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 489, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 502, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 502, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 567, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 567, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 630, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 630, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 637, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 637, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 640, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 640, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 130, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 130, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 819, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 819, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 686, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 686, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 715, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 715, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 705, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 705, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 671, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 671, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 815, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 815, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 871, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 871, 2])
[INFO: train.py:  338]:   [val] ade: 0.653
[INFO: train.py:  338]:   [val] ade_l: 1.437
[INFO: train.py:  338]:   [val] ade_nl: 1.196
[INFO: train.py:  338]:   [val] d_loss: 1.413
[INFO: train.py:  338]:   [val] fde: 1.364
[INFO: train.py:  338]:   [val] fde_l: 3.004
[INFO: train.py:  338]:   [val] fde_nl: 2.499
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.515
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.515
[INFO: train.py:  338]:   [val] resist_count: 2968.000
[INFO: train.py:  338]:   [val] resist_loss: 0.305
[INFO: train.py:  341]:   [train] ade: 0.637
[INFO: train.py:  341]:   [train] ade_l: 1.324
[INFO: train.py:  341]:   [train] ade_nl: 1.229
[INFO: train.py:  341]:   [train] d_loss: 1.396
[INFO: train.py:  341]:   [train] fde: 1.287
[INFO: train.py:  341]:   [train] fde_l: 2.674
[INFO: train.py:  341]:   [train] fde_nl: 2.483
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.440
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.440
[INFO: train.py:  341]:   [train] resist_count: 2980.000
[INFO: train.py:  341]:   [train] resist_loss: 0.185
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.8096], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1933155059814453
[INFO: train.py:  316]: Interation 9790 took 11.004062175750732
[INFO: train.py:  558]: resist loss: tensor([ 12.3474], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8064451217651367
[INFO: train.py:  316]: Interation 9791 took 1.8103721141815186
[INFO: train.py:  558]: resist loss: tensor([ 0.3981], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7488093376159668
[INFO: train.py:  316]: Interation 9792 took 1.7528080940246582
[INFO: train.py:  558]: resist loss: tensor([ 4.4429], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9481463432312012
[INFO: train.py:  316]: Interation 9793 took 1.9521219730377197
[INFO: train.py:  558]: resist loss: tensor([ 4.4732], device='cuda:0')
[INFO: train.py:  310]: g step took 1.793172836303711
[INFO: train.py:  316]: Interation 9794 took 1.7967743873596191
[INFO: train.py:  558]: resist loss: tensor([ 3.5816], device='cuda:0')
[INFO: train.py:  310]: g step took 2.098998785018921
[INFO: train.py:  316]: Interation 9795 took 2.1026742458343506
[INFO: train.py:  558]: resist loss: tensor([ 0.4529], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5821490287780762
[INFO: train.py:  316]: Interation 9796 took 1.5860905647277832
[INFO: train.py:  558]: resist loss: tensor([ 1.8235], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7939229011535645
[INFO: train.py:  316]: Interation 9797 took 1.7979774475097656
[INFO: train.py:  558]: resist loss: tensor([ 9.7164], device='cuda:0')
[INFO: train.py:  310]: g step took 2.10214900970459
[INFO: train.py:  316]: Interation 9798 took 2.1060104370117188
[INFO: train.py:  558]: resist loss: tensor([ 3.3302], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7009084224700928
[INFO: train.py:  316]: Interation 9799 took 1.704763650894165
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 496, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 496, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 556, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 556, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 547, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 547, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 598, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 598, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 583, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 583, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 667, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 667, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 546, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 546, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 539, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 539, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 557, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 557, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 547, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 547, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 562, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 562, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 163, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 163, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 823, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 823, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 754, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 754, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 798, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 798, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 888, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 888, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 727, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 727, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 836, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 836, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 894, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 894, 2])
[INFO: train.py:  338]:   [val] ade: 0.652
[INFO: train.py:  338]:   [val] ade_l: 1.436
[INFO: train.py:  338]:   [val] ade_nl: 1.194
[INFO: train.py:  338]:   [val] d_loss: 1.405
[INFO: train.py:  338]:   [val] fde: 1.349
[INFO: train.py:  338]:   [val] fde_l: 2.969
[INFO: train.py:  338]:   [val] fde_nl: 2.471
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.505
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.505
[INFO: train.py:  338]:   [val] resist_count: 3005.000
[INFO: train.py:  338]:   [val] resist_loss: 0.304
[INFO: train.py:  341]:   [train] ade: 0.649
[INFO: train.py:  341]:   [train] ade_l: 1.397
[INFO: train.py:  341]:   [train] ade_nl: 1.213
[INFO: train.py:  341]:   [train] d_loss: 1.396
[INFO: train.py:  341]:   [train] fde: 1.277
[INFO: train.py:  341]:   [train] fde_l: 2.747
[INFO: train.py:  341]:   [train] fde_nl: 2.386
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.440
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.440
[INFO: train.py:  341]:   [train] resist_count: 3100.000
[INFO: train.py:  341]:   [train] resist_loss: 0.171
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 6.6823], device='cuda:0')
[INFO: train.py:  310]: g step took 2.408872365951538
[INFO: train.py:  316]: Interation 9800 took 11.405875205993652
[INFO: train.py:  558]: resist loss: tensor([ 8.2037], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1984925270080566
[INFO: train.py:  316]: Interation 9801 took 2.2024118900299072
[INFO: train.py:  558]: resist loss: tensor([ 0.8740], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7699477672576904
[INFO: train.py:  316]: Interation 9802 took 1.7736124992370605
[INFO: train.py:  558]: resist loss: tensor([ 0.6189], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9866442680358887
[INFO: train.py:  316]: Interation 9803 took 1.9904956817626953
[INFO: train.py:  558]: resist loss: tensor([ 3.3851], device='cuda:0')
[INFO: train.py:  310]: g step took 2.426224708557129
[INFO: train.py:  316]: Interation 9804 took 2.4302170276641846
[INFO: train.py:  558]: resist loss: tensor([ 3.7133], device='cuda:0')
[INFO: train.py:  310]: g step took 2.036714553833008
[INFO: train.py:  316]: Interation 9805 took 2.041163682937622
[INFO: train.py:  558]: resist loss: tensor([ 1.6542], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8016483783721924
[INFO: train.py:  316]: Interation 9806 took 1.805602788925171
[INFO: train.py:  558]: resist loss: tensor([ 4.3101], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9408175945281982
[INFO: train.py:  316]: Interation 9807 took 1.9446749687194824
[INFO: train.py:  558]: resist loss: tensor([ 2.1150], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9114575386047363
[INFO: train.py:  316]: Interation 9808 took 1.9152979850769043
[INFO: train.py:  558]: resist loss: tensor([ 6.1076], device='cuda:0')
[INFO: train.py:  310]: g step took 2.252744674682617
[INFO: train.py:  316]: Interation 9809 took 2.2564408779144287
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 530, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 530, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 619, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 619, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 604, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 604, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 612, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 612, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 567, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 567, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 617, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 617, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 491, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 491, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 542, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 542, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 437, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 437, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 562, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 562, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 617, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 617, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 163, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 163, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 780, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 780, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 768, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 768, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 699, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 699, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 831, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 831, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 926, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 926, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 826, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 826, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 915, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 915, 2])
[INFO: train.py:  338]:   [val] ade: 0.631
[INFO: train.py:  338]:   [val] ade_l: 1.388
[INFO: train.py:  338]:   [val] ade_nl: 1.155
[INFO: train.py:  338]:   [val] d_loss: 1.407
[INFO: train.py:  338]:   [val] fde: 1.299
[INFO: train.py:  338]:   [val] fde_l: 2.860
[INFO: train.py:  338]:   [val] fde_nl: 2.380
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.475
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.475
[INFO: train.py:  338]:   [val] resist_count: 2663.000
[INFO: train.py:  338]:   [val] resist_loss: 0.263
[INFO: train.py:  341]:   [train] ade: 0.622
[INFO: train.py:  341]:   [train] ade_l: 1.271
[INFO: train.py:  341]:   [train] ade_nl: 1.220
[INFO: train.py:  341]:   [train] d_loss: 1.396
[INFO: train.py:  341]:   [train] fde: 1.197
[INFO: train.py:  341]:   [train] fde_l: 2.445
[INFO: train.py:  341]:   [train] fde_nl: 2.346
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.409
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.409
[INFO: train.py:  341]:   [train] resist_count: 2776.000
[INFO: train.py:  341]:   [train] resist_loss: 0.156
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.5258], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8740673065185547
[INFO: train.py:  316]: Interation 9810 took 10.8120698928833
[INFO: train.py:  558]: resist loss: tensor([ 0.4086], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7815907001495361
[INFO: train.py:  316]: Interation 9811 took 1.7853808403015137
[INFO: train.py:  558]: resist loss: tensor([ 3.8822], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6798763275146484
[INFO: train.py:  316]: Interation 9812 took 1.68373703956604
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 8.2242], device='cuda:0')
[INFO: train.py:  310]: g step took 0.20609831809997559
[INFO: train.py:  316]: Interation 9813 took 0.2100687026977539
[INFO: train.py:  279]: Starting epoch 230
[INFO: train.py:  280]: Epoch resist loss: tensor([ 177.7021])
[INFO: train.py:  558]: resist loss: tensor([ 13.6418], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2033307552337646
[INFO: train.py:  316]: Interation 9814 took 2.5800681114196777
[INFO: train.py:  558]: resist loss: tensor([ 6.3935], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7094590663909912
[INFO: train.py:  316]: Interation 9815 took 1.7310206890106201
[INFO: train.py:  558]: resist loss: tensor([ 9.7249], device='cuda:0')
[INFO: train.py:  310]: g step took 1.853731632232666
[INFO: train.py:  316]: Interation 9816 took 1.8577907085418701
[INFO: train.py:  558]: resist loss: tensor([ 1.9573], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6132943630218506
[INFO: train.py:  316]: Interation 9817 took 1.6137213706970215
[INFO: train.py:  558]: resist loss: tensor([ 15.5364], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2592661380767822
[INFO: train.py:  316]: Interation 9818 took 2.259690761566162
[INFO: train.py:  558]: resist loss: tensor([ 8.7338], device='cuda:0')
[INFO: train.py:  310]: g step took 2.04782772064209
[INFO: train.py:  316]: Interation 9819 took 2.048280954360962
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 578, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 578, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 576, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 576, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 576, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 576, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 541, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 541, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 507, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 507, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 559, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 559, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 528, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 528, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 512, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 512, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 501, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 501, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 665, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 665, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 639, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 639, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 179, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 179, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 895, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 895, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 793, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 793, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 804, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 804, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 746, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 746, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 803, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 803, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 879, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 879, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 769, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 769, 2])
[INFO: train.py:  338]:   [val] ade: 0.627
[INFO: train.py:  338]:   [val] ade_l: 1.382
[INFO: train.py:  338]:   [val] ade_nl: 1.150
[INFO: train.py:  338]:   [val] d_loss: 1.404
[INFO: train.py:  338]:   [val] fde: 1.332
[INFO: train.py:  338]:   [val] fde_l: 2.932
[INFO: train.py:  338]:   [val] fde_nl: 2.439
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.483
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.483
[INFO: train.py:  338]:   [val] resist_count: 2743.000
[INFO: train.py:  338]:   [val] resist_loss: 0.269
[INFO: train.py:  341]:   [train] ade: 0.620
[INFO: train.py:  341]:   [train] ade_l: 1.298
[INFO: train.py:  341]:   [train] ade_nl: 1.187
[INFO: train.py:  341]:   [train] d_loss: 1.394
[INFO: train.py:  341]:   [train] fde: 1.250
[INFO: train.py:  341]:   [train] fde_l: 2.618
[INFO: train.py:  341]:   [train] fde_nl: 2.393
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.407
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.407
[INFO: train.py:  341]:   [train] resist_count: 2927.000
[INFO: train.py:  341]:   [train] resist_loss: 0.178
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.2565], device='cuda:0')
[INFO: train.py:  310]: g step took 1.974048137664795
[INFO: train.py:  316]: Interation 9820 took 10.990313291549683
[INFO: train.py:  558]: resist loss: tensor([ 3.1006], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6762793064117432
[INFO: train.py:  316]: Interation 9821 took 1.6767237186431885
[INFO: train.py:  558]: resist loss: tensor([ 5.8463], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8913450241088867
[INFO: train.py:  316]: Interation 9822 took 1.89542555809021
[INFO: train.py:  558]: resist loss: tensor([ 2.5271], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7663891315460205
[INFO: train.py:  316]: Interation 9823 took 1.7870872020721436
[INFO: train.py:  558]: resist loss: tensor([ 1.8903], device='cuda:0')
[INFO: train.py:  310]: g step took 1.884955644607544
[INFO: train.py:  316]: Interation 9824 took 1.8891215324401855
[INFO: train.py:  558]: resist loss: tensor([ 0.8564], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9877560138702393
[INFO: train.py:  316]: Interation 9825 took 1.9881610870361328
[INFO: train.py:  558]: resist loss: tensor([ 1.9695], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7832460403442383
[INFO: train.py:  316]: Interation 9826 took 1.7836072444915771
[INFO: train.py:  558]: resist loss: tensor([ 7.5617], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2619786262512207
[INFO: train.py:  316]: Interation 9827 took 2.262329339981079
[INFO: train.py:  558]: resist loss: tensor([ 8.1834], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9763891696929932
[INFO: train.py:  316]: Interation 9828 took 1.9767155647277832
[INFO: train.py:  558]: resist loss: tensor([ 6.4270], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0775647163391113
[INFO: train.py:  316]: Interation 9829 took 2.077906370162964
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 484, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 484, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 513, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 513, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 467, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 467, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 623, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 623, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 631, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 631, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 521, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 521, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 557, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 557, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 588, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 588, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 512, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 512, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 661, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 661, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 649, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 649, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 155, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 155, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 898, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 898, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 762, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 762, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 689, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 689, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 784, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 784, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 843, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 843, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 785, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 785, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 819, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 819, 2])
[INFO: train.py:  338]:   [val] ade: 0.623
[INFO: train.py:  338]:   [val] ade_l: 1.372
[INFO: train.py:  338]:   [val] ade_nl: 1.141
[INFO: train.py:  338]:   [val] d_loss: 1.413
[INFO: train.py:  338]:   [val] fde: 1.303
[INFO: train.py:  338]:   [val] fde_l: 2.868
[INFO: train.py:  338]:   [val] fde_nl: 2.387
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.458
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.458
[INFO: train.py:  338]:   [val] resist_count: 2859.000
[INFO: train.py:  338]:   [val] resist_loss: 0.302
[INFO: train.py:  341]:   [train] ade: 0.617
[INFO: train.py:  341]:   [train] ade_l: 1.297
[INFO: train.py:  341]:   [train] ade_nl: 1.178
[INFO: train.py:  341]:   [train] d_loss: 1.405
[INFO: train.py:  341]:   [train] fde: 1.199
[INFO: train.py:  341]:   [train] fde_l: 2.518
[INFO: train.py:  341]:   [train] fde_nl: 2.287
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.399
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.399
[INFO: train.py:  341]:   [train] resist_count: 2988.000
[INFO: train.py:  341]:   [train] resist_loss: 0.197
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 3.1359], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7689907550811768
[INFO: train.py:  316]: Interation 9830 took 10.703745603561401
[INFO: train.py:  558]: resist loss: tensor([ 6.3572], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7888693809509277
[INFO: train.py:  316]: Interation 9831 took 1.79282808303833
[INFO: train.py:  558]: resist loss: tensor([ 0.4292], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0605461597442627
[INFO: train.py:  316]: Interation 9832 took 2.064602851867676
[INFO: train.py:  558]: resist loss: tensor([ 7.0936], device='cuda:0')
[INFO: train.py:  310]: g step took 1.575347661972046
[INFO: train.py:  316]: Interation 9833 took 1.579270601272583
[INFO: train.py:  558]: resist loss: tensor([ 0.5541], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2437314987182617
[INFO: train.py:  316]: Interation 9834 took 2.247703790664673
[INFO: train.py:  558]: resist loss: tensor([ 3.2322], device='cuda:0')
[INFO: train.py:  310]: g step took 2.397242307662964
[INFO: train.py:  316]: Interation 9835 took 2.4012889862060547
[INFO: train.py:  558]: resist loss: tensor([ 4.8043], device='cuda:0')
[INFO: train.py:  310]: g step took 2.5578091144561768
[INFO: train.py:  316]: Interation 9836 took 2.56142258644104
[INFO: train.py:  558]: resist loss: tensor([ 1.1128], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3008134365081787
[INFO: train.py:  316]: Interation 9837 took 2.3048698902130127
[INFO: train.py:  558]: resist loss: tensor([ 0.7861], device='cuda:0')
[INFO: train.py:  310]: g step took 2.452423095703125
[INFO: train.py:  316]: Interation 9838 took 2.455575704574585
[INFO: train.py:  558]: resist loss: tensor([ 16.5261], device='cuda:0')
[INFO: train.py:  310]: g step took 2.8236169815063477
[INFO: train.py:  316]: Interation 9839 took 2.827597141265869
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 587, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 587, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 497, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 497, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 639, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 639, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 459, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 459, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 639, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 639, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 509, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 509, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 602, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 602, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 544, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 544, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 582, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 582, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 649, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 649, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 462, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 462, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 192, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 192, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 777, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 777, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 797, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 797, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 733, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 733, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 775, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 775, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 674, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 674, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 726, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 726, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 797, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 797, 2])
[INFO: train.py:  338]:   [val] ade: 0.605
[INFO: train.py:  338]:   [val] ade_l: 1.332
[INFO: train.py:  338]:   [val] ade_nl: 1.108
[INFO: train.py:  338]:   [val] d_loss: 1.415
[INFO: train.py:  338]:   [val] fde: 1.307
[INFO: train.py:  338]:   [val] fde_l: 2.879
[INFO: train.py:  338]:   [val] fde_nl: 2.395
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.456
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.456
[INFO: train.py:  338]:   [val] resist_count: 2879.000
[INFO: train.py:  338]:   [val] resist_loss: 0.304
[INFO: train.py:  341]:   [train] ade: 0.602
[INFO: train.py:  341]:   [train] ade_l: 1.264
[INFO: train.py:  341]:   [train] ade_nl: 1.150
[INFO: train.py:  341]:   [train] d_loss: 1.397
[INFO: train.py:  341]:   [train] fde: 1.229
[INFO: train.py:  341]:   [train] fde_l: 2.580
[INFO: train.py:  341]:   [train] fde_nl: 2.348
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.401
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.401
[INFO: train.py:  341]:   [train] resist_count: 2758.000
[INFO: train.py:  341]:   [train] resist_loss: 0.163
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 7.4530], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2420473098754883
[INFO: train.py:  316]: Interation 9840 took 11.862685203552246
[INFO: train.py:  558]: resist loss: tensor([ 1.1143], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9963922500610352
[INFO: train.py:  316]: Interation 9841 took 2.00126051902771
[INFO: train.py:  558]: resist loss: tensor([ 7.7357], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7971370220184326
[INFO: train.py:  316]: Interation 9842 took 1.8009488582611084
[INFO: train.py:  558]: resist loss: tensor([ 3.1409], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8260235786437988
[INFO: train.py:  316]: Interation 9843 took 1.8300058841705322
[INFO: train.py:  558]: resist loss: tensor([ 3.6940], device='cuda:0')
[INFO: train.py:  310]: g step took 2.021287679672241
[INFO: train.py:  316]: Interation 9844 took 2.025130271911621
[INFO: train.py:  558]: resist loss: tensor([ 9.6935], device='cuda:0')
[INFO: train.py:  310]: g step took 2.02386212348938
[INFO: train.py:  316]: Interation 9845 took 2.0277211666107178
[INFO: train.py:  558]: resist loss: tensor([ 0.6538], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2762465476989746
[INFO: train.py:  316]: Interation 9846 took 2.279700517654419
[INFO: train.py:  558]: resist loss: tensor([ 0.4860], device='cuda:0')
[INFO: train.py:  310]: g step took 2.101428270339966
[INFO: train.py:  316]: Interation 9847 took 2.105260133743286
[INFO: train.py:  558]: resist loss: tensor([ 0.3847], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7705209255218506
[INFO: train.py:  316]: Interation 9848 took 1.7745108604431152
[INFO: train.py:  558]: resist loss: tensor([ 0.7040], device='cuda:0')
[INFO: train.py:  310]: g step took 1.877612590789795
[INFO: train.py:  316]: Interation 9849 took 1.8815464973449707
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 489, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 489, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 550, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 550, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 617, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 617, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 519, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 519, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 494, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 494, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 460, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 460, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 654, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 654, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 667, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 667, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 586, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 586, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 578, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 578, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 550, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 550, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 197, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 197, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 598, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 598, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 821, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 821, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 629, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 629, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 651, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 651, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 902, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 902, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 849, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 849, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 713, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 713, 2])
[INFO: train.py:  338]:   [val] ade: 0.609
[INFO: train.py:  338]:   [val] ade_l: 1.340
[INFO: train.py:  338]:   [val] ade_nl: 1.115
[INFO: train.py:  338]:   [val] d_loss: 1.414
[INFO: train.py:  338]:   [val] fde: 1.293
[INFO: train.py:  338]:   [val] fde_l: 2.847
[INFO: train.py:  338]:   [val] fde_nl: 2.369
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.469
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.469
[INFO: train.py:  338]:   [val] resist_count: 2863.000
[INFO: train.py:  338]:   [val] resist_loss: 0.296
[INFO: train.py:  341]:   [train] ade: 0.583
[INFO: train.py:  341]:   [train] ade_l: 1.252
[INFO: train.py:  341]:   [train] ade_nl: 1.092
[INFO: train.py:  341]:   [train] d_loss: 1.415
[INFO: train.py:  341]:   [train] fde: 1.170
[INFO: train.py:  341]:   [train] fde_l: 2.511
[INFO: train.py:  341]:   [train] fde_nl: 2.190
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.375
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.375
[INFO: train.py:  341]:   [train] resist_count: 2858.000
[INFO: train.py:  341]:   [train] resist_loss: 0.178
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 3.5329], device='cuda:0')
[INFO: train.py:  310]: g step took 1.847032070159912
[INFO: train.py:  316]: Interation 9850 took 10.534455060958862
[INFO: train.py:  558]: resist loss: tensor([ 5.4327], device='cuda:0')
[INFO: train.py:  310]: g step took 2.078453302383423
[INFO: train.py:  316]: Interation 9851 took 2.0823895931243896
[INFO: train.py:  558]: resist loss: tensor([ 3.5284], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8892736434936523
[INFO: train.py:  316]: Interation 9852 took 1.8928394317626953
[INFO: train.py:  558]: resist loss: tensor([ 5.9577], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0968856811523438
[INFO: train.py:  316]: Interation 9853 took 2.1007802486419678
[INFO: train.py:  558]: resist loss: tensor([ 10.3730], device='cuda:0')
[INFO: train.py:  310]: g step took 2.109295606613159
[INFO: train.py:  316]: Interation 9854 took 2.1125972270965576
[INFO: train.py:  558]: resist loss: tensor([ 6.1889], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2062594890594482
[INFO: train.py:  316]: Interation 9855 took 2.2101073265075684
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 3.5640], device='cuda:0')
[INFO: train.py:  310]: g step took 0.221815824508667
[INFO: train.py:  316]: Interation 9856 took 0.22744274139404297
[INFO: train.py:  279]: Starting epoch 231
[INFO: train.py:  280]: Epoch resist loss: tensor([ 208.7472])
[INFO: train.py:  558]: resist loss: tensor([ 4.4624], device='cuda:0')
[INFO: train.py:  310]: g step took 2.396108865737915
[INFO: train.py:  316]: Interation 9857 took 2.8040919303894043
[INFO: train.py:  558]: resist loss: tensor([ 2.2842], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9123611450195312
[INFO: train.py:  316]: Interation 9858 took 1.940392255783081
[INFO: train.py:  558]: resist loss: tensor([ 1.1729], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7949397563934326
[INFO: train.py:  316]: Interation 9859 took 1.7954387664794922
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 614, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 614, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 542, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 542, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 583, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 583, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 534, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 534, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 531, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 531, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 546, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 546, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 624, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 624, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 647, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 647, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 492, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 492, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 543, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 543, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 553, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 553, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 152, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 152, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 854, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 854, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 733, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 733, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 859, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 859, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 720, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 720, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 862, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 862, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 672, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 672, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 628, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 628, 2])
[INFO: train.py:  338]:   [val] ade: 0.631
[INFO: train.py:  338]:   [val] ade_l: 1.390
[INFO: train.py:  338]:   [val] ade_nl: 1.156
[INFO: train.py:  338]:   [val] d_loss: 1.412
[INFO: train.py:  338]:   [val] fde: 1.325
[INFO: train.py:  338]:   [val] fde_l: 2.917
[INFO: train.py:  338]:   [val] fde_nl: 2.427
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.469
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.469
[INFO: train.py:  338]:   [val] resist_count: 3741.000
[INFO: train.py:  338]:   [val] resist_loss: 0.353
[INFO: train.py:  341]:   [train] ade: 0.618
[INFO: train.py:  341]:   [train] ade_l: 1.269
[INFO: train.py:  341]:   [train] ade_nl: 1.205
[INFO: train.py:  341]:   [train] d_loss: 1.399
[INFO: train.py:  341]:   [train] fde: 1.226
[INFO: train.py:  341]:   [train] fde_l: 2.517
[INFO: train.py:  341]:   [train] fde_nl: 2.390
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.415
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.415
[INFO: train.py:  341]:   [train] resist_count: 3216.000
[INFO: train.py:  341]:   [train] resist_loss: 0.200
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 4.8825], device='cuda:0')
[INFO: train.py:  310]: g step took 2.120058298110962
[INFO: train.py:  316]: Interation 9860 took 10.352594375610352
[INFO: train.py:  558]: resist loss: tensor([ 0.8655], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7922866344451904
[INFO: train.py:  316]: Interation 9861 took 1.792809247970581
[INFO: train.py:  558]: resist loss: tensor([ 8.4159], device='cuda:0')
[INFO: train.py:  310]: g step took 1.828437089920044
[INFO: train.py:  316]: Interation 9862 took 1.8289659023284912
[INFO: train.py:  558]: resist loss: tensor([ 6.2426], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1012938022613525
[INFO: train.py:  316]: Interation 9863 took 2.1016886234283447
[INFO: train.py:  558]: resist loss: tensor([ 1.0614], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9951035976409912
[INFO: train.py:  316]: Interation 9864 took 1.9955377578735352
[INFO: train.py:  558]: resist loss: tensor([ 5.2927], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0202198028564453
[INFO: train.py:  316]: Interation 9865 took 2.02061128616333
[INFO: train.py:  558]: resist loss: tensor([ 2.1513], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8480472564697266
[INFO: train.py:  316]: Interation 9866 took 1.8643019199371338
[INFO: train.py:  558]: resist loss: tensor([ 8.2104], device='cuda:0')
[INFO: train.py:  310]: g step took 2.001993179321289
[INFO: train.py:  316]: Interation 9867 took 2.0023789405822754
[INFO: train.py:  558]: resist loss: tensor([ 8.1651], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8856699466705322
[INFO: train.py:  316]: Interation 9868 took 1.8859803676605225
[INFO: train.py:  558]: resist loss: tensor([ 2.1870], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9849750995635986
[INFO: train.py:  316]: Interation 9869 took 1.985457181930542
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 587, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 587, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 529, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 529, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 587, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 587, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 592, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 592, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 517, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 517, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 569, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 569, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 653, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 653, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 516, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 516, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 644, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 644, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 532, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 532, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 512, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 512, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 123, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 123, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 685, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 685, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 775, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 775, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 763, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 763, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 742, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 742, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 711, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 711, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 963, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 963, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 822, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 822, 2])
[INFO: train.py:  338]:   [val] ade: 0.624
[INFO: train.py:  338]:   [val] ade_l: 1.374
[INFO: train.py:  338]:   [val] ade_nl: 1.143
[INFO: train.py:  338]:   [val] d_loss: 1.420
[INFO: train.py:  338]:   [val] fde: 1.303
[INFO: train.py:  338]:   [val] fde_l: 2.868
[INFO: train.py:  338]:   [val] fde_nl: 2.386
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.464
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.464
[INFO: train.py:  338]:   [val] resist_count: 3066.000
[INFO: train.py:  338]:   [val] resist_loss: 0.322
[INFO: train.py:  341]:   [train] ade: 0.631
[INFO: train.py:  341]:   [train] ade_l: 1.328
[INFO: train.py:  341]:   [train] ade_nl: 1.202
[INFO: train.py:  341]:   [train] d_loss: 1.405
[INFO: train.py:  341]:   [train] fde: 1.232
[INFO: train.py:  341]:   [train] fde_l: 2.594
[INFO: train.py:  341]:   [train] fde_nl: 2.347
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.415
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.415
[INFO: train.py:  341]:   [train] resist_count: 3091.000
[INFO: train.py:  341]:   [train] resist_loss: 0.202
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.7625], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2278831005096436
[INFO: train.py:  316]: Interation 9870 took 10.817531824111938
[INFO: train.py:  558]: resist loss: tensor([ 1.0712], device='cuda:0')
[INFO: train.py:  310]: g step took 2.41788649559021
[INFO: train.py:  316]: Interation 9871 took 2.418233633041382
[INFO: train.py:  558]: resist loss: tensor([ 0.3106], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8509557247161865
[INFO: train.py:  316]: Interation 9872 took 1.8513848781585693
[INFO: train.py:  558]: resist loss: tensor([ 2.9981], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7410039901733398
[INFO: train.py:  316]: Interation 9873 took 1.7451303005218506
[INFO: train.py:  558]: resist loss: tensor([ 1.4835], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6247341632843018
[INFO: train.py:  316]: Interation 9874 took 1.6283042430877686
[INFO: train.py:  558]: resist loss: tensor([ 7.2370], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6911866664886475
[INFO: train.py:  316]: Interation 9875 took 1.695047378540039
[INFO: train.py:  558]: resist loss: tensor([ 15.1882], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7708227634429932
[INFO: train.py:  316]: Interation 9876 took 1.7747080326080322
[INFO: train.py:  558]: resist loss: tensor([ 9.0735], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8813936710357666
[INFO: train.py:  316]: Interation 9877 took 1.8852126598358154
[INFO: train.py:  558]: resist loss: tensor([ 3.5489], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3222358226776123
[INFO: train.py:  316]: Interation 9878 took 2.326127767562866
[INFO: train.py:  558]: resist loss: tensor([ 8.5796], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1356873512268066
[INFO: train.py:  316]: Interation 9879 took 2.1396987438201904
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 596, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 596, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 604, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 604, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 491, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 491, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 548, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 548, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 568, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 568, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 528, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 528, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 633, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 633, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 616, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 616, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 634, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 634, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 603, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 603, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 436, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 436, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 104, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 104, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 849, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 849, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 873, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 873, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 908, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 908, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 723, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 723, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 912, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 912, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 764, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 764, 2])
[INFO: train.py:  338]:   [val] ade: 0.662
[INFO: train.py:  338]:   [val] ade_l: 1.458
[INFO: train.py:  338]:   [val] ade_nl: 1.213
[INFO: train.py:  338]:   [val] d_loss: 1.407
[INFO: train.py:  338]:   [val] fde: 1.379
[INFO: train.py:  338]:   [val] fde_l: 3.035
[INFO: train.py:  338]:   [val] fde_nl: 2.526
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.500
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.500
[INFO: train.py:  338]:   [val] resist_count: 3010.000
[INFO: train.py:  338]:   [val] resist_loss: 0.319
[INFO: train.py:  341]:   [train] ade: 0.687
[INFO: train.py:  341]:   [train] ade_l: 1.498
[INFO: train.py:  341]:   [train] ade_nl: 1.270
[INFO: train.py:  341]:   [train] d_loss: 1.406
[INFO: train.py:  341]:   [train] fde: 1.347
[INFO: train.py:  341]:   [train] fde_l: 2.936
[INFO: train.py:  341]:   [train] fde_nl: 2.489
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.482
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.482
[INFO: train.py:  341]:   [train] resist_count: 2677.000
[INFO: train.py:  341]:   [train] resist_loss: 0.151
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.4273], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1889257431030273
[INFO: train.py:  316]: Interation 9880 took 11.688300848007202
[INFO: train.py:  558]: resist loss: tensor([ 5.6793], device='cuda:0')
[INFO: train.py:  310]: g step took 2.5746045112609863
[INFO: train.py:  316]: Interation 9881 took 2.578824043273926
[INFO: train.py:  558]: resist loss: tensor([ 1.7631], device='cuda:0')
[INFO: train.py:  310]: g step took 2.267965316772461
[INFO: train.py:  316]: Interation 9882 took 2.2720301151275635
[INFO: train.py:  558]: resist loss: tensor([ 5.9325], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4891517162323
[INFO: train.py:  316]: Interation 9883 took 2.4932730197906494
[INFO: train.py:  558]: resist loss: tensor([ 12.2332], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4265973567962646
[INFO: train.py:  316]: Interation 9884 took 2.4308135509490967
[INFO: train.py:  558]: resist loss: tensor([ 6.1012], device='cuda:0')
[INFO: train.py:  310]: g step took 2.905802011489868
[INFO: train.py:  316]: Interation 9885 took 2.9097237586975098
[INFO: train.py:  558]: resist loss: tensor([ 5.4566], device='cuda:0')
[INFO: train.py:  310]: g step took 2.399057149887085
[INFO: train.py:  316]: Interation 9886 took 2.402679681777954
[INFO: train.py:  558]: resist loss: tensor([ 12.5263], device='cuda:0')
[INFO: train.py:  310]: g step took 2.7012195587158203
[INFO: train.py:  316]: Interation 9887 took 2.7052435874938965
[INFO: train.py:  558]: resist loss: tensor([ 8.0318], device='cuda:0')
[INFO: train.py:  310]: g step took 2.446225881576538
[INFO: train.py:  316]: Interation 9888 took 2.4503397941589355
[INFO: train.py:  558]: resist loss: tensor([ 15.6223], device='cuda:0')
[INFO: train.py:  310]: g step took 2.503635883331299
[INFO: train.py:  316]: Interation 9889 took 2.5076346397399902
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 593, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 593, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 498, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 498, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 554, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 554, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 458, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 458, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 539, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 539, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 581, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 581, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 536, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 536, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 576, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 576, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 524, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 524, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 670, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 670, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 667, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 667, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 165, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 165, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 830, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 830, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 776, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 776, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 607, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 607, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 733, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 733, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 869, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 869, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 882, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 882, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 670, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 670, 2])
[INFO: train.py:  338]:   [val] ade: 0.621
[INFO: train.py:  338]:   [val] ade_l: 1.368
[INFO: train.py:  338]:   [val] ade_nl: 1.138
[INFO: train.py:  338]:   [val] d_loss: 1.399
[INFO: train.py:  338]:   [val] fde: 1.343
[INFO: train.py:  338]:   [val] fde_l: 2.958
[INFO: train.py:  338]:   [val] fde_nl: 2.461
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.469
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.469
[INFO: train.py:  338]:   [val] resist_count: 3125.000
[INFO: train.py:  338]:   [val] resist_loss: 0.292
[INFO: train.py:  341]:   [train] ade: 0.617
[INFO: train.py:  341]:   [train] ade_l: 1.262
[INFO: train.py:  341]:   [train] ade_nl: 1.208
[INFO: train.py:  341]:   [train] d_loss: 1.397
[INFO: train.py:  341]:   [train] fde: 1.257
[INFO: train.py:  341]:   [train] fde_l: 2.571
[INFO: train.py:  341]:   [train] fde_nl: 2.460
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.417
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.417
[INFO: train.py:  341]:   [train] resist_count: 2877.000
[INFO: train.py:  341]:   [train] resist_loss: 0.173
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.2572], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6031014919281006
[INFO: train.py:  316]: Interation 9890 took 11.083013772964478
[INFO: train.py:  558]: resist loss: tensor([ 21.2250], device='cuda:0')
[INFO: train.py:  310]: g step took 2.6071364879608154
[INFO: train.py:  316]: Interation 9891 took 2.6108245849609375
[INFO: train.py:  558]: resist loss: tensor([ 2.0706], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1616578102111816
[INFO: train.py:  316]: Interation 9892 took 2.165900707244873
[INFO: train.py:  558]: resist loss: tensor([ 7.4803], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4872395992279053
[INFO: train.py:  316]: Interation 9893 took 1.4911441802978516
[INFO: train.py:  558]: resist loss: tensor([ 0.3197], device='cuda:0')
[INFO: train.py:  310]: g step took 2.205402374267578
[INFO: train.py:  316]: Interation 9894 took 2.2092792987823486
[INFO: train.py:  558]: resist loss: tensor([ 0.1571], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2918190956115723
[INFO: train.py:  316]: Interation 9895 took 1.2957372665405273
[INFO: train.py:  558]: resist loss: tensor([ 3.6327], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1468565464019775
[INFO: train.py:  316]: Interation 9896 took 2.150782823562622
[INFO: train.py:  558]: resist loss: tensor([ 0.6152], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9651505947113037
[INFO: train.py:  316]: Interation 9897 took 1.9691689014434814
[INFO: train.py:  558]: resist loss: tensor([ 3.8355], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9260859489440918
[INFO: train.py:  316]: Interation 9898 took 1.929969310760498
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 9.6066], device='cuda:0')
[INFO: train.py:  310]: g step took 0.16766977310180664
[INFO: train.py:  316]: Interation 9899 took 0.17148065567016602
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 566, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 566, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 515, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 515, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 557, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 557, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 565, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 565, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 527, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 527, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 659, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 659, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 605, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 605, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 549, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 549, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 516, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 516, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 641, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 641, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 476, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 476, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 185, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 185, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 833, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 833, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 757, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 757, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 860, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 860, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 843, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 843, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 796, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 796, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 753, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 753, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 690, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 690, 2])
[INFO: train.py:  338]:   [val] ade: 0.625
[INFO: train.py:  338]:   [val] ade_l: 1.376
[INFO: train.py:  338]:   [val] ade_nl: 1.145
[INFO: train.py:  338]:   [val] d_loss: 1.409
[INFO: train.py:  338]:   [val] fde: 1.340
[INFO: train.py:  338]:   [val] fde_l: 2.951
[INFO: train.py:  338]:   [val] fde_nl: 2.456
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.480
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.480
[INFO: train.py:  338]:   [val] resist_count: 3015.000
[INFO: train.py:  338]:   [val] resist_loss: 0.271
[INFO: train.py:  341]:   [train] ade: 0.631
[INFO: train.py:  341]:   [train] ade_l: 1.366
[INFO: train.py:  341]:   [train] ade_nl: 1.174
[INFO: train.py:  341]:   [train] d_loss: 1.412
[INFO: train.py:  341]:   [train] fde: 1.288
[INFO: train.py:  341]:   [train] fde_l: 2.787
[INFO: train.py:  341]:   [train] fde_nl: 2.395
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.427
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.427
[INFO: train.py:  341]:   [train] resist_count: 2747.000
[INFO: train.py:  341]:   [train] resist_loss: 0.143
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  279]: Starting epoch 232
[INFO: train.py:  280]: Epoch resist loss: tensor([ 223.1095])
[INFO: train.py:  558]: resist loss: tensor([ 7.3516], device='cuda:0')
[INFO: train.py:  310]: g step took 2.348268747329712
[INFO: train.py:  316]: Interation 9900 took 12.873453378677368
[INFO: train.py:  558]: resist loss: tensor([ 8.5624], device='cuda:0')
[INFO: train.py:  310]: g step took 2.469034433364868
[INFO: train.py:  316]: Interation 9901 took 2.469759225845337
[INFO: train.py:  558]: resist loss: tensor([ 10.7204], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2987124919891357
[INFO: train.py:  316]: Interation 9902 took 2.3064489364624023
[INFO: train.py:  558]: resist loss: tensor([ 1.2978], device='cuda:0')
[INFO: train.py:  310]: g step took 2.056945323944092
[INFO: train.py:  316]: Interation 9903 took 2.071608304977417
[INFO: train.py:  558]: resist loss: tensor([ 0.4214], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3077425956726074
[INFO: train.py:  316]: Interation 9904 took 2.315401077270508
[INFO: train.py:  558]: resist loss: tensor([ 0.9070], device='cuda:0')
[INFO: train.py:  310]: g step took 2.439040184020996
[INFO: train.py:  316]: Interation 9905 took 2.439363956451416
[INFO: train.py:  558]: resist loss: tensor([ 6.9098], device='cuda:0')
[INFO: train.py:  310]: g step took 2.139511823654175
[INFO: train.py:  316]: Interation 9906 took 2.139857769012451
[INFO: train.py:  558]: resist loss: tensor([ 13.1410], device='cuda:0')
[INFO: train.py:  310]: g step took 2.456624984741211
[INFO: train.py:  316]: Interation 9907 took 2.4571104049682617
[INFO: train.py:  558]: resist loss: tensor([ 3.5518], device='cuda:0')
[INFO: train.py:  310]: g step took 2.210824489593506
[INFO: train.py:  316]: Interation 9908 took 2.2112038135528564
[INFO: train.py:  558]: resist loss: tensor([ 5.0190], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9857568740844727
[INFO: train.py:  316]: Interation 9909 took 1.9862253665924072
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 519, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 519, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 546, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 546, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 681, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 681, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 562, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 562, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 503, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 503, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 553, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 553, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 566, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 566, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 633, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 633, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 624, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 624, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 582, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 582, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 454, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 454, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 138, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 138, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 665, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 665, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 748, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 748, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 757, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 757, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 937, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 937, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 766, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 766, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 776, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 776, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 867, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 867, 2])
[INFO: train.py:  338]:   [val] ade: 0.605
[INFO: train.py:  338]:   [val] ade_l: 1.332
[INFO: train.py:  338]:   [val] ade_nl: 1.108
[INFO: train.py:  338]:   [val] d_loss: 1.416
[INFO: train.py:  338]:   [val] fde: 1.245
[INFO: train.py:  338]:   [val] fde_l: 2.742
[INFO: train.py:  338]:   [val] fde_nl: 2.281
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.432
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.432
[INFO: train.py:  338]:   [val] resist_count: 2764.000
[INFO: train.py:  338]:   [val] resist_loss: 0.304
[INFO: train.py:  341]:   [train] ade: 0.608
[INFO: train.py:  341]:   [train] ade_l: 1.287
[INFO: train.py:  341]:   [train] ade_nl: 1.153
[INFO: train.py:  341]:   [train] d_loss: 1.412
[INFO: train.py:  341]:   [train] fde: 1.175
[INFO: train.py:  341]:   [train] fde_l: 2.486
[INFO: train.py:  341]:   [train] fde_nl: 2.227
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.382
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.382
[INFO: train.py:  341]:   [train] resist_count: 3175.000
[INFO: train.py:  341]:   [train] resist_loss: 0.189
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 11.0224], device='cuda:0')
[INFO: train.py:  310]: g step took 2.136232852935791
[INFO: train.py:  316]: Interation 9910 took 10.885860919952393
[INFO: train.py:  558]: resist loss: tensor([ 9.8879], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0602526664733887
[INFO: train.py:  316]: Interation 9911 took 2.067808151245117
[INFO: train.py:  558]: resist loss: tensor([ 2.0469], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8576900959014893
[INFO: train.py:  316]: Interation 9912 took 1.8580079078674316
[INFO: train.py:  558]: resist loss: tensor([ 16.0714], device='cuda:0')
[INFO: train.py:  310]: g step took 2.065204620361328
[INFO: train.py:  316]: Interation 9913 took 2.0655555725097656
[INFO: train.py:  558]: resist loss: tensor([ 1.7034], device='cuda:0')
[INFO: train.py:  310]: g step took 2.023228406906128
[INFO: train.py:  316]: Interation 9914 took 2.0235629081726074
[INFO: train.py:  558]: resist loss: tensor([ 0.3149], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7446417808532715
[INFO: train.py:  316]: Interation 9915 took 1.7449924945831299
[INFO: train.py:  558]: resist loss: tensor([ 7.1700], device='cuda:0')
[INFO: train.py:  310]: g step took 1.97977614402771
[INFO: train.py:  316]: Interation 9916 took 1.9833502769470215
[INFO: train.py:  558]: resist loss: tensor([ 6.9808], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8359081745147705
[INFO: train.py:  316]: Interation 9917 took 1.8398923873901367
[INFO: train.py:  558]: resist loss: tensor([ 0.6513], device='cuda:0')
[INFO: train.py:  310]: g step took 1.649315357208252
[INFO: train.py:  316]: Interation 9918 took 1.6529784202575684
[INFO: train.py:  558]: resist loss: tensor([ 7.9235], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7177975177764893
[INFO: train.py:  316]: Interation 9919 took 1.7221622467041016
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 601, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 601, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 531, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 531, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 563, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 563, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 629, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 629, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 607, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 607, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 563, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 563, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 580, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 580, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 487, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 487, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 570, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 570, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 513, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 513, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 574, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 574, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 143, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 143, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 793, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 793, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 662, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 662, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 801, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 801, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 668, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 668, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 711, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 711, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 720, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 720, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 785, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 785, 2])
[INFO: train.py:  338]:   [val] ade: 0.572
[INFO: train.py:  338]:   [val] ade_l: 1.259
[INFO: train.py:  338]:   [val] ade_nl: 1.047
[INFO: train.py:  338]:   [val] d_loss: 1.404
[INFO: train.py:  338]:   [val] fde: 1.199
[INFO: train.py:  338]:   [val] fde_l: 2.639
[INFO: train.py:  338]:   [val] fde_nl: 2.196
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.407
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.407
[INFO: train.py:  338]:   [val] resist_count: 2789.000
[INFO: train.py:  338]:   [val] resist_loss: 0.303
[INFO: train.py:  341]:   [train] ade: 0.569
[INFO: train.py:  341]:   [train] ade_l: 1.194
[INFO: train.py:  341]:   [train] ade_nl: 1.087
[INFO: train.py:  341]:   [train] d_loss: 1.403
[INFO: train.py:  341]:   [train] fde: 1.136
[INFO: train.py:  341]:   [train] fde_l: 2.384
[INFO: train.py:  341]:   [train] fde_nl: 2.170
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.363
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.363
[INFO: train.py:  341]:   [train] resist_count: 2554.000
[INFO: train.py:  341]:   [train] resist_loss: 0.148
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 1.5470], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7060554027557373
[INFO: train.py:  316]: Interation 9920 took 10.149147987365723
[INFO: train.py:  558]: resist loss: tensor([ 4.4402], device='cuda:0')
[INFO: train.py:  310]: g step took 2.013000965118408
[INFO: train.py:  316]: Interation 9921 took 2.0172481536865234
[INFO: train.py:  558]: resist loss: tensor([ 9.9823], device='cuda:0')
[INFO: train.py:  310]: g step took 1.98299241065979
[INFO: train.py:  316]: Interation 9922 took 1.9870500564575195
[INFO: train.py:  558]: resist loss: tensor([ 1.6133], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9681456089019775
[INFO: train.py:  316]: Interation 9923 took 1.9717481136322021
[INFO: train.py:  558]: resist loss: tensor([ 2.3625], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1740846633911133
[INFO: train.py:  316]: Interation 9924 took 2.177349328994751
[INFO: train.py:  558]: resist loss: tensor([ 12.3311], device='cuda:0')
[INFO: train.py:  310]: g step took 2.353355646133423
[INFO: train.py:  316]: Interation 9925 took 2.357374668121338
[INFO: train.py:  558]: resist loss: tensor([ 5.5867], device='cuda:0')
[INFO: train.py:  310]: g step took 2.201270341873169
[INFO: train.py:  316]: Interation 9926 took 2.2046589851379395
[INFO: train.py:  558]: resist loss: tensor([ 0.8990], device='cuda:0')
[INFO: train.py:  310]: g step took 2.382171154022217
[INFO: train.py:  316]: Interation 9927 took 2.3856987953186035
[INFO: train.py:  558]: resist loss: tensor([ 6.5531], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0907256603240967
[INFO: train.py:  316]: Interation 9928 took 2.0943567752838135
[INFO: train.py:  558]: resist loss: tensor([ 9.8194], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9752464294433594
[INFO: train.py:  316]: Interation 9929 took 1.9792633056640625
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 522, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 522, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 497, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 497, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 539, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 539, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 658, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 658, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 636, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 636, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 579, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 579, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 632, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 632, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 523, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 523, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 483, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 483, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 650, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 650, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 474, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 474, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 168, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 168, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 728, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 728, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 874, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 874, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 748, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 748, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 856, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 856, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 707, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 707, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 733, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 733, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 812, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 812, 2])
[INFO: train.py:  338]:   [val] ade: 0.625
[INFO: train.py:  338]:   [val] ade_l: 1.377
[INFO: train.py:  338]:   [val] ade_nl: 1.146
[INFO: train.py:  338]:   [val] d_loss: 1.410
[INFO: train.py:  338]:   [val] fde: 1.364
[INFO: train.py:  338]:   [val] fde_l: 3.002
[INFO: train.py:  338]:   [val] fde_nl: 2.498
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.494
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.494
[INFO: train.py:  338]:   [val] resist_count: 2784.000
[INFO: train.py:  338]:   [val] resist_loss: 0.252
[INFO: train.py:  341]:   [train] ade: 0.608
[INFO: train.py:  341]:   [train] ade_l: 1.262
[INFO: train.py:  341]:   [train] ade_nl: 1.173
[INFO: train.py:  341]:   [train] d_loss: 1.397
[INFO: train.py:  341]:   [train] fde: 1.278
[INFO: train.py:  341]:   [train] fde_l: 2.654
[INFO: train.py:  341]:   [train] fde_nl: 2.466
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.411
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.411
[INFO: train.py:  341]:   [train] resist_count: 2849.000
[INFO: train.py:  341]:   [train] resist_loss: 0.147
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 4.2690], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7575089931488037
[INFO: train.py:  316]: Interation 9930 took 10.895894765853882
[INFO: train.py:  558]: resist loss: tensor([ 16.5349], device='cuda:0')
[INFO: train.py:  310]: g step took 2.984602928161621
[INFO: train.py:  316]: Interation 9931 took 2.9886035919189453
[INFO: train.py:  558]: resist loss: tensor([ 3.2141], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9209742546081543
[INFO: train.py:  316]: Interation 9932 took 1.9246907234191895
[INFO: train.py:  558]: resist loss: tensor([ 0.8247], device='cuda:0')
[INFO: train.py:  310]: g step took 2.431292772293091
[INFO: train.py:  316]: Interation 9933 took 2.4351701736450195
[INFO: train.py:  558]: resist loss: tensor([ 9.6841], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3607585430145264
[INFO: train.py:  316]: Interation 9934 took 2.364133834838867
[INFO: train.py:  558]: resist loss: tensor([ 1.8327], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2557945251464844
[INFO: train.py:  316]: Interation 9935 took 2.2596209049224854
[INFO: train.py:  558]: resist loss: tensor([ 5.7920], device='cuda:0')
[INFO: train.py:  310]: g step took 2.5515053272247314
[INFO: train.py:  316]: Interation 9936 took 2.5553624629974365
[INFO: train.py:  558]: resist loss: tensor([ 3.6316], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8346247673034668
[INFO: train.py:  316]: Interation 9937 took 1.8385286331176758
[INFO: train.py:  558]: resist loss: tensor([ 3.9081], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8340866565704346
[INFO: train.py:  316]: Interation 9938 took 1.8380215167999268
[INFO: train.py:  558]: resist loss: tensor([ 12.9145], device='cuda:0')
[INFO: train.py:  310]: g step took 2.938815116882324
[INFO: train.py:  316]: Interation 9939 took 2.9427502155303955
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 566, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 566, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 596, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 596, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 568, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 568, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 541, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 541, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 589, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 589, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 552, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 552, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 614, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 614, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 536, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 536, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 536, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 536, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 706, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 706, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 447, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 447, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 110, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 110, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 882, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 882, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 612, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 612, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 827, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 827, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 666, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 666, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 896, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 896, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 777, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 777, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 929, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 929, 2])
[INFO: train.py:  338]:   [val] ade: 0.613
[INFO: train.py:  338]:   [val] ade_l: 1.349
[INFO: train.py:  338]:   [val] ade_nl: 1.122
[INFO: train.py:  338]:   [val] d_loss: 1.404
[INFO: train.py:  338]:   [val] fde: 1.273
[INFO: train.py:  338]:   [val] fde_l: 2.803
[INFO: train.py:  338]:   [val] fde_nl: 2.332
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.442
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.442
[INFO: train.py:  338]:   [val] resist_count: 2800.000
[INFO: train.py:  338]:   [val] resist_loss: 0.281
[INFO: train.py:  341]:   [train] ade: 0.599
[INFO: train.py:  341]:   [train] ade_l: 1.228
[INFO: train.py:  341]:   [train] ade_nl: 1.170
[INFO: train.py:  341]:   [train] d_loss: 1.405
[INFO: train.py:  341]:   [train] fde: 1.159
[INFO: train.py:  341]:   [train] fde_l: 2.376
[INFO: train.py:  341]:   [train] fde_nl: 2.264
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.377
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.377
[INFO: train.py:  341]:   [train] resist_count: 2753.000
[INFO: train.py:  341]:   [train] resist_loss: 0.173
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.2440], device='cuda:0')
[INFO: train.py:  310]: g step took 2.6667120456695557
[INFO: train.py:  316]: Interation 9940 took 12.68799638748169
[INFO: train.py:  558]: resist loss: tensor([ 0.2555], device='cuda:0')
[INFO: train.py:  310]: g step took 2.241175413131714
[INFO: train.py:  316]: Interation 9941 took 2.2451283931732178
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 4.6844], device='cuda:0')
[INFO: train.py:  310]: g step took 0.22501444816589355
[INFO: train.py:  316]: Interation 9942 took 0.22828984260559082
[INFO: train.py:  279]: Starting epoch 233
[INFO: train.py:  280]: Epoch resist loss: tensor([ 239.9415])
[INFO: train.py:  558]: resist loss: tensor([ 4.3885], device='cuda:0')
[INFO: train.py:  310]: g step took 2.405158042907715
[INFO: train.py:  316]: Interation 9943 took 2.8012163639068604
[INFO: train.py:  558]: resist loss: tensor([ 6.1494], device='cuda:0')
[INFO: train.py:  310]: g step took 2.112525701522827
[INFO: train.py:  316]: Interation 9944 took 2.1129448413848877
[INFO: train.py:  558]: resist loss: tensor([ 9.1104], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0091543197631836
[INFO: train.py:  316]: Interation 9945 took 2.0194010734558105
[INFO: train.py:  558]: resist loss: tensor([ 6.2395], device='cuda:0')
[INFO: train.py:  310]: g step took 2.265742063522339
[INFO: train.py:  316]: Interation 9946 took 2.273097038269043
[INFO: train.py:  558]: resist loss: tensor([ 3.3143], device='cuda:0')
[INFO: train.py:  310]: g step took 2.340583324432373
[INFO: train.py:  316]: Interation 9947 took 2.344027519226074
[INFO: train.py:  558]: resist loss: tensor([ 3.5991], device='cuda:0')
[INFO: train.py:  310]: g step took 2.251861095428467
[INFO: train.py:  316]: Interation 9948 took 2.2522807121276855
[INFO: train.py:  558]: resist loss: tensor([ 0.9626], device='cuda:0')
[INFO: train.py:  310]: g step took 2.472663640975952
[INFO: train.py:  316]: Interation 9949 took 2.4797868728637695
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 489, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 489, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 421, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 421, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 611, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 611, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 674, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 674, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 616, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 616, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 638, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 638, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 542, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 542, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 553, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 553, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 549, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 549, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 595, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 595, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 519, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 519, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 154, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 154, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 754, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 754, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 960, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 960, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 597, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 597, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 894, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 894, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 841, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 841, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 755, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 755, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 663, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 663, 2])
[INFO: train.py:  338]:   [val] ade: 0.642
[INFO: train.py:  338]:   [val] ade_l: 1.415
[INFO: train.py:  338]:   [val] ade_nl: 1.177
[INFO: train.py:  338]:   [val] d_loss: 1.418
[INFO: train.py:  338]:   [val] fde: 1.342
[INFO: train.py:  338]:   [val] fde_l: 2.955
[INFO: train.py:  338]:   [val] fde_nl: 2.459
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.462
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.462
[INFO: train.py:  338]:   [val] resist_count: 3012.000
[INFO: train.py:  338]:   [val] resist_loss: 0.326
[INFO: train.py:  341]:   [train] ade: 0.650
[INFO: train.py:  341]:   [train] ade_l: 1.391
[INFO: train.py:  341]:   [train] ade_nl: 1.221
[INFO: train.py:  341]:   [train] d_loss: 1.406
[INFO: train.py:  341]:   [train] fde: 1.284
[INFO: train.py:  341]:   [train] fde_l: 2.748
[INFO: train.py:  341]:   [train] fde_nl: 2.411
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.433
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.433
[INFO: train.py:  341]:   [train] resist_count: 2842.000
[INFO: train.py:  341]:   [train] resist_loss: 0.167
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 12.3715], device='cuda:0')
[INFO: train.py:  310]: g step took 2.661008596420288
[INFO: train.py:  316]: Interation 9950 took 12.973155975341797
[INFO: train.py:  558]: resist loss: tensor([ 0.4986], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2180309295654297
[INFO: train.py:  316]: Interation 9951 took 2.218477964401245
[INFO: train.py:  558]: resist loss: tensor([ 0.6104], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3602824211120605
[INFO: train.py:  316]: Interation 9952 took 2.360764265060425
[INFO: train.py:  558]: resist loss: tensor([ 2.8774], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1673004627227783
[INFO: train.py:  316]: Interation 9953 took 2.1773996353149414
[INFO: train.py:  558]: resist loss: tensor([ 18.3775], device='cuda:0')
[INFO: train.py:  310]: g step took 2.8966548442840576
[INFO: train.py:  316]: Interation 9954 took 2.903987407684326
[INFO: train.py:  558]: resist loss: tensor([ 0.6351], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8518650531768799
[INFO: train.py:  316]: Interation 9955 took 1.852229356765747
[INFO: train.py:  558]: resist loss: tensor([ 0.3432], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2764978408813477
[INFO: train.py:  316]: Interation 9956 took 2.2768290042877197
[INFO: train.py:  558]: resist loss: tensor([ 2.6396], device='cuda:0')
[INFO: train.py:  310]: g step took 2.187861442565918
[INFO: train.py:  316]: Interation 9957 took 2.1918253898620605
[INFO: train.py:  558]: resist loss: tensor([ 8.3116], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3962247371673584
[INFO: train.py:  316]: Interation 9958 took 2.396566390991211
[INFO: train.py:  558]: resist loss: tensor([ 8.5110], device='cuda:0')
[INFO: train.py:  310]: g step took 2.396362543106079
[INFO: train.py:  316]: Interation 9959 took 2.399622917175293
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 671, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 671, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 587, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 587, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 489, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 489, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 545, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 545, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 638, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 638, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 612, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 612, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 559, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 559, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 514, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 514, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 525, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 525, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 560, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 560, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 477, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 477, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 184, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 184, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 763, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 763, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 906, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 906, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 855, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 855, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 832, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 832, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 680, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 680, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 836, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 836, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 834, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 834, 2])
[INFO: train.py:  338]:   [val] ade: 0.595
[INFO: train.py:  338]:   [val] ade_l: 1.311
[INFO: train.py:  338]:   [val] ade_nl: 1.091
[INFO: train.py:  338]:   [val] d_loss: 1.410
[INFO: train.py:  338]:   [val] fde: 1.279
[INFO: train.py:  338]:   [val] fde_l: 2.816
[INFO: train.py:  338]:   [val] fde_nl: 2.343
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.440
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.440
[INFO: train.py:  338]:   [val] resist_count: 2628.000
[INFO: train.py:  338]:   [val] resist_loss: 0.240
[INFO: train.py:  341]:   [train] ade: 0.589
[INFO: train.py:  341]:   [train] ade_l: 1.204
[INFO: train.py:  341]:   [train] ade_nl: 1.152
[INFO: train.py:  341]:   [train] d_loss: 1.407
[INFO: train.py:  341]:   [train] fde: 1.197
[INFO: train.py:  341]:   [train] fde_l: 2.448
[INFO: train.py:  341]:   [train] fde_nl: 2.342
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.382
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.382
[INFO: train.py:  341]:   [train] resist_count: 2635.000
[INFO: train.py:  341]:   [train] resist_loss: 0.143
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.7953], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1413934230804443
[INFO: train.py:  316]: Interation 9960 took 12.187281131744385
[INFO: train.py:  558]: resist loss: tensor([ 4.6862], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2578489780426025
[INFO: train.py:  316]: Interation 9961 took 2.2619221210479736
[INFO: train.py:  558]: resist loss: tensor([ 8.2499], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0107648372650146
[INFO: train.py:  316]: Interation 9962 took 2.0147852897644043
[INFO: train.py:  558]: resist loss: tensor([ 7.0209], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1692535877227783
[INFO: train.py:  316]: Interation 9963 took 2.172663450241089
[INFO: train.py:  558]: resist loss: tensor([ 7.9243], device='cuda:0')
[INFO: train.py:  310]: g step took 2.456977367401123
[INFO: train.py:  316]: Interation 9964 took 2.460559844970703
[INFO: train.py:  558]: resist loss: tensor([ 0.4351], device='cuda:0')
[INFO: train.py:  310]: g step took 2.202655792236328
[INFO: train.py:  316]: Interation 9965 took 2.2065086364746094
[INFO: train.py:  558]: resist loss: tensor([ 0.1742], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1287729740142822
[INFO: train.py:  316]: Interation 9966 took 2.1326262950897217
[INFO: train.py:  558]: resist loss: tensor([ 7.7013], device='cuda:0')
[INFO: train.py:  310]: g step took 2.496157646179199
[INFO: train.py:  316]: Interation 9967 took 2.4999592304229736
[INFO: train.py:  558]: resist loss: tensor([ 3.5143], device='cuda:0')
[INFO: train.py:  310]: g step took 2.416100025177002
[INFO: train.py:  316]: Interation 9968 took 2.420100688934326
[INFO: train.py:  558]: resist loss: tensor([ 1.8917], device='cuda:0')
[INFO: train.py:  310]: g step took 2.613920211791992
[INFO: train.py:  316]: Interation 9969 took 2.6173603534698486
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 481, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 481, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 552, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 552, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 621, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 621, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 453, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 453, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 592, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 592, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 621, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 621, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 613, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 613, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 524, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 524, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 550, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 550, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 556, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 556, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 641, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 641, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 157, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 157, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 763, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 763, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 899, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 899, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 900, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 900, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 925, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 925, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 635, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 635, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 788, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 788, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 784, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 784, 2])
[INFO: train.py:  338]:   [val] ade: 0.597
[INFO: train.py:  338]:   [val] ade_l: 1.314
[INFO: train.py:  338]:   [val] ade_nl: 1.093
[INFO: train.py:  338]:   [val] d_loss: 1.413
[INFO: train.py:  338]:   [val] fde: 1.245
[INFO: train.py:  338]:   [val] fde_l: 2.741
[INFO: train.py:  338]:   [val] fde_nl: 2.281
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.439
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.439
[INFO: train.py:  338]:   [val] resist_count: 2582.000
[INFO: train.py:  338]:   [val] resist_loss: 0.280
[INFO: train.py:  341]:   [train] ade: 0.613
[INFO: train.py:  341]:   [train] ade_l: 1.289
[INFO: train.py:  341]:   [train] ade_nl: 1.170
[INFO: train.py:  341]:   [train] d_loss: 1.405
[INFO: train.py:  341]:   [train] fde: 1.188
[INFO: train.py:  341]:   [train] fde_l: 2.497
[INFO: train.py:  341]:   [train] fde_nl: 2.266
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.413
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.413
[INFO: train.py:  341]:   [train] resist_count: 2834.000
[INFO: train.py:  341]:   [train] resist_loss: 0.162
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 7.6782], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3388350009918213
[INFO: train.py:  316]: Interation 9970 took 11.984956741333008
[INFO: train.py:  558]: resist loss: tensor([ 3.0780], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1446616649627686
[INFO: train.py:  316]: Interation 9971 took 2.1479744911193848
[INFO: train.py:  558]: resist loss: tensor([ 5.2086], device='cuda:0')
[INFO: train.py:  310]: g step took 2.5695881843566895
[INFO: train.py:  316]: Interation 9972 took 2.573028564453125
[INFO: train.py:  558]: resist loss: tensor([ 9.4073], device='cuda:0')
[INFO: train.py:  310]: g step took 2.607293128967285
[INFO: train.py:  316]: Interation 9973 took 2.6106882095336914
[INFO: train.py:  558]: resist loss: tensor([ 2.7790], device='cuda:0')
[INFO: train.py:  310]: g step took 2.5432488918304443
[INFO: train.py:  316]: Interation 9974 took 2.54655385017395
[INFO: train.py:  558]: resist loss: tensor([ 0.7285], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4474010467529297
[INFO: train.py:  316]: Interation 9975 took 2.4508650302886963
[INFO: train.py:  558]: resist loss: tensor([ 11.4864], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3303935527801514
[INFO: train.py:  316]: Interation 9976 took 2.3343024253845215
[INFO: train.py:  558]: resist loss: tensor([ 1.3324], device='cuda:0')
[INFO: train.py:  310]: g step took 2.049034833908081
[INFO: train.py:  316]: Interation 9977 took 2.052238702774048
[INFO: train.py:  558]: resist loss: tensor([ 12.5852], device='cuda:0')
[INFO: train.py:  310]: g step took 2.266040325164795
[INFO: train.py:  316]: Interation 9978 took 2.2699248790740967
[INFO: train.py:  558]: resist loss: tensor([ 0.5499], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6266717910766602
[INFO: train.py:  316]: Interation 9979 took 1.629789113998413
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 545, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 545, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 426, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 426, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 615, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 615, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 469, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 469, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 644, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 644, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 670, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 670, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 508, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 508, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 636, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 636, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 557, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 557, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 524, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 524, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 609, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 609, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 158, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 158, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 623, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 623, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 824, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 824, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 802, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 802, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 760, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 760, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 946, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 946, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 811, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 811, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 807, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 807, 2])
[INFO: train.py:  338]:   [val] ade: 0.644
[INFO: train.py:  338]:   [val] ade_l: 1.418
[INFO: train.py:  338]:   [val] ade_nl: 1.180
[INFO: train.py:  338]:   [val] d_loss: 1.420
[INFO: train.py:  338]:   [val] fde: 1.203
[INFO: train.py:  338]:   [val] fde_l: 2.649
[INFO: train.py:  338]:   [val] fde_nl: 2.204
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.450
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.450
[INFO: train.py:  338]:   [val] resist_count: 3125.000
[INFO: train.py:  338]:   [val] resist_loss: 0.364
[INFO: train.py:  341]:   [train] ade: 0.667
[INFO: train.py:  341]:   [train] ade_l: 1.396
[INFO: train.py:  341]:   [train] ade_nl: 1.277
[INFO: train.py:  341]:   [train] d_loss: 1.415
[INFO: train.py:  341]:   [train] fde: 1.155
[INFO: train.py:  341]:   [train] fde_l: 2.418
[INFO: train.py:  341]:   [train] fde_nl: 2.211
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.424
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.424
[INFO: train.py:  341]:   [train] resist_count: 3608.000
[INFO: train.py:  341]:   [train] resist_loss: 0.238
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 8.6469], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2002804279327393
[INFO: train.py:  316]: Interation 9980 took 10.87055778503418
[INFO: train.py:  558]: resist loss: tensor([ 11.5899], device='cuda:0')
[INFO: train.py:  310]: g step took 2.237715005874634
[INFO: train.py:  316]: Interation 9981 took 2.2416059970855713
[INFO: train.py:  558]: resist loss: tensor([ 0.3878], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9806792736053467
[INFO: train.py:  316]: Interation 9982 took 1.9846744537353516
[INFO: train.py:  558]: resist loss: tensor([ 11.5494], device='cuda:0')
[INFO: train.py:  310]: g step took 2.3568646907806396
[INFO: train.py:  316]: Interation 9983 took 2.360642671585083
[INFO: train.py:  558]: resist loss: tensor([ 0.9886], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9281201362609863
[INFO: train.py:  316]: Interation 9984 took 1.931966781616211
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 2.1397], device='cuda:0')
[INFO: train.py:  310]: g step took 0.1680622100830078
[INFO: train.py:  316]: Interation 9985 took 0.17183971405029297
[INFO: train.py:  279]: Starting epoch 234
[INFO: train.py:  280]: Epoch resist loss: tensor([ 219.3500])
[INFO: train.py:  558]: resist loss: tensor([ 2.9809], device='cuda:0')
[INFO: train.py:  310]: g step took 1.807354211807251
[INFO: train.py:  316]: Interation 9986 took 2.19950795173645
[INFO: train.py:  558]: resist loss: tensor([ 7.3328], device='cuda:0')
[INFO: train.py:  310]: g step took 1.973998785018921
[INFO: train.py:  316]: Interation 9987 took 1.9743678569793701
[INFO: train.py:  558]: resist loss: tensor([ 7.4524], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8074824810028076
[INFO: train.py:  316]: Interation 9988 took 1.8117225170135498
[INFO: train.py:  558]: resist loss: tensor([ 1.2726], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7768547534942627
[INFO: train.py:  316]: Interation 9989 took 1.7772440910339355
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 700, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 700, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 618, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 618, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 586, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 586, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 495, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 495, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 689, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 689, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 512, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 512, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 479, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 479, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 475, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 475, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 602, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 602, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 509, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 509, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 581, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 581, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 115, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 115, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 859, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 859, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 632, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 632, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 805, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 805, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 718, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 718, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 684, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 684, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 888, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 888, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 877, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 877, 2])
[INFO: train.py:  338]:   [val] ade: 0.632
[INFO: train.py:  338]:   [val] ade_l: 1.391
[INFO: train.py:  338]:   [val] ade_nl: 1.157
[INFO: train.py:  338]:   [val] d_loss: 1.405
[INFO: train.py:  338]:   [val] fde: 1.301
[INFO: train.py:  338]:   [val] fde_l: 2.864
[INFO: train.py:  338]:   [val] fde_nl: 2.383
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.462
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.462
[INFO: train.py:  338]:   [val] resist_count: 3089.000
[INFO: train.py:  338]:   [val] resist_loss: 0.353
[INFO: train.py:  341]:   [train] ade: 0.636
[INFO: train.py:  341]:   [train] ade_l: 1.311
[INFO: train.py:  341]:   [train] ade_nl: 1.236
[INFO: train.py:  341]:   [train] d_loss: 1.396
[INFO: train.py:  341]:   [train] fde: 1.233
[INFO: train.py:  341]:   [train] fde_l: 2.541
[INFO: train.py:  341]:   [train] fde_nl: 2.396
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.428
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.428
[INFO: train.py:  341]:   [train] resist_count: 3063.000
[INFO: train.py:  341]:   [train] resist_loss: 0.198
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 4.4820], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0496578216552734
[INFO: train.py:  316]: Interation 9990 took 10.715603590011597
[INFO: train.py:  558]: resist loss: tensor([ 1.1993], device='cuda:0')
[INFO: train.py:  310]: g step took 2.109769582748413
[INFO: train.py:  316]: Interation 9991 took 2.110124349594116
[INFO: train.py:  558]: resist loss: tensor([ 4.8194], device='cuda:0')
[INFO: train.py:  310]: g step took 1.957226276397705
[INFO: train.py:  316]: Interation 9992 took 1.9576590061187744
[INFO: train.py:  558]: resist loss: tensor([ 1.5139], device='cuda:0')
[INFO: train.py:  310]: g step took 2.082864284515381
[INFO: train.py:  316]: Interation 9993 took 2.083286762237549
[INFO: train.py:  558]: resist loss: tensor([ 9.5100], device='cuda:0')
[INFO: train.py:  310]: g step took 2.116121292114258
[INFO: train.py:  316]: Interation 9994 took 2.140547037124634
[INFO: train.py:  558]: resist loss: tensor([ 9.6057], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8540918827056885
[INFO: train.py:  316]: Interation 9995 took 1.854459524154663
[INFO: train.py:  558]: resist loss: tensor([ 11.1194], device='cuda:0')
[INFO: train.py:  310]: g step took 1.988527774810791
[INFO: train.py:  316]: Interation 9996 took 1.9888994693756104
[INFO: train.py:  558]: resist loss: tensor([ 8.3949], device='cuda:0')
[INFO: train.py:  310]: g step took 1.884676456451416
[INFO: train.py:  316]: Interation 9997 took 1.8851566314697266
[INFO: train.py:  558]: resist loss: tensor([ 9.0589], device='cuda:0')
[INFO: train.py:  310]: g step took 2.04803729057312
[INFO: train.py:  316]: Interation 9998 took 2.0484778881073
[INFO: train.py:  558]: resist loss: tensor([ 3.8050], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0993785858154297
[INFO: train.py:  316]: Interation 9999 took 2.0997800827026367
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 534, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 534, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 579, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 579, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 494, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 494, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 656, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 656, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 552, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 552, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 548, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 548, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 605, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 605, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 576, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 576, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 438, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 438, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 507, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 507, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 662, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 662, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 210, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 210, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 643, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 643, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 982, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 982, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 709, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 709, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 768, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 768, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 653, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 653, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 692, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 692, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 854, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 854, 2])
[INFO: train.py:  338]:   [val] ade: 0.615
[INFO: train.py:  338]:   [val] ade_l: 1.355
[INFO: train.py:  338]:   [val] ade_nl: 1.127
[INFO: train.py:  338]:   [val] d_loss: 1.407
[INFO: train.py:  338]:   [val] fde: 1.216
[INFO: train.py:  338]:   [val] fde_l: 2.677
[INFO: train.py:  338]:   [val] fde_nl: 2.227
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.452
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.452
[INFO: train.py:  338]:   [val] resist_count: 2694.000
[INFO: train.py:  338]:   [val] resist_loss: 0.294
[INFO: train.py:  341]:   [train] ade: 0.610
[INFO: train.py:  341]:   [train] ade_l: 1.232
[INFO: train.py:  341]:   [train] ade_nl: 1.209
[INFO: train.py:  341]:   [train] d_loss: 1.406
[INFO: train.py:  341]:   [train] fde: 1.142
[INFO: train.py:  341]:   [train] fde_l: 2.305
[INFO: train.py:  341]:   [train] fde_nl: 2.263
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.403
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.403
[INFO: train.py:  341]:   [train] resist_count: 2505.000
[INFO: train.py:  341]:   [train] resist_loss: 0.153
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 5.3547], device='cuda:0')
[INFO: train.py:  310]: g step took 2.5422286987304688
[INFO: train.py:  316]: Interation 10000 took 11.388312339782715
[INFO: train.py:  558]: resist loss: tensor([ 0.4186], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4991633892059326
[INFO: train.py:  316]: Interation 10001 took 1.4995872974395752
[INFO: train.py:  558]: resist loss: tensor([ 2.4900], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7718579769134521
[INFO: train.py:  316]: Interation 10002 took 1.776026725769043
[INFO: train.py:  558]: resist loss: tensor([ 0.3876], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0261638164520264
[INFO: train.py:  316]: Interation 10003 took 2.0302188396453857
[INFO: train.py:  558]: resist loss: tensor([ 1.0061], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0738885402679443
[INFO: train.py:  316]: Interation 10004 took 2.077970504760742
[INFO: train.py:  558]: resist loss: tensor([ 1.5444], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6831600666046143
[INFO: train.py:  316]: Interation 10005 took 1.6871485710144043
[INFO: train.py:  558]: resist loss: tensor([ 4.8223], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8999438285827637
[INFO: train.py:  316]: Interation 10006 took 1.9037961959838867
[INFO: train.py:  558]: resist loss: tensor([ 17.4655], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9521374702453613
[INFO: train.py:  316]: Interation 10007 took 1.956230640411377
[INFO: train.py:  558]: resist loss: tensor([ 7.3031], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2341079711914062
[INFO: train.py:  316]: Interation 10008 took 2.2380542755126953
[INFO: train.py:  558]: resist loss: tensor([ 0.7710], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9921214580535889
[INFO: train.py:  316]: Interation 10009 took 1.9960649013519287
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 496, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 496, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 446, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 446, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 503, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 503, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 548, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 548, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 571, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 571, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 539, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 539, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 712, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 712, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 691, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 691, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 553, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 553, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 588, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 588, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 513, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 513, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 201, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 201, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 764, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 764, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 797, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 797, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 910, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 910, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 784, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 784, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 744, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 744, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 713, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 713, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 569, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 569, 2])
[INFO: train.py:  338]:   [val] ade: 0.576
[INFO: train.py:  338]:   [val] ade_l: 1.267
[INFO: train.py:  338]:   [val] ade_nl: 1.055
[INFO: train.py:  338]:   [val] d_loss: 1.405
[INFO: train.py:  338]:   [val] fde: 1.174
[INFO: train.py:  338]:   [val] fde_l: 2.586
[INFO: train.py:  338]:   [val] fde_nl: 2.152
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.397
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.397
[INFO: train.py:  338]:   [val] resist_count: 3017.000
[INFO: train.py:  338]:   [val] resist_loss: 0.354
[INFO: train.py:  341]:   [train] ade: 0.579
[INFO: train.py:  341]:   [train] ade_l: 1.209
[INFO: train.py:  341]:   [train] ade_nl: 1.112
[INFO: train.py:  341]:   [train] d_loss: 1.394
[INFO: train.py:  341]:   [train] fde: 1.117
[INFO: train.py:  341]:   [train] fde_l: 2.331
[INFO: train.py:  341]:   [train] fde_nl: 2.143
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.361
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.361
[INFO: train.py:  341]:   [train] resist_count: 2942.000
[INFO: train.py:  341]:   [train] resist_loss: 0.192
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.1476], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7770164012908936
[INFO: train.py:  316]: Interation 10010 took 10.680332660675049
[INFO: train.py:  558]: resist loss: tensor([ 6.4522], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9034223556518555
[INFO: train.py:  316]: Interation 10011 took 1.9075343608856201
[INFO: train.py:  558]: resist loss: tensor([ 0.2638], device='cuda:0')
[INFO: train.py:  310]: g step took 1.927880048751831
[INFO: train.py:  316]: Interation 10012 took 1.932178020477295
[INFO: train.py:  558]: resist loss: tensor([ 1.9766], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5175137519836426
[INFO: train.py:  316]: Interation 10013 took 1.5213875770568848
[INFO: train.py:  558]: resist loss: tensor([ 13.1856], device='cuda:0')
[INFO: train.py:  310]: g step took 2.043915033340454
[INFO: train.py:  316]: Interation 10014 took 2.0476813316345215
[INFO: train.py:  558]: resist loss: tensor([ 3.8935], device='cuda:0')
[INFO: train.py:  310]: g step took 1.479907751083374
[INFO: train.py:  316]: Interation 10015 took 1.4838767051696777
[INFO: train.py:  558]: resist loss: tensor([ 4.2558], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4940359592437744
[INFO: train.py:  316]: Interation 10016 took 2.4979889392852783
[INFO: train.py:  558]: resist loss: tensor([ 5.4822], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5483696460723877
[INFO: train.py:  316]: Interation 10017 took 1.5524277687072754
[INFO: train.py:  558]: resist loss: tensor([ 1.4417], device='cuda:0')
[INFO: train.py:  310]: g step took 2.042996644973755
[INFO: train.py:  316]: Interation 10018 took 2.0469372272491455
[INFO: train.py:  558]: resist loss: tensor([ 0.6092], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1200904846191406
[INFO: train.py:  316]: Interation 10019 took 2.123906373977661
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 489, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 489, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 535, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 535, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 616, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 616, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 553, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 553, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 634, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 634, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 589, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 589, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 626, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 626, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 577, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 577, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 520, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 520, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 619, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 619, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 462, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 462, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 141, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 141, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 715, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 715, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 634, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 634, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 728, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 728, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 721, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 721, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 900, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 900, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 676, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 676, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 768, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 768, 2])
[INFO: train.py:  338]:   [val] ade: 0.590
[INFO: train.py:  338]:   [val] ade_l: 1.300
[INFO: train.py:  338]:   [val] ade_nl: 1.082
[INFO: train.py:  338]:   [val] d_loss: 1.410
[INFO: train.py:  338]:   [val] fde: 1.235
[INFO: train.py:  338]:   [val] fde_l: 2.718
[INFO: train.py:  338]:   [val] fde_nl: 2.262
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.433
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.433
[INFO: train.py:  338]:   [val] resist_count: 2836.000
[INFO: train.py:  338]:   [val] resist_loss: 0.329
[INFO: train.py:  341]:   [train] ade: 0.580
[INFO: train.py:  341]:   [train] ade_l: 1.176
[INFO: train.py:  341]:   [train] ade_nl: 1.142
[INFO: train.py:  341]:   [train] d_loss: 1.397
[INFO: train.py:  341]:   [train] fde: 1.162
[INFO: train.py:  341]:   [train] fde_l: 2.360
[INFO: train.py:  341]:   [train] fde_nl: 2.291
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.369
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.369
[INFO: train.py:  341]:   [train] resist_count: 2520.000
[INFO: train.py:  341]:   [train] resist_loss: 0.172
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.9117], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8202321529388428
[INFO: train.py:  316]: Interation 10020 took 10.581166744232178
[INFO: train.py:  558]: resist loss: tensor([ 3.2896], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1049976348876953
[INFO: train.py:  316]: Interation 10021 took 2.1088085174560547
[INFO: train.py:  558]: resist loss: tensor([ 11.7318], device='cuda:0')
[INFO: train.py:  310]: g step took 2.187380790710449
[INFO: train.py:  316]: Interation 10022 took 2.1912167072296143
[INFO: train.py:  558]: resist loss: tensor([ 7.7363], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8102059364318848
[INFO: train.py:  316]: Interation 10023 took 1.8141658306121826
[INFO: train.py:  558]: resist loss: tensor([ 3.4606], device='cuda:0')
[INFO: train.py:  310]: g step took 2.114830493927002
[INFO: train.py:  316]: Interation 10024 took 2.1187009811401367
[INFO: train.py:  558]: resist loss: tensor([ 5.3818], device='cuda:0')
[INFO: train.py:  310]: g step took 1.864213228225708
[INFO: train.py:  316]: Interation 10025 took 1.8681552410125732
[INFO: train.py:  558]: resist loss: tensor([ 11.1353], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7656888961791992
[INFO: train.py:  316]: Interation 10026 took 1.7695338726043701
[INFO: train.py:  558]: resist loss: tensor([ 2.3690], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6693956851959229
[INFO: train.py:  316]: Interation 10027 took 1.6732919216156006
[INFO: train.py:  558]: resist loss: tensor([ 0.], device='cuda:0')
[INFO: train.py:  310]: g step took 0.12469959259033203
[INFO: train.py:  316]: Interation 10028 took 0.1285402774810791
[INFO: train.py:  279]: Starting epoch 235
[INFO: train.py:  280]: Epoch resist loss: tensor([ 211.8352])
[INFO: train.py:  558]: resist loss: tensor([ 1.0530], device='cuda:0')
[INFO: train.py:  310]: g step took 2.1367642879486084
[INFO: train.py:  316]: Interation 10029 took 2.5188210010528564
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 479, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 479, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 635, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 635, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 669, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 669, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 473, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 473, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 449, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 449, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 518, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 518, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 584, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 584, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 542, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 542, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 709, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 709, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 628, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 628, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 532, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 532, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 143, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 143, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 712, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 712, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 882, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 882, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 770, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 770, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 759, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 759, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 749, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 749, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 917, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 917, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 712, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 712, 2])
[INFO: train.py:  338]:   [val] ade: 0.642
[INFO: train.py:  338]:   [val] ade_l: 1.414
[INFO: train.py:  338]:   [val] ade_nl: 1.177
[INFO: train.py:  338]:   [val] d_loss: 1.407
[INFO: train.py:  338]:   [val] fde: 1.233
[INFO: train.py:  338]:   [val] fde_l: 2.715
[INFO: train.py:  338]:   [val] fde_nl: 2.259
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.483
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.483
[INFO: train.py:  338]:   [val] resist_count: 2621.000
[INFO: train.py:  338]:   [val] resist_loss: 0.333
[INFO: train.py:  341]:   [train] ade: 0.670
[INFO: train.py:  341]:   [train] ade_l: 1.444
[INFO: train.py:  341]:   [train] ade_nl: 1.250
[INFO: train.py:  341]:   [train] d_loss: 1.409
[INFO: train.py:  341]:   [train] fde: 1.211
[INFO: train.py:  341]:   [train] fde_l: 2.610
[INFO: train.py:  341]:   [train] fde_nl: 2.258
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.452
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.452
[INFO: train.py:  341]:   [train] resist_count: 2844.000
[INFO: train.py:  341]:   [train] resist_loss: 0.206
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 5.4153], device='cuda:0')
[INFO: train.py:  310]: g step took 2.6995747089385986
[INFO: train.py:  316]: Interation 10030 took 12.80668044090271
[INFO: train.py:  558]: resist loss: tensor([ 4.6072], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2780773639678955
[INFO: train.py:  316]: Interation 10031 took 2.2892158031463623
[INFO: train.py:  558]: resist loss: tensor([ 0.5541], device='cuda:0')
[INFO: train.py:  310]: g step took 2.5368926525115967
[INFO: train.py:  316]: Interation 10032 took 2.537336587905884
[INFO: train.py:  558]: resist loss: tensor([ 10.5022], device='cuda:0')
[INFO: train.py:  310]: g step took 2.80611252784729
[INFO: train.py:  316]: Interation 10033 took 2.8141753673553467
[INFO: train.py:  558]: resist loss: tensor([ 5.7934], device='cuda:0')
[INFO: train.py:  310]: g step took 1.94594407081604
[INFO: train.py:  316]: Interation 10034 took 1.9464433193206787
[INFO: train.py:  558]: resist loss: tensor([ 5.3913], device='cuda:0')
[INFO: train.py:  310]: g step took 2.4055440425872803
[INFO: train.py:  316]: Interation 10035 took 2.4059534072875977
[INFO: train.py:  558]: resist loss: tensor([ 0.8748], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9768602848052979
[INFO: train.py:  316]: Interation 10036 took 1.9772753715515137
[INFO: train.py:  558]: resist loss: tensor([ 0.6643], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9096672534942627
[INFO: train.py:  316]: Interation 10037 took 1.9169459342956543
[INFO: train.py:  558]: resist loss: tensor([ 3.3063], device='cuda:0')
[INFO: train.py:  310]: g step took 2.464909315109253
[INFO: train.py:  316]: Interation 10038 took 2.4725303649902344
[INFO: train.py:  558]: resist loss: tensor([ 2.7185], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2786505222320557
[INFO: train.py:  316]: Interation 10039 took 2.292442798614502
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 600, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 600, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 498, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 498, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 476, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 476, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 551, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 551, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 530, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 530, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 526, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 526, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 556, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 556, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 660, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 660, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 599, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 599, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 655, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 655, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 524, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 524, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 186, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 186, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 790, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 790, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 755, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 755, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 848, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 848, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 807, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 807, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 809, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 809, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 738, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 738, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 820, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 820, 2])
[INFO: train.py:  338]:   [val] ade: 0.686
[INFO: train.py:  338]:   [val] ade_l: 1.510
[INFO: train.py:  338]:   [val] ade_nl: 1.256
[INFO: train.py:  338]:   [val] d_loss: 1.413
[INFO: train.py:  338]:   [val] fde: 1.318
[INFO: train.py:  338]:   [val] fde_l: 2.902
[INFO: train.py:  338]:   [val] fde_nl: 2.415
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.505
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.505
[INFO: train.py:  338]:   [val] resist_count: 3433.000
[INFO: train.py:  338]:   [val] resist_loss: 0.350
[INFO: train.py:  341]:   [train] ade: 0.678
[INFO: train.py:  341]:   [train] ade_l: 1.410
[INFO: train.py:  341]:   [train] ade_nl: 1.307
[INFO: train.py:  341]:   [train] d_loss: 1.396
[INFO: train.py:  341]:   [train] fde: 1.186
[INFO: train.py:  341]:   [train] fde_l: 2.466
[INFO: train.py:  341]:   [train] fde_nl: 2.284
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.430
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.430
[INFO: train.py:  341]:   [train] resist_count: 3650.000
[INFO: train.py:  341]:   [train] resist_loss: 0.201
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.9498], device='cuda:0')
[INFO: train.py:  310]: g step took 1.743398666381836
[INFO: train.py:  316]: Interation 10040 took 10.665013074874878
[INFO: train.py:  558]: resist loss: tensor([ 7.0570], device='cuda:0')
[INFO: train.py:  310]: g step took 2.08459210395813
[INFO: train.py:  316]: Interation 10041 took 2.0849685668945312
[INFO: train.py:  558]: resist loss: tensor([ 0.2181], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9381177425384521
[INFO: train.py:  316]: Interation 10042 took 1.9385910034179688
[INFO: train.py:  558]: resist loss: tensor([ 9.6028], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2288143634796143
[INFO: train.py:  316]: Interation 10043 took 2.2292842864990234
[INFO: train.py:  558]: resist loss: tensor([ 1.5443], device='cuda:0')
[INFO: train.py:  310]: g step took 2.113697052001953
[INFO: train.py:  316]: Interation 10044 took 2.1141140460968018
[INFO: train.py:  558]: resist loss: tensor([ 0.2257], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0377259254455566
[INFO: train.py:  316]: Interation 10045 took 2.0419883728027344
[INFO: train.py:  558]: resist loss: tensor([ 0.2198], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7950570583343506
[INFO: train.py:  316]: Interation 10046 took 1.7986059188842773
[INFO: train.py:  558]: resist loss: tensor([ 11.5404], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8518459796905518
[INFO: train.py:  316]: Interation 10047 took 1.855731725692749
[INFO: train.py:  558]: resist loss: tensor([ 1.5211], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9840283393859863
[INFO: train.py:  316]: Interation 10048 took 1.9879615306854248
[INFO: train.py:  558]: resist loss: tensor([ 5.9119], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9321238994598389
[INFO: train.py:  316]: Interation 10049 took 1.9362151622772217
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 481, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 481, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 445, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 445, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 569, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 569, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 601, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 601, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 603, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 603, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 577, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 577, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 682, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 682, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 585, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 585, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 468, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 468, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 596, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 596, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 560, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 560, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 194, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 194, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 849, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 849, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 668, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 668, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 773, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 773, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 709, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 709, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 659, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 659, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 947, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 947, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 726, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 726, 2])
[INFO: train.py:  338]:   [val] ade: 0.595
[INFO: train.py:  338]:   [val] ade_l: 1.310
[INFO: train.py:  338]:   [val] ade_nl: 1.090
[INFO: train.py:  338]:   [val] d_loss: 1.402
[INFO: train.py:  338]:   [val] fde: 1.227
[INFO: train.py:  338]:   [val] fde_l: 2.702
[INFO: train.py:  338]:   [val] fde_nl: 2.248
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.448
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.448
[INFO: train.py:  338]:   [val] resist_count: 3207.000
[INFO: train.py:  338]:   [val] resist_loss: 0.298
[INFO: train.py:  341]:   [train] ade: 0.564
[INFO: train.py:  341]:   [train] ade_l: 1.146
[INFO: train.py:  341]:   [train] ade_nl: 1.109
[INFO: train.py:  341]:   [train] d_loss: 1.399
[INFO: train.py:  341]:   [train] fde: 1.056
[INFO: train.py:  341]:   [train] fde_l: 2.147
[INFO: train.py:  341]:   [train] fde_nl: 2.077
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.330
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.330
[INFO: train.py:  341]:   [train] resist_count: 3741.000
[INFO: train.py:  341]:   [train] resist_loss: 0.216
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 9.5806], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2090868949890137
[INFO: train.py:  316]: Interation 10050 took 10.624434471130371
[INFO: train.py:  558]: resist loss: tensor([ 19.2082], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2281577587127686
[INFO: train.py:  316]: Interation 10051 took 2.2321457862854004
[INFO: train.py:  558]: resist loss: tensor([ 5.9203], device='cuda:0')
[INFO: train.py:  310]: g step took 2.2271623611450195
[INFO: train.py:  316]: Interation 10052 took 2.2309677600860596
[INFO: train.py:  558]: resist loss: tensor([ 5.3523], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9429121017456055
[INFO: train.py:  316]: Interation 10053 took 1.9468319416046143
[INFO: train.py:  558]: resist loss: tensor([ 2.4196], device='cuda:0')
[INFO: train.py:  310]: g step took 1.820136308670044
[INFO: train.py:  316]: Interation 10054 took 1.823645830154419
[INFO: train.py:  558]: resist loss: tensor([ 2.1747], device='cuda:0')
[INFO: train.py:  310]: g step took 1.489743947982788
[INFO: train.py:  316]: Interation 10055 took 1.4944636821746826
[INFO: train.py:  558]: resist loss: tensor([ 15.1879], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8213379383087158
[INFO: train.py:  316]: Interation 10056 took 1.8248472213745117
[INFO: train.py:  558]: resist loss: tensor([ 0.3526], device='cuda:0')
[INFO: train.py:  310]: g step took 1.1711087226867676
[INFO: train.py:  316]: Interation 10057 took 1.1749720573425293
[INFO: train.py:  558]: resist loss: tensor([ 7.9133], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5268101692199707
[INFO: train.py:  316]: Interation 10058 took 1.5307996273040771
[INFO: train.py:  558]: resist loss: tensor([ 5.6172], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3337011337280273
[INFO: train.py:  316]: Interation 10059 took 1.3377532958984375
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 556, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 556, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 508, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 508, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 474, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 474, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 610, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 610, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 607, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 607, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 453, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 453, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 603, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 603, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 455, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 455, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 729, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 729, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 618, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 618, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 598, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 598, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 150, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 150, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 852, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 852, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 773, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 773, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 738, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 738, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 761, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 761, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 775, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 775, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 781, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 781, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 832, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 832, 2])
[INFO: train.py:  338]:   [val] ade: 0.593
[INFO: train.py:  338]:   [val] ade_l: 1.306
[INFO: train.py:  338]:   [val] ade_nl: 1.087
[INFO: train.py:  338]:   [val] d_loss: 1.420
[INFO: train.py:  338]:   [val] fde: 1.226
[INFO: train.py:  338]:   [val] fde_l: 2.699
[INFO: train.py:  338]:   [val] fde_nl: 2.246
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.435
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.435
[INFO: train.py:  338]:   [val] resist_count: 2880.000
[INFO: train.py:  338]:   [val] resist_loss: 0.330
[INFO: train.py:  341]:   [train] ade: 0.595
[INFO: train.py:  341]:   [train] ade_l: 1.266
[INFO: train.py:  341]:   [train] ade_nl: 1.124
[INFO: train.py:  341]:   [train] d_loss: 1.414
[INFO: train.py:  341]:   [train] fde: 1.148
[INFO: train.py:  341]:   [train] fde_l: 2.442
[INFO: train.py:  341]:   [train] fde_nl: 2.168
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.379
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.379
[INFO: train.py:  341]:   [train] resist_count: 2937.000
[INFO: train.py:  341]:   [train] resist_loss: 0.175
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 10.0116], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4315321445465088
[INFO: train.py:  316]: Interation 10060 took 7.823569297790527
[INFO: train.py:  558]: resist loss: tensor([ 0.9852], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3576703071594238
[INFO: train.py:  316]: Interation 10061 took 1.3620965480804443
[INFO: train.py:  558]: resist loss: tensor([ 8.6599], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2707765102386475
[INFO: train.py:  316]: Interation 10062 took 1.2743110656738281
[INFO: train.py:  558]: resist loss: tensor([ 4.2080], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4314944744110107
[INFO: train.py:  316]: Interation 10063 took 1.4357054233551025
[INFO: train.py:  558]: resist loss: tensor([ 3.5585], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3215630054473877
[INFO: train.py:  316]: Interation 10064 took 1.3253116607666016
[INFO: train.py:  558]: resist loss: tensor([ 0.4579], device='cuda:0')
[INFO: train.py:  310]: g step took 1.132300615310669
[INFO: train.py:  316]: Interation 10065 took 1.136505365371704
[INFO: train.py:  558]: resist loss: tensor([ 9.8145], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3653028011322021
[INFO: train.py:  316]: Interation 10066 took 1.369253158569336
[INFO: train.py:  558]: resist loss: tensor([ 0.9106], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4926772117614746
[INFO: train.py:  316]: Interation 10067 took 1.4969725608825684
[INFO: train.py:  558]: resist loss: tensor([ 1.5840], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2402992248535156
[INFO: train.py:  316]: Interation 10068 took 1.2447326183319092
[INFO: train.py:  558]: resist loss: tensor([ 3.4495], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4670751094818115
[INFO: train.py:  316]: Interation 10069 took 1.471128225326538
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 595, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 595, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 681, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 681, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 529, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 529, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 472, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 472, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 555, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 555, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 590, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 590, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 496, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 496, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 562, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 562, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 492, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 492, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 594, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 594, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 644, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 644, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 151, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 151, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 827, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 827, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 869, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 869, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 735, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 735, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 827, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 827, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 790, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 790, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 648, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 648, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 719, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 719, 2])
[INFO: train.py:  338]:   [val] ade: 0.633
[INFO: train.py:  338]:   [val] ade_l: 1.394
[INFO: train.py:  338]:   [val] ade_nl: 1.160
[INFO: train.py:  338]:   [val] d_loss: 1.399
[INFO: train.py:  338]:   [val] fde: 1.294
[INFO: train.py:  338]:   [val] fde_l: 2.848
[INFO: train.py:  338]:   [val] fde_nl: 2.370
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.454
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.454
[INFO: train.py:  338]:   [val] resist_count: 2875.000
[INFO: train.py:  338]:   [val] resist_loss: 0.310
[INFO: train.py:  341]:   [train] ade: 0.635
[INFO: train.py:  341]:   [train] ade_l: 1.346
[INFO: train.py:  341]:   [train] ade_nl: 1.204
[INFO: train.py:  341]:   [train] d_loss: 1.399
[INFO: train.py:  341]:   [train] fde: 1.219
[INFO: train.py:  341]:   [train] fde_l: 2.582
[INFO: train.py:  341]:   [train] fde_nl: 2.310
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.404
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.404
[INFO: train.py:  341]:   [train] resist_count: 2637.000
[INFO: train.py:  341]:   [train] resist_loss: 0.176
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 8.7601], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6231353282928467
[INFO: train.py:  316]: Interation 10070 took 8.604009866714478
[INFO: train.py:  558]: resist loss: tensor([ 0.], device='cuda:0')
[INFO: train.py:  310]: g step took 0.10471701622009277
[INFO: train.py:  316]: Interation 10071 took 0.11007118225097656
[INFO: train.py:  279]: Starting epoch 236
[INFO: train.py:  280]: Epoch resist loss: tensor([ 205.7978])
[INFO: train.py:  558]: resist loss: tensor([ 5.2743], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3208327293395996
[INFO: train.py:  316]: Interation 10072 took 1.7702088356018066
[INFO: train.py:  558]: resist loss: tensor([ 1.7943], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4106643199920654
[INFO: train.py:  316]: Interation 10073 took 1.4111473560333252
[INFO: train.py:  558]: resist loss: tensor([ 1.7447], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5843377113342285
[INFO: train.py:  316]: Interation 10074 took 1.58477783203125
[INFO: train.py:  558]: resist loss: tensor([ 6.0134], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5547447204589844
[INFO: train.py:  316]: Interation 10075 took 1.5627477169036865
[INFO: train.py:  558]: resist loss: tensor([ 0.8077], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2084143161773682
[INFO: train.py:  316]: Interation 10076 took 1.2088513374328613
[INFO: train.py:  558]: resist loss: tensor([ 9.7594], device='cuda:0')
[INFO: train.py:  310]: g step took 1.411113977432251
[INFO: train.py:  316]: Interation 10077 took 1.4114747047424316
[INFO: train.py:  558]: resist loss: tensor([ 0.9733], device='cuda:0')
[INFO: train.py:  310]: g step took 1.337066650390625
[INFO: train.py:  316]: Interation 10078 took 1.337491750717163
[INFO: train.py:  558]: resist loss: tensor([ 8.0151], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2516119480133057
[INFO: train.py:  316]: Interation 10079 took 1.252039909362793
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 703, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 703, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 501, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 501, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 559, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 559, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 535, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 535, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 572, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 572, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 572, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 572, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 584, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 584, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 542, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 542, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 510, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 510, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 639, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 639, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 482, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 482, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 162, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 162, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 889, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 889, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 648, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 648, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 850, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 850, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 742, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 742, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 772, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 772, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 636, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 636, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 785, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 785, 2])
[INFO: train.py:  338]:   [val] ade: 0.643
[INFO: train.py:  338]:   [val] ade_l: 1.415
[INFO: train.py:  338]:   [val] ade_nl: 1.178
[INFO: train.py:  338]:   [val] d_loss: 1.398
[INFO: train.py:  338]:   [val] fde: 1.341
[INFO: train.py:  338]:   [val] fde_l: 2.953
[INFO: train.py:  338]:   [val] fde_nl: 2.458
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.475
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.475
[INFO: train.py:  338]:   [val] resist_count: 3158.000
[INFO: train.py:  338]:   [val] resist_loss: 0.308
[INFO: train.py:  341]:   [train] ade: 0.630
[INFO: train.py:  341]:   [train] ade_l: 1.293
[INFO: train.py:  341]:   [train] ade_nl: 1.227
[INFO: train.py:  341]:   [train] d_loss: 1.397
[INFO: train.py:  341]:   [train] fde: 1.249
[INFO: train.py:  341]:   [train] fde_l: 2.564
[INFO: train.py:  341]:   [train] fde_nl: 2.435
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.412
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.412
[INFO: train.py:  341]:   [train] resist_count: 2814.000
[INFO: train.py:  341]:   [train] resist_loss: 0.151
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.7169], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2637889385223389
[INFO: train.py:  316]: Interation 10080 took 7.653241395950317
[INFO: train.py:  558]: resist loss: tensor([ 13.8937], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4883077144622803
[INFO: train.py:  316]: Interation 10081 took 1.4886736869812012
[INFO: train.py:  558]: resist loss: tensor([ 0.1663], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2811388969421387
[INFO: train.py:  316]: Interation 10082 took 1.2815351486206055
[INFO: train.py:  558]: resist loss: tensor([ 4.4275], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6195604801177979
[INFO: train.py:  316]: Interation 10083 took 1.6265692710876465
[INFO: train.py:  558]: resist loss: tensor([ 0.3283], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3222739696502686
[INFO: train.py:  316]: Interation 10084 took 1.3226723670959473
[INFO: train.py:  558]: resist loss: tensor([ 2.1428], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5017709732055664
[INFO: train.py:  316]: Interation 10085 took 1.5021564960479736
[INFO: train.py:  558]: resist loss: tensor([ 1.1904], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2876622676849365
[INFO: train.py:  316]: Interation 10086 took 1.288079023361206
[INFO: train.py:  558]: resist loss: tensor([ 11.7749], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4410064220428467
[INFO: train.py:  316]: Interation 10087 took 1.4415767192840576
[INFO: train.py:  558]: resist loss: tensor([ 0.5552], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3499000072479248
[INFO: train.py:  316]: Interation 10088 took 1.3540668487548828
[INFO: train.py:  558]: resist loss: tensor([ 0.6165], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3797669410705566
[INFO: train.py:  316]: Interation 10089 took 1.383711576461792
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 574, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 574, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 699, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 699, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 633, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 633, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 608, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 608, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 444, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 444, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 628, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 628, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 618, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 618, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 545, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 545, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 517, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 517, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 491, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 491, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 523, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 523, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 81, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 81, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 881, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 881, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 1028, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 1028, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 732, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 732, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 918, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 918, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 710, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 710, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 968, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 968, 2])
[INFO: train.py:  338]:   [val] ade: 0.651
[INFO: train.py:  338]:   [val] ade_l: 1.432
[INFO: train.py:  338]:   [val] ade_nl: 1.192
[INFO: train.py:  338]:   [val] d_loss: 1.409
[INFO: train.py:  338]:   [val] fde: 1.376
[INFO: train.py:  338]:   [val] fde_l: 3.031
[INFO: train.py:  338]:   [val] fde_nl: 2.522
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.498
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.498
[INFO: train.py:  338]:   [val] resist_count: 3432.000
[INFO: train.py:  338]:   [val] resist_loss: 0.262
[INFO: train.py:  341]:   [train] ade: 0.626
[INFO: train.py:  341]:   [train] ade_l: 1.313
[INFO: train.py:  341]:   [train] ade_nl: 1.197
[INFO: train.py:  341]:   [train] d_loss: 1.403
[INFO: train.py:  341]:   [train] fde: 1.227
[INFO: train.py:  341]:   [train] fde_l: 2.572
[INFO: train.py:  341]:   [train] fde_nl: 2.344
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.407
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.407
[INFO: train.py:  341]:   [train] resist_count: 2859.000
[INFO: train.py:  341]:   [train] resist_loss: 0.129
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.4964], device='cuda:0')
[INFO: train.py:  310]: g step took 1.456770658493042
[INFO: train.py:  316]: Interation 10090 took 7.6627867221832275
[INFO: train.py:  558]: resist loss: tensor([ 1.8769], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4243500232696533
[INFO: train.py:  316]: Interation 10091 took 1.4278182983398438
[INFO: train.py:  558]: resist loss: tensor([ 7.4915], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3247644901275635
[INFO: train.py:  316]: Interation 10092 took 1.328831672668457
[INFO: train.py:  558]: resist loss: tensor([ 1.5035], device='cuda:0')
[INFO: train.py:  310]: g step took 1.512716293334961
[INFO: train.py:  316]: Interation 10093 took 1.5171804428100586
[INFO: train.py:  558]: resist loss: tensor([ 4.1734], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5516200065612793
[INFO: train.py:  316]: Interation 10094 took 1.555762767791748
[INFO: train.py:  558]: resist loss: tensor([ 5.9586], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4749135971069336
[INFO: train.py:  316]: Interation 10095 took 1.4786813259124756
[INFO: train.py:  558]: resist loss: tensor([ 3.8517], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2553861141204834
[INFO: train.py:  316]: Interation 10096 took 1.2598390579223633
[INFO: train.py:  558]: resist loss: tensor([ 1.0536], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4472918510437012
[INFO: train.py:  316]: Interation 10097 took 1.4511711597442627
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 7.2853], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2721428871154785
[INFO: train.py:  316]: Interation 10098 took 1.276824951171875
[INFO: train.py:  558]: resist loss: tensor([ 5.7262], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3118059635162354
[INFO: train.py:  316]: Interation 10099 took 1.315401554107666
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 669, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 669, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 549, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 549, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 662, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 662, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 612, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 612, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 517, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 517, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 508, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 508, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 569, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 569, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 623, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 623, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 534, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 534, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 540, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 540, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 445, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 445, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 133, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 133, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 597, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 597, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 766, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 766, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 886, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 886, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 810, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 810, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 833, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 833, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 872, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 872, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 815, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 815, 2])
[INFO: train.py:  338]:   [val] ade: 0.636
[INFO: train.py:  338]:   [val] ade_l: 1.400
[INFO: train.py:  338]:   [val] ade_nl: 1.165
[INFO: train.py:  338]:   [val] d_loss: 1.408
[INFO: train.py:  338]:   [val] fde: 1.310
[INFO: train.py:  338]:   [val] fde_l: 2.883
[INFO: train.py:  338]:   [val] fde_nl: 2.399
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.465
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.465
[INFO: train.py:  338]:   [val] resist_count: 2920.000
[INFO: train.py:  338]:   [val] resist_loss: 0.273
[INFO: train.py:  341]:   [train] ade: 0.638
[INFO: train.py:  341]:   [train] ade_l: 1.338
[INFO: train.py:  341]:   [train] ade_nl: 1.221
[INFO: train.py:  341]:   [train] d_loss: 1.409
[INFO: train.py:  341]:   [train] fde: 1.219
[INFO: train.py:  341]:   [train] fde_l: 2.554
[INFO: train.py:  341]:   [train] fde_nl: 2.331
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.413
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.413
[INFO: train.py:  341]:   [train] resist_count: 3085.000
[INFO: train.py:  341]:   [train] resist_loss: 0.179
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 11.4655], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6433041095733643
[INFO: train.py:  316]: Interation 10100 took 8.052293300628662
[INFO: train.py:  558]: resist loss: tensor([ 9.0264], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4431755542755127
[INFO: train.py:  316]: Interation 10101 took 1.4476804733276367
[INFO: train.py:  558]: resist loss: tensor([ 3.8679], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4955604076385498
[INFO: train.py:  316]: Interation 10102 took 1.4995410442352295
[INFO: train.py:  558]: resist loss: tensor([ 1.9170], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4362521171569824
[INFO: train.py:  316]: Interation 10103 took 1.440267562866211
[INFO: train.py:  558]: resist loss: tensor([ 0.3283], device='cuda:0')
[INFO: train.py:  310]: g step took 1.1292986869812012
[INFO: train.py:  316]: Interation 10104 took 1.1336696147918701
[INFO: train.py:  558]: resist loss: tensor([ 7.5994], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3377790451049805
[INFO: train.py:  316]: Interation 10105 took 1.3420038223266602
[INFO: train.py:  558]: resist loss: tensor([ 0.2347], device='cuda:0')
[INFO: train.py:  310]: g step took 1.167891263961792
[INFO: train.py:  316]: Interation 10106 took 1.1724989414215088
[INFO: train.py:  558]: resist loss: tensor([ 12.2759], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6120998859405518
[INFO: train.py:  316]: Interation 10107 took 1.615142822265625
[INFO: train.py:  558]: resist loss: tensor([ 2.2347], device='cuda:0')
[INFO: train.py:  310]: g step took 1.337850570678711
[INFO: train.py:  316]: Interation 10108 took 1.341871976852417
[INFO: train.py:  558]: resist loss: tensor([ 13.5027], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7067663669586182
[INFO: train.py:  316]: Interation 10109 took 1.7111773490905762
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 488, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 488, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 477, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 477, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 560, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 560, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 637, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 637, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 598, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 598, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 640, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 640, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 464, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 464, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 632, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 632, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 601, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 601, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 548, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 548, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 614, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 614, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 102, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 102, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 864, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 864, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 800, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 800, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 724, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 724, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 625, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 625, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 788, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 788, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 914, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 914, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 839, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 839, 2])
[INFO: train.py:  338]:   [val] ade: 0.649
[INFO: train.py:  338]:   [val] ade_l: 1.430
[INFO: train.py:  338]:   [val] ade_nl: 1.190
[INFO: train.py:  338]:   [val] d_loss: 1.420
[INFO: train.py:  338]:   [val] fde: 1.326
[INFO: train.py:  338]:   [val] fde_l: 2.920
[INFO: train.py:  338]:   [val] fde_nl: 2.430
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.471
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.471
[INFO: train.py:  338]:   [val] resist_count: 3148.000
[INFO: train.py:  338]:   [val] resist_loss: 0.375
[INFO: train.py:  341]:   [train] ade: 0.650
[INFO: train.py:  341]:   [train] ade_l: 1.347
[INFO: train.py:  341]:   [train] ade_nl: 1.256
[INFO: train.py:  341]:   [train] d_loss: 1.412
[INFO: train.py:  341]:   [train] fde: 1.242
[INFO: train.py:  341]:   [train] fde_l: 2.575
[INFO: train.py:  341]:   [train] fde_nl: 2.401
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.420
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.420
[INFO: train.py:  341]:   [train] resist_count: 3300.000
[INFO: train.py:  341]:   [train] resist_loss: 0.219
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.0569], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3334054946899414
[INFO: train.py:  316]: Interation 10110 took 7.771066904067993
[INFO: train.py:  558]: resist loss: tensor([ 0.9103], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3695175647735596
[INFO: train.py:  316]: Interation 10111 took 1.3739712238311768
[INFO: train.py:  558]: resist loss: tensor([ 6.1030], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3858659267425537
[INFO: train.py:  316]: Interation 10112 took 1.3900845050811768
[INFO: train.py:  558]: resist loss: tensor([ 2.0466], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3135621547698975
[INFO: train.py:  316]: Interation 10113 took 1.3174464702606201
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 5.8241], device='cuda:0')
[INFO: train.py:  310]: g step took 0.15354466438293457
[INFO: train.py:  316]: Interation 10114 took 0.15777325630187988
[INFO: train.py:  279]: Starting epoch 237
[INFO: train.py:  280]: Epoch resist loss: tensor([ 176.0269])
[INFO: train.py:  558]: resist loss: tensor([ 6.8671], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4416296482086182
[INFO: train.py:  316]: Interation 10115 took 1.857494831085205
[INFO: train.py:  558]: resist loss: tensor([ 0.6353], device='cuda:0')
[INFO: train.py:  310]: g step took 1.111480951309204
[INFO: train.py:  316]: Interation 10116 took 1.1230864524841309
[INFO: train.py:  558]: resist loss: tensor([ 2.9023], device='cuda:0')
[INFO: train.py:  310]: g step took 1.482027530670166
[INFO: train.py:  316]: Interation 10117 took 1.4823977947235107
[INFO: train.py:  558]: resist loss: tensor([ 7.5383], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2448737621307373
[INFO: train.py:  316]: Interation 10118 took 1.2533090114593506
[INFO: train.py:  558]: resist loss: tensor([ 0.3789], device='cuda:0')
[INFO: train.py:  310]: g step took 1.150327205657959
[INFO: train.py:  316]: Interation 10119 took 1.1506938934326172
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 670, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 670, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 497, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 497, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 499, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 499, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 581, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 581, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 534, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 534, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 521, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 521, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 614, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 614, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 493, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 493, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 701, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 701, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 536, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 536, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 607, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 607, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 108, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 108, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 892, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 892, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 745, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 745, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 658, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 658, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 750, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 750, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 629, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 629, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 927, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 927, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 531, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 531, 2])
[INFO: train.py:  338]:   [val] ade: 0.631
[INFO: train.py:  338]:   [val] ade_l: 1.388
[INFO: train.py:  338]:   [val] ade_nl: 1.155
[INFO: train.py:  338]:   [val] d_loss: 1.407
[INFO: train.py:  338]:   [val] fde: 1.314
[INFO: train.py:  338]:   [val] fde_l: 2.894
[INFO: train.py:  338]:   [val] fde_nl: 2.408
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.484
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.484
[INFO: train.py:  338]:   [val] resist_count: 2837.000
[INFO: train.py:  338]:   [val] resist_loss: 0.332
[INFO: train.py:  341]:   [train] ade: 0.624
[INFO: train.py:  341]:   [train] ade_l: 1.328
[INFO: train.py:  341]:   [train] ade_nl: 1.178
[INFO: train.py:  341]:   [train] d_loss: 1.414
[INFO: train.py:  341]:   [train] fde: 1.234
[INFO: train.py:  341]:   [train] fde_l: 2.624
[INFO: train.py:  341]:   [train] fde_nl: 2.328
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.418
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.418
[INFO: train.py:  341]:   [train] resist_count: 2643.000
[INFO: train.py:  341]:   [train] resist_loss: 0.178
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.9132], device='cuda:0')
[INFO: train.py:  310]: g step took 1.0212159156799316
[INFO: train.py:  316]: Interation 10120 took 7.269916296005249
[INFO: train.py:  558]: resist loss: tensor([ 3.6357], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4112021923065186
[INFO: train.py:  316]: Interation 10121 took 1.4155678749084473
[INFO: train.py:  558]: resist loss: tensor([ 2.4919], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4509241580963135
[INFO: train.py:  316]: Interation 10122 took 1.4512972831726074
[INFO: train.py:  558]: resist loss: tensor([ 1.0535], device='cuda:0')
[INFO: train.py:  310]: g step took 1.380666732788086
[INFO: train.py:  316]: Interation 10123 took 1.3957102298736572
[INFO: train.py:  558]: resist loss: tensor([ 0.3368], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2946052551269531
[INFO: train.py:  316]: Interation 10124 took 1.308375597000122
[INFO: train.py:  558]: resist loss: tensor([ 6.3113], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2105507850646973
[INFO: train.py:  316]: Interation 10125 took 1.2109107971191406
[INFO: train.py:  558]: resist loss: tensor([ 7.6488], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5373585224151611
[INFO: train.py:  316]: Interation 10126 took 1.5378084182739258
[INFO: train.py:  558]: resist loss: tensor([ 1.8139], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3919751644134521
[INFO: train.py:  316]: Interation 10127 took 1.3924181461334229
[INFO: train.py:  558]: resist loss: tensor([ 0.8390], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4023642539978027
[INFO: train.py:  316]: Interation 10128 took 1.4028518199920654
[INFO: train.py:  558]: resist loss: tensor([ 7.4010], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4168505668640137
[INFO: train.py:  316]: Interation 10129 took 1.4172468185424805
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 500, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 500, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 525, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 525, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 624, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 624, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 552, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 552, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 610, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 610, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 585, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 585, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 675, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 675, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 466, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 466, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 501, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 501, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 613, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 613, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 557, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 557, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 153, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 153, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 696, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 696, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 758, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 758, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 836, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 836, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 774, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 774, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 822, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 822, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 1007, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 1007, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 845, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 845, 2])
[INFO: train.py:  338]:   [val] ade: 0.588
[INFO: train.py:  338]:   [val] ade_l: 1.294
[INFO: train.py:  338]:   [val] ade_nl: 1.076
[INFO: train.py:  338]:   [val] d_loss: 1.404
[INFO: train.py:  338]:   [val] fde: 1.210
[INFO: train.py:  338]:   [val] fde_l: 2.664
[INFO: train.py:  338]:   [val] fde_nl: 2.216
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.416
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.416
[INFO: train.py:  338]:   [val] resist_count: 2946.000
[INFO: train.py:  338]:   [val] resist_loss: 0.330
[INFO: train.py:  341]:   [train] ade: 0.563
[INFO: train.py:  341]:   [train] ade_l: 1.146
[INFO: train.py:  341]:   [train] ade_nl: 1.107
[INFO: train.py:  341]:   [train] d_loss: 1.408
[INFO: train.py:  341]:   [train] fde: 1.079
[INFO: train.py:  341]:   [train] fde_l: 2.197
[INFO: train.py:  341]:   [train] fde_nl: 2.121
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.334
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.334
[INFO: train.py:  341]:   [train] resist_count: 3265.000
[INFO: train.py:  341]:   [train] resist_loss: 0.200
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 11.7030], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3219590187072754
[INFO: train.py:  316]: Interation 10130 took 7.796108245849609
[INFO: train.py:  558]: resist loss: tensor([ 5.9218], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2528777122497559
[INFO: train.py:  316]: Interation 10131 took 1.25726318359375
[INFO: train.py:  558]: resist loss: tensor([ 0.4976], device='cuda:0')
[INFO: train.py:  310]: g step took 1.1417324542999268
[INFO: train.py:  316]: Interation 10132 took 1.1460683345794678
[INFO: train.py:  558]: resist loss: tensor([ 7.5308], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3041481971740723
[INFO: train.py:  316]: Interation 10133 took 1.3087270259857178
[INFO: train.py:  558]: resist loss: tensor([ 0.4641], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2654759883880615
[INFO: train.py:  316]: Interation 10134 took 1.2696492671966553
[INFO: train.py:  558]: resist loss: tensor([ 6.4300], device='cuda:0')
[INFO: train.py:  310]: g step took 1.556335210800171
[INFO: train.py:  316]: Interation 10135 took 1.560199499130249
[INFO: train.py:  558]: resist loss: tensor([ 0.8720], device='cuda:0')
[INFO: train.py:  310]: g step took 1.35331392288208
[INFO: train.py:  316]: Interation 10136 took 1.3574328422546387
[INFO: train.py:  558]: resist loss: tensor([ 1.6066], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4836986064910889
[INFO: train.py:  316]: Interation 10137 took 1.4882431030273438
[INFO: train.py:  558]: resist loss: tensor([ 8.3049], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4912378787994385
[INFO: train.py:  316]: Interation 10138 took 1.4957892894744873
[INFO: train.py:  558]: resist loss: tensor([ 5.4159], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5662598609924316
[INFO: train.py:  316]: Interation 10139 took 1.5703439712524414
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 497, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 497, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 589, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 589, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 560, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 560, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 492, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 492, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 527, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 527, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 569, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 569, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 607, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 607, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 478, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 478, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 766, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 766, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 638, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 638, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 504, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 504, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 134, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 134, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 779, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 779, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 844, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 844, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 889, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 889, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 745, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 745, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 773, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 773, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 703, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 703, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 685, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 685, 2])
[INFO: train.py:  338]:   [val] ade: 0.616
[INFO: train.py:  338]:   [val] ade_l: 1.355
[INFO: train.py:  338]:   [val] ade_nl: 1.128
[INFO: train.py:  338]:   [val] d_loss: 1.412
[INFO: train.py:  338]:   [val] fde: 1.344
[INFO: train.py:  338]:   [val] fde_l: 2.958
[INFO: train.py:  338]:   [val] fde_nl: 2.461
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.459
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.459
[INFO: train.py:  338]:   [val] resist_count: 3055.000
[INFO: train.py:  338]:   [val] resist_loss: 0.317
[INFO: train.py:  341]:   [train] ade: 0.619
[INFO: train.py:  341]:   [train] ade_l: 1.286
[INFO: train.py:  341]:   [train] ade_nl: 1.194
[INFO: train.py:  341]:   [train] d_loss: 1.394
[INFO: train.py:  341]:   [train] fde: 1.284
[INFO: train.py:  341]:   [train] fde_l: 2.667
[INFO: train.py:  341]:   [train] fde_nl: 2.476
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.419
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.419
[INFO: train.py:  341]:   [train] resist_count: 3021.000
[INFO: train.py:  341]:   [train] resist_loss: 0.178
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.3006], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4754984378814697
[INFO: train.py:  316]: Interation 10140 took 7.8573338985443115
[INFO: train.py:  558]: resist loss: tensor([ 6.2333], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7114007472991943
[INFO: train.py:  316]: Interation 10141 took 1.7158467769622803
[INFO: train.py:  558]: resist loss: tensor([ 0.4840], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3312945365905762
[INFO: train.py:  316]: Interation 10142 took 1.335374355316162
[INFO: train.py:  558]: resist loss: tensor([ 0.6677], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3677079677581787
[INFO: train.py:  316]: Interation 10143 took 1.3719286918640137
[INFO: train.py:  558]: resist loss: tensor([ 4.5769], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4166231155395508
[INFO: train.py:  316]: Interation 10144 took 1.4209692478179932
[INFO: train.py:  558]: resist loss: tensor([ 7.1193], device='cuda:0')
[INFO: train.py:  310]: g step took 1.502741813659668
[INFO: train.py:  316]: Interation 10145 took 1.5069975852966309
[INFO: train.py:  558]: resist loss: tensor([ 0.6628], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4606022834777832
[INFO: train.py:  316]: Interation 10146 took 1.4644687175750732
[INFO: train.py:  558]: resist loss: tensor([ 9.1262], device='cuda:0')
[INFO: train.py:  310]: g step took 1.541806697845459
[INFO: train.py:  316]: Interation 10147 took 1.546532154083252
[INFO: train.py:  558]: resist loss: tensor([ 0.3854], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5120277404785156
[INFO: train.py:  316]: Interation 10148 took 1.5161194801330566
[INFO: train.py:  558]: resist loss: tensor([ 0.4923], device='cuda:0')
[INFO: train.py:  310]: g step took 1.646186351776123
[INFO: train.py:  316]: Interation 10149 took 1.6506328582763672
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 524, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 524, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 523, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 523, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 620, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 620, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 580, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 580, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 575, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 575, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 508, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 508, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 532, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 532, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 626, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 626, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 597, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 597, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 548, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 548, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 588, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 588, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 140, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 140, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 717, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 717, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 748, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 748, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 869, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 869, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 660, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 660, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 830, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 830, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 749, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 749, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 842, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 842, 2])
[INFO: train.py:  338]:   [val] ade: 0.603
[INFO: train.py:  338]:   [val] ade_l: 1.328
[INFO: train.py:  338]:   [val] ade_nl: 1.105
[INFO: train.py:  338]:   [val] d_loss: 1.404
[INFO: train.py:  338]:   [val] fde: 1.261
[INFO: train.py:  338]:   [val] fde_l: 2.777
[INFO: train.py:  338]:   [val] fde_nl: 2.311
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.433
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.433
[INFO: train.py:  338]:   [val] resist_count: 2795.000
[INFO: train.py:  338]:   [val] resist_loss: 0.313
[INFO: train.py:  341]:   [train] ade: 0.616
[INFO: train.py:  341]:   [train] ade_l: 1.333
[INFO: train.py:  341]:   [train] ade_nl: 1.146
[INFO: train.py:  341]:   [train] d_loss: 1.406
[INFO: train.py:  341]:   [train] fde: 1.204
[INFO: train.py:  341]:   [train] fde_l: 2.604
[INFO: train.py:  341]:   [train] fde_nl: 2.240
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.387
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.387
[INFO: train.py:  341]:   [train] resist_count: 2837.000
[INFO: train.py:  341]:   [train] resist_loss: 0.177
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 1.9367], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5048868656158447
[INFO: train.py:  316]: Interation 10150 took 7.8929502964019775
[INFO: train.py:  558]: resist loss: tensor([ 3.7330], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3313605785369873
[INFO: train.py:  316]: Interation 10151 took 1.3350260257720947
[INFO: train.py:  558]: resist loss: tensor([ 1.5848], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4757051467895508
[INFO: train.py:  316]: Interation 10152 took 1.4798738956451416
[INFO: train.py:  558]: resist loss: tensor([ 5.3798], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3634052276611328
[INFO: train.py:  316]: Interation 10153 took 1.367354154586792
[INFO: train.py:  558]: resist loss: tensor([ 7.1986], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3334393501281738
[INFO: train.py:  316]: Interation 10154 took 1.337228536605835
[INFO: train.py:  558]: resist loss: tensor([ 0.8213], device='cuda:0')
[INFO: train.py:  310]: g step took 1.650531530380249
[INFO: train.py:  316]: Interation 10155 took 1.6545791625976562
[INFO: train.py:  558]: resist loss: tensor([ 0.7135], device='cuda:0')
[INFO: train.py:  310]: g step took 1.464608907699585
[INFO: train.py:  316]: Interation 10156 took 1.4687485694885254
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 6.9918], device='cuda:0')
[INFO: train.py:  310]: g step took 0.11411809921264648
[INFO: train.py:  316]: Interation 10157 took 0.11809754371643066
[INFO: train.py:  279]: Starting epoch 238
[INFO: train.py:  280]: Epoch resist loss: tensor([ 152.9999])
[INFO: train.py:  558]: resist loss: tensor([ 9.4416], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4930353164672852
[INFO: train.py:  316]: Interation 10158 took 1.9126336574554443
[INFO: train.py:  558]: resist loss: tensor([ 1.3801], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2270638942718506
[INFO: train.py:  316]: Interation 10159 took 1.26600980758667
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 462, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 462, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 566, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 566, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 523, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 523, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 568, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 568, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 532, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 532, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 463, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 463, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 690, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 690, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 741, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 741, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 517, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 517, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 594, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 594, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 559, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 559, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 146, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 146, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 710, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 710, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 831, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 831, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 732, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 732, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 803, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 803, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 665, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 665, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 747, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 747, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 794, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 794, 2])
[INFO: train.py:  338]:   [val] ade: 0.619
[INFO: train.py:  338]:   [val] ade_l: 1.362
[INFO: train.py:  338]:   [val] ade_nl: 1.133
[INFO: train.py:  338]:   [val] d_loss: 1.413
[INFO: train.py:  338]:   [val] fde: 1.268
[INFO: train.py:  338]:   [val] fde_l: 2.793
[INFO: train.py:  338]:   [val] fde_nl: 2.324
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.449
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.449
[INFO: train.py:  338]:   [val] resist_count: 2649.000
[INFO: train.py:  338]:   [val] resist_loss: 0.299
[INFO: train.py:  341]:   [train] ade: 0.627
[INFO: train.py:  341]:   [train] ade_l: 1.303
[INFO: train.py:  341]:   [train] ade_nl: 1.209
[INFO: train.py:  341]:   [train] d_loss: 1.409
[INFO: train.py:  341]:   [train] fde: 1.204
[INFO: train.py:  341]:   [train] fde_l: 2.501
[INFO: train.py:  341]:   [train] fde_nl: 2.320
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.415
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.415
[INFO: train.py:  341]:   [train] resist_count: 2465.000
[INFO: train.py:  341]:   [train] resist_loss: 0.164
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 7.0436], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3659648895263672
[INFO: train.py:  316]: Interation 10160 took 7.589307546615601
[INFO: train.py:  558]: resist loss: tensor([ 0.8488], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2446212768554688
[INFO: train.py:  316]: Interation 10161 took 1.245041847229004
[INFO: train.py:  558]: resist loss: tensor([ 2.7382], device='cuda:0')
[INFO: train.py:  310]: g step took 1.298590898513794
[INFO: train.py:  316]: Interation 10162 took 1.2990102767944336
[INFO: train.py:  558]: resist loss: tensor([ 6.7100], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2275104522705078
[INFO: train.py:  316]: Interation 10163 took 1.2279613018035889
[INFO: train.py:  558]: resist loss: tensor([ 0.5427], device='cuda:0')
[INFO: train.py:  310]: g step took 1.293703317642212
[INFO: train.py:  316]: Interation 10164 took 1.2941606044769287
[INFO: train.py:  558]: resist loss: tensor([ 14.8374], device='cuda:0')
[INFO: train.py:  310]: g step took 1.668158769607544
[INFO: train.py:  316]: Interation 10165 took 1.6686885356903076
[INFO: train.py:  558]: resist loss: tensor([ 1.0159], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5458276271820068
[INFO: train.py:  316]: Interation 10166 took 1.546360969543457
[INFO: train.py:  558]: resist loss: tensor([ 0.2825], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3220391273498535
[INFO: train.py:  316]: Interation 10167 took 1.3297755718231201
[INFO: train.py:  558]: resist loss: tensor([ 5.9041], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3030002117156982
[INFO: train.py:  316]: Interation 10168 took 1.3033936023712158
[INFO: train.py:  558]: resist loss: tensor([ 16.3860], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6690900325775146
[INFO: train.py:  316]: Interation 10169 took 1.6695313453674316
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 588, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 588, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 542, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 542, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 479, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 479, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 655, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 655, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 522, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 522, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 501, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 501, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 675, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 675, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 487, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 487, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 587, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 587, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 548, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 548, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 668, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 668, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 109, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 109, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 734, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 734, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 676, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 676, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 811, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 811, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 845, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 845, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 677, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 677, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 774, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 774, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 753, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 753, 2])
[INFO: train.py:  338]:   [val] ade: 0.612
[INFO: train.py:  338]:   [val] ade_l: 1.348
[INFO: train.py:  338]:   [val] ade_nl: 1.121
[INFO: train.py:  338]:   [val] d_loss: 1.411
[INFO: train.py:  338]:   [val] fde: 1.287
[INFO: train.py:  338]:   [val] fde_l: 2.834
[INFO: train.py:  338]:   [val] fde_nl: 2.358
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.434
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.434
[INFO: train.py:  338]:   [val] resist_count: 3014.000
[INFO: train.py:  338]:   [val] resist_loss: 0.328
[INFO: train.py:  341]:   [train] ade: 0.611
[INFO: train.py:  341]:   [train] ade_l: 1.219
[INFO: train.py:  341]:   [train] ade_nl: 1.224
[INFO: train.py:  341]:   [train] d_loss: 1.406
[INFO: train.py:  341]:   [train] fde: 1.192
[INFO: train.py:  341]:   [train] fde_l: 2.379
[INFO: train.py:  341]:   [train] fde_nl: 2.388
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.388
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.388
[INFO: train.py:  341]:   [train] resist_count: 2740.000
[INFO: train.py:  341]:   [train] resist_loss: 0.164
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.7442], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4481465816497803
[INFO: train.py:  316]: Interation 10170 took 7.786823987960815
[INFO: train.py:  558]: resist loss: tensor([ 1.8903], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4832847118377686
[INFO: train.py:  316]: Interation 10171 took 1.483713150024414
[INFO: train.py:  558]: resist loss: tensor([ 1.3573], device='cuda:0')
[INFO: train.py:  310]: g step took 1.1740009784698486
[INFO: train.py:  316]: Interation 10172 took 1.1744024753570557
[INFO: train.py:  558]: resist loss: tensor([ 2.1248], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4790337085723877
[INFO: train.py:  316]: Interation 10173 took 1.4794974327087402
[INFO: train.py:  558]: resist loss: tensor([ 1.0905], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3694069385528564
[INFO: train.py:  316]: Interation 10174 took 1.3736929893493652
[INFO: train.py:  558]: resist loss: tensor([ 0.3170], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2955615520477295
[INFO: train.py:  316]: Interation 10175 took 1.2999696731567383
[INFO: train.py:  558]: resist loss: tensor([ 12.1610], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4422390460968018
[INFO: train.py:  316]: Interation 10176 took 1.4461908340454102
[INFO: train.py:  558]: resist loss: tensor([ 5.3337], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4108526706695557
[INFO: train.py:  316]: Interation 10177 took 1.4151558876037598
[INFO: train.py:  558]: resist loss: tensor([ 4.1060], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6378819942474365
[INFO: train.py:  316]: Interation 10178 took 1.6420001983642578
[INFO: train.py:  558]: resist loss: tensor([ 0.8945], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4049630165100098
[INFO: train.py:  316]: Interation 10179 took 1.408935546875
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 550, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 550, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 535, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 535, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 616, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 616, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 527, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 527, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 507, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 507, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 643, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 643, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 503, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 503, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 606, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 606, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 567, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 567, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 629, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 629, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 521, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 521, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 157, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 157, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 749, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 749, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 814, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 814, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 687, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 687, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 834, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 834, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 933, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 933, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 768, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 768, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 805, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 805, 2])
[INFO: train.py:  338]:   [val] ade: 0.593
[INFO: train.py:  338]:   [val] ade_l: 1.305
[INFO: train.py:  338]:   [val] ade_nl: 1.086
[INFO: train.py:  338]:   [val] d_loss: 1.415
[INFO: train.py:  338]:   [val] fde: 1.253
[INFO: train.py:  338]:   [val] fde_l: 2.759
[INFO: train.py:  338]:   [val] fde_nl: 2.296
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.426
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.426
[INFO: train.py:  338]:   [val] resist_count: 2848.000
[INFO: train.py:  338]:   [val] resist_loss: 0.334
[INFO: train.py:  341]:   [train] ade: 0.602
[INFO: train.py:  341]:   [train] ade_l: 1.271
[INFO: train.py:  341]:   [train] ade_nl: 1.143
[INFO: train.py:  341]:   [train] d_loss: 1.398
[INFO: train.py:  341]:   [train] fde: 1.190
[INFO: train.py:  341]:   [train] fde_l: 2.513
[INFO: train.py:  341]:   [train] fde_nl: 2.260
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.385
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.385
[INFO: train.py:  341]:   [train] resist_count: 2563.000
[INFO: train.py:  341]:   [train] resist_loss: 0.168
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 12.7094], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5288290977478027
[INFO: train.py:  316]: Interation 10180 took 7.915768623352051
[INFO: train.py:  558]: resist loss: tensor([ 4.7056], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3832998275756836
[INFO: train.py:  316]: Interation 10181 took 1.3880643844604492
[INFO: train.py:  558]: resist loss: tensor([ 9.2780], device='cuda:0')
[INFO: train.py:  310]: g step took 1.404228687286377
[INFO: train.py:  316]: Interation 10182 took 1.4085988998413086
[INFO: train.py:  558]: resist loss: tensor([ 1.7632], device='cuda:0')
[INFO: train.py:  310]: g step took 1.283785104751587
[INFO: train.py:  316]: Interation 10183 took 1.2877612113952637
[INFO: train.py:  558]: resist loss: tensor([ 7.2186], device='cuda:0')
[INFO: train.py:  310]: g step took 1.327559471130371
[INFO: train.py:  316]: Interation 10184 took 1.331535816192627
[INFO: train.py:  558]: resist loss: tensor([ 3.5780], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3749916553497314
[INFO: train.py:  316]: Interation 10185 took 1.3789105415344238
[INFO: train.py:  558]: resist loss: tensor([ 0.5415], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5278234481811523
[INFO: train.py:  316]: Interation 10186 took 1.531562328338623
[INFO: train.py:  558]: resist loss: tensor([ 3.0563], device='cuda:0')
[INFO: train.py:  310]: g step took 1.0736024379730225
[INFO: train.py:  316]: Interation 10187 took 1.077744722366333
[INFO: train.py:  558]: resist loss: tensor([ 1.4510], device='cuda:0')
[INFO: train.py:  310]: g step took 1.392324686050415
[INFO: train.py:  316]: Interation 10188 took 1.3963115215301514
[INFO: train.py:  558]: resist loss: tensor([ 1.4509], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2216315269470215
[INFO: train.py:  316]: Interation 10189 took 1.2259957790374756
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 715, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 715, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 554, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 554, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 667, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 667, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 689, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 689, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 440, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 440, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 425, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 425, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 520, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 520, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 489, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 489, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 605, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 605, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 492, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 492, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 589, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 589, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 176, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 176, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 799, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 799, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 588, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 588, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 854, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 854, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 891, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 891, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 884, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 884, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 884, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 884, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 747, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 747, 2])
[INFO: train.py:  338]:   [val] ade: 0.637
[INFO: train.py:  338]:   [val] ade_l: 1.403
[INFO: train.py:  338]:   [val] ade_nl: 1.167
[INFO: train.py:  338]:   [val] d_loss: 1.405
[INFO: train.py:  338]:   [val] fde: 1.305
[INFO: train.py:  338]:   [val] fde_l: 2.874
[INFO: train.py:  338]:   [val] fde_nl: 2.391
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.460
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.460
[INFO: train.py:  338]:   [val] resist_count: 3160.000
[INFO: train.py:  338]:   [val] resist_loss: 0.348
[INFO: train.py:  341]:   [train] ade: 0.617
[INFO: train.py:  341]:   [train] ade_l: 1.323
[INFO: train.py:  341]:   [train] ade_nl: 1.156
[INFO: train.py:  341]:   [train] d_loss: 1.408
[INFO: train.py:  341]:   [train] fde: 1.183
[INFO: train.py:  341]:   [train] fde_l: 2.535
[INFO: train.py:  341]:   [train] fde_nl: 2.217
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.381
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.381
[INFO: train.py:  341]:   [train] resist_count: 3337.000
[INFO: train.py:  341]:   [train] resist_loss: 0.193
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.4426], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3167784214019775
[INFO: train.py:  316]: Interation 10190 took 7.749262094497681
[INFO: train.py:  558]: resist loss: tensor([ 9.2053], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4207277297973633
[INFO: train.py:  316]: Interation 10191 took 1.42509126663208
[INFO: train.py:  558]: resist loss: tensor([ 0.7811], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5955333709716797
[INFO: train.py:  316]: Interation 10192 took 1.5999979972839355
[INFO: train.py:  558]: resist loss: tensor([ 2.6702], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5173242092132568
[INFO: train.py:  316]: Interation 10193 took 1.5215213298797607
[INFO: train.py:  558]: resist loss: tensor([ 8.6202], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4149293899536133
[INFO: train.py:  316]: Interation 10194 took 1.4189529418945312
[INFO: train.py:  558]: resist loss: tensor([ 1.6249], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5088937282562256
[INFO: train.py:  316]: Interation 10195 took 1.5130410194396973
[INFO: train.py:  558]: resist loss: tensor([ 5.7011], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4185760021209717
[INFO: train.py:  316]: Interation 10196 took 1.422598123550415
[INFO: train.py:  558]: resist loss: tensor([ 5.7490], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3959598541259766
[INFO: train.py:  316]: Interation 10197 took 1.4000194072723389
[INFO: train.py:  558]: resist loss: tensor([ 4.7196], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6317715644836426
[INFO: train.py:  316]: Interation 10198 took 1.636040449142456
[INFO: train.py:  558]: resist loss: tensor([ 8.9250], device='cuda:0')
[INFO: train.py:  310]: g step took 1.508786916732788
[INFO: train.py:  316]: Interation 10199 took 1.5130805969238281
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 622, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 622, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 614, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 614, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 465, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 465, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 720, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 720, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 593, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 593, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 472, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 472, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 534, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 534, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 549, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 549, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 580, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 580, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 526, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 526, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 513, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 513, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 173, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 173, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 859, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 859, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 747, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 747, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 793, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 793, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 573, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 573, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 708, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 708, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 780, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 780, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 704, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 704, 2])
[INFO: train.py:  338]:   [val] ade: 0.616
[INFO: train.py:  338]:   [val] ade_l: 1.357
[INFO: train.py:  338]:   [val] ade_nl: 1.129
[INFO: train.py:  338]:   [val] d_loss: 1.412
[INFO: train.py:  338]:   [val] fde: 1.284
[INFO: train.py:  338]:   [val] fde_l: 2.826
[INFO: train.py:  338]:   [val] fde_nl: 2.352
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.454
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.454
[INFO: train.py:  338]:   [val] resist_count: 2905.000
[INFO: train.py:  338]:   [val] resist_loss: 0.303
[INFO: train.py:  341]:   [train] ade: 0.616
[INFO: train.py:  341]:   [train] ade_l: 1.294
[INFO: train.py:  341]:   [train] ade_nl: 1.175
[INFO: train.py:  341]:   [train] d_loss: 1.405
[INFO: train.py:  341]:   [train] fde: 1.214
[INFO: train.py:  341]:   [train] fde_l: 2.552
[INFO: train.py:  341]:   [train] fde_nl: 2.316
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.415
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.415
[INFO: train.py:  341]:   [train] resist_count: 2270.000
[INFO: train.py:  341]:   [train] resist_loss: 0.156
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.1920], device='cuda:0')
[INFO: train.py:  310]: g step took 0.1375288963317871
[INFO: train.py:  316]: Interation 10200 took 6.377692699432373
[INFO: train.py:  279]: Starting epoch 239
[INFO: train.py:  280]: Epoch resist loss: tensor([ 191.5338])
[INFO: train.py:  558]: resist loss: tensor([ 1.1577], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4118366241455078
[INFO: train.py:  316]: Interation 10201 took 1.8640379905700684
[INFO: train.py:  558]: resist loss: tensor([ 8.7449], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4085845947265625
[INFO: train.py:  316]: Interation 10202 took 1.409095048904419
[INFO: train.py:  558]: resist loss: tensor([ 1.5635], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5708765983581543
[INFO: train.py:  316]: Interation 10203 took 1.5813241004943848
[INFO: train.py:  558]: resist loss: tensor([ 1.7195], device='cuda:0')
[INFO: train.py:  310]: g step took 1.382145643234253
[INFO: train.py:  316]: Interation 10204 took 1.3825881481170654
[INFO: train.py:  558]: resist loss: tensor([ 1.7928], device='cuda:0')
[INFO: train.py:  310]: g step took 1.421182632446289
[INFO: train.py:  316]: Interation 10205 took 1.4215879440307617
[INFO: train.py:  558]: resist loss: tensor([ 0.8922], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2737464904785156
[INFO: train.py:  316]: Interation 10206 took 1.274134635925293
[INFO: train.py:  558]: resist loss: tensor([ 1.3530], device='cuda:0')
[INFO: train.py:  310]: g step took 1.090850830078125
[INFO: train.py:  316]: Interation 10207 took 1.0912599563598633
[INFO: train.py:  558]: resist loss: tensor([ 1.7605], device='cuda:0')
[INFO: train.py:  310]: g step took 1.521481990814209
[INFO: train.py:  316]: Interation 10208 took 1.5218689441680908
[INFO: train.py:  558]: resist loss: tensor([ 3.0553], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2448031902313232
[INFO: train.py:  316]: Interation 10209 took 1.2570130825042725
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 457, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 457, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 732, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 732, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 654, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 654, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 563, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 563, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 568, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 568, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 488, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 488, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 501, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 501, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 545, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 545, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 484, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 484, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 657, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 657, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 540, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 540, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 172, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 172, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 731, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 731, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 852, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 852, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 743, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 743, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 885, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 885, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 678, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 678, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 830, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 830, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 855, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 855, 2])
[INFO: train.py:  338]:   [val] ade: 0.609
[INFO: train.py:  338]:   [val] ade_l: 1.341
[INFO: train.py:  338]:   [val] ade_nl: 1.116
[INFO: train.py:  338]:   [val] d_loss: 1.412
[INFO: train.py:  338]:   [val] fde: 1.289
[INFO: train.py:  338]:   [val] fde_l: 2.838
[INFO: train.py:  338]:   [val] fde_nl: 2.362
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.433
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.433
[INFO: train.py:  338]:   [val] resist_count: 3218.000
[INFO: train.py:  338]:   [val] resist_loss: 0.316
[INFO: train.py:  341]:   [train] ade: 0.617
[INFO: train.py:  341]:   [train] ade_l: 1.311
[INFO: train.py:  341]:   [train] ade_nl: 1.167
[INFO: train.py:  341]:   [train] d_loss: 1.405
[INFO: train.py:  341]:   [train] fde: 1.231
[INFO: train.py:  341]:   [train] fde_l: 2.613
[INFO: train.py:  341]:   [train] fde_nl: 2.326
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.400
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.400
[INFO: train.py:  341]:   [train] resist_count: 3104.000
[INFO: train.py:  341]:   [train] resist_loss: 0.181
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 8.2377], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5013673305511475
[INFO: train.py:  316]: Interation 10210 took 7.984199523925781
[INFO: train.py:  558]: resist loss: tensor([ 0.3769], device='cuda:0')
[INFO: train.py:  310]: g step took 1.1609396934509277
[INFO: train.py:  316]: Interation 10211 took 1.1682705879211426
[INFO: train.py:  558]: resist loss: tensor([ 8.3854], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8587818145751953
[INFO: train.py:  316]: Interation 10212 took 1.8592174053192139
[INFO: train.py:  558]: resist loss: tensor([ 6.2321], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3235180377960205
[INFO: train.py:  316]: Interation 10213 took 1.3239920139312744
[INFO: train.py:  558]: resist loss: tensor([ 0.3377], device='cuda:0')
[INFO: train.py:  310]: g step took 1.215644121170044
[INFO: train.py:  316]: Interation 10214 took 1.2160797119140625
[INFO: train.py:  558]: resist loss: tensor([ 11.8711], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5035269260406494
[INFO: train.py:  316]: Interation 10215 took 1.5039582252502441
[INFO: train.py:  558]: resist loss: tensor([ 1.8260], device='cuda:0')
[INFO: train.py:  310]: g step took 1.435370922088623
[INFO: train.py:  316]: Interation 10216 took 1.4357919692993164
[INFO: train.py:  558]: resist loss: tensor([ 2.8124], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3322339057922363
[INFO: train.py:  316]: Interation 10217 took 1.336899995803833
[INFO: train.py:  558]: resist loss: tensor([ 0.4008], device='cuda:0')
[INFO: train.py:  310]: g step took 1.32338547706604
[INFO: train.py:  316]: Interation 10218 took 1.3277785778045654
[INFO: train.py:  558]: resist loss: tensor([ 0.2771], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2342486381530762
[INFO: train.py:  316]: Interation 10219 took 1.2381591796875
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 592, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 592, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 512, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 512, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 606, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 606, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 508, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 508, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 603, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 603, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 559, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 559, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 672, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 672, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 497, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 497, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 554, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 554, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 612, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 612, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 453, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 453, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 193, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 193, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 776, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 776, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 799, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 799, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 845, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 845, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 642, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 642, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 818, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 818, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 793, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 793, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 834, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 834, 2])
[INFO: train.py:  338]:   [val] ade: 0.608
[INFO: train.py:  338]:   [val] ade_l: 1.339
[INFO: train.py:  338]:   [val] ade_nl: 1.114
[INFO: train.py:  338]:   [val] d_loss: 1.409
[INFO: train.py:  338]:   [val] fde: 1.258
[INFO: train.py:  338]:   [val] fde_l: 2.770
[INFO: train.py:  338]:   [val] fde_nl: 2.305
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.432
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.432
[INFO: train.py:  338]:   [val] resist_count: 3237.000
[INFO: train.py:  338]:   [val] resist_loss: 0.368
[INFO: train.py:  341]:   [train] ade: 0.594
[INFO: train.py:  341]:   [train] ade_l: 1.246
[INFO: train.py:  341]:   [train] ade_nl: 1.136
[INFO: train.py:  341]:   [train] d_loss: 1.406
[INFO: train.py:  341]:   [train] fde: 1.159
[INFO: train.py:  341]:   [train] fde_l: 2.429
[INFO: train.py:  341]:   [train] fde_nl: 2.216
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.366
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.366
[INFO: train.py:  341]:   [train] resist_count: 3007.000
[INFO: train.py:  341]:   [train] resist_loss: 0.184
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.7190], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8093297481536865
[INFO: train.py:  316]: Interation 10220 took 9.138580799102783
[INFO: train.py:  558]: resist loss: tensor([ 3.6024], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8140478134155273
[INFO: train.py:  316]: Interation 10221 took 1.8181114196777344
[INFO: train.py:  558]: resist loss: tensor([ 2.8296], device='cuda:0')
[INFO: train.py:  310]: g step took 1.908937692642212
[INFO: train.py:  316]: Interation 10222 took 1.9129338264465332
[INFO: train.py:  558]: resist loss: tensor([ 1.3798], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8261487483978271
[INFO: train.py:  316]: Interation 10223 took 1.8300502300262451
[INFO: train.py:  558]: resist loss: tensor([ 2.6310], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6110661029815674
[INFO: train.py:  316]: Interation 10224 took 1.615124225616455
[INFO: train.py:  558]: resist loss: tensor([ 4.8378], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6053876876831055
[INFO: train.py:  316]: Interation 10225 took 1.608837604522705
[INFO: train.py:  558]: resist loss: tensor([ 0.8261], device='cuda:0')
[INFO: train.py:  310]: g step took 1.630549669265747
[INFO: train.py:  316]: Interation 10226 took 1.6345374584197998
[INFO: train.py:  558]: resist loss: tensor([ 0.7544], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8094799518585205
[INFO: train.py:  316]: Interation 10227 took 1.8135285377502441
[INFO: train.py:  558]: resist loss: tensor([ 0.3488], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6527161598205566
[INFO: train.py:  316]: Interation 10228 took 1.656083106994629
[INFO: train.py:  558]: resist loss: tensor([ 0.2348], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5879943370819092
[INFO: train.py:  316]: Interation 10229 took 1.5918500423431396
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 569, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 569, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 527, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 527, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 586, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 586, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 648, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 648, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 446, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 446, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 558, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 558, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 508, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 508, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 475, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 475, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 666, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 666, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 590, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 590, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 661, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 661, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 127, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 127, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 805, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 805, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 738, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 738, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 854, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 854, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 769, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 769, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 726, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 726, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 762, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 762, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 930, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 930, 2])
[INFO: train.py:  338]:   [val] ade: 0.609
[INFO: train.py:  338]:   [val] ade_l: 1.341
[INFO: train.py:  338]:   [val] ade_nl: 1.116
[INFO: train.py:  338]:   [val] d_loss: 1.419
[INFO: train.py:  338]:   [val] fde: 1.295
[INFO: train.py:  338]:   [val] fde_l: 2.850
[INFO: train.py:  338]:   [val] fde_nl: 2.372
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.458
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.458
[INFO: train.py:  338]:   [val] resist_count: 2777.000
[INFO: train.py:  338]:   [val] resist_loss: 0.293
[INFO: train.py:  341]:   [train] ade: 0.619
[INFO: train.py:  341]:   [train] ade_l: 1.273
[INFO: train.py:  341]:   [train] ade_nl: 1.204
[INFO: train.py:  341]:   [train] d_loss: 1.408
[INFO: train.py:  341]:   [train] fde: 1.218
[INFO: train.py:  341]:   [train] fde_l: 2.505
[INFO: train.py:  341]:   [train] fde_nl: 2.369
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.409
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.409
[INFO: train.py:  341]:   [train] resist_count: 2861.000
[INFO: train.py:  341]:   [train] resist_loss: 0.177
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 8.8753], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3092103004455566
[INFO: train.py:  316]: Interation 10230 took 7.817768812179565
[INFO: train.py:  558]: resist loss: tensor([ 2.7308], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5118284225463867
[INFO: train.py:  316]: Interation 10231 took 1.5157899856567383
[INFO: train.py:  558]: resist loss: tensor([ 3.6295], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6188664436340332
[INFO: train.py:  316]: Interation 10232 took 1.6230504512786865
[INFO: train.py:  558]: resist loss: tensor([ 5.9916], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3670384883880615
[INFO: train.py:  316]: Interation 10233 took 1.3700201511383057
[INFO: train.py:  558]: resist loss: tensor([ 11.5671], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4027338027954102
[INFO: train.py:  316]: Interation 10234 took 1.4069135189056396
[INFO: train.py:  558]: resist loss: tensor([ 7.8279], device='cuda:0')
[INFO: train.py:  310]: g step took 1.1654024124145508
[INFO: train.py:  316]: Interation 10235 took 1.169299840927124
[INFO: train.py:  558]: resist loss: tensor([ 6.8818], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5009572505950928
[INFO: train.py:  316]: Interation 10236 took 1.5043199062347412
[INFO: train.py:  558]: resist loss: tensor([ 7.5152], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3856942653656006
[INFO: train.py:  316]: Interation 10237 took 1.3896958827972412
[INFO: train.py:  558]: resist loss: tensor([ 3.7148], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6090734004974365
[INFO: train.py:  316]: Interation 10238 took 1.6132574081420898
[INFO: train.py:  558]: resist loss: tensor([ 1.2120], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2323272228240967
[INFO: train.py:  316]: Interation 10239 took 1.236588716506958
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 640, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 640, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 570, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 570, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 568, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 568, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 625, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 625, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 548, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 548, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 596, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 596, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 563, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 563, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 569, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 569, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 439, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 439, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 578, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 578, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 527, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 527, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 138, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 138, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 632, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 632, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 931, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 931, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 784, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 784, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 894, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 894, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 852, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 852, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 657, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 657, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 902, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 902, 2])
[INFO: train.py:  338]:   [val] ade: 0.658
[INFO: train.py:  338]:   [val] ade_l: 1.448
[INFO: train.py:  338]:   [val] ade_nl: 1.205
[INFO: train.py:  338]:   [val] d_loss: 1.404
[INFO: train.py:  338]:   [val] fde: 1.415
[INFO: train.py:  338]:   [val] fde_l: 3.116
[INFO: train.py:  338]:   [val] fde_nl: 2.593
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.540
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.540
[INFO: train.py:  338]:   [val] resist_count: 2411.000
[INFO: train.py:  338]:   [val] resist_loss: 0.226
[INFO: train.py:  341]:   [train] ade: 0.651
[INFO: train.py:  341]:   [train] ade_l: 1.340
[INFO: train.py:  341]:   [train] ade_nl: 1.266
[INFO: train.py:  341]:   [train] d_loss: 1.400
[INFO: train.py:  341]:   [train] fde: 1.322
[INFO: train.py:  341]:   [train] fde_l: 2.721
[INFO: train.py:  341]:   [train] fde_nl: 2.571
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.465
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.465
[INFO: train.py:  341]:   [train] resist_count: 2492.000
[INFO: train.py:  341]:   [train] resist_loss: 0.139
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 5.2255], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4032206535339355
[INFO: train.py:  316]: Interation 10240 took 7.811840772628784
[INFO: train.py:  558]: resist loss: tensor([ 11.0547], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5132522583007812
[INFO: train.py:  316]: Interation 10241 took 1.5164504051208496
[INFO: train.py:  558]: resist loss: tensor([ 0.8838], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2240829467773438
[INFO: train.py:  316]: Interation 10242 took 1.2279341220855713
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 3.6765], device='cuda:0')
[INFO: train.py:  310]: g step took 0.11800265312194824
[INFO: train.py:  316]: Interation 10243 took 0.12236452102661133
[INFO: train.py:  279]: Starting epoch 240
[INFO: train.py:  280]: Epoch resist loss: tensor([ 158.1070])
[INFO: train.py:  558]: resist loss: tensor([ 1.0697], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2995564937591553
[INFO: train.py:  316]: Interation 10244 took 1.7542636394500732
[INFO: train.py:  558]: resist loss: tensor([ 4.3847], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4702203273773193
[INFO: train.py:  316]: Interation 10245 took 1.4750666618347168
[INFO: train.py:  558]: resist loss: tensor([ 1.3704], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5648162364959717
[INFO: train.py:  316]: Interation 10246 took 1.565253496170044
[INFO: train.py:  558]: resist loss: tensor([ 9.5734], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6347551345825195
[INFO: train.py:  316]: Interation 10247 took 1.635180950164795
[INFO: train.py:  558]: resist loss: tensor([ 1.2170], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3936550617218018
[INFO: train.py:  316]: Interation 10248 took 1.3978922367095947
[INFO: train.py:  558]: resist loss: tensor([ 2.1329], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4715652465820312
[INFO: train.py:  316]: Interation 10249 took 1.4719491004943848
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 583, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 583, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 627, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 627, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 621, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 621, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 531, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 531, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 454, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 454, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 570, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 570, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 564, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 564, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 497, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 497, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 589, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 589, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 606, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 606, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 608, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 608, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 111, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 111, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 795, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 795, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 783, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 783, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 755, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 755, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 835, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 835, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 821, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 821, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 862, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 862, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 852, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 852, 2])
[INFO: train.py:  338]:   [val] ade: 0.625
[INFO: train.py:  338]:   [val] ade_l: 1.377
[INFO: train.py:  338]:   [val] ade_nl: 1.146
[INFO: train.py:  338]:   [val] d_loss: 1.409
[INFO: train.py:  338]:   [val] fde: 1.305
[INFO: train.py:  338]:   [val] fde_l: 2.873
[INFO: train.py:  338]:   [val] fde_nl: 2.390
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.458
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.458
[INFO: train.py:  338]:   [val] resist_count: 2732.000
[INFO: train.py:  338]:   [val] resist_loss: 0.267
[INFO: train.py:  341]:   [train] ade: 0.619
[INFO: train.py:  341]:   [train] ade_l: 1.294
[INFO: train.py:  341]:   [train] ade_nl: 1.187
[INFO: train.py:  341]:   [train] d_loss: 1.395
[INFO: train.py:  341]:   [train] fde: 1.207
[INFO: train.py:  341]:   [train] fde_l: 2.522
[INFO: train.py:  341]:   [train] fde_nl: 2.314
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.392
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.392
[INFO: train.py:  341]:   [train] resist_count: 2686.000
[INFO: train.py:  341]:   [train] resist_loss: 0.154
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.3209], device='cuda:0')
[INFO: train.py:  310]: g step took 1.512927770614624
[INFO: train.py:  316]: Interation 10250 took 7.984946966171265
[INFO: train.py:  558]: resist loss: tensor([ 3.2124], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6565821170806885
[INFO: train.py:  316]: Interation 10251 took 1.6569862365722656
[INFO: train.py:  558]: resist loss: tensor([ 0.4500], device='cuda:0')
[INFO: train.py:  310]: g step took 1.255335807800293
[INFO: train.py:  316]: Interation 10252 took 1.269505500793457
[INFO: train.py:  558]: resist loss: tensor([ 1.5696], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2956862449645996
[INFO: train.py:  316]: Interation 10253 took 1.2998967170715332
[INFO: train.py:  558]: resist loss: tensor([ 9.8097], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4527289867401123
[INFO: train.py:  316]: Interation 10254 took 1.4530422687530518
[INFO: train.py:  558]: resist loss: tensor([ 2.0529], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5316405296325684
[INFO: train.py:  316]: Interation 10255 took 1.5320017337799072
[INFO: train.py:  558]: resist loss: tensor([ 0.5475], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3277130126953125
[INFO: train.py:  316]: Interation 10256 took 1.3319013118743896
[INFO: train.py:  558]: resist loss: tensor([ 0.6707], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2469282150268555
[INFO: train.py:  316]: Interation 10257 took 1.2472937107086182
[INFO: train.py:  558]: resist loss: tensor([ 0.7512], device='cuda:0')
[INFO: train.py:  310]: g step took 1.490670919418335
[INFO: train.py:  316]: Interation 10258 took 1.4910595417022705
[INFO: train.py:  558]: resist loss: tensor([ 6.1333], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3635311126708984
[INFO: train.py:  316]: Interation 10259 took 1.3639371395111084
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 636, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 636, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 691, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 691, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 562, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 562, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 631, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 631, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 561, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 561, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 608, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 608, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 535, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 535, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 437, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 437, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 507, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 507, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 559, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 559, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 508, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 508, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 126, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 126, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 940, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 940, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 591, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 591, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 786, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 786, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 706, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 706, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 720, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 720, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 971, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 971, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 761, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 761, 2])
[INFO: train.py:  338]:   [val] ade: 0.625
[INFO: train.py:  338]:   [val] ade_l: 1.375
[INFO: train.py:  338]:   [val] ade_nl: 1.144
[INFO: train.py:  338]:   [val] d_loss: 1.412
[INFO: train.py:  338]:   [val] fde: 1.287
[INFO: train.py:  338]:   [val] fde_l: 2.835
[INFO: train.py:  338]:   [val] fde_nl: 2.359
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.458
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.458
[INFO: train.py:  338]:   [val] resist_count: 2880.000
[INFO: train.py:  338]:   [val] resist_loss: 0.247
[INFO: train.py:  341]:   [train] ade: 0.621
[INFO: train.py:  341]:   [train] ade_l: 1.295
[INFO: train.py:  341]:   [train] ade_nl: 1.192
[INFO: train.py:  341]:   [train] d_loss: 1.394
[INFO: train.py:  341]:   [train] fde: 1.208
[INFO: train.py:  341]:   [train] fde_l: 2.521
[INFO: train.py:  341]:   [train] fde_nl: 2.320
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.415
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.415
[INFO: train.py:  341]:   [train] resist_count: 2893.000
[INFO: train.py:  341]:   [train] resist_loss: 0.154
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.8139], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4713661670684814
[INFO: train.py:  316]: Interation 10260 took 7.91557765007019
[INFO: train.py:  558]: resist loss: tensor([ 2.0580], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4200751781463623
[INFO: train.py:  316]: Interation 10261 took 1.4240174293518066
[INFO: train.py:  558]: resist loss: tensor([ 1.7102], device='cuda:0')
[INFO: train.py:  310]: g step took 1.074821949005127
[INFO: train.py:  316]: Interation 10262 took 1.078582525253296
[INFO: train.py:  558]: resist loss: tensor([ 1.2268], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3047575950622559
[INFO: train.py:  316]: Interation 10263 took 1.3089327812194824
[INFO: train.py:  558]: resist loss: tensor([ 2.3161], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4434287548065186
[INFO: train.py:  316]: Interation 10264 took 1.4478724002838135
[INFO: train.py:  558]: resist loss: tensor([ 3.5396], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2077066898345947
[INFO: train.py:  316]: Interation 10265 took 1.2121849060058594
[INFO: train.py:  558]: resist loss: tensor([ 10.3607], device='cuda:0')
[INFO: train.py:  310]: g step took 1.556433916091919
[INFO: train.py:  316]: Interation 10266 took 1.560748815536499
[INFO: train.py:  558]: resist loss: tensor([ 0.3534], device='cuda:0')
[INFO: train.py:  310]: g step took 1.1189334392547607
[INFO: train.py:  316]: Interation 10267 took 1.1229095458984375
[INFO: train.py:  558]: resist loss: tensor([ 13.6612], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7236285209655762
[INFO: train.py:  316]: Interation 10268 took 1.7277722358703613
[INFO: train.py:  558]: resist loss: tensor([ 2.6111], device='cuda:0')
[INFO: train.py:  310]: g step took 1.299682855606079
[INFO: train.py:  316]: Interation 10269 took 1.3036768436431885
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 659, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 659, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 487, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 487, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 518, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 518, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 585, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 585, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 538, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 538, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 456, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 456, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 573, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 573, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 632, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 632, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 532, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 532, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 536, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 536, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 630, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 630, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 215, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 215, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 869, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 869, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 726, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 726, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 740, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 740, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 949, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 949, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 833, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 833, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 778, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 778, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 778, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 778, 2])
[INFO: train.py:  338]:   [val] ade: 0.638
[INFO: train.py:  338]:   [val] ade_l: 1.405
[INFO: train.py:  338]:   [val] ade_nl: 1.169
[INFO: train.py:  338]:   [val] d_loss: 1.410
[INFO: train.py:  338]:   [val] fde: 1.310
[INFO: train.py:  338]:   [val] fde_l: 2.884
[INFO: train.py:  338]:   [val] fde_nl: 2.399
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.455
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.455
[INFO: train.py:  338]:   [val] resist_count: 2966.000
[INFO: train.py:  338]:   [val] resist_loss: 0.327
[INFO: train.py:  341]:   [train] ade: 0.645
[INFO: train.py:  341]:   [train] ade_l: 1.320
[INFO: train.py:  341]:   [train] ade_nl: 1.260
[INFO: train.py:  341]:   [train] d_loss: 1.403
[INFO: train.py:  341]:   [train] fde: 1.215
[INFO: train.py:  341]:   [train] fde_l: 2.487
[INFO: train.py:  341]:   [train] fde_nl: 2.373
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.413
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.413
[INFO: train.py:  341]:   [train] resist_count: 3015.000
[INFO: train.py:  341]:   [train] resist_loss: 0.180
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.5865], device='cuda:0')
[INFO: train.py:  310]: g step took 1.1725986003875732
[INFO: train.py:  316]: Interation 10270 took 7.740865707397461
[INFO: train.py:  558]: resist loss: tensor([ 1.3055], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2019264698028564
[INFO: train.py:  316]: Interation 10271 took 1.2058603763580322
[INFO: train.py:  558]: resist loss: tensor([ 9.1219], device='cuda:0')
[INFO: train.py:  310]: g step took 1.475602626800537
[INFO: train.py:  316]: Interation 10272 took 1.479935646057129
[INFO: train.py:  558]: resist loss: tensor([ 7.2257], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2925190925598145
[INFO: train.py:  316]: Interation 10273 took 1.2968087196350098
[INFO: train.py:  558]: resist loss: tensor([ 0.5227], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3554203510284424
[INFO: train.py:  316]: Interation 10274 took 1.3594682216644287
[INFO: train.py:  558]: resist loss: tensor([ 1.6614], device='cuda:0')
[INFO: train.py:  310]: g step took 1.450150489807129
[INFO: train.py:  316]: Interation 10275 took 1.4541637897491455
[INFO: train.py:  558]: resist loss: tensor([ 7.9916], device='cuda:0')
[INFO: train.py:  310]: g step took 1.483872890472412
[INFO: train.py:  316]: Interation 10276 took 1.4881093502044678
[INFO: train.py:  558]: resist loss: tensor([ 1.0969], device='cuda:0')
[INFO: train.py:  310]: g step took 1.586486577987671
[INFO: train.py:  316]: Interation 10277 took 1.5905120372772217
[INFO: train.py:  558]: resist loss: tensor([ 2.4172], device='cuda:0')
[INFO: train.py:  310]: g step took 1.339977741241455
[INFO: train.py:  316]: Interation 10278 took 1.3440971374511719
[INFO: train.py:  558]: resist loss: tensor([ 6.5722], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2851917743682861
[INFO: train.py:  316]: Interation 10279 took 1.2896113395690918
[INFO: train.py:  327]: Checking stats on val ...
Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7fc4dd406ba8>>
Traceback (most recent call last):
  File "/data/xinjiey/Group_Navi_GAN/env/lib/python3.5/site-packages/torch/utils/data/dataloader.py", line 349, in __del__
    self._shutdown_workers()
  File "/data/xinjiey/Group_Navi_GAN/env/lib/python3.5/site-packages/torch/utils/data/dataloader.py", line 328, in _shutdown_workers
    self.worker_result_queue.get()
  File "/usr/lib/python3.5/multiprocessing/queues.py", line 345, in get
    return ForkingPickler.loads(res)
  File "/data/xinjiey/Group_Navi_GAN/env/lib/python3.5/site-packages/torch/multiprocessing/reductions.py", line 70, in rebuild_storage_fd
    fd = df.detach()
  File "/usr/lib/python3.5/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/usr/lib/python3.5/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 493, in Client
    answer_challenge(c, authkey)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 737, in answer_challenge
    response = connection.recv_bytes(256)        # reject large message
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
ConnectionResetError: [Errno 104] Connection reset by peer
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 591, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 591, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 584, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 584, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 494, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 494, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 546, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 546, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 533, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 533, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 520, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 520, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 596, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 596, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 606, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 606, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 635, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 635, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 483, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 483, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 643, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 643, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 130, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 130, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 714, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 714, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 839, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 839, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 658, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 658, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 633, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 633, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 753, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 753, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 638, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 638, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 814, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 814, 2])
[INFO: train.py:  338]:   [val] ade: 0.590
[INFO: train.py:  338]:   [val] ade_l: 1.299
[INFO: train.py:  338]:   [val] ade_nl: 1.081
[INFO: train.py:  338]:   [val] d_loss: 1.420
[INFO: train.py:  338]:   [val] fde: 1.201
[INFO: train.py:  338]:   [val] fde_l: 2.644
[INFO: train.py:  338]:   [val] fde_nl: 2.200
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.413
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.413
[INFO: train.py:  338]:   [val] resist_count: 2845.000
[INFO: train.py:  338]:   [val] resist_loss: 0.338
[INFO: train.py:  341]:   [train] ade: 0.581
[INFO: train.py:  341]:   [train] ade_l: 1.193
[INFO: train.py:  341]:   [train] ade_nl: 1.133
[INFO: train.py:  341]:   [train] d_loss: 1.417
[INFO: train.py:  341]:   [train] fde: 1.110
[INFO: train.py:  341]:   [train] fde_l: 2.278
[INFO: train.py:  341]:   [train] fde_nl: 2.165
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.365
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.365
[INFO: train.py:  341]:   [train] resist_count: 2562.000
[INFO: train.py:  341]:   [train] resist_loss: 0.180
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.5835], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5717768669128418
[INFO: train.py:  316]: Interation 10280 took 7.87195897102356
[INFO: train.py:  558]: resist loss: tensor([ 10.6371], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4514660835266113
[INFO: train.py:  316]: Interation 10281 took 1.4558079242706299
[INFO: train.py:  558]: resist loss: tensor([ 0.5410], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2233686447143555
[INFO: train.py:  316]: Interation 10282 took 1.2275915145874023
[INFO: train.py:  558]: resist loss: tensor([ 0.9136], device='cuda:0')
[INFO: train.py:  310]: g step took 1.23036789894104
[INFO: train.py:  316]: Interation 10283 took 1.2346351146697998
[INFO: train.py:  558]: resist loss: tensor([ 19.4469], device='cuda:0')
[INFO: train.py:  310]: g step took 1.454162359237671
[INFO: train.py:  316]: Interation 10284 took 1.4585130214691162
[INFO: train.py:  558]: resist loss: tensor([ 8.3144], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2569031715393066
[INFO: train.py:  316]: Interation 10285 took 1.261047124862671
[INFO: train.py:  558]: resist loss: tensor(1.00000e-03 *
       [ 5.8943], device='cuda:0')
[INFO: train.py:  310]: g step took 0.11438131332397461
[INFO: train.py:  316]: Interation 10286 took 0.11821341514587402
[INFO: train.py:  279]: Starting epoch 241
[INFO: train.py:  280]: Epoch resist loss: tensor([ 166.8612])
[INFO: train.py:  558]: resist loss: tensor([ 13.2103], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7080016136169434
[INFO: train.py:  316]: Interation 10287 took 2.1629350185394287
[INFO: train.py:  558]: resist loss: tensor([ 4.9283], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4258317947387695
[INFO: train.py:  316]: Interation 10288 took 1.4301164150238037
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 1.1407], device='cuda:0')
[INFO: train.py:  310]: g step took 1.295281171798706
[INFO: train.py:  316]: Interation 10289 took 1.2957415580749512
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 521, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 521, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 446, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 446, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 635, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 635, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 589, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 589, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 527, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 527, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 579, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 579, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 577, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 577, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 594, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 594, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 584, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 584, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 642, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 642, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 508, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 508, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 159, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 159, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 851, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 851, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 753, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 753, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 760, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 760, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 763, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 763, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 631, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 631, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 768, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 768, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 869, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 869, 2])
[INFO: train.py:  338]:   [val] ade: 0.612
[INFO: train.py:  338]:   [val] ade_l: 1.348
[INFO: train.py:  338]:   [val] ade_nl: 1.122
[INFO: train.py:  338]:   [val] d_loss: 1.413
[INFO: train.py:  338]:   [val] fde: 1.254
[INFO: train.py:  338]:   [val] fde_l: 2.761
[INFO: train.py:  338]:   [val] fde_nl: 2.298
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.428
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.428
[INFO: train.py:  338]:   [val] resist_count: 2909.000
[INFO: train.py:  338]:   [val] resist_loss: 0.338
[INFO: train.py:  341]:   [train] ade: 0.627
[INFO: train.py:  341]:   [train] ade_l: 1.302
[INFO: train.py:  341]:   [train] ade_nl: 1.210
[INFO: train.py:  341]:   [train] d_loss: 1.402
[INFO: train.py:  341]:   [train] fde: 1.194
[INFO: train.py:  341]:   [train] fde_l: 2.479
[INFO: train.py:  341]:   [train] fde_nl: 2.304
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.398
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.398
[INFO: train.py:  341]:   [train] resist_count: 2937.000
[INFO: train.py:  341]:   [train] resist_loss: 0.174
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 9.5464], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4405639171600342
[INFO: train.py:  316]: Interation 10290 took 7.79680323600769
[INFO: train.py:  558]: resist loss: tensor([ 19.7646], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8921358585357666
[INFO: train.py:  316]: Interation 10291 took 1.892580509185791
[INFO: train.py:  558]: resist loss: tensor([ 3.2628], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6270718574523926
[INFO: train.py:  316]: Interation 10292 took 1.6275103092193604
[INFO: train.py:  558]: resist loss: tensor([ 2.4338], device='cuda:0')
[INFO: train.py:  310]: g step took 1.194772720336914
[INFO: train.py:  316]: Interation 10293 took 1.195216417312622
[INFO: train.py:  558]: resist loss: tensor([ 1.2484], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4239461421966553
[INFO: train.py:  316]: Interation 10294 took 1.4243884086608887
[INFO: train.py:  558]: resist loss: tensor([ 1.0762], device='cuda:0')
[INFO: train.py:  310]: g step took 1.417987585067749
[INFO: train.py:  316]: Interation 10295 took 1.4366822242736816
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 9.3385], device='cuda:0')
[INFO: train.py:  310]: g step took 1.335235357284546
[INFO: train.py:  316]: Interation 10296 took 1.3355989456176758
[INFO: train.py:  558]: resist loss: tensor([ 1.3163], device='cuda:0')
[INFO: train.py:  310]: g step took 1.328672170639038
[INFO: train.py:  316]: Interation 10297 took 1.3290410041809082
[INFO: train.py:  558]: resist loss: tensor([ 1.7714], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2317085266113281
[INFO: train.py:  316]: Interation 10298 took 1.2320973873138428
[INFO: train.py:  558]: resist loss: tensor([ 1.2628], device='cuda:0')
[INFO: train.py:  310]: g step took 1.553877830505371
[INFO: train.py:  316]: Interation 10299 took 1.5542750358581543
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 517, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 517, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 513, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 513, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 563, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 563, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 585, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 585, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 533, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 533, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 503, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 503, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 659, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 659, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 590, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 590, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 648, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 648, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 612, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 612, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 528, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 528, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 110, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 110, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 677, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 677, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 827, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 827, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 688, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 688, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 816, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 816, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 903, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 903, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 772, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 772, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 684, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 684, 2])
[INFO: train.py:  338]:   [val] ade: 0.611
[INFO: train.py:  338]:   [val] ade_l: 1.345
[INFO: train.py:  338]:   [val] ade_nl: 1.120
[INFO: train.py:  338]:   [val] d_loss: 1.410
[INFO: train.py:  338]:   [val] fde: 1.245
[INFO: train.py:  338]:   [val] fde_l: 2.742
[INFO: train.py:  338]:   [val] fde_nl: 2.282
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.424
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.424
[INFO: train.py:  338]:   [val] resist_count: 3017.000
[INFO: train.py:  338]:   [val] resist_loss: 0.273
[INFO: train.py:  341]:   [train] ade: 0.612
[INFO: train.py:  341]:   [train] ade_l: 1.239
[INFO: train.py:  341]:   [train] ade_nl: 1.209
[INFO: train.py:  341]:   [train] d_loss: 1.405
[INFO: train.py:  341]:   [train] fde: 1.173
[INFO: train.py:  341]:   [train] fde_l: 2.375
[INFO: train.py:  341]:   [train] fde_nl: 2.319
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.384
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.384
[INFO: train.py:  341]:   [train] resist_count: 2753.000
[INFO: train.py:  341]:   [train] resist_loss: 0.156
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 12.7948], device='cuda:0')
[INFO: train.py:  310]: g step took 1.70723295211792
[INFO: train.py:  316]: Interation 10300 took 8.160473346710205
[INFO: train.py:  558]: resist loss: tensor([ 1.8065], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4238147735595703
[INFO: train.py:  316]: Interation 10301 took 1.4242467880249023
[INFO: train.py:  558]: resist loss: tensor([ 0.9968], device='cuda:0')
[INFO: train.py:  310]: g step took 1.520742654800415
[INFO: train.py:  316]: Interation 10302 took 1.5211701393127441
[INFO: train.py:  558]: resist loss: tensor([ 12.8449], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5111465454101562
[INFO: train.py:  316]: Interation 10303 took 1.5166094303131104
[INFO: train.py:  558]: resist loss: tensor([ 5.8433], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3375890254974365
[INFO: train.py:  316]: Interation 10304 took 1.3418183326721191
[INFO: train.py:  558]: resist loss: tensor([ 0.5567], device='cuda:0')
[INFO: train.py:  310]: g step took 1.530588150024414
[INFO: train.py:  316]: Interation 10305 took 1.534656047821045
[INFO: train.py:  558]: resist loss: tensor([ 5.9987], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2594215869903564
[INFO: train.py:  316]: Interation 10306 took 1.2633702754974365
[INFO: train.py:  558]: resist loss: tensor([ 5.4291], device='cuda:0')
[INFO: train.py:  310]: g step took 1.235581636428833
[INFO: train.py:  316]: Interation 10307 took 1.2398157119750977
[INFO: train.py:  558]: resist loss: tensor([ 2.4413], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6488399505615234
[INFO: train.py:  316]: Interation 10308 took 1.6530876159667969
[INFO: train.py:  558]: resist loss: tensor([ 3.6107], device='cuda:0')
[INFO: train.py:  310]: g step took 1.192307710647583
[INFO: train.py:  316]: Interation 10309 took 1.1962766647338867
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 545, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 545, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 479, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 479, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 670, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 670, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 559, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 559, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 704, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 704, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 563, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 563, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 456, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 456, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 622, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 622, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 491, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 491, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 465, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 465, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 690, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 690, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 117, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 117, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 769, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 769, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 817, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 817, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 852, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 852, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 618, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 618, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 698, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 698, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 913, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 913, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 699, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 699, 2])
[INFO: train.py:  338]:   [val] ade: 0.682
[INFO: train.py:  338]:   [val] ade_l: 1.501
[INFO: train.py:  338]:   [val] ade_nl: 1.249
[INFO: train.py:  338]:   [val] d_loss: 1.401
[INFO: train.py:  338]:   [val] fde: 1.253
[INFO: train.py:  338]:   [val] fde_l: 2.759
[INFO: train.py:  338]:   [val] fde_nl: 2.296
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.473
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.473
[INFO: train.py:  338]:   [val] resist_count: 3315.000
[INFO: train.py:  338]:   [val] resist_loss: 0.372
[INFO: train.py:  341]:   [train] ade: 0.692
[INFO: train.py:  341]:   [train] ade_l: 1.466
[INFO: train.py:  341]:   [train] ade_nl: 1.312
[INFO: train.py:  341]:   [train] d_loss: 1.401
[INFO: train.py:  341]:   [train] fde: 1.194
[INFO: train.py:  341]:   [train] fde_l: 2.529
[INFO: train.py:  341]:   [train] fde_nl: 2.263
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.437
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.437
[INFO: train.py:  341]:   [train] resist_count: 3469.000
[INFO: train.py:  341]:   [train] resist_loss: 0.222
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 4.6861], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3983991146087646
[INFO: train.py:  316]: Interation 10310 took 7.7475621700286865
[INFO: train.py:  558]: resist loss: tensor([ 20.6738], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5438058376312256
[INFO: train.py:  316]: Interation 10311 took 1.5476374626159668
[INFO: train.py:  558]: resist loss: tensor([ 1.3257], device='cuda:0')
[INFO: train.py:  310]: g step took 1.30037260055542
[INFO: train.py:  316]: Interation 10312 took 1.3043735027313232
[INFO: train.py:  558]: resist loss: tensor([ 2.1957], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3284261226654053
[INFO: train.py:  316]: Interation 10313 took 1.3325574398040771
[INFO: train.py:  558]: resist loss: tensor([ 0.5541], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4360501766204834
[INFO: train.py:  316]: Interation 10314 took 1.440387487411499
[INFO: train.py:  558]: resist loss: tensor([ 7.9346], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3664636611938477
[INFO: train.py:  316]: Interation 10315 took 1.3707373142242432
[INFO: train.py:  558]: resist loss: tensor([ 8.4651], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4057326316833496
[INFO: train.py:  316]: Interation 10316 took 1.4099595546722412
[INFO: train.py:  558]: resist loss: tensor([ 3.2138], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2803471088409424
[INFO: train.py:  316]: Interation 10317 took 1.2845423221588135
[INFO: train.py:  558]: resist loss: tensor([ 3.5803], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3159115314483643
[INFO: train.py:  316]: Interation 10318 took 1.320124864578247
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 9.3859], device='cuda:0')
[INFO: train.py:  310]: g step took 1.1604392528533936
[INFO: train.py:  316]: Interation 10319 took 1.164879322052002
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 527, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 527, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 663, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 663, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 516, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 516, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 547, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 547, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 555, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 555, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 637, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 637, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 435, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 435, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 555, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 555, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 593, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 593, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 746, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 746, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 455, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 455, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 132, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 132, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 786, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 786, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 614, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 614, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 816, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 816, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 713, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 713, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 878, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 878, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 617, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 617, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 743, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 743, 2])
[INFO: train.py:  338]:   [val] ade: 0.598
[INFO: train.py:  338]:   [val] ade_l: 1.317
[INFO: train.py:  338]:   [val] ade_nl: 1.096
[INFO: train.py:  338]:   [val] d_loss: 1.418
[INFO: train.py:  338]:   [val] fde: 1.211
[INFO: train.py:  338]:   [val] fde_l: 2.666
[INFO: train.py:  338]:   [val] fde_nl: 2.218
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.427
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.427
[INFO: train.py:  338]:   [val] resist_count: 2830.000
[INFO: train.py:  338]:   [val] resist_loss: 0.312
[INFO: train.py:  341]:   [train] ade: 0.593
[INFO: train.py:  341]:   [train] ade_l: 1.224
[INFO: train.py:  341]:   [train] ade_nl: 1.152
[INFO: train.py:  341]:   [train] d_loss: 1.405
[INFO: train.py:  341]:   [train] fde: 1.136
[INFO: train.py:  341]:   [train] fde_l: 2.343
[INFO: train.py:  341]:   [train] fde_nl: 2.207
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.388
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.388
[INFO: train.py:  341]:   [train] resist_count: 2595.000
[INFO: train.py:  341]:   [train] resist_loss: 0.180
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.2131], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2745509147644043
[INFO: train.py:  316]: Interation 10320 took 7.729010343551636
[INFO: train.py:  558]: resist loss: tensor([ 1.6596], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3556561470031738
[INFO: train.py:  316]: Interation 10321 took 1.3597967624664307
[INFO: train.py:  558]: resist loss: tensor([ 0.9537], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3881266117095947
[INFO: train.py:  316]: Interation 10322 took 1.3923046588897705
[INFO: train.py:  558]: resist loss: tensor([ 8.1682], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3488409519195557
[INFO: train.py:  316]: Interation 10323 took 1.3532376289367676
[INFO: train.py:  558]: resist loss: tensor([ 11.6331], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5413696765899658
[INFO: train.py:  316]: Interation 10324 took 1.5457556247711182
[INFO: train.py:  558]: resist loss: tensor([ 2.5073], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3994860649108887
[INFO: train.py:  316]: Interation 10325 took 1.4033899307250977
[INFO: train.py:  558]: resist loss: tensor([ 1.2218], device='cuda:0')
[INFO: train.py:  310]: g step took 1.1047322750091553
[INFO: train.py:  316]: Interation 10326 took 1.1087172031402588
[INFO: train.py:  558]: resist loss: tensor([ 5.1791], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3710670471191406
[INFO: train.py:  316]: Interation 10327 took 1.3756189346313477
[INFO: train.py:  558]: resist loss: tensor([ 1.7727], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3705644607543945
[INFO: train.py:  316]: Interation 10328 took 1.3747308254241943
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 5.5164], device='cuda:0')
[INFO: train.py:  310]: g step took 0.09171557426452637
[INFO: train.py:  316]: Interation 10329 took 0.09580492973327637
[INFO: train.py:  327]: Checking stats on val ...
Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7fc4dd52fc18>>
Traceback (most recent call last):
  File "/data/xinjiey/Group_Navi_GAN/env/lib/python3.5/site-packages/torch/utils/data/dataloader.py", line 349, in __del__
    self._shutdown_workers()
  File "/data/xinjiey/Group_Navi_GAN/env/lib/python3.5/site-packages/torch/utils/data/dataloader.py", line 328, in _shutdown_workers
    self.worker_result_queue.get()
  File "/usr/lib/python3.5/multiprocessing/queues.py", line 345, in get
    return ForkingPickler.loads(res)
  File "/data/xinjiey/Group_Navi_GAN/env/lib/python3.5/site-packages/torch/multiprocessing/reductions.py", line 70, in rebuild_storage_fd
    fd = df.detach()
  File "/usr/lib/python3.5/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/usr/lib/python3.5/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 494, in Client
    deliver_challenge(c, authkey)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 722, in deliver_challenge
    response = connection.recv_bytes(256)        # reject large message
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
ConnectionResetError: [Errno 104] Connection reset by peer
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 541, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 541, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 564, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 564, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 611, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 611, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 517, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 517, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 637, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 637, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 538, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 538, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 580, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 580, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 561, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 561, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 614, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 614, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 456, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 456, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 566, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 566, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 176, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 176, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 769, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 769, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 953, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 953, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 998, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 998, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 702, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 702, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 646, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 646, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 735, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 735, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 866, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 866, 2])
[INFO: train.py:  338]:   [val] ade: 0.585
[INFO: train.py:  338]:   [val] ade_l: 1.288
[INFO: train.py:  338]:   [val] ade_nl: 1.072
[INFO: train.py:  338]:   [val] d_loss: 1.416
[INFO: train.py:  338]:   [val] fde: 1.206
[INFO: train.py:  338]:   [val] fde_l: 2.656
[INFO: train.py:  338]:   [val] fde_nl: 2.210
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.435
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.435
[INFO: train.py:  338]:   [val] resist_count: 2618.000
[INFO: train.py:  338]:   [val] resist_loss: 0.302
[INFO: train.py:  341]:   [train] ade: 0.604
[INFO: train.py:  341]:   [train] ade_l: 1.268
[INFO: train.py:  341]:   [train] ade_nl: 1.154
[INFO: train.py:  341]:   [train] d_loss: 1.407
[INFO: train.py:  341]:   [train] fde: 1.145
[INFO: train.py:  341]:   [train] fde_l: 2.404
[INFO: train.py:  341]:   [train] fde_nl: 2.187
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.399
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.399
[INFO: train.py:  341]:   [train] resist_count: 2788.000
[INFO: train.py:  341]:   [train] resist_loss: 0.171
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  279]: Starting epoch 242
[INFO: train.py:  280]: Epoch resist loss: tensor([ 198.3357])
Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7fc4dd52fc18>>
Traceback (most recent call last):
  File "/data/xinjiey/Group_Navi_GAN/env/lib/python3.5/site-packages/torch/utils/data/dataloader.py", line 349, in __del__
    self._shutdown_workers()
  File "/data/xinjiey/Group_Navi_GAN/env/lib/python3.5/site-packages/torch/utils/data/dataloader.py", line 328, in _shutdown_workers
    self.worker_result_queue.get()
  File "/usr/lib/python3.5/multiprocessing/queues.py", line 345, in get
    return ForkingPickler.loads(res)
  File "/data/xinjiey/Group_Navi_GAN/env/lib/python3.5/site-packages/torch/multiprocessing/reductions.py", line 70, in rebuild_storage_fd
    fd = df.detach()
  File "/usr/lib/python3.5/multiprocessing/resource_sharer.py", line 58, in detach
    return reduction.recv_handle(conn)
  File "/usr/lib/python3.5/multiprocessing/reduction.py", line 181, in recv_handle
    return recvfds(s, 1)[0]
  File "/usr/lib/python3.5/multiprocessing/reduction.py", line 152, in recvfds
    msg, ancdata, flags, addr = sock.recvmsg(1, socket.CMSG_LEN(bytes_size))
ConnectionResetError: [Errno 104] Connection reset by peer
[INFO: train.py:  558]: resist loss: tensor([ 1.5557], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2555735111236572
[INFO: train.py:  316]: Interation 10330 took 8.332403659820557
[INFO: train.py:  558]: resist loss: tensor([ 3.2084], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2851307392120361
[INFO: train.py:  316]: Interation 10331 took 1.2855887413024902
[INFO: train.py:  558]: resist loss: tensor([ 6.3753], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2854950428009033
[INFO: train.py:  316]: Interation 10332 took 1.3037145137786865
[INFO: train.py:  558]: resist loss: tensor([ 5.3059], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2834608554840088
[INFO: train.py:  316]: Interation 10333 took 1.2838163375854492
[INFO: train.py:  558]: resist loss: tensor([ 2.6722], device='cuda:0')
[INFO: train.py:  310]: g step took 1.627086877822876
[INFO: train.py:  316]: Interation 10334 took 1.6274738311767578
[INFO: train.py:  558]: resist loss: tensor([ 9.2813], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7503390312194824
[INFO: train.py:  316]: Interation 10335 took 1.7507603168487549
[INFO: train.py:  558]: resist loss: tensor([ 6.1959], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4448115825653076
[INFO: train.py:  316]: Interation 10336 took 1.4452235698699951
[INFO: train.py:  558]: resist loss: tensor([ 10.0949], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4535744190216064
[INFO: train.py:  316]: Interation 10337 took 1.4539589881896973
[INFO: train.py:  558]: resist loss: tensor([ 1.4476], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4399445056915283
[INFO: train.py:  316]: Interation 10338 took 1.4537677764892578
[INFO: train.py:  558]: resist loss: tensor([ 9.3727], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7176117897033691
[INFO: train.py:  316]: Interation 10339 took 1.7180204391479492
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 606, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 606, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 618, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 618, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 716, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 716, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 549, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 549, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 566, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 566, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 494, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 494, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 601, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 601, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 487, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 487, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 548, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 548, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 573, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 573, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 501, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 501, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 102, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 102, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 789, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 789, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 734, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 734, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 1010, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 1010, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 722, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 722, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 698, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 698, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 813, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 813, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 783, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 783, 2])
[INFO: train.py:  338]:   [val] ade: 0.601
[INFO: train.py:  338]:   [val] ade_l: 1.323
[INFO: train.py:  338]:   [val] ade_nl: 1.101
[INFO: train.py:  338]:   [val] d_loss: 1.414
[INFO: train.py:  338]:   [val] fde: 1.260
[INFO: train.py:  338]:   [val] fde_l: 2.775
[INFO: train.py:  338]:   [val] fde_nl: 2.309
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.443
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.443
[INFO: train.py:  338]:   [val] resist_count: 2619.000
[INFO: train.py:  338]:   [val] resist_loss: 0.273
[INFO: train.py:  341]:   [train] ade: 0.611
[INFO: train.py:  341]:   [train] ade_l: 1.246
[INFO: train.py:  341]:   [train] ade_nl: 1.198
[INFO: train.py:  341]:   [train] d_loss: 1.404
[INFO: train.py:  341]:   [train] fde: 1.197
[INFO: train.py:  341]:   [train] fde_l: 2.442
[INFO: train.py:  341]:   [train] fde_nl: 2.348
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.405
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.405
[INFO: train.py:  341]:   [train] resist_count: 2627.000
[INFO: train.py:  341]:   [train] resist_loss: 0.143
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 8.5789], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3789937496185303
[INFO: train.py:  316]: Interation 10340 took 7.782803535461426
[INFO: train.py:  558]: resist loss: tensor([ 1.9694], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4287526607513428
[INFO: train.py:  316]: Interation 10341 took 1.429168939590454
[INFO: train.py:  558]: resist loss: tensor([ 0.7624], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3655247688293457
[INFO: train.py:  316]: Interation 10342 took 1.365980625152588
[INFO: train.py:  558]: resist loss: tensor([ 1.5072], device='cuda:0')
[INFO: train.py:  310]: g step took 1.567781686782837
[INFO: train.py:  316]: Interation 10343 took 1.5682170391082764
[INFO: train.py:  558]: resist loss: tensor([ 18.0395], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6658422946929932
[INFO: train.py:  316]: Interation 10344 took 1.666443109512329
[INFO: train.py:  558]: resist loss: tensor([ 0.6728], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5048024654388428
[INFO: train.py:  316]: Interation 10345 took 1.5052666664123535
[INFO: train.py:  558]: resist loss: tensor([ 4.3794], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6464240550994873
[INFO: train.py:  316]: Interation 10346 took 1.6507785320281982
[INFO: train.py:  558]: resist loss: tensor([ 4.7299], device='cuda:0')
[INFO: train.py:  310]: g step took 1.1004273891448975
[INFO: train.py:  316]: Interation 10347 took 1.1049144268035889
[INFO: train.py:  558]: resist loss: tensor([ 7.7090], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2956185340881348
[INFO: train.py:  316]: Interation 10348 took 1.3000030517578125
[INFO: train.py:  558]: resist loss: tensor([ 5.0004], device='cuda:0')
[INFO: train.py:  310]: g step took 1.356757640838623
[INFO: train.py:  316]: Interation 10349 took 1.3609671592712402
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 525, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 525, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 701, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 701, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 610, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 610, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 563, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 563, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 592, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 592, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 457, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 457, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 651, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 651, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 463, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 463, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 520, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 520, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 621, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 621, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 516, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 516, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 142, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 142, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 692, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 692, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 908, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 908, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 779, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 779, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 865, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 865, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 718, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 718, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 839, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 839, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 721, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 721, 2])
[INFO: train.py:  338]:   [val] ade: 0.583
[INFO: train.py:  338]:   [val] ade_l: 1.285
[INFO: train.py:  338]:   [val] ade_nl: 1.069
[INFO: train.py:  338]:   [val] d_loss: 1.404
[INFO: train.py:  338]:   [val] fde: 1.175
[INFO: train.py:  338]:   [val] fde_l: 2.586
[INFO: train.py:  338]:   [val] fde_nl: 2.152
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.405
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.405
[INFO: train.py:  338]:   [val] resist_count: 2873.000
[INFO: train.py:  338]:   [val] resist_loss: 0.340
[INFO: train.py:  341]:   [train] ade: 0.594
[INFO: train.py:  341]:   [train] ade_l: 1.234
[INFO: train.py:  341]:   [train] ade_nl: 1.147
[INFO: train.py:  341]:   [train] d_loss: 1.402
[INFO: train.py:  341]:   [train] fde: 1.119
[INFO: train.py:  341]:   [train] fde_l: 2.322
[INFO: train.py:  341]:   [train] fde_nl: 2.160
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.358
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.358
[INFO: train.py:  341]:   [train] resist_count: 3004.000
[INFO: train.py:  341]:   [train] resist_loss: 0.198
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 5.2685], device='cuda:0')
[INFO: train.py:  310]: g step took 1.413217544555664
[INFO: train.py:  316]: Interation 10350 took 7.8380653858184814
[INFO: train.py:  558]: resist loss: tensor([ 7.5965], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2975857257843018
[INFO: train.py:  316]: Interation 10351 took 1.3020853996276855
[INFO: train.py:  558]: resist loss: tensor([ 7.3274], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5742309093475342
[INFO: train.py:  316]: Interation 10352 took 1.578721046447754
[INFO: train.py:  558]: resist loss: tensor([ 0.7387], device='cuda:0')
[INFO: train.py:  310]: g step took 1.464249610900879
[INFO: train.py:  316]: Interation 10353 took 1.4682416915893555
[INFO: train.py:  558]: resist loss: tensor([ 0.5768], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5748414993286133
[INFO: train.py:  316]: Interation 10354 took 1.5789434909820557
[INFO: train.py:  558]: resist loss: tensor([ 7.0734], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4528224468231201
[INFO: train.py:  316]: Interation 10355 took 1.45711088180542
[INFO: train.py:  558]: resist loss: tensor([ 0.8281], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3032844066619873
[INFO: train.py:  316]: Interation 10356 took 1.3072412014007568
[INFO: train.py:  558]: resist loss: tensor([ 16.2343], device='cuda:0')
[INFO: train.py:  310]: g step took 1.545849323272705
[INFO: train.py:  316]: Interation 10357 took 1.5502018928527832
[INFO: train.py:  558]: resist loss: tensor([ 0.2279], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3939342498779297
[INFO: train.py:  316]: Interation 10358 took 1.398616075515747
[INFO: train.py:  558]: resist loss: tensor([ 0.6295], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3771631717681885
[INFO: train.py:  316]: Interation 10359 took 1.381181240081787
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 488, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 488, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 470, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 470, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 557, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 557, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 577, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 577, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 530, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 530, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 656, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 656, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 567, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 567, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 557, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 557, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 627, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 627, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 584, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 584, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 595, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 595, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 153, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 153, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 803, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 803, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 775, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 775, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 670, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 670, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 759, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 759, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 720, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 720, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 759, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 759, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 826, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 826, 2])
[INFO: train.py:  338]:   [val] ade: 0.581
[INFO: train.py:  338]:   [val] ade_l: 1.280
[INFO: train.py:  338]:   [val] ade_nl: 1.065
[INFO: train.py:  338]:   [val] d_loss: 1.417
[INFO: train.py:  338]:   [val] fde: 1.222
[INFO: train.py:  338]:   [val] fde_l: 2.691
[INFO: train.py:  338]:   [val] fde_nl: 2.239
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.417
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.417
[INFO: train.py:  338]:   [val] resist_count: 2981.000
[INFO: train.py:  338]:   [val] resist_loss: 0.321
[INFO: train.py:  341]:   [train] ade: 0.556
[INFO: train.py:  341]:   [train] ade_l: 1.166
[INFO: train.py:  341]:   [train] ade_nl: 1.065
[INFO: train.py:  341]:   [train] d_loss: 1.413
[INFO: train.py:  341]:   [train] fde: 1.112
[INFO: train.py:  341]:   [train] fde_l: 2.330
[INFO: train.py:  341]:   [train] fde_nl: 2.127
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.340
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.340
[INFO: train.py:  341]:   [train] resist_count: 2604.000
[INFO: train.py:  341]:   [train] resist_loss: 0.190
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 5.6404], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5966403484344482
[INFO: train.py:  316]: Interation 10360 took 7.960566520690918
[INFO: train.py:  558]: resist loss: tensor([ 6.0313], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4145395755767822
[INFO: train.py:  316]: Interation 10361 took 1.4184141159057617
[INFO: train.py:  558]: resist loss: tensor([ 4.9535], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4551689624786377
[INFO: train.py:  316]: Interation 10362 took 1.4591772556304932
[INFO: train.py:  558]: resist loss: tensor([ 9.9425], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4284169673919678
[INFO: train.py:  316]: Interation 10363 took 1.4324207305908203
[INFO: train.py:  558]: resist loss: tensor([ 1.5123], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6154122352600098
[INFO: train.py:  316]: Interation 10364 took 1.619943380355835
[INFO: train.py:  558]: resist loss: tensor([ 2.3420], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2397222518920898
[INFO: train.py:  316]: Interation 10365 took 1.2436435222625732
[INFO: train.py:  558]: resist loss: tensor([ 3.4094], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6186985969543457
[INFO: train.py:  316]: Interation 10366 took 1.6227355003356934
[INFO: train.py:  558]: resist loss: tensor([ 1.6816], device='cuda:0')
[INFO: train.py:  310]: g step took 1.36753511428833
[INFO: train.py:  316]: Interation 10367 took 1.371765375137329
[INFO: train.py:  558]: resist loss: tensor([ 8.0695], device='cuda:0')
[INFO: train.py:  310]: g step took 1.605111837387085
[INFO: train.py:  316]: Interation 10368 took 1.6094648838043213
[INFO: train.py:  558]: resist loss: tensor([ 0.1734], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2403056621551514
[INFO: train.py:  316]: Interation 10369 took 1.2446954250335693
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 598, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 598, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 625, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 625, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 518, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 518, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 541, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 541, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 555, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 555, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 554, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 554, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 453, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 453, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 634, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 634, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 665, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 665, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 576, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 576, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 474, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 474, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 168, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 168, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 845, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 845, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 703, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 703, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 813, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 813, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 797, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 797, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 752, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 752, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 788, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 788, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 882, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 882, 2])
[INFO: train.py:  338]:   [val] ade: 0.575
[INFO: train.py:  338]:   [val] ade_l: 1.266
[INFO: train.py:  338]:   [val] ade_nl: 1.053
[INFO: train.py:  338]:   [val] d_loss: 1.412
[INFO: train.py:  338]:   [val] fde: 1.226
[INFO: train.py:  338]:   [val] fde_l: 2.699
[INFO: train.py:  338]:   [val] fde_nl: 2.246
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.414
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.414
[INFO: train.py:  338]:   [val] resist_count: 2801.000
[INFO: train.py:  338]:   [val] resist_loss: 0.281
[INFO: train.py:  341]:   [train] ade: 0.577
[INFO: train.py:  341]:   [train] ade_l: 1.247
[INFO: train.py:  341]:   [train] ade_nl: 1.075
[INFO: train.py:  341]:   [train] d_loss: 1.396
[INFO: train.py:  341]:   [train] fde: 1.163
[INFO: train.py:  341]:   [train] fde_l: 2.512
[INFO: train.py:  341]:   [train] fde_nl: 2.165
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.364
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.364
[INFO: train.py:  341]:   [train] resist_count: 2932.000
[INFO: train.py:  341]:   [train] resist_loss: 0.173
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 6.9155], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2338879108428955
[INFO: train.py:  316]: Interation 10370 took 7.757218360900879
[INFO: train.py:  558]: resist loss: tensor([ 8.3119], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3521485328674316
[INFO: train.py:  316]: Interation 10371 took 1.3554198741912842
[INFO: train.py:  558]: resist loss: tensor([ 0.], device='cuda:0')
[INFO: train.py:  310]: g step took 0.09529614448547363
[INFO: train.py:  316]: Interation 10372 took 0.09859132766723633
[INFO: train.py:  279]: Starting epoch 243
[INFO: train.py:  280]: Epoch resist loss: tensor([ 214.3435])
[INFO: train.py:  558]: resist loss: tensor([ 1.8556], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4980144500732422
[INFO: train.py:  316]: Interation 10373 took 1.937898874282837
[INFO: train.py:  558]: resist loss: tensor([ 1.0796], device='cuda:0')
[INFO: train.py:  310]: g step took 1.50919508934021
[INFO: train.py:  316]: Interation 10374 took 1.509666919708252
[INFO: train.py:  558]: resist loss: tensor([ 1.9705], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3420653343200684
[INFO: train.py:  316]: Interation 10375 took 1.342529058456421
[INFO: train.py:  558]: resist loss: tensor([ 0.9661], device='cuda:0')
[INFO: train.py:  310]: g step took 1.1968986988067627
[INFO: train.py:  316]: Interation 10376 took 1.2014265060424805
[INFO: train.py:  558]: resist loss: tensor([ 1.0657], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4732584953308105
[INFO: train.py:  316]: Interation 10377 took 1.477950096130371
[INFO: train.py:  558]: resist loss: tensor([ 1.9281], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5600519180297852
[INFO: train.py:  316]: Interation 10378 took 1.560462474822998
[INFO: train.py:  558]: resist loss: tensor([ 14.6989], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5549471378326416
[INFO: train.py:  316]: Interation 10379 took 1.5554215908050537
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 610, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 610, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 539, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 539, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 463, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 463, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 525, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 525, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 726, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 726, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 554, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 554, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 468, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 468, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 496, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 496, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 639, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 639, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 642, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 642, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 519, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 519, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 180, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 180, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 744, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 744, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 935, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 935, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 690, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 690, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 710, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 710, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 844, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 844, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 866, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 866, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 891, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 891, 2])
[INFO: train.py:  338]:   [val] ade: 0.625
[INFO: train.py:  338]:   [val] ade_l: 1.375
[INFO: train.py:  338]:   [val] ade_nl: 1.144
[INFO: train.py:  338]:   [val] d_loss: 1.416
[INFO: train.py:  338]:   [val] fde: 1.332
[INFO: train.py:  338]:   [val] fde_l: 2.933
[INFO: train.py:  338]:   [val] fde_nl: 2.440
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.472
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.472
[INFO: train.py:  338]:   [val] resist_count: 2761.000
[INFO: train.py:  338]:   [val] resist_loss: 0.255
[INFO: train.py:  341]:   [train] ade: 0.598
[INFO: train.py:  341]:   [train] ade_l: 1.230
[INFO: train.py:  341]:   [train] ade_nl: 1.164
[INFO: train.py:  341]:   [train] d_loss: 1.411
[INFO: train.py:  341]:   [train] fde: 1.207
[INFO: train.py:  341]:   [train] fde_l: 2.482
[INFO: train.py:  341]:   [train] fde_nl: 2.349
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.390
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.390
[INFO: train.py:  341]:   [train] resist_count: 2811.000
[INFO: train.py:  341]:   [train] resist_loss: 0.165
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 1.1671], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5104243755340576
[INFO: train.py:  316]: Interation 10380 took 7.958070516586304
[INFO: train.py:  558]: resist loss: tensor([ 0.6362], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4826478958129883
[INFO: train.py:  316]: Interation 10381 took 1.5188274383544922
[INFO: train.py:  558]: resist loss: tensor([ 0.7762], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8677520751953125
[INFO: train.py:  316]: Interation 10382 took 1.8681302070617676
[INFO: train.py:  558]: resist loss: tensor([ 1.7099], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5448806285858154
[INFO: train.py:  316]: Interation 10383 took 1.545273780822754
[INFO: train.py:  558]: resist loss: tensor([ 1.4248], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8472280502319336
[INFO: train.py:  316]: Interation 10384 took 1.8476650714874268
[INFO: train.py:  558]: resist loss: tensor([ 0.5821], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6027131080627441
[INFO: train.py:  316]: Interation 10385 took 1.603179693222046
[INFO: train.py:  558]: resist loss: tensor([ 1.7272], device='cuda:0')
[INFO: train.py:  310]: g step took 1.9074490070343018
[INFO: train.py:  316]: Interation 10386 took 1.9080655574798584
[INFO: train.py:  558]: resist loss: tensor([ 9.6985], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8041517734527588
[INFO: train.py:  316]: Interation 10387 took 1.8046224117279053
[INFO: train.py:  558]: resist loss: tensor([ 0.3431], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6423048973083496
[INFO: train.py:  316]: Interation 10388 took 1.6427130699157715
[INFO: train.py:  558]: resist loss: tensor([ 0.6719], device='cuda:0')
[INFO: train.py:  310]: g step took 1.866222858428955
[INFO: train.py:  316]: Interation 10389 took 1.870424509048462
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 501, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 501, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 584, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 584, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 608, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 608, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 464, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 464, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 599, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 599, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 669, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 669, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 563, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 563, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 517, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 517, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 519, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 519, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 610, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 610, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 617, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 617, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 110, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 110, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 755, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 755, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 904, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 904, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 957, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 957, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 743, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 743, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 774, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 774, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 746, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 746, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 734, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 734, 2])
[INFO: train.py:  338]:   [val] ade: 0.657
[INFO: train.py:  338]:   [val] ade_l: 1.446
[INFO: train.py:  338]:   [val] ade_nl: 1.203
[INFO: train.py:  338]:   [val] d_loss: 1.407
[INFO: train.py:  338]:   [val] fde: 1.416
[INFO: train.py:  338]:   [val] fde_l: 3.117
[INFO: train.py:  338]:   [val] fde_nl: 2.594
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.509
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.509
[INFO: train.py:  338]:   [val] resist_count: 3120.000
[INFO: train.py:  338]:   [val] resist_loss: 0.272
[INFO: train.py:  341]:   [train] ade: 0.670
[INFO: train.py:  341]:   [train] ade_l: 1.375
[INFO: train.py:  341]:   [train] ade_nl: 1.306
[INFO: train.py:  341]:   [train] d_loss: 1.410
[INFO: train.py:  341]:   [train] fde: 1.356
[INFO: train.py:  341]:   [train] fde_l: 2.783
[INFO: train.py:  341]:   [train] fde_nl: 2.643
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.462
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.462
[INFO: train.py:  341]:   [train] resist_count: 3157.000
[INFO: train.py:  341]:   [train] resist_loss: 0.140
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.6455], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3876240253448486
[INFO: train.py:  316]: Interation 10390 took 7.830151796340942
[INFO: train.py:  558]: resist loss: tensor([ 7.9103], device='cuda:0')
[INFO: train.py:  310]: g step took 1.471721887588501
[INFO: train.py:  316]: Interation 10391 took 1.4756956100463867
[INFO: train.py:  558]: resist loss: tensor([ 8.1477], device='cuda:0')
[INFO: train.py:  310]: g step took 1.1570861339569092
[INFO: train.py:  316]: Interation 10392 took 1.1611676216125488
[INFO: train.py:  558]: resist loss: tensor([ 1.3410], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3679563999176025
[INFO: train.py:  316]: Interation 10393 took 1.3723976612091064
[INFO: train.py:  558]: resist loss: tensor([ 1.9674], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3493595123291016
[INFO: train.py:  316]: Interation 10394 took 1.3537423610687256
[INFO: train.py:  558]: resist loss: tensor([ 2.8754], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6652076244354248
[INFO: train.py:  316]: Interation 10395 took 1.669337272644043
[INFO: train.py:  558]: resist loss: tensor([ 0.5592], device='cuda:0')
[INFO: train.py:  310]: g step took 1.253612995147705
[INFO: train.py:  316]: Interation 10396 took 1.257802963256836
[INFO: train.py:  558]: resist loss: tensor([ 0.7351], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4352121353149414
[INFO: train.py:  316]: Interation 10397 took 1.4388577938079834
[INFO: train.py:  558]: resist loss: tensor([ 6.1300], device='cuda:0')
[INFO: train.py:  310]: g step took 1.683365821838379
[INFO: train.py:  316]: Interation 10398 took 1.6879332065582275
[INFO: train.py:  558]: resist loss: tensor([ 1.1042], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3745274543762207
[INFO: train.py:  316]: Interation 10399 took 1.3789498805999756
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 602, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 602, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 694, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 694, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 586, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 586, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 544, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 544, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 660, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 660, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 540, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 540, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 426, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 426, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 576, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 576, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 487, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 487, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 585, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 585, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 567, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 567, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 94, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 94, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 796, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 796, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 758, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 758, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 648, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 648, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 743, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 743, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 759, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 759, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 986, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 986, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 786, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 786, 2])
[INFO: train.py:  338]:   [val] ade: 0.588
[INFO: train.py:  338]:   [val] ade_l: 1.295
[INFO: train.py:  338]:   [val] ade_nl: 1.077
[INFO: train.py:  338]:   [val] d_loss: 1.411
[INFO: train.py:  338]:   [val] fde: 1.217
[INFO: train.py:  338]:   [val] fde_l: 2.680
[INFO: train.py:  338]:   [val] fde_nl: 2.230
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.415
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.415
[INFO: train.py:  338]:   [val] resist_count: 2869.000
[INFO: train.py:  338]:   [val] resist_loss: 0.309
[INFO: train.py:  341]:   [train] ade: 0.581
[INFO: train.py:  341]:   [train] ade_l: 1.223
[INFO: train.py:  341]:   [train] ade_nl: 1.106
[INFO: train.py:  341]:   [train] d_loss: 1.405
[INFO: train.py:  341]:   [train] fde: 1.115
[INFO: train.py:  341]:   [train] fde_l: 2.347
[INFO: train.py:  341]:   [train] fde_nl: 2.123
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.355
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.355
[INFO: train.py:  341]:   [train] resist_count: 2799.000
[INFO: train.py:  341]:   [train] resist_loss: 0.167
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.3065], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2953073978424072
[INFO: train.py:  316]: Interation 10400 took 7.596153497695923
[INFO: train.py:  558]: resist loss: tensor([ 0.7947], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2891623973846436
[INFO: train.py:  316]: Interation 10401 took 1.2931466102600098
[INFO: train.py:  558]: resist loss: tensor([ 4.0783], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4954049587249756
[INFO: train.py:  316]: Interation 10402 took 1.49979567527771
[INFO: train.py:  558]: resist loss: tensor([ 8.2549], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4593360424041748
[INFO: train.py:  316]: Interation 10403 took 1.463740587234497
[INFO: train.py:  558]: resist loss: tensor([ 12.0495], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4921367168426514
[INFO: train.py:  316]: Interation 10404 took 1.4964768886566162
[INFO: train.py:  558]: resist loss: tensor([ 1.8830], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3228340148925781
[INFO: train.py:  316]: Interation 10405 took 1.3263530731201172
[INFO: train.py:  558]: resist loss: tensor([ 9.7775], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3758435249328613
[INFO: train.py:  316]: Interation 10406 took 1.3802154064178467
[INFO: train.py:  558]: resist loss: tensor([ 4.1239], device='cuda:0')
[INFO: train.py:  310]: g step took 1.374009609222412
[INFO: train.py:  316]: Interation 10407 took 1.3784220218658447
[INFO: train.py:  558]: resist loss: tensor(1.00000e-02 *
       [ 5.9404], device='cuda:0')
[INFO: train.py:  310]: g step took 1.265333890914917
[INFO: train.py:  316]: Interation 10408 took 1.2697186470031738
[INFO: train.py:  558]: resist loss: tensor([ 0.5614], device='cuda:0')
[INFO: train.py:  310]: g step took 1.171736240386963
[INFO: train.py:  316]: Interation 10409 took 1.1754472255706787
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 541, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 541, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 509, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 509, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 438, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 438, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 628, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 628, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 575, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 575, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 597, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 597, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 677, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 677, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 663, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 663, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 526, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 526, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 544, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 544, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 496, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 496, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 167, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 167, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 739, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 739, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 1031, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 1031, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 799, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 799, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 826, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 826, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 757, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 757, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 767, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 767, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 801, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 801, 2])
[INFO: train.py:  338]:   [val] ade: 0.633
[INFO: train.py:  338]:   [val] ade_l: 1.394
[INFO: train.py:  338]:   [val] ade_nl: 1.160
[INFO: train.py:  338]:   [val] d_loss: 1.411
[INFO: train.py:  338]:   [val] fde: 1.218
[INFO: train.py:  338]:   [val] fde_l: 2.682
[INFO: train.py:  338]:   [val] fde_nl: 2.232
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.439
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.439
[INFO: train.py:  338]:   [val] resist_count: 3335.000
[INFO: train.py:  338]:   [val] resist_loss: 0.385
[INFO: train.py:  341]:   [train] ade: 0.629
[INFO: train.py:  341]:   [train] ade_l: 1.302
[INFO: train.py:  341]:   [train] ade_nl: 1.218
[INFO: train.py:  341]:   [train] d_loss: 1.392
[INFO: train.py:  341]:   [train] fde: 1.123
[INFO: train.py:  341]:   [train] fde_l: 2.324
[INFO: train.py:  341]:   [train] fde_nl: 2.174
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.377
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.377
[INFO: train.py:  341]:   [train] resist_count: 3613.000
[INFO: train.py:  341]:   [train] resist_loss: 0.241
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 15.0621], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5723252296447754
[INFO: train.py:  316]: Interation 10410 took 8.096674680709839
[INFO: train.py:  558]: resist loss: tensor([ 6.7948], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3214004039764404
[INFO: train.py:  316]: Interation 10411 took 1.3257830142974854
[INFO: train.py:  558]: resist loss: tensor([ 1.2838], device='cuda:0')
[INFO: train.py:  310]: g step took 1.433502435684204
[INFO: train.py:  316]: Interation 10412 took 1.438075065612793
[INFO: train.py:  558]: resist loss: tensor([ 7.2323], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4899320602416992
[INFO: train.py:  316]: Interation 10413 took 1.4935064315795898
[INFO: train.py:  558]: resist loss: tensor([ 0.7304], device='cuda:0')
[INFO: train.py:  310]: g step took 1.249645471572876
[INFO: train.py:  316]: Interation 10414 took 1.2534942626953125
[INFO: train.py:  558]: resist loss: tensor([ 0.1068], device='cuda:0')
[INFO: train.py:  310]: g step took 0.11600303649902344
[INFO: train.py:  316]: Interation 10415 took 0.11991143226623535
[INFO: train.py:  279]: Starting epoch 244
[INFO: train.py:  280]: Epoch resist loss: tensor([ 146.8166])
[INFO: train.py:  558]: resist loss: tensor([ 4.3054], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3566441535949707
[INFO: train.py:  316]: Interation 10416 took 1.8113596439361572
[INFO: train.py:  558]: resist loss: tensor([ 0.6177], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5720343589782715
[INFO: train.py:  316]: Interation 10417 took 1.5756523609161377
[INFO: train.py:  558]: resist loss: tensor([ 2.2639], device='cuda:0')
[INFO: train.py:  310]: g step took 1.205528974533081
[INFO: train.py:  316]: Interation 10418 took 1.2135071754455566
[INFO: train.py:  558]: resist loss: tensor([ 10.4034], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3238945007324219
[INFO: train.py:  316]: Interation 10419 took 1.3242874145507812
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 541, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 541, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 462, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 462, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 635, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 635, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 483, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 483, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 574, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 574, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 615, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 615, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 677, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 677, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 597, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 597, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 360, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 360, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 543, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 543, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 739, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 739, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 135, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 135, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 739, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 739, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 1020, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 1020, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 579, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 579, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 684, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 684, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 729, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 729, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 771, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 771, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 880, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 880, 2])
[INFO: train.py:  338]:   [val] ade: 0.629
[INFO: train.py:  338]:   [val] ade_l: 1.384
[INFO: train.py:  338]:   [val] ade_nl: 1.152
[INFO: train.py:  338]:   [val] d_loss: 1.415
[INFO: train.py:  338]:   [val] fde: 1.264
[INFO: train.py:  338]:   [val] fde_l: 2.783
[INFO: train.py:  338]:   [val] fde_nl: 2.315
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.448
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.448
[INFO: train.py:  338]:   [val] resist_count: 2978.000
[INFO: train.py:  338]:   [val] resist_loss: 0.353
[INFO: train.py:  341]:   [train] ade: 0.621
[INFO: train.py:  341]:   [train] ade_l: 1.332
[INFO: train.py:  341]:   [train] ade_nl: 1.165
[INFO: train.py:  341]:   [train] d_loss: 1.409
[INFO: train.py:  341]:   [train] fde: 1.168
[INFO: train.py:  341]:   [train] fde_l: 2.503
[INFO: train.py:  341]:   [train] fde_nl: 2.190
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.394
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.394
[INFO: train.py:  341]:   [train] resist_count: 2709.000
[INFO: train.py:  341]:   [train] resist_loss: 0.191
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 1.9182], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4402947425842285
[INFO: train.py:  316]: Interation 10420 took 7.851937532424927
[INFO: train.py:  558]: resist loss: tensor([ 10.2380], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5084853172302246
[INFO: train.py:  316]: Interation 10421 took 1.5088756084442139
[INFO: train.py:  558]: resist loss: tensor([ 4.8416], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5753452777862549
[INFO: train.py:  316]: Interation 10422 took 1.575758457183838
[INFO: train.py:  558]: resist loss: tensor([ 1.4687], device='cuda:0')
[INFO: train.py:  310]: g step took 1.622528314590454
[INFO: train.py:  316]: Interation 10423 took 1.6270768642425537
[INFO: train.py:  558]: resist loss: tensor([ 0.6554], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6550426483154297
[INFO: train.py:  316]: Interation 10424 took 1.6720945835113525
[INFO: train.py:  558]: resist loss: tensor([ 0.8267], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3342702388763428
[INFO: train.py:  316]: Interation 10425 took 1.3386216163635254
[INFO: train.py:  558]: resist loss: tensor([ 4.9855], device='cuda:0')
[INFO: train.py:  310]: g step took 1.377563238143921
[INFO: train.py:  316]: Interation 10426 took 1.3817076683044434
[INFO: train.py:  558]: resist loss: tensor([ 19.9635], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5742740631103516
[INFO: train.py:  316]: Interation 10427 took 1.5746574401855469
[INFO: train.py:  558]: resist loss: tensor([ 2.3722], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3377900123596191
[INFO: train.py:  316]: Interation 10428 took 1.3382105827331543
[INFO: train.py:  558]: resist loss: tensor([ 7.4896], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3789446353912354
[INFO: train.py:  316]: Interation 10429 took 1.3793537616729736
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 541, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 541, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 480, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 480, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 626, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 626, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 576, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 576, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 790, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 790, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 546, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 546, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 507, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 507, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 593, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 593, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 603, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 603, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 436, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 436, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 558, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 558, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 105, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 105, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 660, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 660, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 686, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 686, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 648, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 648, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 678, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 678, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 867, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 867, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 980, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 980, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 749, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 749, 2])
[INFO: train.py:  338]:   [val] ade: 0.628
[INFO: train.py:  338]:   [val] ade_l: 1.383
[INFO: train.py:  338]:   [val] ade_nl: 1.151
[INFO: train.py:  338]:   [val] d_loss: 1.398
[INFO: train.py:  338]:   [val] fde: 1.353
[INFO: train.py:  338]:   [val] fde_l: 2.978
[INFO: train.py:  338]:   [val] fde_nl: 2.478
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.470
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.470
[INFO: train.py:  338]:   [val] resist_count: 2797.000
[INFO: train.py:  338]:   [val] resist_loss: 0.261
[INFO: train.py:  341]:   [train] ade: 0.625
[INFO: train.py:  341]:   [train] ade_l: 1.305
[INFO: train.py:  341]:   [train] ade_nl: 1.199
[INFO: train.py:  341]:   [train] d_loss: 1.402
[INFO: train.py:  341]:   [train] fde: 1.273
[INFO: train.py:  341]:   [train] fde_l: 2.659
[INFO: train.py:  341]:   [train] fde_nl: 2.444
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.430
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.430
[INFO: train.py:  341]:   [train] resist_count: 2328.000
[INFO: train.py:  341]:   [train] resist_loss: 0.138
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 4.2526], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3237717151641846
[INFO: train.py:  316]: Interation 10430 took 7.678477048873901
[INFO: train.py:  558]: resist loss: tensor([ 2.7929], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5234696865081787
[INFO: train.py:  316]: Interation 10431 took 1.5278234481811523
[INFO: train.py:  558]: resist loss: tensor([ 0.2144], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4030766487121582
[INFO: train.py:  316]: Interation 10432 took 1.4075841903686523
[INFO: train.py:  558]: resist loss: tensor([ 0.4383], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2917134761810303
[INFO: train.py:  316]: Interation 10433 took 1.295581340789795
[INFO: train.py:  558]: resist loss: tensor([ 9.1613], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5135340690612793
[INFO: train.py:  316]: Interation 10434 took 1.5174334049224854
[INFO: train.py:  558]: resist loss: tensor([ 3.6175], device='cuda:0')
[INFO: train.py:  310]: g step took 1.1750950813293457
[INFO: train.py:  316]: Interation 10435 took 1.1790318489074707
[INFO: train.py:  558]: resist loss: tensor([ 3.4563], device='cuda:0')
[INFO: train.py:  310]: g step took 1.489673376083374
[INFO: train.py:  316]: Interation 10436 took 1.4928951263427734
[INFO: train.py:  558]: resist loss: tensor([ 1.1596], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3457603454589844
[INFO: train.py:  316]: Interation 10437 took 1.3494534492492676
[INFO: train.py:  558]: resist loss: tensor([ 3.2953], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4001271724700928
[INFO: train.py:  316]: Interation 10438 took 1.4042079448699951
[INFO: train.py:  558]: resist loss: tensor([ 0.5127], device='cuda:0')
[INFO: train.py:  310]: g step took 1.283945083618164
[INFO: train.py:  316]: Interation 10439 took 1.2880244255065918
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 505, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 505, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 533, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 533, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 571, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 571, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 528, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 528, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 684, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 684, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 554, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 554, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 552, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 552, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 614, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 614, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 522, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 522, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 544, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 544, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 634, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 634, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 120, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 120, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 701, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 701, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 912, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 912, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 625, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 625, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 763, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 763, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 921, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 921, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 729, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 729, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 696, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 696, 2])
[INFO: train.py:  338]:   [val] ade: 0.724
[INFO: train.py:  338]:   [val] ade_l: 1.593
[INFO: train.py:  338]:   [val] ade_nl: 1.326
[INFO: train.py:  338]:   [val] d_loss: 1.406
[INFO: train.py:  338]:   [val] fde: 1.543
[INFO: train.py:  338]:   [val] fde_l: 3.397
[INFO: train.py:  338]:   [val] fde_nl: 2.827
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.613
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.613
[INFO: train.py:  338]:   [val] resist_count: 2759.000
[INFO: train.py:  338]:   [val] resist_loss: 0.233
[INFO: train.py:  341]:   [train] ade: 0.715
[INFO: train.py:  341]:   [train] ade_l: 1.512
[INFO: train.py:  341]:   [train] ade_nl: 1.357
[INFO: train.py:  341]:   [train] d_loss: 1.395
[INFO: train.py:  341]:   [train] fde: 1.469
[INFO: train.py:  341]:   [train] fde_l: 3.106
[INFO: train.py:  341]:   [train] fde_nl: 2.787
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.552
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.552
[INFO: train.py:  341]:   [train] resist_count: 2649.000
[INFO: train.py:  341]:   [train] resist_loss: 0.138
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.5588], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3279407024383545
[INFO: train.py:  316]: Interation 10440 took 7.596790790557861
[INFO: train.py:  558]: resist loss: tensor([ 5.0057], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3045942783355713
[INFO: train.py:  316]: Interation 10441 took 1.3088629245758057
[INFO: train.py:  558]: resist loss: tensor([ 4.3411], device='cuda:0')
[INFO: train.py:  310]: g step took 1.217677116394043
[INFO: train.py:  316]: Interation 10442 took 1.2221918106079102
[INFO: train.py:  558]: resist loss: tensor([ 4.2143], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3661630153656006
[INFO: train.py:  316]: Interation 10443 took 1.3706679344177246
[INFO: train.py:  558]: resist loss: tensor([ 7.9926], device='cuda:0')
[INFO: train.py:  310]: g step took 1.7237164974212646
[INFO: train.py:  316]: Interation 10444 took 1.7272250652313232
[INFO: train.py:  558]: resist loss: tensor([ 1.3519], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2704544067382812
[INFO: train.py:  316]: Interation 10445 took 1.2737412452697754
[INFO: train.py:  558]: resist loss: tensor([ 9.4704], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3631987571716309
[INFO: train.py:  316]: Interation 10446 took 1.3673877716064453
[INFO: train.py:  558]: resist loss: tensor([ 3.2984], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3295502662658691
[INFO: train.py:  316]: Interation 10447 took 1.333613634109497
[INFO: train.py:  558]: resist loss: tensor([ 6.6597], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4341990947723389
[INFO: train.py:  316]: Interation 10448 took 1.4383227825164795
[INFO: train.py:  558]: resist loss: tensor([ 6.0583], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4508991241455078
[INFO: train.py:  316]: Interation 10449 took 1.4556560516357422
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 537, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 537, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 587, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 587, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 655, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 655, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 505, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 505, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 552, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 552, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 490, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 490, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 539, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 539, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 520, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 520, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 545, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 545, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 680, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 680, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 558, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 558, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 193, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 193, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 932, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 932, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 858, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 858, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 701, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 701, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 764, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 764, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 830, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 830, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 842, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 842, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 822, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 822, 2])
[INFO: train.py:  338]:   [val] ade: 0.619
[INFO: train.py:  338]:   [val] ade_l: 1.364
[INFO: train.py:  338]:   [val] ade_nl: 1.135
[INFO: train.py:  338]:   [val] d_loss: 1.398
[INFO: train.py:  338]:   [val] fde: 1.335
[INFO: train.py:  338]:   [val] fde_l: 2.940
[INFO: train.py:  338]:   [val] fde_nl: 2.446
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.462
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.462
[INFO: train.py:  338]:   [val] resist_count: 2660.000
[INFO: train.py:  338]:   [val] resist_loss: 0.231
[INFO: train.py:  341]:   [train] ade: 0.633
[INFO: train.py:  341]:   [train] ade_l: 1.311
[INFO: train.py:  341]:   [train] ade_nl: 1.222
[INFO: train.py:  341]:   [train] d_loss: 1.394
[INFO: train.py:  341]:   [train] fde: 1.278
[INFO: train.py:  341]:   [train] fde_l: 2.650
[INFO: train.py:  341]:   [train] fde_nl: 2.470
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.425
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.425
[INFO: train.py:  341]:   [train] resist_count: 2585.000
[INFO: train.py:  341]:   [train] resist_loss: 0.127
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.8779], device='cuda:0')
[INFO: train.py:  310]: g step took 1.599625587463379
[INFO: train.py:  316]: Interation 10450 took 8.141677856445312
[INFO: train.py:  558]: resist loss: tensor([ 0.2890], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3106999397277832
[INFO: train.py:  316]: Interation 10451 took 1.3146469593048096
[INFO: train.py:  558]: resist loss: tensor([ 1.4999], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4220457077026367
[INFO: train.py:  316]: Interation 10452 took 1.4253311157226562
[INFO: train.py:  558]: resist loss: tensor([ 10.0330], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4195935726165771
[INFO: train.py:  316]: Interation 10453 took 1.4229753017425537
[INFO: train.py:  558]: resist loss: tensor([ 1.6627], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4474189281463623
[INFO: train.py:  316]: Interation 10454 took 1.451395034790039
[INFO: train.py:  558]: resist loss: tensor([ 3.9877], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2103800773620605
[INFO: train.py:  316]: Interation 10455 took 1.2148737907409668
[INFO: train.py:  558]: resist loss: tensor([ 8.8279], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6647205352783203
[INFO: train.py:  316]: Interation 10456 took 1.6685988903045654
[INFO: train.py:  558]: resist loss: tensor([ 2.4958], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3893730640411377
[INFO: train.py:  316]: Interation 10457 took 1.393784999847412
[INFO: train.py:  558]: resist loss: tensor([ 0.9421], device='cuda:0')
[INFO: train.py:  310]: g step took 0.20237326622009277
[INFO: train.py:  316]: Interation 10458 took 0.20657086372375488
[INFO: train.py:  279]: Starting epoch 245
[INFO: train.py:  280]: Epoch resist loss: tensor([ 180.8181])
[INFO: train.py:  558]: resist loss: tensor([ 0.6218], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4946954250335693
[INFO: train.py:  316]: Interation 10459 took 1.951127290725708
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 491, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 491, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 592, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 592, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 495, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 495, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 639, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 639, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 628, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 628, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 490, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 490, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 629, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 629, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 588, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 588, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 551, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 551, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 568, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 568, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 547, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 547, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 143, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 143, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 695, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 695, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 728, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 728, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 949, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 949, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 574, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 574, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 812, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 812, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 945, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 945, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 739, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 739, 2])
[INFO: train.py:  338]:   [val] ade: 0.644
[INFO: train.py:  338]:   [val] ade_l: 1.418
[INFO: train.py:  338]:   [val] ade_nl: 1.180
[INFO: train.py:  338]:   [val] d_loss: 1.418
[INFO: train.py:  338]:   [val] fde: 1.416
[INFO: train.py:  338]:   [val] fde_l: 3.117
[INFO: train.py:  338]:   [val] fde_nl: 2.594
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.518
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.518
[INFO: train.py:  338]:   [val] resist_count: 2770.000
[INFO: train.py:  338]:   [val] resist_loss: 0.260
[INFO: train.py:  341]:   [train] ade: 0.641
[INFO: train.py:  341]:   [train] ade_l: 1.350
[INFO: train.py:  341]:   [train] ade_nl: 1.220
[INFO: train.py:  341]:   [train] d_loss: 1.398
[INFO: train.py:  341]:   [train] fde: 1.342
[INFO: train.py:  341]:   [train] fde_l: 2.826
[INFO: train.py:  341]:   [train] fde_nl: 2.555
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.457
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.457
[INFO: train.py:  341]:   [train] resist_count: 2556.000
[INFO: train.py:  341]:   [train] resist_loss: 0.153
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 5.0997], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3285298347473145
[INFO: train.py:  316]: Interation 10460 took 7.6225426197052
[INFO: train.py:  558]: resist loss: tensor([ 0.6177], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4538166522979736
[INFO: train.py:  316]: Interation 10461 took 1.4616410732269287
[INFO: train.py:  558]: resist loss: tensor([ 3.2369], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4850060939788818
[INFO: train.py:  316]: Interation 10462 took 1.4853737354278564
[INFO: train.py:  558]: resist loss: tensor([ 0.4660], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2105436325073242
[INFO: train.py:  316]: Interation 10463 took 1.2109146118164062
[INFO: train.py:  558]: resist loss: tensor([ 12.3624], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5562012195587158
[INFO: train.py:  316]: Interation 10464 took 1.5565779209136963
[INFO: train.py:  558]: resist loss: tensor([ 7.4718], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4010133743286133
[INFO: train.py:  316]: Interation 10465 took 1.4013760089874268
[INFO: train.py:  558]: resist loss: tensor([ 3.9184], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3358745574951172
[INFO: train.py:  316]: Interation 10466 took 1.3362846374511719
[INFO: train.py:  558]: resist loss: tensor([ 1.5526], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3310620784759521
[INFO: train.py:  316]: Interation 10467 took 1.3520755767822266
[INFO: train.py:  558]: resist loss: tensor([ 2.1186], device='cuda:0')
[INFO: train.py:  310]: g step took 1.581679105758667
[INFO: train.py:  316]: Interation 10468 took 1.5820331573486328
[INFO: train.py:  558]: resist loss: tensor([ 9.5892], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3790626525878906
[INFO: train.py:  316]: Interation 10469 took 1.3868422508239746
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 612, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 612, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 534, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 534, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 566, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 566, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 521, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 521, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 717, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 717, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 556, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 556, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 510, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 510, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 501, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 501, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 597, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 597, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 551, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 551, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 563, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 563, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 133, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 133, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 1047, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 1047, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 791, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 791, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 949, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 949, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 818, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 818, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 766, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 766, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 519, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 519, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 586, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 586, 2])
[INFO: train.py:  338]:   [val] ade: 0.630
[INFO: train.py:  338]:   [val] ade_l: 1.387
[INFO: train.py:  338]:   [val] ade_nl: 1.154
[INFO: train.py:  338]:   [val] d_loss: 1.406
[INFO: train.py:  338]:   [val] fde: 1.361
[INFO: train.py:  338]:   [val] fde_l: 2.996
[INFO: train.py:  338]:   [val] fde_nl: 2.493
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.494
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.494
[INFO: train.py:  338]:   [val] resist_count: 2785.000
[INFO: train.py:  338]:   [val] resist_loss: 0.257
[INFO: train.py:  341]:   [train] ade: 0.630
[INFO: train.py:  341]:   [train] ade_l: 1.306
[INFO: train.py:  341]:   [train] ade_nl: 1.216
[INFO: train.py:  341]:   [train] d_loss: 1.404
[INFO: train.py:  341]:   [train] fde: 1.285
[INFO: train.py:  341]:   [train] fde_l: 2.665
[INFO: train.py:  341]:   [train] fde_nl: 2.480
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.451
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.451
[INFO: train.py:  341]:   [train] resist_count: 2656.000
[INFO: train.py:  341]:   [train] resist_loss: 0.154
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.5083], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2284560203552246
[INFO: train.py:  316]: Interation 10470 took 7.675118446350098
[INFO: train.py:  558]: resist loss: tensor([ 3.5509], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5977072715759277
[INFO: train.py:  316]: Interation 10471 took 1.5981109142303467
[INFO: train.py:  558]: resist loss: tensor([ 10.1908], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5976903438568115
[INFO: train.py:  316]: Interation 10472 took 1.5981364250183105
[INFO: train.py:  558]: resist loss: tensor([ 2.7368], device='cuda:0')
[INFO: train.py:  310]: g step took 1.291693925857544
[INFO: train.py:  316]: Interation 10473 took 1.292163372039795
[INFO: train.py:  558]: resist loss: tensor([ 1.8778], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4857828617095947
[INFO: train.py:  316]: Interation 10474 took 1.486192226409912
[INFO: train.py:  558]: resist loss: tensor([ 0.9706], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4130241870880127
[INFO: train.py:  316]: Interation 10475 took 1.4175965785980225
[INFO: train.py:  558]: resist loss: tensor([ 3.0641], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4423973560333252
[INFO: train.py:  316]: Interation 10476 took 1.4466938972473145
[INFO: train.py:  558]: resist loss: tensor([ 1.1911], device='cuda:0')
[INFO: train.py:  310]: g step took 1.1846911907196045
[INFO: train.py:  316]: Interation 10477 took 1.18937349319458
[INFO: train.py:  558]: resist loss: tensor([ 0.8366], device='cuda:0')
[INFO: train.py:  310]: g step took 1.1880035400390625
[INFO: train.py:  316]: Interation 10478 took 1.191680908203125
[INFO: train.py:  558]: resist loss: tensor([ 1.7713], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3804428577423096
[INFO: train.py:  316]: Interation 10479 took 1.384296178817749
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 538, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 538, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 589, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 589, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 625, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 625, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 566, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 566, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 454, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 454, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 601, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 601, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 554, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 554, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 592, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 592, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 594, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 594, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 537, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 537, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 594, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 594, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 117, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 117, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 714, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 714, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 788, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 788, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 865, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 865, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 893, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 893, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 942, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 942, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 714, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 714, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 792, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 792, 2])
[INFO: train.py:  338]:   [val] ade: 0.663
[INFO: train.py:  338]:   [val] ade_l: 1.459
[INFO: train.py:  338]:   [val] ade_nl: 1.214
[INFO: train.py:  338]:   [val] d_loss: 1.407
[INFO: train.py:  338]:   [val] fde: 1.417
[INFO: train.py:  338]:   [val] fde_l: 3.120
[INFO: train.py:  338]:   [val] fde_nl: 2.596
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.513
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.513
[INFO: train.py:  338]:   [val] resist_count: 3123.000
[INFO: train.py:  338]:   [val] resist_loss: 0.313
[INFO: train.py:  341]:   [train] ade: 0.654
[INFO: train.py:  341]:   [train] ade_l: 1.344
[INFO: train.py:  341]:   [train] ade_nl: 1.274
[INFO: train.py:  341]:   [train] d_loss: 1.414
[INFO: train.py:  341]:   [train] fde: 1.318
[INFO: train.py:  341]:   [train] fde_l: 2.708
[INFO: train.py:  341]:   [train] fde_nl: 2.568
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.451
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.451
[INFO: train.py:  341]:   [train] resist_count: 3327.000
[INFO: train.py:  341]:   [train] resist_loss: 0.198
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 1.0127], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3725576400756836
[INFO: train.py:  316]: Interation 10480 took 7.734037399291992
[INFO: train.py:  558]: resist loss: tensor([ 1.2185], device='cuda:0')
[INFO: train.py:  310]: g step took 1.350362777709961
[INFO: train.py:  316]: Interation 10481 took 1.3544363975524902
[INFO: train.py:  558]: resist loss: tensor([ 6.2711], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4178283214569092
[INFO: train.py:  316]: Interation 10482 took 1.4220681190490723
[INFO: train.py:  558]: resist loss: tensor([ 10.1986], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4397633075714111
[INFO: train.py:  316]: Interation 10483 took 1.4437384605407715
[INFO: train.py:  558]: resist loss: tensor([ 3.9247], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5721046924591064
[INFO: train.py:  316]: Interation 10484 took 1.576275110244751
[INFO: train.py:  558]: resist loss: tensor([ 10.5294], device='cuda:0')
[INFO: train.py:  310]: g step took 1.518921136856079
[INFO: train.py:  316]: Interation 10485 took 1.522947072982788
[INFO: train.py:  558]: resist loss: tensor([ 8.4358], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2163145542144775
[INFO: train.py:  316]: Interation 10486 took 1.2198824882507324
[INFO: train.py:  558]: resist loss: tensor([ 1.5739], device='cuda:0')
[INFO: train.py:  310]: g step took 1.387397050857544
[INFO: train.py:  316]: Interation 10487 took 1.3913569450378418
[INFO: train.py:  558]: resist loss: tensor([ 6.8775], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2396588325500488
[INFO: train.py:  316]: Interation 10488 took 1.2436864376068115
[INFO: train.py:  558]: resist loss: tensor([ 8.9748], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4133238792419434
[INFO: train.py:  316]: Interation 10489 took 1.4172642230987549
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 498, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 498, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 580, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 580, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 651, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 651, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 510, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 510, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 532, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 532, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 523, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 523, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 611, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 611, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 580, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 580, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 577, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 577, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 539, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 539, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 662, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 662, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 98, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 98, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 609, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 609, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 866, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 866, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 624, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 624, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 907, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 907, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 765, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 765, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 734, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 734, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 905, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 905, 2])
[INFO: train.py:  338]:   [val] ade: 0.632
[INFO: train.py:  338]:   [val] ade_l: 1.393
[INFO: train.py:  338]:   [val] ade_nl: 1.159
[INFO: train.py:  338]:   [val] d_loss: 1.393
[INFO: train.py:  338]:   [val] fde: 1.364
[INFO: train.py:  338]:   [val] fde_l: 3.002
[INFO: train.py:  338]:   [val] fde_nl: 2.498
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.483
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.483
[INFO: train.py:  338]:   [val] resist_count: 2810.000
[INFO: train.py:  338]:   [val] resist_loss: 0.261
[INFO: train.py:  341]:   [train] ade: 0.630
[INFO: train.py:  341]:   [train] ade_l: 1.289
[INFO: train.py:  341]:   [train] ade_nl: 1.232
[INFO: train.py:  341]:   [train] d_loss: 1.401
[INFO: train.py:  341]:   [train] fde: 1.276
[INFO: train.py:  341]:   [train] fde_l: 2.611
[INFO: train.py:  341]:   [train] fde_nl: 2.496
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.427
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.427
[INFO: train.py:  341]:   [train] resist_count: 2471.000
[INFO: train.py:  341]:   [train] resist_loss: 0.151
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 2.9515], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8699438571929932
[INFO: train.py:  316]: Interation 10490 took 8.260733366012573
[INFO: train.py:  558]: resist loss: tensor([ 2.3422], device='cuda:0')
[INFO: train.py:  310]: g step took 2.0958621501922607
[INFO: train.py:  316]: Interation 10491 took 2.0994372367858887
[INFO: train.py:  558]: resist loss: tensor([ 2.3912], device='cuda:0')
[INFO: train.py:  310]: g step took 1.463622808456421
[INFO: train.py:  316]: Interation 10492 took 1.4675309658050537
[INFO: train.py:  558]: resist loss: tensor([ 14.7962], device='cuda:0')
[INFO: train.py:  310]: g step took 1.927051305770874
[INFO: train.py:  316]: Interation 10493 took 1.9309971332550049
[INFO: train.py:  558]: resist loss: tensor([ 1.2630], device='cuda:0')
[INFO: train.py:  310]: g step took 1.8996295928955078
[INFO: train.py:  316]: Interation 10494 took 1.9031248092651367
[INFO: train.py:  558]: resist loss: tensor([ 1.7004], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4218380451202393
[INFO: train.py:  316]: Interation 10495 took 1.4257285594940186
[INFO: train.py:  558]: resist loss: tensor([ 1.4698], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6346862316131592
[INFO: train.py:  316]: Interation 10496 took 1.6385080814361572
[INFO: train.py:  558]: resist loss: tensor([ 0.3495], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4311392307281494
[INFO: train.py:  316]: Interation 10497 took 1.4350247383117676
[INFO: train.py:  558]: resist loss: tensor([ 0.7436], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2236175537109375
[INFO: train.py:  316]: Interation 10498 took 1.2274091243743896
[INFO: train.py:  558]: resist loss: tensor([ 0.7755], device='cuda:0')
[INFO: train.py:  310]: g step took 1.314460277557373
[INFO: train.py:  316]: Interation 10499 took 1.318603515625
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 694, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 694, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 589, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 589, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 717, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 717, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 585, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 585, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 448, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 448, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 536, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 536, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 608, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 608, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 517, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 517, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 564, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 564, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 504, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 504, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 450, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 450, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 149, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 149, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 780, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 780, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 823, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 823, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 854, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 854, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 743, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 743, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 751, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 751, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 882, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 882, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 793, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 793, 2])
[INFO: train.py:  338]:   [val] ade: 0.679
[INFO: train.py:  338]:   [val] ade_l: 1.494
[INFO: train.py:  338]:   [val] ade_nl: 1.243
[INFO: train.py:  338]:   [val] d_loss: 1.403
[INFO: train.py:  338]:   [val] fde: 1.462
[INFO: train.py:  338]:   [val] fde_l: 3.218
[INFO: train.py:  338]:   [val] fde_nl: 2.678
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.553
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.553
[INFO: train.py:  338]:   [val] resist_count: 2721.000
[INFO: train.py:  338]:   [val] resist_loss: 0.236
[INFO: train.py:  341]:   [train] ade: 0.672
[INFO: train.py:  341]:   [train] ade_l: 1.425
[INFO: train.py:  341]:   [train] ade_nl: 1.270
[INFO: train.py:  341]:   [train] d_loss: 1.399
[INFO: train.py:  341]:   [train] fde: 1.376
[INFO: train.py:  341]:   [train] fde_l: 2.921
[INFO: train.py:  341]:   [train] fde_nl: 2.603
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.480
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.480
[INFO: train.py:  341]:   [train] resist_count: 2673.000
[INFO: train.py:  341]:   [train] resist_loss: 0.141
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 1.0350], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3430562019348145
[INFO: train.py:  316]: Interation 10500 took 7.836061239242554
[INFO: train.py:  558]: resist loss: tensor([ 0.], device='cuda:0')
[INFO: train.py:  310]: g step took 0.08965444564819336
[INFO: train.py:  316]: Interation 10501 took 0.09349417686462402
[INFO: train.py:  279]: Starting epoch 246
[INFO: train.py:  280]: Epoch resist loss: tensor([ 162.5882])
[INFO: train.py:  558]: resist loss: tensor([ 0.3337], device='cuda:0')
[INFO: train.py:  310]: g step took 1.3235385417938232
[INFO: train.py:  316]: Interation 10502 took 1.746868371963501
[INFO: train.py:  558]: resist loss: tensor([ 3.9962], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4867403507232666
[INFO: train.py:  316]: Interation 10503 took 1.4872453212738037
[INFO: train.py:  558]: resist loss: tensor([ 3.1468], device='cuda:0')
[INFO: train.py:  310]: g step took 1.1788127422332764
[INFO: train.py:  316]: Interation 10504 took 1.1831462383270264
[INFO: train.py:  558]: resist loss: tensor([ 4.3460], device='cuda:0')
[INFO: train.py:  310]: g step took 1.364882469177246
[INFO: train.py:  316]: Interation 10505 took 1.372649908065796
[INFO: train.py:  558]: resist loss: tensor([ 10.7226], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5225584506988525
[INFO: train.py:  316]: Interation 10506 took 1.5336101055145264
[INFO: train.py:  558]: resist loss: tensor([ 10.6970], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4150002002716064
[INFO: train.py:  316]: Interation 10507 took 1.415412187576294
[INFO: train.py:  558]: resist loss: tensor([ 3.1790], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2647364139556885
[INFO: train.py:  316]: Interation 10508 took 1.2651076316833496
[INFO: train.py:  558]: resist loss: tensor([ 2.6172], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2793128490447998
[INFO: train.py:  316]: Interation 10509 took 1.2797021865844727
[INFO: train.py:  327]: Checking stats on val ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 567, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 567, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 646, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 646, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 579, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 579, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 677, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 677, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 480, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 480, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 575, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 575, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 493, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 493, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 591, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 591, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 519, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 519, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 559, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 559, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 497, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 497, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 178, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 178, 2])
[INFO: train.py:  331]: Checking stats on train ...
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 839, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 839, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 695, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 695, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 771, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 771, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 550, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 550, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 805, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 805, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 733, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 733, 2])
[INFO: train.py:  600]: attention_generator 6008
[INFO: train.py:  601]: pred_traj_fake_rel 601 torch.Size([8, 798, 2])
[INFO: train.py:  602]: pred_traj_gt 602 torch.Size([8, 798, 2])
[INFO: train.py:  338]:   [val] ade: 0.674
[INFO: train.py:  338]:   [val] ade_l: 1.484
[INFO: train.py:  338]:   [val] ade_nl: 1.235
[INFO: train.py:  338]:   [val] d_loss: 1.400
[INFO: train.py:  338]:   [val] fde: 1.427
[INFO: train.py:  338]:   [val] fde_l: 3.141
[INFO: train.py:  338]:   [val] fde_nl: 2.614
[INFO: train.py:  338]:   [val] g_l2_loss_abs: 0.548
[INFO: train.py:  338]:   [val] g_l2_loss_rel: 0.548
[INFO: train.py:  338]:   [val] resist_count: 2364.000
[INFO: train.py:  338]:   [val] resist_loss: 0.209
[INFO: train.py:  341]:   [train] ade: 0.675
[INFO: train.py:  341]:   [train] ade_l: 1.392
[INFO: train.py:  341]:   [train] ade_nl: 1.312
[INFO: train.py:  341]:   [train] d_loss: 1.402
[INFO: train.py:  341]:   [train] fde: 1.368
[INFO: train.py:  341]:   [train] fde_l: 2.820
[INFO: train.py:  341]:   [train] fde_nl: 2.657
[INFO: train.py:  341]:   [train] g_l2_loss_abs: 0.507
[INFO: train.py:  341]:   [train] g_l2_loss_rel: 0.507
[INFO: train.py:  341]:   [train] resist_count: 2026.000
[INFO: train.py:  341]:   [train] resist_loss: 0.112
[INFO: train.py:  368]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_with_model.pt
[INFO: train.py:  370]: Done.
[INFO: train.py:  376]: Saving checkpoint to ./models/benchmark_zara1_batch32_epoch500_spool_no_model.pt
[INFO: train.py:  387]: Done.
[INFO: train.py:  558]: resist loss: tensor([ 0.7566], device='cuda:0')
[INFO: train.py:  310]: g step took 1.5201385021209717
[INFO: train.py:  316]: Interation 10510 took 7.78100848197937
[INFO: train.py:  558]: resist loss: tensor([ 3.5890], device='cuda:0')
[INFO: train.py:  310]: g step took 1.2929604053497314
[INFO: train.py:  316]: Interation 10511 took 1.2974772453308105
[INFO: train.py:  558]: resist loss: tensor([ 12.6961], device='cuda:0')
[INFO: train.py:  310]: g step took 1.6555404663085938
[INFO: train.py:  316]: Interation 10512 took 1.6595251560211182
[INFO: train.py:  558]: resist loss: tensor([ 0.8437], device='cuda:0')
[INFO: train.py:  310]: g step took 1.4481799602508545
[INFO: train.py:  316]: Interation 10513 took 1.4629535675048828

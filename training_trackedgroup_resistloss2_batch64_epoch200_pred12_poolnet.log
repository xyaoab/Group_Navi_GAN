[INFO: train.py:  133]: Initializing train dataset
[INFO: train.py:  135]: Initializing val dataset
[INFO: train.py:  149]: There are 18.140625 iterations per epoch
[INFO: train.py:  152]: There are 9070 iterations
[INFO: train.py:  155]: There are 500 epochs
[INFO: train.py:  194]: Here is the late-attention generator:
[INFO: train.py:  195]: LateAttentionFullGenerator(
  (intention_encoder): Encoder(
    (encoder): LSTM(16, 32)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
  )
  (force_encoder): Encoder(
    (encoder): LSTM(16, 32)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
  )
  (intention_decoder): Decoder(
    (decoder): LSTM(16, 32)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
    (hidden2pos): Linear(in_features=32, out_features=2, bias=True)
  )
  (force_decoder): Decoder(
    (decoder): LSTM(16, 32)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
    (hidden2pos): Linear(in_features=32, out_features=2, bias=True)
  )
  (pool_net): PoolHiddenNet(
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
    (mlp_pre_pool): Sequential(
      (0): Linear(in_features=48, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=32, bias=True)
      (3): ReLU()
    )
  )
  (force_mlp_decoder_context): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=32, bias=True)
    (3): ReLU()
  )
  (intention_mlp_decoder_context): Sequential(
    (0): Linear(in_features=32, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=30, bias=True)
    (3): ReLU()
  )
  (attention_mlp): Linear(in_features=64, out_features=2, bias=True)
)
[INFO: train.py:  211]: Here is the discriminator:
[INFO: train.py:  212]: TrajectoryDiscriminator(
  (encoder): Encoder(
    (encoder): LSTM(16, 64)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
  )
  (real_classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=1, bias=True)
    (3): ReLU()
  )
)
[INFO: train.py:  234]: Restoring from checkpoint ./models/trackedgroup_resistloss2_zara1_batch64_epoch500_pred12_poolnet_with_model.pt
[INFO: train.py:  283]: Starting epoch 247
[INFO: train.py:  284]: Epoch resist loss: tensor([ 0.])
[INFO: train.py:  593]: resist loss: tensor([ 69.4124], device='cuda:0')
[INFO: train.py:  314]: g step took 1.5407803058624268
[INFO: train.py:  331]: Checking stats on val ...
[INFO: train.py:  335]: Checking stats on train ...
[INFO: train.py:  342]:   [val] ade: 0.801
[INFO: train.py:  342]:   [val] ade_l: 3.237
[INFO: train.py:  342]:   [val] ade_nl: 1.065
[INFO: train.py:  342]:   [val] d_loss: 1.428
[INFO: train.py:  342]:   [val] fde: 1.927
[INFO: train.py:  342]:   [val] fde_l: 7.783
[INFO: train.py:  342]:   [val] fde_nl: 2.561
[INFO: train.py:  342]:   [val] g_l2_loss_abs: 0.860
[INFO: train.py:  342]:   [val] g_l2_loss_rel: 0.860
[INFO: train.py:  342]:   [val] resist_count: 6324.000
[INFO: train.py:  342]:   [val] resist_loss: 0.156
[INFO: train.py:  345]:   [train] ade: 0.825
[INFO: train.py:  345]:   [train] ade_l: 3.855
[INFO: train.py:  345]:   [train] ade_nl: 1.050
[INFO: train.py:  345]:   [train] d_loss: 1.436
[INFO: train.py:  345]:   [train] fde: 2.024
[INFO: train.py:  345]:   [train] fde_l: 9.455
[INFO: train.py:  345]:   [train] fde_nl: 2.576
[INFO: train.py:  345]:   [train] g_l2_loss_abs: 0.793
[INFO: train.py:  345]:   [train] g_l2_loss_rel: 0.793
[INFO: train.py:  345]:   [train] resist_count: 10834.000
[INFO: train.py:  345]:   [train] resist_loss: 0.209
[INFO: train.py:  372]: Saving checkpoint to ./models/trackedgroup_resistloss2_zara1_batch64_epoch500_pred12_poolnet_with_model.pt
[INFO: train.py:  374]: Done.
[INFO: train.py:  380]: Saving checkpoint to ./models/trackedgroup_resistloss2_zara1_batch64_epoch500_pred12_poolnet_no_model.pt
[INFO: train.py:  391]: Done.
[INFO: train.py:  593]: resist loss: tensor([ 54.8306], device='cuda:0')
[INFO: train.py:  314]: g step took 1.933342695236206
[INFO: train.py:  320]: Interation 9060 took 10.384758710861206
[INFO: train.py:  593]: resist loss: tensor([ 91.1188], device='cuda:0')
[INFO: train.py:  314]: g step took 1.768341064453125
[INFO: train.py:  320]: Interation 9061 took 1.7850382328033447
[INFO: train.py:  593]: resist loss: tensor([ 86.9981], device='cuda:0')
[INFO: train.py:  314]: g step took 1.6280403137207031
[INFO: train.py:  320]: Interation 9062 took 1.6286487579345703
[INFO: train.py:  593]: resist loss: tensor([ 70.5599], device='cuda:0')
[INFO: train.py:  314]: g step took 1.4243228435516357
[INFO: train.py:  320]: Interation 9063 took 1.4249742031097412
[INFO: train.py:  593]: resist loss: tensor([ 61.6347], device='cuda:0')
[INFO: train.py:  314]: g step took 1.3688769340515137
[INFO: train.py:  320]: Interation 9064 took 1.3694071769714355
[INFO: train.py:  593]: resist loss: tensor([ 70.8642], device='cuda:0')
[INFO: train.py:  314]: g step took 1.4798383712768555
[INFO: train.py:  320]: Interation 9065 took 1.4803845882415771
[INFO: train.py:  593]: resist loss: tensor([ 27.5164], device='cuda:0')
[INFO: train.py:  314]: g step took 1.114988088607788
[INFO: train.py:  320]: Interation 9066 took 1.1155064105987549
[INFO: train.py:  593]: resist loss: tensor([ 84.7586], device='cuda:0')
[INFO: train.py:  314]: g step took 1.6143698692321777
[INFO: train.py:  320]: Interation 9067 took 1.6305179595947266
[INFO: train.py:  593]: resist loss: tensor([ 39.6868], device='cuda:0')
[INFO: train.py:  314]: g step took 1.2092499732971191
[INFO: train.py:  320]: Interation 9068 took 1.2099027633666992

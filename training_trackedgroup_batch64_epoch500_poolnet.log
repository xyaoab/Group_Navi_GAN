[INFO: train.py:  133]: Initializing train dataset
[INFO: train.py:  135]: Initializing val dataset
[INFO: train.py:  149]: There are 21.03125 iterations per epoch
[INFO: train.py:  152]: There are 10515 iterations
[INFO: train.py:  155]: There are 500 epochs
[INFO: train.py:  194]: Here is the late-attention generator:
[INFO: train.py:  195]: LateAttentionFullGenerator(
  (intention_encoder): Encoder(
    (encoder): LSTM(16, 32)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
  )
  (force_encoder): Encoder(
    (encoder): LSTM(16, 32)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
  )
  (intention_decoder): Decoder(
    (decoder): LSTM(16, 32)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
    (hidden2pos): Linear(in_features=32, out_features=2, bias=True)
  )
  (force_decoder): Decoder(
    (decoder): LSTM(16, 32)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
    (hidden2pos): Linear(in_features=32, out_features=2, bias=True)
  )
  (pool_net): PoolHiddenNet(
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
    (mlp_pre_pool): Sequential(
      (0): Linear(in_features=48, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=32, bias=True)
      (3): ReLU()
    )
  )
  (force_mlp_decoder_context): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=32, bias=True)
    (3): ReLU()
  )
  (intention_mlp_decoder_context): Sequential(
    (0): Linear(in_features=32, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=30, bias=True)
    (3): ReLU()
  )
  (attention_mlp): Linear(in_features=64, out_features=2, bias=True)
)
[INFO: train.py:  211]: Here is the discriminator:
[INFO: train.py:  212]: TrajectoryDiscriminator(
  (encoder): Encoder(
    (encoder): LSTM(16, 64)
    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)
  )
  (real_classifier): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=1, bias=True)
    (3): ReLU()
  )
)
[INFO: train.py:  234]: Restoring from checkpoint ./models/trackedgroup_zara1_batch64_epoch500_poolnet_with_model.pt
[INFO: train.py:  283]: Starting epoch 247
[INFO: train.py:  284]: Epoch resist loss: tensor([ 0.])
[INFO: train.py:  593]: resist loss: tensor([ 24.5582], device='cuda:0')
[INFO: train.py:  314]: g step took 1.913851022720337
[INFO: train.py:  331]: Checking stats on val ...
[INFO: train.py:  335]: Checking stats on train ...
[INFO: train.py:  342]:   [val] ade: 0.442
[INFO: train.py:  342]:   [val] ade_l: 0.973
[INFO: train.py:  342]:   [val] ade_nl: 0.810
[INFO: train.py:  342]:   [val] d_loss: 1.392
[INFO: train.py:  342]:   [val] fde: 0.944
[INFO: train.py:  342]:   [val] fde_l: 2.079
[INFO: train.py:  342]:   [val] fde_nl: 1.730
[INFO: train.py:  342]:   [val] g_l2_loss_abs: 0.266
[INFO: train.py:  342]:   [val] g_l2_loss_rel: 0.266
[INFO: train.py:  342]:   [val] resist_count: 4934.000
[INFO: train.py:  342]:   [val] resist_loss: 0.249
[INFO: train.py:  345]:   [train] ade: 0.412
[INFO: train.py:  345]:   [train] ade_l: 0.853
[INFO: train.py:  345]:   [train] ade_nl: 0.799
[INFO: train.py:  345]:   [train] d_loss: 1.389
[INFO: train.py:  345]:   [train] fde: 0.847
[INFO: train.py:  345]:   [train] fde_l: 1.751
[INFO: train.py:  345]:   [train] fde_nl: 1.640
[INFO: train.py:  345]:   [train] g_l2_loss_abs: 0.196
[INFO: train.py:  345]:   [train] g_l2_loss_rel: 0.196
[INFO: train.py:  345]:   [train] resist_count: 6516.000
[INFO: train.py:  345]:   [train] resist_loss: 0.288
[INFO: train.py:  372]: Saving checkpoint to ./models/trackedgroup_zara1_batch64_epoch500_poolnet_with_model.pt
[INFO: train.py:  374]: Done.
[INFO: train.py:  380]: Saving checkpoint to ./models/trackedgroup_zara1_batch64_epoch500_poolnet_no_model.pt
[INFO: train.py:  391]: Done.
[INFO: train.py:  593]: resist loss: tensor([ 33.4396], device='cuda:0')
[INFO: train.py:  314]: g step took 2.267113208770752
[INFO: train.py:  320]: Interation 10510 took 12.668767929077148
[INFO: train.py:  593]: resist loss: tensor([ 29.7515], device='cuda:0')
[INFO: train.py:  314]: g step took 1.9660866260528564
[INFO: train.py:  320]: Interation 10511 took 1.9665312767028809
[INFO: train.py:  593]: resist loss: tensor([ 25.2596], device='cuda:0')
[INFO: train.py:  314]: g step took 1.798992395401001
[INFO: train.py:  320]: Interation 10512 took 1.799431324005127
[INFO: train.py:  593]: resist loss: tensor([ 18.9473], device='cuda:0')
[INFO: train.py:  314]: g step took 1.3941614627838135
[INFO: train.py:  320]: Interation 10513 took 1.3949058055877686
